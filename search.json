[
  {
    "objectID": "posts/notes/linear_algebra/6-more_eigen_egs.html#normal-mode",
    "href": "posts/notes/linear_algebra/6-more_eigen_egs.html#normal-mode",
    "title": "More Eigen examples",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode\n\n2.1 Exampe 1\n\n\n\n2.2 Exampe 2\n\n\n\n2.3 Exampe 3"
  },
  {
    "objectID": "posts/notes/linear_algebra/4-diagonlisation.html#normal-mode",
    "href": "posts/notes/linear_algebra/4-diagonlisation.html#normal-mode",
    "title": "Diagonal Matrices are trivial",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/2-eigenvalues_eigenvectors.html",
    "href": "posts/notes/linear_algebra/2-eigenvalues_eigenvectors.html",
    "title": "Eigen is my valentines in 2024",
    "section": "",
    "text": "Note on Colours:\n- I’m colourblind (red-green). Read more here.\n- I’m using Nebo App on a Lenovo Tablet in Dark Mode. The app doesn’t actually export the way I see it, it exports in non-dark mode so it looks completely different to how I chose the colours. If the colours are an eyesore, I apologise 🤭 (It’s probably sub-optimal without the export issues already).\n- I used a website to reverse colours but it isn’t right either.\nI’ll figure it out… for now I’ve put up both unwanted versions because I havent posted in 4 days (awful).\n\n1. Dark-mode\n\n\n\n2. Normal-mode"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html",
    "href": "posts/notes/coding/3-bash.html",
    "title": "Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#basics",
    "href": "posts/notes/coding/3-bash.html#basics",
    "title": "Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#variables",
    "href": "posts/notes/coding/3-bash.html#variables",
    "title": "Bash Basics",
    "section": "2. Variables",
    "text": "2. Variables\nFIRST_NAME=tony: set a variable\necho FIRST_NAME: echo the variable’\n\\': escape the single quote with backtick\n\n2.1 Fixed Variables\n\nhellothere.sh # [Terminal]\n\n\n#!/bin/bash\nFIRST_NAME=Tony\nLAST_NAME=JustDevs\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere.sh # [Terminal]\n./hellothere.sh # [Terminal]\n\n\n\n2.2 Interactive Variables\n\nhellothere_interactive.sh # [Terminal]\n\n\n#/bin/bash\n\necho What is your first name?\nread FIRST_NAME\necho What is your last name?\nread LAST_NAME\n\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere_interactive.sh # [Terminal]\n./hellothere_interactive.sh # [Terminal]\n\n\n\n2.3 Positional Arguments\n\nvim hellothere_posarg.sh  # [Terminal]\n\n\n#!/bin/bash\n\necho Hello $1 $2\n\n\ncbmod u+x hellothere_posargs.sh     # [Terminal]\n./hellothere_posargs.sh Tony JustDevs # [Terminal]"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#output-redirection",
    "href": "posts/notes/coding/3-bash.html#output-redirection",
    "title": "Bash Basics",
    "section": "3. Output redirection",
    "text": "3. Output redirection\n\n3.1 Piping |\n\nThe output of the previous command ls -l /usr/bin is forwarded to the command after the |.\nAdd grep bash to filter for bash.\n\n\nls -l /usr/bin | grep bash # [Terminal]\n\n\n\n3.2 Override &gt;\nE.g. Logging something from a script to a log-file: 1. Catch output from echo command\n2. Override of a text file\n\necho Hello World! &gt; output_override_to_text.txt\ncat output_override_to_text.txt\n\n\n\n3.3 Append &gt;&gt;\nAppend from script to a log-file: 1. Catch output from echo command\n2. Append output into a text file\n\necho Hello World! &gt; output_append_to_text.txt\ncat output_override_to_text.txt\necho Good day matey! &gt; output_append_to_text.txt\ncat output_override_to_text.txt"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#input-direction",
    "href": "posts/notes/coding/3-bash.html#input-direction",
    "title": "Bash Basics",
    "section": "4. Input direction",
    "text": "4. Input direction\n\n&lt;: from a file\n&lt;&lt;: from multiple lines of text\n&lt;&lt;&lt;: from single string of text\n\n\n4.1 &lt; from a line\nUse word-count wc command to for number of words in text 1. Command to receive Input 2. Input direction of text\n\nwc -w &lt; output_append_to_text.txt # input direction\ncat output_append_to_text.txt | wc -w # output direction\n\n\n\n4.2 &lt;&lt; from multiple lines\nSupply multiple lines of words 1. Command to receive Input 2. Input direction to Command 3. KeywordStart 4. Actual text 5. KeywordEnd\n\ncat &lt;&lt; EOF\nthis is some text\nwith multiple\nlines\nEOF\n\n\n\n4.3 &lt;&lt;&lt; from single line\n\nwc -w &lt;&lt;&lt; \"a sentence line with 6 words\""
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#test-operators",
    "href": "posts/notes/coding/3-bash.html#test-operators",
    "title": "Bash Basics",
    "section": "5. Test Operators",
    "text": "5. Test Operators\n\n5.1 Equality\nTests whether an express exists with 0(No issues) or 1 (Error) 1. Write expression 2. Print exit-code of last executed command\n\n[ hello = hello ]\necho $? # exits 0\n\n[ 1 = 0 ] \necho $? # exits 1\n\n[ 1 -eq 1 ] # equate numericals\necho $?\n\n\n\n5.2 If / Elif / Else\n${1,,} Parameter Expansion: Ignores lower and upper-cases when comparing to values\n\n#/bin/bash\n\nif [ ${1,,} = tonydevs ]; then\n        echo \"Oh, you're the boss here. Welcome!\"\nelif [ ${1,,} = help]; then\n        echo \"Just enter your username, duh!\"\nelse\n        echo \"I don't know who you are. But you're not the boss of me!\"\nfi\n~       \n\n\n\n5.3 Case statements\nBetter than if / elif /else: - Checking for multiple values - is easier to read\n\nvim case_stmts.sh #[Terminal]\n\n\n#!/bin/bash\n\ncase ${1,,} in\n        tony | administrator)\n                echo \"Gday, you're the boss here!\"\n                ;;\n        help)\n                echo \"Just enter your username!\"\n                ;;\n        *)\n                echo \"Hello there, you're not the boss of me. Enter a valid username!\"\nesac\n\n\nhttps://www.youtube.com/watch?v=tK9Oc6AEnR4"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#arrays",
    "href": "posts/notes/coding/3-bash.html#arrays",
    "title": "Bash Basics",
    "section": "6. Arrays",
    "text": "6. Arrays\nStore multiple variables in a list called Arrays\n\n6.1 Indexing\n\nMY_FIRST_LIST=(one two three four five)\necho $MY_FIRST_LIST # print only first element [TERMINAL]\necho ${MY_FIRST_LIST[@]} # prints everything\necho ${MY_FIRST_LIST[1]} # prints second element\n\n\n\n6.2 Indexing\nitem: each element in loop\n${MY_FIRST_LIST[@]}: all items in list\ndo echo -n: do echo and ignore all new line characters\n$item: represents each single item in array\n|: output direction\nwc -c: count characters\ndone: finish loop\n\nfor item in ${MY_FIRST_LIST[@]}; do echo -n $item | wc -c; done"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#functions",
    "href": "posts/notes/coding/3-bash.html#functions",
    "title": "Bash Basics",
    "section": "7. Functions",
    "text": "7. Functions\n\n7.1 Function only\n\nCreate shell\nDefine function\nCatch output for up and since with their different flags\nPrint everything between the two EOFs keywords\nCall the variables generated\nClose function\n\n\nvim first_function.sh # [Terminal]\n\n\n#!/bin/bash \nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\n\n\n\n7.2 Not Declaring Local Variables (Wrong!)\nIf variables inside a function are not declared local, they may override variables of the same name in the global variables in the global environment/\n\n#!/bin/bash \nup=\"global up\" # add global variable 1\nsince=\"global since\" # add global variable 2 \necho $up\necho $since\n\nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.3 Declaring Local Variables in a Function\nDefine variables inside functions as local variables so they’re only available to the functions and not to the entire script.\n\n#!/bin/bash \nup=\"global up\" \nsince=\"global since\" \necho $up\necho $since\n\nshowuptime(){\n    local up=$(uptime -p | cut -c4-) # add local prefix to declare local variable 1\n    local since=$(uptime -s) # add local prefix to declare local variable 2\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.4 Position Arguments\nJust like shell scripts, shell functions can also have positional arguments\n\n#!/bin/bash\n\nshowname(){\n    echo hello $1 $2\n}\nshowname Tony JustDevs"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#exit-codes",
    "href": "posts/notes/coding/3-bash.html#exit-codes",
    "title": "Bash Basics",
    "section": "8. Exit Codes",
    "text": "8. Exit Codes\n\n#!/bin/bash\nshowname(){\n    echo hello $1\n    if [ ${1,,} = tony ]; then\n        return 0\n    else\n        return 1\n    fi\n}\nshowname() $1\nif [ $? = 1 ]; then\n    echo = \"A strange has called the function!\"\nfi"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#awk",
    "href": "posts/notes/coding/3-bash.html#awk",
    "title": "Bash Basics",
    "section": "9. awk",
    "text": "9. awk\nFilter contents to and fro: 1. files or 2. output of a command\n\n9.1 Filter a Text File\n\necho one two three &gt; onetwothree.txt #[Terminal]\nawk '{print $1}' onetwothree.txt\n\n\n\n9.2 Filter a CSV File\n\nvim csv_test.csv \none,two,three #[csv_test.csv]\nawk -F, '{print $1 $2}'\n\n\n\n\n\n9.3 Piping into awk\n\necho \"Just get this world: Hello\" | awk '{print $5}'\necho \"Just get this world: Hello\" | awk -F: '{print $2}' | cut -c2"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#sed",
    "href": "posts/notes/coding/3-bash.html#sed",
    "title": "Bash Basics",
    "section": "10. sed",
    "text": "10. sed\nReplace values in text files with Regular Expressions\nExample: sed 's/word1/word2/g' sedtest.txt\nsed: replace values command\ns: means subtsitute\ng: globally, across the whole text file -i.ORIGINAL: keeps original file appends .ORIGINALto file name\n\n# [terminal]\nvim sed_test.txt\n\n# [sed_test.txt]\nThe fly flies like no fly flies. \nA fly is an insect that has wings and a fly likes to eat leftovers  \n\n# Just prints into terminal \nsed 's/fly/grasshopper/g' sedtest.txt \n\n# replace og file with command + creates new file .txt.ORIGINAL of og content\nsed -i.ORIGINAL 's/fly/grasshopper/g' sedtest.txt"
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#the-setup",
    "href": "posts/notes/coding/1-github_resolve.html#the-setup",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "1. The Setup",
    "text": "1. The Setup\nTesting the automation of closing a GitHub Issue via a VSCode Commit Message shown in youtube tutorial: How to Use GitHub for Automated Kanban Project Management\n\nHigh level steps:\n\nCreate Issue\n\nAttach associated Repo\n\nAttach associated Project\n\nAttach any relevant Tags\n\nDo required changes to your repo files\n\nCommit with “resolve #” associated to Issue\n\n[Important]: to include “resolve #58” in Commit Message in order to tell Github to automatically resolve it."
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#issue-is-open",
    "href": "posts/notes/coding/1-github_resolve.html#issue-is-open",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "2. Issue is Open",
    "text": "2. Issue is Open"
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#issue-is-closed-successfully",
    "href": "posts/notes/coding/1-github_resolve.html#issue-is-closed-successfully",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "3. Issue is Closed successfully",
    "text": "3. Issue is Closed successfully\nActions: Commmited, Staged and Pushed.\n[SUCCESS]: Issue #58 has indeed been automatically closed without a manual intervention on the kanban board!"
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "href": "posts/notes/coding/1-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "4. A Tick ☑️ as a little reward for work done",
    "text": "4. A Tick ☑️ as a little reward for work done"
  },
  {
    "objectID": "posts/leetcode/3-binary_search/LC704.html",
    "href": "posts/leetcode/3-binary_search/LC704.html",
    "title": "LC: 704. Binary Search",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/3-binary_search/LC704.html#problem-description",
    "href": "posts/leetcode/3-binary_search/LC704.html#problem-description",
    "title": "LC: 704. Binary Search",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nGiven an array of integers nums which is sorted in: - ascending order, and an - integer target, - write a function to search target in nums. - If target exists, then - return its index. Otherwise, - return -1\nYou must write an algorithm with O(log n) runtime complexity.\n\n1.1 Example 1:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 9\nOutput: 4\nExplanation: 9 exists in nums and its index is 4\n\n\n1.2 Example 2:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 2\nOutput: -1\nExplanation: 2 does not exist in nums so return -1"
  },
  {
    "objectID": "posts/leetcode/3-binary_search/LC704.html#code",
    "href": "posts/leetcode/3-binary_search/LC704.html#code",
    "title": "LC: 704. Binary Search",
    "section": "3. Code",
    "text": "3. Code\nTest the cases that its larger, smaller and on the split.\n\n3.1 larger than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],  1, {2}, 3, *4*, [5]]\n           # [[-1], 0, {3}, 5, *9*, [12]] \n            if nums[m]&lt;target: #if 3&lt;9:\n                l = m + 1\n           # [[3], *4*, [5]]\n           # [[5], *9*, [12]] \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1\n    \narr = [-1,0,3,5,9,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n4\n\n\n\n\n3.2 less than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{-1}, 9, {10}, 11, 12, [12]] \n            \n            if nums[m]&lt;target:\n                l = m + 1\n\n           # [[0],*1*,{2},3,*4*,[5]]\n           # [{-1}, *9*, {10}, 11, 12, [12]] \n                \n            elif nums[m]&gt;target:\n                \n           # [[0],*1*,[2],3,*4*,[5]]\n           # [{-1}, *9*, [10], 11, 12, [12]]                \n                r = m\n            else:\n                return m\n        return -1\n\narr = [-1,9,10,11,12,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n1\n\n\n\n\n3.3 On a split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{7}, 8, {*9*}, 11, 12, [13]] \n            \n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:          \n                r = m\n            else:\n                return m\n        return -1\n    \n\narr = [7,7,9,11,12,13]\nsoln = Solution()\nsoln.search(arr, 9)\n\n2\n\n\n\n\n4.4 Clean version\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1"
  },
  {
    "objectID": "posts/leetcode/3-binary_search/LC704.html#submit",
    "href": "posts/leetcode/3-binary_search/LC704.html#submit",
    "title": "LC: 704. Binary Search",
    "section": "6. Submit",
    "text": "6. Submit\nMiddle of the pack \nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html",
    "href": "posts/leetcode/1-min_stack/LC155.html",
    "title": "LC: 155. Min Stack",
    "section": "",
    "text": "link to the submission, you can see the question but a login is required to see my results\nlink to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#problem-description",
    "href": "posts/leetcode/1-min_stack/LC155.html#problem-description",
    "title": "LC: 155. Min Stack",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time.\nImplement the MinStack class:\n1. MinStack() initializes the stack object.\n2. void push(int val) pushes the element val onto the stack.\n3. void pop() removes the element on the top of the stack.\n4. int top() gets the top element of the stack.\n5. int getMin() retrieves the minimum element in the stack.\n\n1.1 LeetCode example\nInput:\n[\"MinStack\",\"push\",\"push\",\"push\",\"getMin\",\"pop\",\"top\",\"getMin\"]\n[[],[-2],[0],[-3],[],[],[],[]]\nOutput:\n[null,null,null,null,-3,null,0,-2]"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#analysis",
    "href": "posts/leetcode/1-min_stack/LC155.html#analysis",
    "title": "LC: 155. Min Stack",
    "section": "2. Analysis",
    "text": "2. Analysis\nI’ve decomposed the Inputs (code + variables) and expected outputs (stack and return values) for each line of code run.\n[Future Iteration 1]: Learn how to assert or include code that checks inputs what they are expected in an automatic way (The Output_Mine should be filled later hopefully automatically. For now, I eyeball the results and have LeetCode accept whether its passing or failing)\n[Future Iteration 2]: I’m using Python Lists, I could do the same attempt with chr and string types as parentheses are simply characters.\n\n2.1 Summary Table\n\n\n\nPython_Executed\nStack_Expected\nOutput_Expected\nOutput_Mine\n\n\n\n\nMinStack minStack = new MinStack();\n[]\nnull\nasdf\n\n\nminStack.push(-2);\n[-2]\nnull\nasdf\n\n\nminStack.push(0)\n[0,-2]\nnull\nasdf\n\n\nminStack.push(-3);\n[-3,0,-2]\nnull\nasdf\n\n\nminStack.getMin()\n[-3,0,-2]\n-3\nasdf\n\n\nminStack.pop()\n[0,-2]\nnull\nasdf\n\n\nminStack.top()\n[0,-2]\n0\nasdf\n\n\nminStack.getMin()\n[0,-2]\n-2\nasdf"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#code",
    "href": "posts/leetcode/1-min_stack/LC155.html#code",
    "title": "LC: 155. Min Stack",
    "section": "3. Code",
    "text": "3. Code\nWrite the MinStack() class and its requried methods.\n\nclass MinStack():\n    def __init__(self):\n        self.stack = [] # create empty list\n\n    def push(self, val: int) -&gt; None:\n        self.stack.append(val) # add value to end of list\n\n    def pop(self) -&gt; None:\n        self.stack.pop() # remove last val of the list\n\n    def top(self) -&gt; int:\n        return self.stack[-1] # in a list, top of stack is the last item list[-1]\n    \n    def getMin(self) -&gt; int:\n        return min(self.stack)"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#test-functionality",
    "href": "posts/leetcode/1-min_stack/LC155.html#test-functionality",
    "title": "LC: 155. Min Stack",
    "section": "4. Test Functionality",
    "text": "4. Test Functionality\n\nminStack = MinStack()\n\n\nminStack.push(-2);\n\n\nminStack.push(0);\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.push(-3);\nminStack.stack\n\n[-2, 0, -3]\n\n\n\nminStack.getMin() # // return -3\n# minStack.stack\n\n-3\n\n\n\nminStack.pop();\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.top() # return 0\n\n0\n\n\n\nminStack.getMin() # return -2\n\n-2"
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#submit",
    "href": "posts/leetcode/1-min_stack/LC155.html#submit",
    "title": "LC: 155. Min Stack",
    "section": "5. Submit",
    "text": "5. Submit\nThe code is slow but great memory management.\nAt the my current level, I’m happy to simply solve the problems. I don’t usually solve Mediums that easily."
  },
  {
    "objectID": "posts/leetcode/1-min_stack/LC155.html#some-commentary",
    "href": "posts/leetcode/1-min_stack/LC155.html#some-commentary",
    "title": "LC: 155. Min Stack",
    "section": "6. Some Commentary",
    "text": "6. Some Commentary\nThe question is framed from a Java’s perspective hence there are types in front of each declaration:\n- void pop()\n- int top()\n- new MinStack()\nNote: I’ve never touched Java 🤭.\nJava is a Static-Typed whilst Python is a Dynamically-Type.\n\nJava requires variables and method return values be explicitly declared at compile-time.\nPython data types are determined at runtime.\n\nPython doesn’t require explicit type declarations for variables, function return types, or when creating objects.\n\n\nThat is, since I’m using Python, so I won’t need to declare my return types when creating a method of a class."
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#introduction",
    "href": "posts/kaggle/2-us-patents-offline/index.html#introduction",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "1. Introduction",
    "text": "1. Introduction\nFrom Part 1, the Kaggle Competition: U.S. Patent Phrase to Phrase Matching was a notebook competition, that is, a simple csv upload of predictions would not suffice.\nA notebook with code needs to be submitted in order to succesfully enter and be graded.\nThis notebook will have access the kaggles cloud folders to gather the raw data, process and model it. The only catch is the notebook has no access to the internet. This means pip install package will not work.\nThus, the pre-trained models and tokenizers need to be uploaded to the inputs folder, before being installed.\nWhy? Even though transformers library is available on Kaggle via import, each time a function like AutoTokenizer is called, this accesses the internet to reach the HuggingFace Model Hub and looks for the latest available models.\nIn order to upload files though, they need to be exported first, but in order for them to be exported, they need to be downloaded first!. Well that is what I figured out, there’s probably a vastly more seemless way but I didn’t go out of my way to find out a way to do it, this way just made the most sense. In the future, I’ll find out a better way.\nSo, the idea is:\n1. create new kaggle noteook with internet access\n2. install libraries\n3. run our models\n4. export our models\n5. download our libraries\n6. create new kaggle noteook with no internet access\n7. upload downloaded libraries and exported models\n8. install libraries via uploaded files\n9. import pre-trained models vias uploaded files\n10. conduct training\n11. make predictions 12. export to csv\n13. submit notebook"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#export-model-and-tokenizer",
    "href": "posts/kaggle/2-us-patents-offline/index.html#export-model-and-tokenizer",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "2. Export Model and Tokenizer",
    "text": "2. Export Model and Tokenizer\n\ndebv3_tokenizer.save_pretrained(\"./tokenizer\")\nmodel.save_pretrained(\"./model\")"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#download-libraries",
    "href": "posts/kaggle/2-us-patents-offline/index.html#download-libraries",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "3. Download Libraries",
    "text": "3. Download Libraries\nTwo libraries are required for this notebook to run datasets and transformers\n\n!pip download datasets\n!pip download transformers"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#upload-file-to-kaggle",
    "href": "posts/kaggle/2-us-patents-offline/index.html#upload-file-to-kaggle",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "4. Upload File to Kaggle",
    "text": "4. Upload File to Kaggle\n\n4.1 Gather files\nPlace all json files (tokenizer and model) and whl files (libraries) in the same folder.\n\n\n\n4.2 Kaggle Upload\n\nGo to [Datasets]\nThen [New Dataset]\nName a [Dataset Title]\nChoose all files from your local folder\nClick [Create]\n\n\n\n\n4.3 Load Succesful\nUpon completion, a greeting of success should appear.\n\n\n\n4.4 Add Data\n\nClick [Add Data]\nFilter for [Your Datasets]\nFind the uploaded Dataset"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#code",
    "href": "posts/kaggle/2-us-patents-offline/index.html#code",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "5. Code",
    "text": "5. Code\nIt’s almost the same code as the previous post so I’ve combined it altogether.\n\n!pip install --no-index --find-links=. transformers\n!pip install --no-index --find-links=. datasets\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments,Trainer\nfrom pathlib import Path\nfrom datasets import Dataset,DatasetDict\nimport pandas as pd\nimport numpy as np\nimport datasets\n\nmodel_nm = \"microsoft/deberta-v3-small\"\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching')\nmypath = Path('/kaggle/input/us-patents-libraries-model-tokenizer')\ntokenizer_uploaded  = AutoTokenizer.from_pretrained(mypath)\nmodel_uploaded = AutoModelForSequenceClassification.from_pretrained(mypath)\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\nds = Dataset.from_pandas(df)\ndef tok_func(x): return tokenizer_uploaded(x[\"input\"])\ntok_ds = ds.map(tok_func, batched=True)\ntok_ds = tok_ds.rename_columns({'score':'labels'})\ndds = tok_ds.train_test_split(0.25, seed=42)\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\nbs = 128\nepochs = 2\nlr = 8e-5\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\nmodel = AutoModelForSequenceClassification.from_pretrained(mypath, num_labels=1,ignore_mismatched_sizes=True)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokenizer_uploaded, compute_metrics=corr_d)\ntrainer.train()\npreds = trainer.predict(eval_ds).predictions.astype(float)\npreds = np.clip(preds, 0, 1)\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds.squeeze()\n})\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#results",
    "href": "posts/kaggle/2-us-patents-offline/index.html#results",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "6. Results",
    "text": "6. Results\nIt worked!"
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "title": "Let’s Make Some Noise",
    "section": "2.1 Statistical Properties",
    "text": "2.1 Statistical Properties\n\nGaussian noise is characterized by a normal distribution, which is well-studied and has known statistical properties.\nThis makes it easy to model and analyze mathematically."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "title": "Let’s Make Some Noise",
    "section": "2.2 Central Limit Theorem:",
    "text": "2.2 Central Limit Theorem:\n\nThe Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables, each with finite mean and variance, will be approximately normally distributed.\nThis property makes Gaussian noise a natural choice in many scenarios where the noise is a result of multiple independent factors."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "title": "Let’s Make Some Noise",
    "section": "2.3 Mathematical Simplicity:",
    "text": "2.3 Mathematical Simplicity:\n\nThe normal distribution has simple and well-defined mathematical properties, making it easy to work with in analytical and computational contexts."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "title": "Let’s Make Some Noise",
    "section": "2.4 Robustness in Estimation:",
    "text": "2.4 Robustness in Estimation:\n\nMany statistical estimation methods, including maximum likelihood estimation, assume that the underlying noise follows a Gaussian distribution.\nThis can lead to more robust parameter estimates when the actual noise is close to Gaussian."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "title": "Let’s Make Some Noise",
    "section": "2.5 Convenient in Machine Learning:",
    "text": "2.5 Convenient in Machine Learning:\n\nIn machine learning, adding Gaussian noise can act as a form of regularization, preventing overfitting by introducing a controlled amount of randomness during training. It is also commonly used in generative models, such as Gaussian Mixture Models (GMMs)."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#parameters",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#parameters",
    "title": "Let’s Make Some Noise",
    "section": "3.1 Parameters",
    "text": "3.1 Parameters\ny: - The input array to which noise will be added.\nscale: - The standard deviation of the added noise (a floating-point number). - A higher value for scale results in larger variations in the noise."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#function-body",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#function-body",
    "title": "Let’s Make Some Noise",
    "section": "3.2 Function Body:",
    "text": "3.2 Function Body:\nnp.random.normal(scale=scale, size=y.shape): - This line utilizes the normal function from NumPy’s random module.\nscale=scale: - The standard deviation of the generated noise distribution.\nsize=y.shape: - Ensures that the generated noise array has the same shape as the input array y. - Allows element-wise addition of noise to the original data."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#return-value",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#return-value",
    "title": "Let’s Make Some Noise",
    "section": "3.3 Return Value:",
    "text": "3.3 Return Value:\nreturned array: - contains random values drawn from a normal distribution with the specified standard deviation (scale). - Has the same shape as the input array y."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "title": "Let’s Make Some Noise",
    "section": "4.1 Regularization and Preventing Memorization:",
    "text": "4.1 Regularization and Preventing Memorization:\nAvoid and  Discouraging Overfitting:\n\nAdding random noise to the input data can act as a form of regularization, preventing the model from fitting the training data too closely.\nThis can improve the generalization of the model to new, unseen data.\nModels that are too complex may memorize the training data instead of learning the underlying patterns.\nAdding noise makes it more challenging for the model to memorize specific examples and encourages it to focus on general patterns."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "title": "Let’s Make Some Noise",
    "section": "4.2 Data Augmentation:",
    "text": "4.2 Data Augmentation:\nIncreased Variability:\n\nIntroducing noise during training can artificially increase the variability in the dataset.\nThis can be particularly useful when dealing with limited training data, helping the model generalize better to different variations of the input."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "title": "Let’s Make Some Noise",
    "section": "4.3 Robustness Testing:",
    "text": "4.3 Robustness Testing:\nModel Robustness:\n\nAdding noise during training can make the model more robust to variations and uncertainties in real-world data.\nThis is especially important when the model needs to perform well on data that may have different levels of noise or unexpected variations."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "title": "Let’s Make Some Noise",
    "section": "4.4 Stochasticity in Training:",
    "text": "4.4 Stochasticity in Training:\nEncouraging Exploration:\n\nDuring the training process, introducing randomness can encourage the model to explore different parts of the parameter space.\nThis can be especially beneficial in reinforcement learning or optimization problems, helping to avoid getting stuck in local minima."
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "1. Download Kaggle Data",
    "text": "1. Download Kaggle Data\nLog into Kaggle:\n1. Competitions\n2. Titanic\n3. Data\n4. Train.csv and Download"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "2. Clean Dataset",
    "text": "2. Clean Dataset\nEach single passenger is represented by a single row with demographics and information across the columns.\nFor this first attempt, I’ll keep the model simple and used 8 columns and discarded the rest.\n[Future Iteration]: Would using more columns increase my accuracy?\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger - Kaggle Data Description\nNote: There are originally 891 Passengers (rows) in the training dataset.\nThere were a few steps taken to clean the data:\n1. Keep Certain Columns Only:\n- Survived\n- Pclass - Sex - Age - SibSp - Parch - Fare - Embarked 2. Remove blanks from: - Sex (177 rows removed) - Embarked (2 rows removed) Columns: Remaining Passengers (712 = 891-177-2)\n\nCreate a New Sheet and Copy over the editted Dataset"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "3. Binary Categorical Variables",
    "text": "3. Binary Categorical Variables\nRecall a Function has inputs and parameters. The output is calculated by adding the all the inputs which are weighted (multiplied) by the parameters.\nIn neural network basics: - the inputs were a single variable x and the output was a single y (or f(x)).\n- the parameters (coefficients of x) could be optimised against a Loss Function (Mean Squared Error) to achieve a high accuracy (good predictability) for that function, called Gradient Descent - an arbitrary number of Rectified Linear Unit (ReLU) could be added together to form any function to fit a given set of data and parameter (weights) can be optimised to minimise the loss function as above with gradient descent.\nSimilarly, the inputs in the Titanic model will be the information describing the passengers, i.e. columns in our spreadsheet, are multiplied by the parameters (weights or coefficients) to represents its importance.\n\nQuestion: But how can a parameter (number) be multiplied to word (text) such as male or female from the Sex Column or Letter S or C or Q from the Embarked Column?\nAnswer: You Can’t.\n\nHowever, Categorical Variables (unordered) can be converted into Binary Categorical Variables:\n- IsMale will indicate a 1 for True (Male) and 0 for False (Female)\n- Embarked has 3 categories “S, C and Q: Having two columns (S and C) to represent the 3 categories will suffice. If both S and C columns have 0’s, this implies it is a Q, so we do not need the extra column to have all the information.\n- PClass (1, 2 and 3) also has 3 categories and is treated the same as above.\n- Age and Fare are continuous values and left them as is for now"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "4. Regression",
    "text": "4. Regression\nI created random variables (coefficients or weights for our parameters) with rand() and multiplied them to each parameter. I did this for several rows to and looked at the output.\nLooks like Age and Fare columns are dominating our function.\n\n\n4.1 Dealing with Continuous Variables Age and Fare\nIts probably fair (see what I did there) that a Passenger’s age (or fare) shouldn’t be the only two defining factors to determine their survivability as the above model suggests.\nThese values need to be normalised: - For Age, I divided each passengers age by the maximum age. - For Fare, I took the Logarithm of each passengers fare. Taking the Log of a variable where there are very small values and a few large ones distributes the values more evenly.\n\n\n\n4.2 Prediction and Loss and Average Loss\nPrediction: Multiply each parameter by the random coefficient created and sum it up to have our prediction.\n- I used the SumProduct() function. - I also created a manual linear version from scratch to see test my understanding was correct and sumproduct was working as expected. It was.\nLoss: It’s the survival (0 No, 1 Yes) minus the Prediction, then squared. - This is the squared error. If the errors are not squared, the errors end up cancelling each other off. Alternatively, the absolute errors could be taken done previously.\nAverage Loss: Self-explanatory.\n\nNote: Current Average Loss is 0.886 with random parameters.\n\n\n4.3 Gradient Descent (or Solver)\nSetting the Solver to Minimise our Average Loss, our parameters have been adjusted and Average Loss has come down to: 0.535!\nNot but but this isn’t a neural net yet, its just a regression."
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "5. Neural Network",
    "text": "5. Neural Network\nParams_2: Add another set of random coefficients.\nLinear_2: Calculate the linear model on this set of coefficients.\nReLU: ReLUs are calculated with an IF() statement, if it is below zero, then set to zero, otherwise keep the value.\nPrediction: Add the ReLUs.\nLoss Prediction minus Survived.\nAverage Loss: Run Solver, but this time allow the change of both sets of coefficients Params_1 and Params_2\nNote: Current Neural Network Average Loss is 0.527 with random parameters.\n\n[Future Iteration]: To be honest, I haven’t quite understood fully whats going on here. The concept of adding a second set of parameters and then having two Linear Models and adding together their reLUs will give a prediction that can be optimised, just dont get it yet. be fair, I just learnt Gradient Descent a day or two ago.\n\n5.1 Error In Optimisation - All ReLUs going to Zero\nHaving no constraints on whether coefficients can be negative or positive, the Solver found the most convenient result of making all parameters less than zero, hence making outputs a negative linear output, which makes all the ReLUs Zero, hence simply making the prediction that everyone died! A quick and dirty prediction thats not too bad but very scientific…\nNote: I’m currently using WPS Solver rather than Excel Solver (Don’t own paid version of Excel). Not sure if I did a mistake in my model or its a Solver thing.\n\n\n\n5.2 Setting Constraints (Coefficients &gt; 0)\nBy placing the constraint the Solver seems to finally do what is expected.\nThe Average Loss has come down from the Regresssion 0.535 to 0.235!\n\n\n\n5.3 Added Ones Columns\nBut this didn’t fix the Solver Issuer.\n\n\n\n5.4 Matrix Multiplication\nI made a Matrix Multiplication version and optimised with the same silly negative parameters solution"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "6. Mission Failed.",
    "text": "6. Mission Failed.\nHaving downloaded the spreadsheet from Jeremy and ran the Solver, the Zero ReLUs error persists. This is a WPS Sheets issue.\nI also tried getting Solver on Google Sheets with no Luck however my emails permissions didn’t allow the install. Will give it a go to fix it next time.\nFor now, today I’ll admit defeat. Onwards to tomorrow…\nI’ll upload this notebook anyway because I want to record my failures as well as my triumphs."
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html",
    "href": "posts/2024-02-02-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 2)",
    "section": "",
    "text": "Automation of finding the best parameters (lowest loss) based on Mean Average Error (MAE) using Gradient Descent for our Quadratic Function"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#import-libraries",
    "href": "posts/2024-02-02-neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 2)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd\nfrom functools import partial"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "href": "posts/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "title": "Neural Network Basics (Part 2)",
    "section": "2. Upload Data and Convert Data to Pytorch Tensors",
    "text": "2. Upload Data and Convert Data to Pytorch Tensors\n\ndf = pd.read_csv(\"upload_dataset.csv\")\nx_trch = torch.tensor(df.x) \ny_trch = torch.tensor(df.y)"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "href": "posts/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "title": "Neural Network Basics (Part 2)",
    "section": "3. Create Customisable Quadratic functions and Interactively Plot with MAE",
    "text": "3. Create Customisable Quadratic functions and Interactively Plot with MAE\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\ndef torch_mae(prediction, actual): return (torch.abs(prediction-actual).mean())\ndef torch_mse(prediction, actual): return ((prediction-actual)**2).mean()\n\n\n# def mae(prediction, actual): return np.mean(abs(prediction-actual))\n# def torch_mae(prediction, actual): return np.mean(torch.abs(prediction-actual))\n# def mae(prediction, actual): return (torch.abs(prediction-actual).mean())\n# def mae2(prediction, actual): return abs(prediction-actual).mean()\n# def mae_jh(prediction, actual): return (abs(prediction-actual)).mean()\n# def mse_jh(prediction, actual): return ((prediction-actual)**2).mean()\n# def mae(preds, acts): return (torch.abs(preds-acts)).mean()\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,2.1,0.1),b=(0,2.1,0.1),c=(0,2.1,0.1))\ndef interactive_plot(a,b,c):\n# 1.    plot scatter\n    plt.scatter(x_trch, y_trch)\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = x_trch\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n# 4.    calc mae\n    y_actual     = y_trch\n    y_predicted  = custom_quad_fn(a,b,c)(x_trch)\n    interact_mae = torch_mae(y_predicted,y_actual)\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae:.2f}\")"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "href": "posts/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "title": "Neural Network Basics (Part 2)",
    "section": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)",
    "text": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)\nThe key thing to understand if whether the loss function gets better or worse when you increase the parameters a little.\nThere are two ways we can try: 1. Manually adjust the parameter: Move each parameter each way and observe the impact to MAE.\n2. Calculate the Derivative of the parameter: A Derivative iS a function that tells you if you increase the input the: - direction in which output changes (increases or decreases) and the;\n- magnitude of the change to the output\n\n4.1 Create Mean-Absolute-Error (mae) Quadratic Function\nThis function will take in the parameters or coefficients of a quadratic function and output the MSE. - Input: coeffiicents of quadratic - Output: MAE (between the prediction of the quadratic with the coffecients of the quadratic and the actual predictsions)\n\ndef mae_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mae(y_predicted_trch,y_actual_trch)\n\ndef mse_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mse(y_predicted_trch,y_actual_trch)\n\nThe chart shows MAE(2,2,2) = 1.4501 loss Our mae_function also calculates 1.491 loss.\n\nmae_quad_fn(x_trch=x_trch,y_trch=y_trch,abc_params=[1.0,1.0,1.0])\n\ntensor(2.6103, dtype=torch.float64)\n\n\nA tensor is a pytorch type that works with: - lists (1D tensors) - tables (2D tensors) - layers of tables of numbers (3D tensors) and etc\n\n\n4.2 Telling PyTorch to calculate gradients\nBy calling method .requires_grad_(), our abc_rg tensor is not will calculate gradients whenever we use the tensor.\n\n# rank 1 tensor\nabc_rg = torch.tensor([1.0,1.0,1.0])\nabc_rg.requires_grad_()\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\nabc_rg\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\n4.2.1 Method .requires_grad_()\ngrad_fn=&lt;MeanBackward0&gt; shows the gradients are calculated to for each parameter (our inputs)\n\nloss = mae_quad_fn(x_trch, y_trch, abc_rg)\nloss\n\ntensor(2.6103, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n\n4.2.2 Method .backward()\nThis adds an attribute .grad to our abc_rg tensor.\n\nloss.backward()\n\n\n\n4.2.3 Attribute .grad\nThis attributes tells us if we increase the input slightly in the same position of this tensor, the loss will increase (if its positive) or decrease (if negative)\n\nabc_rg.grad\n\ntensor([-1.3529, -0.0316, -0.5000])\n\n\n\n\n4.2.4 Increase our abc parameters and recalculate loss\n\nwith torch.no_grad():\n    print(f\"loss before: {loss}\")\n    abc_rg -= abc_rg.grad * 0.01\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    print(f\"loss after: {loss}\")\n\nloss before: 2.61030324932801\nloss after: 2.5894896953092177\n\n\n\n\n4.2.5 Automate it\nCreate a loop that decreases the loss by iteratively increasing the parameters (since the gradients are negative, or vice versa)\n\nfor i in range(10):\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    loss.backward()\n    with torch.no_grad(): abc_rg -= abc_rg.grad * 0.01\n    print(f\"step {i}: {loss} - {abc_rg.grad}\") \n\nstep 0: 2.5894896953092177 - tensor([-2.7058, -0.0632, -1.0000])\nstep 1: 2.547862587271633 - tensor([-4.0587, -0.0947, -1.5000])\nstep 2: 2.4854217639359875 - tensor([-5.4116, -0.1263, -2.0000])\nstep 3: 2.4021673865815485 - tensor([-6.7645, -0.1579, -2.5000])\nstep 4: 2.2980994552083187 - tensor([-8.1175, -0.1895, -3.0000])\nstep 5: 2.173217969816296 - tensor([-9.4704, -0.2211, -3.5000])\nstep 6: 2.0300959430578267 - tensor([-10.6892,  -0.3684,  -3.9000])\nstep 7: 1.883669135864714 - tensor([-11.9080,  -0.5158,  -4.3000])\nstep 8: 1.740979068220988 - tensor([-12.9396,  -0.8000,  -4.6000])\nstep 9: 1.5914231086209807 - tensor([-13.9712,  -1.0842,  -4.9000])\n\n\n\n\n\n5 Parameters are getting closer\nThe parameters started as 1,1,1 and now are 1.9, 1.0, 1.3, the underlying function was modelled with 3, 2, 1 so its getting there!\n[Future Iteration] How to just fix a parameter and just move the others?\n\nabc_rg\n\ntensor([1.8739, 1.0365, 1.3170], requires_grad=True)"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "href": "posts/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nNext A universal function called the ReLU Function (rather than a quadratric function) is used for our modelling.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html",
    "href": "posts/2024-01-27-99_kaggle_api/index.html",
    "title": "How To Setup a Kaggle API",
    "section": "",
    "text": "I’m planning to learn and test myself with competitions on Kaggle.\nKaggle is a place with real-world problems where Data Scientists and alike can go against each other to solve problems with Machine Learning.\nFrom my understanding:\n- There is a validation set where your model is tested against and a public leader board to see how you’re going.\n- At the end of the competition, there is an unseen test set where everyones models is tested against and where the final rankings are determined.\n- This is quite reflective of real world where preparing a representative validation set is vital, thus will perform well on the test set.\n- A common mistake for newbs is over-fitting to the validation set. I’m ready to make that mistake 🤣.\nAs for the Kaggle API, you can download the kernel which is the necessary datasets and source files to do the competitions.\nAlternatively, I can use the notebooks on their website. I plan to try doing competitions both ways.\nThis is how I set up my Kaggle API"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#install-library",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#install-library",
    "title": "How To Setup a Kaggle API",
    "section": "1. Install Library",
    "text": "1. Install Library\npip install python"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "title": "How To Setup a Kaggle API",
    "section": "2. Create API token (.json file)",
    "text": "2. Create API token (.json file)\n\nGo to Kaggle\n\nGo to Settings\n\nCreate New Token"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "title": "How To Setup a Kaggle API",
    "section": "3. Save to your local .kaggle folder (Windows)",
    "text": "3. Save to your local .kaggle folder (Windows)\nLocation: C:\\Users\\&lt;Windows-username&gt;\\.kaggle\\kaggle.json\nKaggle Github Reference\n\n3.1 Pasted into the wrong folder?\nIf you did something wrong then ran kaggle in the terminal, you’ll an error (telling you where to put it):"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "title": "How To Setup a Kaggle API",
    "section": "4 Start Kaggling",
    "text": "4 Start Kaggling\n\nimport kaggle\n??kaggle\n\nType:        module\nString form: &lt;module 'kaggle' from 'c:\\\\Users\\\\tonyp\\\\miniconda3\\\\envs\\\\fastai\\\\Lib\\\\site-packages\\\\kaggle\\\\__init__.py'&gt;\nFile:        c:\\users\\tonyp\\miniconda3\\envs\\fastai\\lib\\site-packages\\kaggle\\__init__.py\nSource:     \n#!/usr/bin/python\n#\n# Copyright 2024 Kaggle Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# coding=utf-8\nfrom __future__ import absolute_import\nfrom kaggle.api.kaggle_api_extended import KaggleApi\nfrom kaggle.api_client import ApiClient\n\napi = KaggleApi(ApiClient())\napi.authenticate()"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html",
    "href": "posts/2024-01-25-98_huggingface/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "",
    "text": "This post shows how to host your working Local Gradio App on HuggingFace.\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "href": "posts/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "Part 3: Host on HuggingFace account",
    "text": "Part 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "href": "posts/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "1 Create HuggingFace Account and Create a ‘Space’",
    "text": "1 Create HuggingFace Account and Create a ‘Space’\n\nChoose your Space name\nChoose Apache-2.0 to avoid any copyright issues\nChoose Gradio\nChoose the Free option\nChoose Public (show you can show it to the world!)"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "href": "posts/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2 Clone the repo",
    "text": "2 Clone the repo\nThis will create allow us deploy the Gradio app to the HuggingFace repository:\ngit clone https://huggingface.co/spaces/tonyjustdevs/pets_breed_predictor"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#gather-your-files",
    "href": "posts/2024-01-25-98_huggingface/index.html#gather-your-files",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2. Gather your files",
    "text": "2. Gather your files\nRecall the various files we needed to run the app locally part 2.\nGather into the cloned huggingface folder:\n- Learner (.pkl)\n- Pet examples (pets.jpg)\n- Gradio app (app.py)\n\nA good way to check for me is seeing the pets_breed_predictor is the git folder and huggingface space."
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "href": "posts/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "3. Push to HuggingFace Repo",
    "text": "3. Push to HuggingFace Repo\nIf you’ve pushed succesfully your app (could take several minutes), then your app is live! Congrats!\nIf you’re like me and forgot to include the requirements.txt then you’ll be greeted with this error.\n\n\n3.1 Add the requirements.txt\nWe imported two libraries fastai and gradio so include them in the requirements.txt file. Commit and push."
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "href": "posts/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "4 Web App Complete and is Live",
    "text": "4 Web App Complete and is Live\nIf all goes well, the HuggingFace space is hosting the Gradio App!\nCheck out my web app here!"
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "",
    "text": "Today I’ll go through how to find and test different deep-learning architectures from Pytorch Image Models (timm) library made available here by Ross Wightman and use them in our models."
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "1. Using timm - PyTorch Image Models",
    "text": "1. Using timm - PyTorch Image Models\n\n1.1 Introduction\nWhat are timm’s models? They’re mathematical functions (i.e. application of matrix multiplication, non-linearities e.g. ReLu’s)\nReference: “Which image model are best” - Jeremy Howard\nReference: “timm” - Ross Wightman\nWe want to know 3 things:\n1. how fast are they? You’d want models in top left of chart.\n2. how much memory?\n3. how accurate are they? Lower error rate the better.\n[Future iteration I]: A formalised metholodgy to decide what is fast enough, appropriate memory-use, and what is accurate enough for our use-cases.\nThere is a useful high-level chart from Jeremy’s notebook charting accuracy (Y-axis) vs secs per sample (X-axis):\n\nI chose to use a model from the convnext family due to its balance of high accuracy and speed.\n[Future iteration II]: Some more formalised methodology on choosing the architecture. Jeremy does mention architecture should be the one last thing things to worry about and he usually builds from resnet and tests whether it is, accurate enough and fast enough, then iterate from there.\n\n\n1.2 Import timm library\n\nimport timm\n\n\n\n1.3 List available model architectures and choose one\n\ntimm.list_models('convnext*') # * wild card searches \n\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']"
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "2. Create your Learner with a timm model",
    "text": "2. Create your Learner with a timm model\n\n2.1 Get your data\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)/'images'\n\n\n\n2.2 Prepare your Functions\n\ndef is_cat(x): return x[0].isupper()\n\n\n\n2.3 Load your DataLoader\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\n\n\n2.4 Build your Learner\n\nlearn_conv = vision_learner(dls, 'convnext_tiny', metrics=error_rate).to_fp16()\nlearn_resn = vision_learner(dls, 'resnet18', metrics=error_rate).to_fp16()\n\n\n\n2.5 Fine-Tune: ResNet18 vs ConvNextTiny\nA 90% reduction in the error rate! (0.6766% to 0.0667%: 1-(0.000677/0.006766)). It’s noted that the resnet error rate was quite low and changing the model was probably not necessary."
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "1. Introduction",
    "text": "1. Introduction\nEmbedding a classic Convolutional Neural Network (CNN) Gradio ‘Cat versus Dog’ classifier Gradio App, hosted on HuggingFace Spaces, into my Quarto Blog. What a mouthful!"
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "2. Background",
    "text": "2. Background\nThis App will guess whether an image is a Cat or Dog with a level of confidence using a deep learning neural network based on 700 mbs of labelled photos of dogs and cats. I’ll post more information on the model itself in a different post.\nAll doggos🐕 & cats🐈 image examples has never been viewed by the Model and it makes a prediction in milliseconds! Images supplied by my good friends in Australia 🦘 and Vietnam 🍜. Thanks guys!\nThe App isn’t perfect:\n- It guesses Incorrectly with great 95% confidence a cat as a dog!\nI’m thrilled to be able to build the app, get it hosted and embed it all in one day for the first time! Alot of firsts today!"
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "3. Future stuff",
    "text": "3. Future stuff\n[1]: Multi-Image Uploader + Predictor.\n[2]: Explain how I built the Gradio App, got it hosted Hugging Face, and embedded here.\n[4]: Upgrade the rice vs noodle model an App and hosted.\n[4]: Learn some HTML/CSS to make things prettier."
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "4. Heres the App!",
    "text": "4. Heres the App!"
  },
  {
    "objectID": "posts/2024-01-16-99_welcome/index.html",
    "href": "posts/2024-01-16-99_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nDefault Quarto content:\n“Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.””"
  },
  {
    "objectID": "posts/2024-01-16-97_post_with_notebook/index.html",
    "href": "posts/2024-01-16-97_post_with_notebook/index.html",
    "title": "Post With Sample Jupyter Notebook",
    "section": "",
    "text": "Learning how quarto works with jupyter notebooks. This is a sample editted notebook from fastai.\n\nfrom fastai.vision.all import *\nchosen_sample_seed          = 42\nchosen_sample_n             = 5\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n# useful informative functions\ndef print_useful_info():\n    global path_dir_obj, list_all_img_path_obj\n    print()\n    print(f\"path_obj_home_dir: \\t{path_dir_obj}\")\n    print(f\"image_list_count: \\t{len(list_all_img_path_obj)}\")\n    return None\n\ndef print_sample_imgs():\n    global path_dir_obj, list_all_img_path_obj, chosen_sample_seed, chosen_sample_n\n    import random\n    set_seed(chosen_sample_seed)\n    print(f\"set_seed_number: \\t{chosen_sample_seed}\")\n    rng         = len(list_all_img_path_obj)-1  # Replace 10 with the desired upper limit (exclusive)\n    random_nos  = random.sample(range(rng), chosen_sample_n)\n    print()\n    print(\"sample_images:\")\n    for index, img_path in enumerate(list_all_img_path_obj[random_nos]):\n        print(f\" {random_nos[index]:&gt;7}: \\t\\t{img_path}\")\n    \n    \n    for image_path in list_all_img_path_obj[random_nos]:\n        img = PILImage.create(image_path)\n        show_image(img)\n    return None\n\n\n# 0. get paths of images\npath_dir_obj                = untar_data(URLs.MNIST_TINY)\nlist_all_img_path_obj       = get_image_files(path_dir_obj)\n\n\n# 1. create learner\ndata_loader = ImageDataLoaders.from_folder(path_dir_obj, \n                                    img_cls=PILImageBW,\n                                    set_seed=42)\nx1,y1 = data_loader.one_batch()\ntest_eq(x1.shape, [64, 1, 28, 28])\n\nprint_useful_info()\nprint_sample_imgs()\n# check valid data sets - can check if splits are as expected\nprint(len(data_loader.valid_ds.items)) # 699 as expected\nprint(len(data_loader.train_ds.items)) # 709 as expected\n\n# can show sample pics\ndata_loader.show_batch() #show examples?\n\n\npath_obj_home_dir:  C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\nimage_list_count:   1428\nset_seed_number:    42\n\nsample_images:\n    1309:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\valid\\7\\9036.png\n     228:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\8830.png\n      51:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\731.png\n     563:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\868.png\n     501:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\8186.png\n699\n709\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnbr_learner = vision_learner(data_loader, resnet34, metrics=error_rate)\n\n\nnbr_learner.fine_tune(4)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/11 00:00&lt;?]\n    \n    \n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.303663\n0.174878\n0.054363\n00:21\n\n\n1\n0.228222\n0.127563\n0.040057\n00:20\n\n\n2\n0.172806\n0.091346\n0.027182\n00:21\n\n\n3\n0.139439\n0.056558\n0.015737\n00:21\n\n\n\n\n\n\nfrom IPython.display import Image # import image viewer\n\n\n\nuploader = SimpleNamespace(data = ['3.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [0], representing [3]\")\n\n\n\n\n\n\n\n\n3\ntensor(0)\ntensor([9.9998e-01, 2.1658e-05])\ncorrectly guessed the [0], representing [3]\n\n\n\n\nuploader = SimpleNamespace(data = ['7.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [1], representing [7]\")\n\n\n\n\n\n\n\n\n\n7\ntensor(1)\ntensor([0.0050, 0.9950])\ncorrectly guessed the [1], representing [7]"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "notes",
    "section": "",
    "text": "Bash Basics\n\n\n\n\n\n\ncoding\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMore Eigen examples\n\n\n\n\n\n\nlinear algebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDiagonal Matrices are trivial\n\n\n\n\n\n\nlinear algebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s nice to be similar (matrices)\n\n\n\n\n\n\nlinear algebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a Data Science Machine\n\n\n\n\n\n\ncoding\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAutomate the closing of Issues in Github Projects\n\n\n\n\n\n\ncoding\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinear algebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigen is my valentines in 2024\n\n\n\n\n\n\nlinear algebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNotes: Change of Basis\n\n\n\n\n\n\nlinear algebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "kaggle.html",
    "href": "kaggle.html",
    "title": "kaggle",
    "section": "",
    "text": "A Basic NLP model - [Competition Version]\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "This is a blog will archive my journey into the more data-science/ml/ai space.\nA Poem of Oreo\nIn a bustling town of Ultimo, where city lights gleam,\nA tale unfolds of Oreo, a kitten’s sweet dream.\nTony brought him home with Lilo by his side,\nA tuxedo cat, in black and white pride.\nOreo, a Maine Coon with a fluffy coat,\nBlack all over, with white around his throat.\nWhite paws that dance, a playful delight,\nA mischievous gleam in his eyes, shining bright.\nLilo, a tiny British Shorthair so fair,\nA dainty companion with a gentle air.\nThey grew up together, a dynamic pair,\nFrom Ultimo to Pyrmont, a journey to share.\nThrough the streets of Townhall, they explored,\nAdventures aplenty, their spirits soared.\nYet, runaway moments were a frequent feat,\nFound and embraced, their connection so sweet.\nOreo, a rogue, with a penchant for bins,\nA greedy delight, where the treasure begins.\nFeasting on scraps, his appetite vast,\nBut his cuteness prevails, a spell he has cast.\nLilo, petite, with a modest cuisine,\nA nibble here, a delicate routine.\nShe watches Oreo with curious eyes,\nAs he plays around, chasing butterflies.\nIn the city’s heartbeat, their story unfolds,\nThrough alleys and parks, where the tale molds.\nOreo, the player, with antics so grand,\nLilo, the watcher, in the city so grand.\nNow, in the world of influencers and fame,\nOreo has found his claim to the game.\nAn influencer cat, with followers galore,\nFrom bins to glamour, a journey to adore.\nThrough Ultimo, Pyrmont, and Townhall’s embrace,\nOreo and Lilo found their special place.\nA tale of friendship, of mischief and grace,\nIn the city’s heartbeat, a memory to trace."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Let’s Make Some Noise\n\n\n\n\n\n\nbasics\n\n\n\nA function to add gaussian noise to existing data\n\n\n\n\n\nMar 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]\n\n\n\n\n\n\ndeep dive\n\n\nlaymens\n\n\n\nDeeper dive into Neural Network basics\n\n\n\n\n\nMar 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nBash Basics\n\n\n\n\n\n\ncoding\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMore Eigen examples\n\n\n\n\n\n\nlinear algebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDiagonal Matrices are trivial\n\n\n\n\n\n\nlinear algebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s nice to be similar (matrices)\n\n\n\n\n\n\nlinear algebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a Data Science Machine\n\n\n\n\n\n\ncoding\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAutomate the closing of Issues in Github Projects\n\n\n\n\n\n\ncoding\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinear algebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model - [Competition Version]\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigen is my valentines in 2024\n\n\n\n\n\n\nlinear algebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 74. Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 704. Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNotes: Change of Basis\n\n\n\n\n\n\nlinear algebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 150. Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 155. Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in a Spreadsheet (Attempt 1)\n\n\n\n\n\n\nspreadsheet\n\n\n\nA failed attempt to apply neural network concepts in a spreadsheet\n\n\n\n\n\nFeb 4, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 3)\n\n\n\n\n\n\nbasics\n\n\n\nCreating the ReLU Function \n\n\n\n\n\nFeb 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 2)\n\n\n\n\n\n\nbasics\n\n\n\nOptimising with Gradient Descent\n\n\n\n\n\nFeb 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 1)\n\n\n\n\n\n\nbasics\n\n\n\nManually fitting a Line (Quadratic Function) to a dataset\n\n\n\n\n\nJan 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Setup a Kaggle API\n\n\n\n\n\n\nkaggle\n\n\n\nContinuing my Data Science journey with Kaggle\n\n\n\n\n\nJan 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\n\n\n\n\n\n\napp\n\n\n\nHost a neural network app live on HuggingFace\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)\n\n\n\n\n\n\napp\n\n\n\nCreate a local neural network Gradio App\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)\n\n\n\n\n\n\nclassifier\n\n\n\nCreate a simple neural network model\n\n\n\n\n\nJan 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to choose a different Deep-Learning Model Architecture\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying My First Live App & it’s a Neural Network!\n\n\n\n\n\n\napp\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSaving a Fast AI Model\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classifier 1: Noodles vs Rice\n\n\n\n\n\n\nclassifier\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Git Clone\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Sample Jupyter Notebook\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost Without Code\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nquarto test\n\n\nhello world\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "leetcode.html",
    "href": "leetcode.html",
    "title": "leetcode",
    "section": "",
    "text": "LC: 74. Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 704. Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 150. Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 155. Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-01-16-96_post_with_git_clone/index.html",
    "href": "posts/2024-01-16-96_post_with_git_clone/index.html",
    "title": "Post With Git Clone",
    "section": "",
    "text": "Learning how git work and\nthis is a post initiated by cloning existing repo."
  },
  {
    "objectID": "posts/2024-01-16-98_post_without_code/index.html",
    "href": "posts/2024-01-16-98_post_without_code/index.html",
    "title": "Post Without Code",
    "section": "",
    "text": "Learning how to quarto blog.\nThis is a post with just this sentence."
  },
  {
    "objectID": "posts/2024-01-18-99_rice_vs_noodles/index.html",
    "href": "posts/2024-01-18-99_rice_vs_noodles/index.html",
    "title": "Image Classifier 1: Noodles vs Rice",
    "section": "",
    "text": "Today I’ll be attempting to build my first deep learning image classifier to distinguish between rice and noodles using knowledge gained from Jeremy Howards Fast AI course\nHigh-level steps:\n1. Search and Prepare Data\n2. Create DataLoader\n3. Create Learner\n4. Prediction\nI will detail any problems, issues, questions and resolutions during the process.\n\n!pip install -Uqq fastai\n\n\nfrom fastbook import * \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n1. Search and Prepare Data\n\n# 1.1 Get 'rice' photos\ndownload_url(search_images_ddg('rice',max_images=1)[0],'rice.jpg',show_progress=False)\nImage.open('rice.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\n\n# 1.2 Get 'noodles' photos\ndownload_url(search_images_ddg('noodles', max_images=1)[0],'noodles.jpg',show_progress=False)\nImage.open('noodles.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\nLets use 60 imagess of ‘rice’ and ‘noodles’ from DuckDuckGo.\nNote: I downloaded for 100 images of each and then taking 60 of them as some images fail so I’m leaving room for failed photos.\nQuestion: Why do we need verify and why do some photos fail?\n\n# 1.3 Prep images in folders\nsearches = ['rice', 'noodles']\npath = Path('rice_or_noodles')\n\nif not path.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=100)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:60])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n# 1.4 Remove Failed images\npath = Path('rice_or_noodles')\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\n\n2. Create DataLoader\n\n# 2.1 \ndls = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path) \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n# 2.2 We can see Paths were created for every image and split into our training and data sets\ndls.train_ds.items[:2]\ndls.valid_ds.items[:2]\n\n[Path('rice_or_noodles/rice/4280fe58-691a-4c0b-85a5-5c1c8400ecb7.jpg'),\n Path('rice_or_noodles/rice/f8a77d77-c007-4854-af8b-2af624a8da66.jpg')]\n\n\n[Question]: How does it know whether it is training set or valid set? I guess theres some indexing somewhere that I dont know how to obtain.\n\n# 2.1 Show a training batch which has an 'image' and a 'label'\ndls.show_batch(max_n=6) #batch shows input and label\n\n\n\n\n\n\n\n\n\n\n2. Create Learner using ResNet\nIn the course, we used a pre-trained model ‘ResNet18’ (RN).\nWhy Pre-trained Models?:\n- Pre-trained models is like getting an athlete who is very good basic sport related skills like hand-eye coordination, jumping, running/sprinting, changing directions etc and then - telling them to learn a specific sport (fine-tuning), - say tennis (labelled dataset provided). With a good base of skills, this person should be able to learn tennis to a good level…\nResNet18:\n- ResNet18 is trained on 1.28 million images with 1000 object categories. - 18 layers\n- Trained on ImageNet dataset\n[Future iterations 1]: Perhaps there are alternative pre-trained models specialising in food?\n[Future iterations 2]: - Read up and try understand the various architectures Fast AI’s TIMM model architectures - Try different architectures and different versions\n\nlearner_RN18 = vision_learner(dls, resnet18, metrics=error_rate)\n\n\n2.1 Learner Model Times:\nThey all took under 10 seconds to create the general learner. Now to fine-tune them!\n\nlearner_RN18.fine_tune(8)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.840357\n4.676042\n0.476190\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.763106\n3.761843\n0.476190\n00:04\n\n\n1\n1.517361\n2.798523\n0.476190\n00:04\n\n\n2\n1.202234\n2.308116\n0.428571\n00:04\n\n\n3\n0.953227\n1.637496\n0.428571\n00:04\n\n\n4\n0.770979\n1.034023\n0.380952\n00:04\n\n\n5\n0.662257\n0.641428\n0.190476\n00:04\n\n\n6\n0.563239\n0.405057\n0.142857\n00:04\n\n\n7\n0.490904\n0.285846\n0.095238\n00:04\n\n\n\n\n\n\nOur learner is performing at 90% accuracy (9% error rate) by looking at only 60 photos!\nLets try predict some random photos of rice and noodles I’ve found on the internet.\n\nfrom IPython.display import Image # import image viewer\n\n\n# noodle predictor\nuploader = SimpleNamespace(data = ['test_noodle.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nnoodles: 99.98%\n\n\n\n\nPrediction 1: Noodles\nThe model predicted noodles correctly with 99.98% confidence!\n\n# rice predictor 1\nuploader = SimpleNamespace(data = ['test_rice.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\n\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 66.22%\n\n\n\n\nPrediction and Results 2: Rice 1\nThe model predicted rice incorrectly with 66.22% confidence!\nI was a bit confused so I decided to provide another image of rice to make\n\n# rice predictor 2\nuploader = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path)) # show image\n\n# get\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 98.51%\n\n\n\n\nPrediction and Results 3: Rice 2\nThe model predicted rice incorrectly with 98.51% confidence!\nOkay now there is clearly something wrong going on. I decide to take a gander at the photos in my ‘rice’ folder.\n\nIt looks like we’ve trained a learner specialises in bowled or white rice. I was testing the model with fried rice since that is my favourite rice dish.\nLets test out a couple photos on bowled rice.\n\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice: 88.73%\nnoodles: 92.57%\n\n\n\n\n\n\n\n\n\nNow I’m confused as its predicting incorrectly with 92.57% confidence.\nPerhaps the model isnt seeing enough data?\nLets train a new model with:\n- 300 images instead of 60\n- ‘rice food’ and ‘noodle food’ as keyword insteads of just ‘rice’ and ‘noodles’\n\nsearches = ['rice food', 'noodles food']\npath_200 = Path('rice_or_noodles_300')\n\nif not path_200.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path_200/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=300)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:200])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n\n# 1.4 Remove Failed images\npath_200 = Path('rice_or_noodles_300')\nfailed = verify_images(get_image_files(path_200))\nfailed.map(Path.unlink)\n\n\n(#10) [None,None,None,None,None,None,None,None,None,None]\n\n\n\n\ndls_200 = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path_200) \n\n\nlearner_RN18_200 = vision_learner(dls_200, resnet18, metrics=error_rate)\n\n\nlearner_RN18_200.fine_tune(4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.155098\n0.872050\n0.338462\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.625260\n0.402908\n0.169231\n00:15\n\n\n1\n0.442973\n0.289800\n0.138462\n00:14\n\n\n2\n0.317375\n0.328805\n0.153846\n00:14\n\n\n3\n0.235606\n0.327507\n0.123077\n00:15\n\n\n\n\n\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18_200.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 100.00%\nrice food: 99.95%\n\n\n\n\n\n\n\n\n\nSo it’s now 100 and 99.95% confident they’re rice, which is great!\nLets try some fried rice!\nWe’ll retest now at the fried rice photo which the initial model guessed to be noodles with 98.5% confidence\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path1 = uploader1.data[0]\n\ndisplay(Image(filename=image_path1)) \n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 99.56%\n\n\nGreat! It is correct with 99.56% confidence.\nI think we’ve created a great rice and noodles classifier, lets stop here.\n[Future Iteration 3]: Build web app for everyone to test it out\n[Future Iteration 4]: Make it useable on my blog\n[Question] I wonder if theres a way to quickly see all specific headings I’ve used, I find myself scrolling up and download to find what Iteration I’m up to…\nApologies for the lack of neatness, lets hope this improves over time…"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html",
    "title": "Saving a Fast AI Model",
    "section": "",
    "text": "This is a short tutorial to save (export) down a fast ai model (pkl file)."
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "title": "Saving a Fast AI Model",
    "section": "1. Load Fast AI Libaries and Download Dataset",
    "text": "1. Load Fast AI Libaries and Download Dataset\n\n!pip install -Uqq fastai\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath\n\nPath('C:/Users/tonyp/.fastai/data/oxford-iiit-pet/images')\n\n\nIf you ran it in GoogleColab or Kaggle (recommended, its faster) then it’ll be stored in the cloud. \nIf you ran it locally, its stored on your machine and you can take a look at the all the cute images! (Not recommended, its slow)"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "title": "Saving a Fast AI Model",
    "section": "2. Labelling Function",
    "text": "2. Labelling Function\n\ndef is_cat(x): return x[0].isupper()\n\nOur data must be consistently labelled and parsed through into the model.\nFor this particular dataset, filenames starting with a Capital letter denotes a Cat, vice versa for a Non-Cat (Dog, in this case).\n\n\n\nPet Filenames\n\n\nLets write a function to handle the files names to get our labels (psuedo-code):\n1. Parse in file name and\n2. Obtain the first character and\n3. Check whether it is an upper case,\n4. If True, then it is a Cat.\nThere are various ways for us to supply the labelling to our model, in a previous blog Rice vs Noodles, the label was supplied via the parent folders name (rice folder and noodle folder).\n\nFast AI provides various helpful functions for common ways data is labelled to parse into our models\nFast AI Docs - Transforms - Label"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "title": "Saving a Fast AI Model",
    "section": "3. DataLoader",
    "text": "3. DataLoader\nCreate the Dataloader and supply the labelling function we wrote into label_func.\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "title": "Saving a Fast AI Model",
    "section": "4. Fine-tune (Non-GPU vs GPU)",
    "text": "4. Fine-tune (Non-GPU vs GPU)\nI attempted to fine-tune via Kaggle (GPU) and Locally (No GPU) and not suprisingly it is incredibly faster with a GPU setup.\nNvidia (and maybe other) GPUs are designed to be able to take multiple images at once (batches) grouped together (tensors) (I think 64 images at once), whereas a laptop without a GPU like mine will be processing 1 image at a time.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\nGPU took 35 seconds an epoch \nNon-GPU took 8 minutes an epoch"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "title": "Saving a Fast AI Model",
    "section": "5. Export the model",
    "text": "5. Export the model\n\nlearn.export('catdogmodel.pkl')\n\nIn Kaggle, the model will be saved on their cloud and you can access it by using right-hand sidebar under Notebook -&gt; Data -&gt; Output\n\nIt’s only 46 Mb!, not too shabby!\n\nThats it! We’ll go through how to use a saved/exported model in an upcoming post."
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html",
    "href": "posts/2024-01-24-99_multi_classifier/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "",
    "text": "I’ve just created my first multi-category classifier using Jeremy Howard’s popular fast ai which is an astraction layer library built on top of the most world’s used deep-learning library PyTorch. I’ve documented the process including the issues I faced (i.e. bugs)\nI found it more easier to digest and understand this process by splitting the steps into 3 parts:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "Part 1: Create Learner (.pkl file)",
    "text": "Part 1: Create Learner (.pkl file)"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.1 Install and import libraries",
    "text": "1.1 Install and import libraries\n\n!pip install timm\n!pip install fastai \n\n\nfrom fastai.vision.all import *\nimport timm"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.2 Download Pets Breed Data",
    "text": "1.2 Download Pets Breed Data\n\npath = untar_data(URLs.PETS)/'images'"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.3 Create Data Loader",
    "text": "1.3 Create Data Loader\n\n1.3.1 (A different) Labelling Function\nHere a different method to label our data was used:\n\nIn ‘noodles vs rice’ model: There were two parent folders separating two categories of data: get_y=parent_label\nIn ‘saving a fast ai’ model: There was a custom labelling function that looked for capital letters for cat breeds def is_cat(x): return x[0].isupper()\nIn this model, I used Regex to find breed names before the last ’_’ in the file name: label_func=RegexLabeller(pat=r'^([^/]+)_\\d). See show_batch() output to see the file names examples.\n\nDid you notice this is the same dataset as the is_cat model? So changing our label resulted in a different model!\n\n\n1.3.2 Data Loader Code\n\npets_dataloaders =  ImageDataLoaders.from_name_func(\n    '.',\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat=r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.4 Batch Examples, Create Learner, Fine-Tune and Export",
    "text": "1.4 Batch Examples, Create Learner, Fine-Tune and Export\nI grouped these steps as the code are exactly the same in previous posts.\n\n1.4.1 Batch Examples\nThis function is also a good way to find out what is the file name structure if we were not sure.\n\npets_dataloaders.show_batch(max_n=8)\n\n\n\n\n\n\n\n\n\n\n1.4.2 Create Learner\nI am still using resnet model architecture for starters for reasons mentioned previously by Jeremy Howard\n\npets_learner = vision_learner(pets_dataloaders, resnet34, metrics=error_rate)\n\n\n\n1.4.3 Fine-Tune\n\npets_learner.fine_tune(3) \n\n\n\n1.4.4 Export\n\npets_learner.export('pets_learner.pkl')"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html",
    "href": "posts/2024-01-25-99_gradio_app/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "",
    "text": "This post shows how to create a Gradio App (app.py) and run it locally in a browser. This app should:\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "href": "posts/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "Part 2: Create Gradio application file (app.py)",
    "text": "Part 2: Create Gradio application file (app.py)"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "href": "posts/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "1. Import Gradio and Fast AI libraries",
    "text": "1. Import Gradio and Fast AI libraries\n\nfrom fastai.vision.all import * \nimport gradio as gr\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn("
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "href": "posts/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "2. Import Learner (.pkl file)",
    "text": "2. Import Learner (.pkl file)\nRecall, this file was created and exported in Part 1\n\nIf you’re running on a Linux, you shouldn’t have any import issues.\n\nIf you’re running a Windows PC, you’ll likely to experience an error.\n\n\npets_learner = load_learner('pets_learner.pkl') \n\nNotImplementedError: cannot instantiate 'PosixPath' on your system\n\n\n\n2.1 Import Learner Error (.pkl file) Solution (Windows only)\nI found a solution here.\nNot too sure why this happens, probably linux vs windows compatibility, forward vs backlashes probably?\nImport the pathlib library below and run the code below to fix the paths:\nNote:\n- This fix is only required during the testing phase of our Gradio App.\n- This testing phase is defined as being able to run the Gradio App locally.\n- When we Upload to HuggingFace Spaces, this code fix is not required (because HF is run on Linux, hence no Posix issues, from my understanding)\n\n# only run to import pkl in windows when youre doing testing in windows | when run in hus | its run via dock images ie linux ie no problems\nimport pathlib # \ntemp = pathlib.PosixPath\npathlib.PosixPath = pathlib.WindowsPath\n\n\npets_learner = load_learner('pets_learner.pkl')"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "href": "posts/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "3 Predict the Breed with Imported Learner",
    "text": "3 Predict the Breed with Imported Learner\n\n3.1 Import Local Image\n\npet1 = PILImage.create('pet1.jpg')\npet1.thumbnail((224,224))\npet1\n\n\n\n\n\n\n\n\n\n\n3.2 Make prediction\nUse predict() to make prediction on the uploaded local image. The results will have 3 items:\n1. The prediction of the breed.\n2. Index of the Tensor (in point 3.)\n3. A Tensor of length 37. Why the odd number?\n- These are the probabilities of each unique breeds in our data!\n- Recall in Part 1, we determined the different categories by using a custom labelling function\n\nres = pets_learner.predict(pet1)\nres\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n('Bombay',\n tensor(3),\n tensor([3.4475e-02, 1.7813e-03, 8.1388e-03, 6.3685e-01, 6.0993e-03, 4.8830e-04,\n         5.0747e-02, 8.8036e-03, 2.1084e-01, 3.4832e-02, 9.6598e-04, 7.6646e-04,\n         6.3764e-04, 2.5949e-04, 8.7999e-05, 1.3308e-03, 6.6650e-05, 5.7116e-05,\n         9.0377e-04, 6.9052e-05, 2.0095e-04, 2.1758e-05, 2.5767e-04, 2.1859e-05,\n         3.8547e-05, 1.6165e-06, 6.2601e-05, 4.3552e-05, 1.4901e-04, 9.6175e-05,\n         1.0010e-04, 1.3717e-04, 2.7684e-04, 5.5386e-05, 5.7012e-05, 4.6809e-05,\n         2.2643e-04]))\n\n\n\n\n3.3 What is the probabilities representing?\nThe probabilities tensor from predict() are the unique categories in our data and are stored in our dataloader\n\ncategories = pets_learner.dls.vocab \ncategories\n\n['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'boxer', 'chihuahua', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian', 'pug', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']\n\n\n\n\n3.4 The prediction and probabilities of our image\n\n# get index of predction\nidx = res[1]\n\n# store list of probalities of our predction\nprobabilities = res[2]\n\n# get breed and probability of our prediction\ncategories[idx],probabilities[idx]\n\n\n('Bombay', tensor(0.6369))\n\n\n\n\n3.5 Probability of every category available\n\ndef classify_image_fn(img):\n    prediction, idx, probabilities = pets_learner.predict(img)\n    return dict(zip(categories, map(float, probabilities)))\n\nclassify_image_fn(pet1)     # names and probabilities\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n{'Abyssinian': 0.034474823623895645,\n 'Bengal': 0.0017812795704230666,\n 'Birman': 0.008138809353113174,\n 'Bombay': 0.6368528604507446,\n 'British_Shorthair': 0.006099338177591562,\n 'Egyptian_Mau': 0.0004883029614575207,\n 'Maine_Coon': 0.05074741691350937,\n 'Persian': 0.008803554810583591,\n 'Ragdoll': 0.21084259450435638,\n 'Russian_Blue': 0.03483246639370918,\n 'Siamese': 0.0009659799397923052,\n 'Sphynx': 0.0007664564182050526,\n 'american_bulldog': 0.0006376394885592163,\n 'american_pit_bull_terrier': 0.0002594943216536194,\n 'basset_hound': 8.799932402325794e-05,\n 'beagle': 0.0013307805638760328,\n 'boxer': 6.664981629000977e-05,\n 'chihuahua': 5.711586709367111e-05,\n 'english_cocker_spaniel': 0.0009037724230438471,\n 'english_setter': 6.905203190399334e-05,\n 'german_shorthaired': 0.00020094779029022902,\n 'great_pyrenees': 2.1758336515631527e-05,\n 'havanese': 0.0002576670085545629,\n 'japanese_chin': 2.1859435946680605e-05,\n 'keeshond': 3.85471066692844e-05,\n 'leonberger': 1.616517351976654e-06,\n 'miniature_pinscher': 6.26009568804875e-05,\n 'newfoundland': 4.355219061835669e-05,\n 'pomeranian': 0.00014901049144100398,\n 'pug': 9.617456089472398e-05,\n 'saint_bernard': 0.0001000974079943262,\n 'samoyed': 0.0001371700782328844,\n 'scottish_terrier': 0.00027684049564413726,\n 'shiba_inu': 5.5386270105373114e-05,\n 'staffordshire_bull_terrier': 5.701235932065174e-05,\n 'wheaten_terrier': 4.680879646912217e-05,\n 'yorkshire_terrier': 0.0002264348149765283}"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "href": "posts/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "4 Run local Gradio App",
    "text": "4 Run local Gradio App\nTheres a variety of ways to alter the app, I’ve set the size of the images and provided some examples:\n\ngr_image = gr.Image(width=244, height=244)\ngr_label = gr.Label()\n\ninput_examples = ['pet1.jpg','pet2.jpg','pet3.jpg','pet4.jpg','pet5.jpg']\nintf = gr.Interface(fn=classify_image_fn,\n                    inputs=gr_image,    \n                    outputs=gr_label,\n                    examples=input_examples)\nintf.launch(inline=False)\n\nRunning on local URL:  http://127.0.0.1:7863\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1 Open Local Gradio App\nOpen the URL provided in your favourite browser\n\n\n\n4.2 Test it out\nThe app knows a pug when it sees one! The app is ready."
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#export-app.py",
    "href": "posts/2024-01-25-99_gradio_app/index.html#export-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "5. Export (app.py)",
    "text": "5. Export (app.py)\nGradio app must be all inside a app.py script when being deployed on HuggingFaces.\nThankfully, there is a library to export all the cell-blocks from our notebook (.ipynb) to python script (app.py).\nReference\n\n5.1 Put directives at front of notebook\n\nPlace ‘#| default_exp app’ in a python codeblock in front of the the notebook\n\n\n\n\n5.2 Choose the cellblocks to export\n\nPlace ‘#| export’ in front of each codeblock you need to export\n\n\n\n\n5.3 Run nbdev and export\n\nfrom nbdev.export import nb_export\nnb_export('app.ipynb')\n\nThis will create a new folder as home directory and place in the app.py"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "href": "posts/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 1)",
    "section": "",
    "text": "A neural network is a mathematical function. So what’s that?\nA function is a mapping or transformation where each unique set of inputs is equal to exactly one output.\nIn highschool, the Vertical Line Test was used to determine whether a line was a function.\nThis post will go through basics of how to fit a line to some data."
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 1)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "title": "Neural Network Basics (Part 1)",
    "section": "2. Upload and Plot Data",
    "text": "2. Upload and Plot Data\n\ndf = pd.read_csv(\"upload_dataset.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2.000000\n11.869037\n\n\n1\n-1.789474\n6.543284\n\n\n2\n-1.578947\n5.939607\n\n\n3\n-1.368421\n2.630370\n\n\n4\n-1.157895\n1.794741\n\n\n\n\n\n\n\n\nplt.scatter(df.x, df.y)"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "title": "Neural Network Basics (Part 1)",
    "section": "3. Quadratic Equation",
    "text": "3. Quadratic Equation\n\n3.1 General Quadratic Equation\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\n\n\n\n3.2 Custom Quadratric Equation\n\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\n\n\n\n3.3 Creating \\(1x^2 + 1x + 1\\)\n\nquad_111 = custom_quad_fn(1,1,1)\n\n\n\n3.4 Plotting \\(1x^2 + 1x + 1\\)\n\nxs_111 = df.x\nys_111 = quad_111(xs_111)\nplt.plot(xs_111,ys_111)\nplt.scatter(df.x, df.y)\n\n\n\n\n\n\n\n\n\n\n3.4 Interactive Quadratic Equation\nThe coefficients a, b and c of the Quadratic Function can be adjusted which in turn changes the shape of the line.\n[Future Iteration]: Figure out how to embed this adjustable plot into quarto blog\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot(a,b,c):\n# 1. plot scatter\n    plt.scatter(df.x, df.y)    \n# 2. create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n# 3. plot custom_quad_interactive\n    plt.ylim(-1,15)\n    plt.plot(xs_interact, custom_quad_fn(a,b,c)(xs_interact))\n\n\n\n\n\n\n\n3.5 Mean Absolute Errors (MAE)\nBy calculating a Loss Function such as Mean Absolute Errors, we can numerically determine what is the ‘best’ fit of our line to the data.\nSure it isn’t entirely scientific to adjust it manually but its a good starting point.\n\ndef mae(prediction, actual): return np.mean(abs(prediction-actual))\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot2(a,b,c):\n# 1.    plot scatter\n    plt.scatter(df.x, df.y)\n\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n\n# 4.    calc mae\n    y_actual     = df.y\n    y_predicted  = custom_quad_fn(a,b,c)(df.x)\n    interact_mae = round(mae(y_actual, y_predicted),3)\n\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae}\")"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nThe next section go through a more automated method to find the smallest MAE.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html",
    "href": "posts/2024-02-03-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 3)",
    "section": "",
    "text": "In Neural Network Basics: Part 2, the parameters of a function were found (optimised) to Minimise the Loss Function. The Loss Function chosen was the Mean Absolute Error, it could have been chosen to be the Mean Squared Error.\nBut What is the mathematical function if the wish to model something more complex like predicting the breed of Cat?\nUnfortunately, its unlikely the relationship between the parameters and whether a pixel is part of a Maine Coon 🐈 is a Quadratic, its going to be something more complicated.\nThankfully, there exists the infinitely flexible function known as Rectified Linear Unit (ReLU)"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "href": "posts/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "title": "Neural Network Basics (Part 3)",
    "section": "1. Rectified Linear Unit (ReLU)",
    "text": "1. Rectified Linear Unit (ReLU)\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nfrom functools import partial\n\n\n1.1 Function\nThe function does two things:\n1. Calculate the output of a line\n2. If the output is smaller than zero, return zero\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y,0.)\n\n\n\n1.2 Create A Custom ReLU Method\n\ndef custom_relu_fn(m,b): return partial(rectified_linear,m,b)\n\n\n\n1.3 Create y = 1x + 1 with Custom ReLU Method\n\nfn_11 = custom_relu_fn(1,1)\nfn_11\n\nfunctools.partial(&lt;function rectified_linear at 0x00000220331C9D00&gt;, 1, 1)\n\n\n\n\n1.4 ReLU y = 1x+ 1 Plot\n\nx = torch.linspace(-2.1,2.1,20)\nplt.plot(x,fn_11(x))\n\n\n\n\n\n\n\n\n\n1.4.1 Interactive ReLU\n\nplt.rc('figure', dpi=90)\n\n@interact(m=1.2, b=1.2)\ndef plot_relu(m, b):\n    min, max = -4.1, 4.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(rectified_linear, m,b)\n    ylim=(-1,4)\n    plt.ylim(ylim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n\n1.5 Double ReLU Function\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1) + rectified_linear(m2,b2) \n\n\n1.5.1 Interactive Double ReLU\n\nplt.rc('figure', dpi=90)\n\ndef dbl_rectified_linear(m1, b1,m2,b2,x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2)\ndef plot_dbl_relu(m1,b1,m2,b2):\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(dbl_rectified_linear, m1,b1,m2,b2)\n    ylim=(-1,4)\n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n1.5.1 Triple ReLU for Good Measure!\n\ndef trple_rectified_linear(m1, b1, m2, b2, m3, b3, x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x) + rectified_linear(m3,b3,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2, m3=0.5, b3=0.5)\ndef plot_trple_relu(m1,b1,m2,b2,m3,b3):\n# static variables\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    \n# update partial to include extra parameters m3, b3\n    triple_relu_fn_y = partial(trple_rectified_linear, m1,b1,m2,b2,m3,b3)\n\n# static variables\n    ylim=(-1,4) \n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, triple_relu_fn_y(x))"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "href": "posts/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "title": "Neural Network Basics (Part 3)",
    "section": "2. ReLU is An Infinitely Flexible Function",
    "text": "2. ReLU is An Infinitely Flexible Function\nThere could be arbitrarily many ReLus added together to form any function!\nThe previous functions are of a single input x i.e. 2-Dimensions.\nReLU’s could be added together over as many dimensions as desired, i.e. ReLU’s over surfaces or ReLU’s over 3D, 4D 5D etc.\nBut adding these ReLU’s, this means there are arbitrary amount of parameters related to each ReLU, how can these parameters be calculated?\nIn Part 2, a optimisation method called Gradient Descent was used to determine Parameters.\nThat’s Deep Learning in a nutshell. Beyond this, Tweaks are to:\n- make it faster\n- require less data"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "href": "posts/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "title": "Neural Network Basics (Part 3)",
    "section": "Neural Network Basics Completed.",
    "text": "Neural Network Basics Completed.\nGo back to a previous post:\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "",
    "text": "POSTING ON LIVE BLOG TO FORCE MYSELF TO FINISH THIS POST ASAP\nIt’s time to dive into previously explored topics a bit more deeply. Time to try to understand what’s actually going on.\nThese posts help me trigger what kind of thought process I had at the time of learning the topic. It’s not be easily disgestable for other people 🗺️ but feel free to read on.\nUp til now, I’ve sped-run topics whilst not understanding much of the details.\nI like to get the code running at least and produce results to expectation before getting in the weeds. At least I know the code works so I don’t end up heading towards doom 🌚.\nIn these deeper dives:"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#the-mission",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#the-mission",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "1.1 The Mission",
    "text": "1.1 The Mission\n\n[Mission]:\n\nCreate a model that takes in some inputs and provides a reasonble output (prediction).\n\n[Method]:\n\nA mathematical function is a form of a model:\n\ntakes in inputs x1, x2, ... and\ntransforms it into a single output y = F(x1, x2, ...).\n\n\nThis seems like a good appraoch to tackle the mission."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#the-mathematical-model",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#the-mathematical-model",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "1.2 The Mathematical Model",
    "text": "1.2 The Mathematical Model\nCreate a Linear Model (or mathematical function) given some (real world) data (data that represents something we want to predict given similar input) in the form \\[y = a_1x_1 + a_2x_2 + ... a_nx_n\\] It is called Linear because our inputs x are of degree 1.\n\nEach inputs (x1, x2, ..., xn) is multiplied by their corresponding coefficients or parameters (a1, a2, ..., an), i.e.: \\[a_1x_1 + a_2x_2 + ...\\]\n\nThe inputs variables x’s are like features or characteristics of our model.\nthe coefficients (known as parameters) in machine learning talk, scale the features/inputs. By scaling the inputs, it’s like finding out which input/feature matters more or not, in determining the output.\n\nThe output y (known as predictions) is calculated by summing all the scaled parameters together: a1x1 + a2x2 + ...: \\[F(x) = y = a_1x_1 + a_2x_2 + ... + a_nx_n\\]\n\n\n1.2.1 Laymens (mathematical model):\n\nIf a coefficient \\(a_1, a_2 ...\\) is almost zero, it’s like saying it does not impact the prediction value (remember we are adding up scaled versions of inputs to calculate the output / prediction). Then thats like saying perhaps this particualr parameter is an unimportant variable (or feature)!\n\nPerhaps we can get rid of it altogether?\nLess variables, less calculations, less overhead (and less work!) and a more simple model without losing significant predictive power.\n\nIf it has a large coefficient, then it would impact the overall sum, hence prediction. Probably shouldnt disregard this parameter."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#mathematical-models-examples",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#mathematical-models-examples",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "1.3 Mathematical models examples",
    "text": "1.3 Mathematical models examples\nTwo simple examples (single input x and a single output y) can be visualised on the 2D-plane:\n\nA straight line where input x is the horizontal-axis and output: F(x) and y is on the vertical-axis is with the formula we all know and love: \\[ F(x) = mx + b \\]\n\nAnd similarly,\n\nA quadratic line is: \\[F(x) = ax^2 + bx + c\\]\n\nNote: Our model should generalise a mathematical function (or find out the core characteristics and relationships ) given our set of data, so once we know that, we can predict unseen data with similar traits.\n\nFor a quadratic equation, what combination of \\(a\\), \\(b\\) and \\(c\\) will help us predict closely the value we want given some random \\(x\\)\nHow about all of \\(x\\) as we want and have good predictions all of them on average \\(x\\)? That’s what we are trying to do!"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#choose-a-model",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#choose-a-model",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "2.1 Choose a Model",
    "text": "2.1 Choose a Model\nWhy are we talking about models where the title is Data Preparation?\nAs seen in our Mission statement, we wish to create a model to solve problems. In my mind, this means we should have some mental model of what we are trying to solve, and then we decide what data that goes into the model.\nIf we just have some data without a sense of how it fits into a particular model in mind, how will know what to do with data, whether the data is relevant, its just a piece of data.\nOnce we established our first model (we could change it later) then we can process our data to enter the model.\n\n2.1.1 Quadratic Equation Example\n\nAssume a quadratic equation: F(x) = ax^2 + bx + c can help us model some real world phenomena (e.g. throwing a ball or driving then stopping)."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#make-predictions-with-our-model",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#make-predictions-with-our-model",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "2.2 Make Predictions with our Model",
    "text": "2.2 Make Predictions with our Model\nGreat! We have our model, lets start making predictions!\nNot quite. There are alot of missing components that has not been decided in our equation.\nAlso what does it mean to even make a prediction and how do we do it?\n\nIn our mathematical model context, it’s as simple as plugging in the different input values (x) and their coefficients (a,b,c) to our quadaratic equation (F(x) = ax^2 + bx + c) to see what output value (y) we get.\nIn other words, calculate the F(x) (predictions) by using different combinations of our inputs x and parameters a,b,c with the equation F(x) = ax^2 + bx + c. Simple!\n\nBut what combinations a,b,c and x do we to use? - Surely not random? Well kind of yes but also no.\nNote: input variables are known as features and coefficients are known as parameters. So, I’ll use them interchangeably.\n[QUESTION]: - To make useful and relevant predictions, is there some systematic way to decide what starting parameters(\\(a, b, c\\)) and features(\\(x_1, x_2\\)) to use?"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#starting-inputs-variables-x_1-x_2-...-x_n",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#starting-inputs-variables-x_1-x_2-...-x_n",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "2.3 Starting Inputs Variables \\(x_1, x_2, ... , x_n\\)",
    "text": "2.3 Starting Inputs Variables \\(x_1, x_2, ... , x_n\\)\nThe question is \\(x\\)’s do we start with?\nLets discuss a model that is a little more complex than a line on a 2-D plane.\nSay we want a predictive model that guesses whether a passenger on the Titanic: - Survived and - Did not Survive\n\n2.3.1 Good Starting Inputs Variables\n\nA good set of input variables would be data on actual passengers of the titanic and information on whether they survived or not.\nThe learning model would learn about all the characteristics of these passengers and then adjust the parameters and scale towards characteristics that matter and and vice version on passengers and their survivability.\nThrough the training process, the model may find some characteristics to be irrelevant (perhaps ear length), but that is not the focus of this part of the process. This part of the process is where to start.\n\n\n\n2.3.2 Bad Starting Inputs\nAn even worse set of inputs (moving towards the bad validation set territory, more on this later). Data from unrelated sources (sorry to state the obvious) such as:\n- the cohort of 2015 Applied Finance Graduates from Macquarie University, Sydney,\n- a group people picked at random off streets of Binh Thanh Saigon, Vietnam,\n- a group of online matches from a popular dating app obtained by a user.\nThese groups technically surivived the Titanic so the model will say all their characteristics of everyone are useful, which isnt a great predictor (it’ll predict being born after the Titanic sunk gives you a 100% chance of surviving the Titanic 🤭)"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#starting-coefficients-x_1-x_2-...-x_n",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#starting-coefficients-x_1-x_2-...-x_n",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "2.4 Starting Coefficients \\(x_1, x_2, ... , x_n\\)",
    "text": "2.4 Starting Coefficients \\(x_1, x_2, ... , x_n\\)\nI heard determeting starting coefficients is more of an art than a science (Lets assume later there are some cool algorithms that give us a hand in the future).\n\n2.4.1 About Zero\nIt would make sense that initially input dominate parameters (input values are large relative to their coefficients) and then they’re scaled by a parameter according to importance through the neural network.\n- This means, start with relatively low value parameters (to it’s input variables) and let these coefficients adjust (learn through gradient descent) to larger values, whether positive or negative.\n- In other words start with coefficients about zero.\n\n\n2.4.1.1 Example\n\nSay we play a game where I tell you to choose a starting value and take count by 1 towards my guess and you want to choose a starting value to minimise the count on average.\n\nAnd I tell you my guess is always random and between -50 and 50.\n\nYou’d probably pick zero because its common sense! (I hope it is)\n\nIt’s kind of same in our model, except we dont pick zero itself because it ruins the math (explain later).\n\n\n\n2.4.2 Titanic\nLets assume we have a parameters should be relatively large and positive (for e.g. being a female or child in first class on the Titanic is probably two good parameters for survivability).\n- If the parameter starts off large and negative then this causes the model to take alot of iterations to learn and adjust the parameter to be positive. And vice versa.\n- So if we set all near zero, it will simply take less time on average for most models for each parameter to get to whether they need to go (optimisation?) considering we don’t know what parameters matter or not, so its random for us, ie, it can be positive or negative, we just don’t know (assuming there is no super obvious characteristic that would dominate a model, in which case, maybe its better to put a larger value? perhaps that isnt a data science way to do things though, I’m not sure yet).\n\n\n2.4.3 Preset Coefficients and Pre-trained Models\nSetting some coefficients initially (rather than using all random coefficients) and then training the model to the training set, this is actually called learning with a pre-trained model (not set by us). - This pre-trained model has already been run and completed by someone else and we are teaching the model learn about our data on top of its knowledge.\n- Most of what I’ll be initially doing is Building a Learner from a Pre-trained Model. In the future, I hope to learn to build the Pre-Trained models from scratch, if its a useful endeavour?\n- Popular examples of pre-trained models are ResNet50, which are trained on (millions of) pictures with 50 layers deep neural network.\n\n\n2.4.4 Isn’t it all relative?\nDoesn’t a coefficients relativeness depend on the actual value of its corresponding input parameter. - So shouldn’t the starting coefficient be set relative to its corresponding starting input parameter, and - Not just an arbitrary range of -0.5 to 0.5?\nAlso, input variables can range drastically within itself and relative to other variables! For example: - age could be range from 1 to 130 years old\n- Amount of money fundraised or donated by people could range 0 to billions\n- Lenght of the petals of a plum flower could range 0.1 mm to 40 mm.\n- x-values of any line function could be negative \\(\\infty\\) to positive \\(\\infty\\) (ngl I wanted to use the \\(\\infty\\) sign for once in my life ♾️)\nWith all these unaswered questions…\nDoes it still make sense to just choose coefficients about zero? (-0.5 to 0.5)?\nYes, because of normalisation."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#normalisation",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#normalisation",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "3. Normalisation",
    "text": "3. Normalisation\nData normalization (in ML) refers to the process of scaling and standardizing the features of a dataset. - This ensures all features contribute equally to the learning process - To avoid issues related to different scales and units in the input data.\nAre there different techniques for numeric versis categorical data? Absolutely."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#numerical-data-techniques",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#numerical-data-techniques",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "3.1 Numerical Data Techniques:",
    "text": "3.1 Numerical Data Techniques:\nMin-Max Scaling: - Scales the data to a specific range, often [0, 1].\nStandardization (Z-score normalization): - Scales the data to have a mean of 0 and a standard deviation of 1.\nRobust Scaling: - Uses the median and interquartile range (IQR) instead of the mean and standard deviation (Similar to standardization). Robust Scaling is less sensitive to outliers than standardization.\nLog Transformation: - Applied when the data is skewed, and you want to reduce the impact of large values.\nNormalization in Neural Networks: - Normalize input features to zero mean and unit variance. Batch normalization layers can also be used within the network to normalize the activations of hidden layers during training.\n\n3.1.1 Problem with Normalised Data\nDuring gradient descent, the algorithm updates the model weights based on the direction of the steepest descent in the cost function (error).\nFor simple linear regression model to predict housing prices based on two features: square footage (ft²) and number of bedrooms: - the large values of square footage will have a much stronger influence on the gradient calculation compared to the number of bedrooms. - This can lead the algorithm to prioritize changes based on square footage, potentially neglecting the impact of bedrooms on price.\n\n\n3.1.2 Benefits to Gradient Descent\nGradient descent is an iterative optimization algorithm commonly used in machine learning for training models. It aims to find the minimum of a cost function by adjusting model parameters iteratively.\nGradient Descent Sensitivity to Scale: - The scale of the input features directly influences the scale of the gradients. Features with larger scales can dominate the learning process and cause the algorithm to converge slowly or not converge at all.\nEqualizing the Influence of Features: - Normalizing data ensures that all features have a similar scale, preventing the algorithm from being biased towards features with larger magnitudes. - This equalization is particularly important when features have different units or scales, as it allows each feature to contribute proportionally to the model’s parameter updates during training.\nFaster Convergence: - Normalization often leads to faster convergence during training. With well-scaled features, the algorithm can take more substantial steps towards the minimum of the cost function, reducing the number of iterations needed for convergence.\nImproved Numerical Stability: - Normalization enhances the numerical stability of the optimization process. It helps prevent issues like vanishing or exploding gradients, which can occur when working with features of vastly different magnitudes.\nRegularization Considerations: - Some regularization techniques, such as L1 and L2 regularization, are sensitive to the scale of features. Normalizing features ensures that regularization terms act uniformly across all features, leading to a fair and effective regularization."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#categorial-data-techniques",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#categorial-data-techniques",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "3.2 Categorial Data Techniques:",
    "text": "3.2 Categorial Data Techniques:\nCategorical data itself cannot be normalized in the same way numerical data is\nDummy Variables or (One-Hot Encoding): - Create a new binary feature for each category within the original categorical variable. - Each new feature gets a value of 1 if the data point belongs to that category, and 0 otherwise. - This is a more robust approach.\nLabel Encoding: - Assign a unique numerical value (integer) to each category. - For example, “Blue” = 1, “Brown” = 2, and “Green” = 3 for eye color categories."
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#create-the-quadratic-equation",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#create-the-quadratic-equation",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "4.1 Create the Quadratic Equation",
    "text": "4.1 Create the Quadratic Equation\n\nfrom functools import partial\ndef quad_fn(a,b,c,x): return a*x**2 + b*x + c \ndef custom_quad_fn(a,b,c): return partial(quad_fn, a,b,c) # partial fixes a b c\n\nquad_111 = custom_quad_fn(1,1,1)\nquad_111 # quadratic function f(x): 1(x)^2 + 1(x) + 1\nquad_111(1) # quadratic function f(1): 1(1)^2 + 1(1) + 1 = 1 + 1 + 1 = 3 \n\n\n3"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#plot-function",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#plot-function",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "4.2 Plot Function",
    "text": "4.2 Plot Function\nInputs: - custom_quad_fn (above) (partial_fn) - x-limits (min, max)(numeric) - colour (str) - y-limit (numeric)\nOutputs: - x-values (tensor): creates 2-D tensor of x-values for plotting based on x-limits - f(x) (tensor) : output of custom_quad_fn based on x-values (tensor)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import torch\n# ***Inputs***: \n# - custom_quad_fn (above) (partial_fn) \n# - x-limits (min, max)(numeric) \n# - colour (str)\n# - y-limit (numeric)  \n# quad_111(1) # quadratic function f(1): 1(1)^2 + 1(1) + 1 = 1 + 1 + 1 = 3 \n# quad_111(2) # quadratic function f(2): 1(2)^2 + 1(2) + 1 = 4 + 2 + 1 = 7\n# quad_111(3) # quadratic function f(3): 1(3)^2 + 1(3) + 1 = 9 + 3 + 1 = 13 \n\nmin_y, max_y = -1, 13\nmin_x, max_x = -2.1, 2.1\n# a,b,c = 3,2,1\n\n# quad_custom_fn = custom_quad_fn(a,b,c)\n\nquad_321 = custom_quad_fn(3,2,1) # og function\n\ndef plot_quad(quad_abc,min_x=-2.1, max_x = 2.1, min_y= -1, max_y= 13 ):\n    x_tnsr = torch.linspace(min_x, max_x,steps= 100)\n    x_tnsr = x_tnsr[:,None] ## WHY?\n\n    y_tnsr_output = quad_abc(x_tnsr) # the shape of y follows x\n    plt.ylim(min_y,max_y)\n    plt.plot(x_tnsr, y_tnsr_output)\n\n\nNameError: name 'interact' is not defined\n\n\n\n# from ipywidgets import interact\n# from fastai.basics import *\n\ndef noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n\nNote:\n\nThese coefficients are started as random because we have to start somewhere.\nStarting off random parameters is generally a good practice, the art is then to incrementally updating our coefficients (known as gradient descent) to make our model (neural network) do better (improving accuracy or decreasing our loss function) at each iteration (known as epoch).\n\n\n2.4 TBA STEP Accuracy\n\nmeasure accuracy of our predictions i.e. Mean Absolute Error (MAE).\n\nFor each actual output/value y, what is our predicted y.\nSince predictions can be above or below the actual value, we apply an absolute function to measure the difference or loss. That is, the MAE is also known as our Loss Function. An alternate popular loss function is the `Mean Squared Function (MSE)\n\n\n\n\n2.4 TBA STEP UPDATE PARAMETERS\n\nupdating parameters to\n\nimprove accuracy of our predictions (i.e. decrease difference between our predictions and data)\ndo it automatically: the art of improving our model or learning is called gradient descent.\n\n\nneural network: Once the model is accuracy we are happy with, this is our neural network.\n\nQuite simple really?"
  },
  {
    "objectID": "posts/2024-03-01-neural_network_basics_revisited/index.html#simulate-data",
    "href": "posts/2024-03-01-neural_network_basics_revisited/index.html#simulate-data",
    "title": "Neural Networks Basics (Revisited) - [DRAFT TBC 02/3/24]",
    "section": "2. Simulate Data",
    "text": "2. Simulate Data\nSimulate content\n\nimport numpy as np, torch\n\nnp.random.seed(42)\ndef noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n\nactual_x_values_tsr = torch.linspace(-2, 2, steps=20)[:,None] # simulate 20 actual x-values + shape to 2D tensor\n\ndef actual_function(x): return 3*x**2 + 2*x + 1 \n# In reality we don't have a real function like this to use, \n# however we use this + add noise, which simulates real data\n# then we try to model this noisey data\nactual_y_values_unrealistic_tsr = actual_function(actual_x_values_tsr)\n # actual y-values of funtion we use to find\n\n#  but again, these values are not realistic because they're based on the real function - something that doenst exist in real life,\n# its like having the exact function that determines whether a photo is a cat or not\n# we can only approximate functions and its parameters\n# in real world, data has noise,\n# introduce data to these unrealistic real values to product realistic actual values\n\n# okay so why dont we need to add noise to actual_x_values? its any input is realistic/real world\n# any photo is can be asked 'is it a cat?'\n# any passenger with any characters can be asked 'did the passenger survive?\n\nactual_y_values_realistic_tsr = add_noise(actual_y_values_unrealistic_tsr, 0.15, 1.5) # use actualy y-values + add noise - to create simulated real data \n\n\n#now that we have a set of (actual realistic) 'data'\n# 1. try 'model' it with a quadratic equation \n# 2. create loss function - mean absolute error - difference between each point of actual y vs predicted y at each x, find difference and then absolute\n\n\n# actual_x_values[:5],actual_y_values_realistic[:5]\n\n# 1. Create quad function with parameters\ndef quad_fn(a,b,c,x): return a*x**2 + b*x + c\ny_a1_b1_c1_x1 = quad_fn(1,1,1,1)\ny_a1_b1_c1_x1  # 3 = (1*1^2) + (1*1) + (1) = 1+1+1\ny_a1_b1_c1_x2 = quad_fn(1,1,1,2)\ny_a1_b1_c1_x2  # 7 = (1*2^2) + (2*1) + (2) = 4+2+1\n\n# Its quite cumbersome to put a new x-value through the function, to get a corresponding predicted y-value\n# ideally we can provide a list of xs to get a list of predicted ys (x-tensor -&gt; f -&gt; y-tensor)\n# and also the coefficients are parameterised\nfrom functools import partial\ndef mk_quad_fn(a,b,c): return partial(quad_fn,a,b,c)\nquad111 = mk_quad_fn(1,1,1)\n# quad111(actual_x_values)\npredicted_quad111_y_values_tsr = quad111(actual_x_values_tsr) # remember is a 2d tensor due to added dimension with: [:,None]\n\n# we have actual-yand predicted-y data, lets compare them\n\ndef mae(actual, preds): return abs(preds-actual).mean()\n\nmae(actual_y_values_realistic_tsr,predicted_quad111_y_values_tsr)\n\n\n\nimport matplotlib.pyplot as plt\n# plt.plot(actual_y_values_realistic_tsr,predicted_quad111_y_values_tsr)\nplt.scatter(actual_x_values_tsr, actual_y_values_realistic_tsr)\n\n# plot predictions\n# for predictions, graphically it will look better to plot a line \n# rather than just a coressponding y-prediction to each actual y\n\n# lets do just corresponding ones first to see what it looks like\n\nplt.scatter(actual_x_values_tsr, predicted_quad111_y_values_tsr)\n\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(actual_x_values_tsr, actual_y_values_realistic_tsr)\n# plt.scatter(actual_x_values_tsr, predicted_quad111_y_values_tsr)\n\n# plot y-line prediction\n\nplt.plot(actual_x_values_tsr, predicted_quad111_y_values_tsr, 'r')\n\n\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact\n\n@interact(a=1,b=1,c=1)\ndef plot_both(a,b,c):\n    # interactive_predicted_quad_y_values_tsr = custom_quad_fn(actual_x_values_tsr)\n\n    plt.scatter(actual_x_values_tsr, actual_y_values_realistic_tsr)\n\n    actual_x_values_for_plotting_tsr = torch.linspace(-2.1,2.1,100)[:,None]\n    custom_quad_fn = mk_quad_fn(a,b,c)\n    interactive_predicted_quad_y_values_tsr = custom_quad_fn(actual_x_values_for_plotting_tsr)\n    plt.ylim((-3,13))\n    plt.plot(actual_x_values_for_plotting_tsr, interactive_predicted_quad_y_values_tsr, 'r')\n\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport numpy as np\n\n\nplt.rc('figure', dpi=90)\n\ndef plot_function(f, title=None, min=-2.1, max=2.1, color='r', ylim=None):\n    x = torch.linspace(min,max, 100)[:,None]\n    if ylim: plt.ylim(ylim)\n    plt.plot(x, f(x), color)\n    if title is not None: plt.title(title)\n\ndef f(x): return 3*x**2 + 2*x + 1\n\n# plot_function(f, \"$3x^2 + 2x + 1$\")\n\ndef quad(a, b, c, x): return a*x**2 + b*x + c\n\ndef mk_quad(a,b,c): return partial(quad, a,b,c)\n\n\n# f2 = mk_quad(3,2,1)\n# plot_function(f2)\n\ndef noise(x, scale): return np.random.normal(scale=scale, size=x.shape)\n\ndef add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)\n\n\n\n\nnp.random.seed(42)\n\nx = torch.linspace(-2, 2, steps=20)[:,None]\ny = add_noise(f(x), 0.15, 1.5)\n@interact(a=1.1, b=1.1, c=1.1)\ndef plot_quad(a, b, c):\n    plt.scatter(x,y)\n    plot_function(mk_quad(a,b,c), ylim=(-3,13))\n\n\n\n\n\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y, 0.)\n\n\nplot_function(partial(rectified_linear, 1,1))\n\n\nimport torch.nn.functional as F\ndef rectified_linear2(m,b,x): return F.relu(m*x+b)\nplot_function(partial(rectified_linear2, 1,1))\n\n\n@interact(m=1.5, b=1.5)\ndef plot_relu(m, b):\n    plot_function(partial(rectified_linear, m,b), ylim=(-1,4))\n\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n\n@interact(m1=-1.5, b1=-1.5, m2=1.5, b2=1.5)\ndef plot_double_relu(m1, b1, m2, b2):\n    plot_function(partial(double_relu, m1,b1,m2,b2), ylim=(-1,6))"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#import-a-pretrained-language-model",
    "href": "posts/kaggle/1-us-patents/index.html#import-a-pretrained-language-model",
    "title": "A Basic NLP model",
    "section": "1. Import a Pretrained Language Model",
    "text": "1. Import a Pretrained Language Model\n\nchosen_pretrained_model = \"microsoft/deberta-v3-small\"\n\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\ndebv3_tokenizer = AutoTokenizer.from_pretrained(chosen_pretrained_model)\n\n\n\n1.1 Look Inside the Language Model\n\nprint(debv3_tokenizer)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#test-out-tokenizer",
    "href": "posts/kaggle/1-us-patents/index.html#test-out-tokenizer",
    "title": "A Basic NLP model",
    "section": "2. Test out Tokenizer",
    "text": "2. Test out Tokenizer\n\ntest_string = (\"Hey all! What's going on? It's Tony from Sydney!\")\ndebv3_tokenizer.tokenize(test_string)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#import-competition-data",
    "href": "posts/kaggle/1-us-patents/index.html#import-competition-data",
    "title": "A Basic NLP model",
    "section": "3. Import Competition Data",
    "text": "3. Import Competition Data\nTo add relevant competition data to your kaggle “Input” folder.\nThis “Input” folder is persistent when you submit to the competition. All other folders created during prior to submitting are disregarded.\n\n3.1 Via GUI:\n\nOn Kaggle, Go to [Add Data]\n\nFilter for “Competition Datasets”\n\nSearch “US Patents”\nClick [Add Competition]\n\n \n\n\n3.2 Via Programatically:\nNote: You’ll need your own GPU’s, I don’t so the rest of the notebook is ran on the Kaggle website 1. Have kaggle login + keys ready locally, explained in this post 2. Run code to download data locally.\n\nfrom pathlib import Path\npath = Path('us-patent-phrase-to-phrase-matching')\nif not path.exists():\n    import zipfile,kaggle\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\n\n\n3.3 Look Inside the Competition Data\n\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching') # Using GUI places comp-data into 'kaggle/input' folder\nimport pandas as pd\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#data-preparation",
    "href": "posts/kaggle/1-us-patents/index.html#data-preparation",
    "title": "A Basic NLP model",
    "section": "4. Data Preparation",
    "text": "4. Data Preparation\n\n4.1 Create Input Column\nCreate a contentated column of imporatant columns context, target and anchor.\n\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\ndf['input']\n\n\n\n\n4.2 Convert Pandas Dataframe to HuggingFace Dataset\n\nfrom datasets import Dataset,DatasetDict\nhf_datasets = Dataset.from_pandas(df)\nhf_datasets.keys\n\n\n\n\n4.3 Tokenize our HuggingFace Dataset\nUsing the tokenizer, we can apply pre-trained model to our new concatenated column.\nA hugging face dataset is in the form of a dictionary so we can index to get a column with dict['column']\nWe can apply the tokenization with batching, resulting in an additional few columns input_ids, token_type_ids, attention_marks, which only took 2 seconds!\n\ndef tok_func(x): return debv3_tokenizer(x[\"input\"])\ntok_ds = hf_datasets.map(tok_func, batched=True)\ntok_ds\n\n\n\n\n4.4 Rename the Columns as to what HF expects\n\ntok_ds = tok_ds.rename_columns({'score':'labels'})\n\n\n\n4.5 Training and Validation Sets\nSplit the above tokenized hugging face datasets into validation and training sets, into DatasetDicts.\nNote: The validation set here is called test and not validate\n\ntok_ds_dicts = tok_ds.train_test_split(0.25, seed=42)\ntok_ds_dicts"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#data-modelling",
    "href": "posts/kaggle/1-us-patents/index.html#data-modelling",
    "title": "A Basic NLP model",
    "section": "5. Data Modelling",
    "text": "5. Data Modelling\n\n5.1 Import libraries and set parameters\nImport modules: - TrainingArgument: to take in all the hyperparameters - Trainer class: combines the TrainingArguments and Pre-trained model Set the main hyper-parameters: - Batch Sizes: to fit on the GPU, - Number of Epochs: for each ‘experiment’ and the - Learning Rate, so it doesnt fail.\n[“Future Iteration”]: More descriptions on these and other parameters in future posts.\n\nfrom transformers import TrainingArguments,Trainer\nbs = 128\nepochs = 4\nlr = 8e-5\n\n\n\n5.2 Setup Training Arguments\n\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n\n\n\n5.3 Create Model\n\nmodel = AutoModelForSequenceClassification.from_pretrained(chosen_pretrained_model, \n                                                           num_labels=1,\n                                                           ignore_mismatched_sizes=True)\n\n\n\n5.4 Create Metrics Functions\nThe Pearson coefficient using numpy.\n\nimport numpy as np\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n\n\n\n5.5 Create Trainer\n\ntrainer = Trainer(model, \n                  args, \n                  train_dataset=tok_ds_dicts['train'], \n                  eval_dataset=tok_ds_dicts['test'],\n                  tokenizer=debv3_tokenizer, \n                  compute_metrics=corr_d)\n\n\n\n5.6 Do the Training\n\ntrainer.train()"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#predictions",
    "href": "posts/kaggle/1-us-patents/index.html#predictions",
    "title": "A Basic NLP model",
    "section": "6. Predictions",
    "text": "6. Predictions\nNow that we have a Trainer (same as Learner in FastAI), we could use it on a an unseen set of data such as a Test Set and make predictions.\n\n6.1 Import Test Dataset\n\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n\n\n\n6.2 Make Predictions\nPredictions are going beyond 0 and 1\n\npreds = trainer.predict(eval_ds).predictions.astype(float)\n\n\n\n\n6.3 Clip Predictions\nPredictions are going beyond 0 and 1\n\npreds = np.clip(preds, 0, 1)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#submission",
    "href": "posts/kaggle/1-us-patents/index.html#submission",
    "title": "A Basic NLP model",
    "section": "7. Submission",
    "text": "7. Submission\n\nimport datasets\n\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds\n})\n\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#part-2",
    "href": "posts/kaggle/1-us-patents/index.html#part-2",
    "title": "A Basic NLP model",
    "section": "8. Part 2",
    "text": "8. Part 2\nActually the submissiong won’t work because it is a Notebook competition is the Internet is Turned Off.\nWhat needs to be done is convert this version to one that works without installing anything from the internet.\nThat would be in Part 2."
  },
  {
    "objectID": "posts/leetcode/0-welcome_to_lc/index.html",
    "href": "posts/leetcode/0-welcome_to_lc/index.html",
    "title": "❄️LeetCode Posts❄️",
    "section": "",
    "text": "link to leetcode profile here\n\nCreated new leetcode.qmd based on front page index.qmd and\n\nDirected contents to point here: contents: posts/lc_posts.\n\nProbably not the ideal blog + folder structure but it’ll do the job👌.\nI don’t claim to be a web-designer in any sense 😂.\nI began 3 months ago with no algorithm or data structures academic background at all. The Easys were definitey not Easy to me as you can see from the number of submissions.\nThe majority of submissions were 2-3 months ago and I made no attempts in January 2024 👏.\nThis page should keep me accountable and these fingers minty as a mojito on a hot day 🍹."
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "",
    "text": "link to question + submission\nlink to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#problem-description",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#problem-description",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an array of strings tokens that represents an arithmetic expression in a Reverse Polish Notation (RPN).\nInput: Evaluate the input RPN arithmetic expression.\nOutput: Return an integer that represents the value of the expression.\nRules:\n1. The valid operators are ‘+’, ‘-’, ‘*’, and ‘/’.\n2. Each operand may be an integer or another expression.\n3. The division between two integers always truncates toward zero\n4. There will not be any division by zero.\n5. The input represents a valid arithmetic expression in a reverse polish notation.\n6. The answer and all the intermediate calculations can be represented in a 32-bit integer."
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#leetcode-examples",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#leetcode-examples",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "2. LeetCode Examples",
    "text": "2. LeetCode Examples\n\n2.1 Example 1\nInput: tokens = [\"2\",\"1\",\"+\",\"3\",\"*\"]\nOutput: 9\nExplanation: ((2 + 1) * 3) = 9\n\n\n2.2 Example 2\nInput: tokens = [\"4\",\"13\",\"5\",\"/\",\"+\"]\nOutput: 6\nExplanation: (4 + (13 / 5)) = 6\n\n\n2.3 Example 3\nInput: tokens = [\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"]\nOutput: 22\nExplanation:\n((10 * (6 / ((9 + 3) * -11))) + 17) + 5\n= ((10 * (6 / (12 * -11))) + 17) + 5\n= ((10 * (6 / -132)) + 17) + 5\n= ((10 * 0) + 17) + 5\n= (0 + 17) + 5\n= 17 + 5\n= 22"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#background-and-analysis",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#background-and-analysis",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "3. Background and Analysis",
    "text": "3. Background and Analysis\nThe wiki explains this is also known as postfix notation, the operators follow their operands, in contrast to prefix (Polish) notation (operators precede their operands).\n\n3.1 Wiki Example\nTo add 3 and 4 together, the expression is [3 4 +] rather than [3 + 4].\n- The conventional notation expression [3 − 4 + 5] becomes [3 4 − 5 +] in reverse Polish notation:\n- 4 is first subtracted from 3, then - 5 is added to it.\n\n\n3.2 Stack Explanation\nThe concept of a stack, a last-in/first-out construct. In the example [3 4 −]:\n1. push 3 to stack: [3] 2. push 4 to stack; ie 4 is now on top, 3 below it: [3 4] 3. apply subtraction operator: - Remove top two items from the stack: - performs 3 − 4, and 4. push the result of −1 to top of stack.\n\n\n3.3 Stack Explanation Table\n\n3.3.1 Example 1: [3 4 −] with all steps\n\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nOutput_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\nnull\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\nnull\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\nnull\npush 4 to stack_top\n\n\nrpn_obj.op()[pt_1]: .pop(top 2)\n[  ]\n[3,4]\npop [3] [4] stack_top_2\n\n\nrpn_obj.op()[pt_2]: .op(top 2)\n[-1]\n[3,4]\noperate(3,4,-) on stack_top_2\n\n\nrpn_obj.op()[pt_3]: .truncate(res)\n[-1]\n-1\nint(result), truncate to zero as per Rule_3\n\n\nrpn_obj.op()[pt_4]: .return()\n[-1]\n-1\nreturn operated result\n\n\nrpn_obj.op()[pt_5]: .push(result)\n[-1]\nnull\npush results stack_top\n\n\n\n\n\n3.3.2 Example 2: [3 4 × 5 6 × +] with concise steps\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\npush 4 to stack_top\n\n\nrpn_obj.op(x)\n[12]\nrem top_2 3,4, op 3*4, push top 12\n\n\nrpn_obj.push(5)\n[12,5]\npush 5 to stack_top\n\n\nrpn_obj.push(6)\n[12,5,6]\npush 6 to stack_top\n\n\nrpn_obj.op(x)\n[12,30]\nrem top_2 5,6, op 5*6, push top 30\n\n\nrpn_obj.op(+)\n[meaning of life]\nrem top_2 12,30, op 12+30, push top 42\n\n\n\n\n\n\n3.3 Why?\nThe advantage of RPN is it:\n- removes the need for order of operations and parentheses that are required by infix notation and\n- can be evaluated linearly, left-to-right.\nFor example, the infix expression (3 × 4) + (5 × 6) becomes [3 4 × 5 6 × +] in reverse Polish notation.*"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#coding",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#coding",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "4. Coding",
    "text": "4. Coding\n\n4.1 Write pseudo-python-code\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        # Rule 5: Input expression is valid, no check required, \n        # ie doesn't start with operateor\n        if len(tokens) ==0: # check if no token \n            return 0 # Probably not needed due for R5 but wrote save time in case \n\n        stack = [] #initialise stack\n        stack.append(tokens[0])  # first item is valid due to R5 so set it to stk\n\n        ### [1]     operator functions/mapping (*,-,+,/)\n        ### [2]     .pop_top_2(stack):    \n        ### [3]     .operate(top_2_items, operator #[2.1]): \n\n        for i in range(1,len(tokens)):\n            # stack = [2]\n            curr_chr = tokens[i]\n\n            if curr_chr in operators:\n                top_2_items = [top_2, top_1] = pop_top_2(stack) # [1]\n                # [validation]: do spot check stacked removed top 2\n                res   = operate(top_2_items,curr_chr) #[2]\n                stack.append(res)\n\n            else: # is a valid integer so just append to top\n                stack.append(curr_chr)\n        return stack\n\n\n\n4.2 Write Required Functions\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        if len(tokens) == 0: \n            return 0 \n        stack = []\n        stack.append(int(tokens[0])) \n\n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            print(f\"operator: {operator}, top2:{x2}, top1:{x1}\")\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            elif operator == '/':\n                return int(x2/x1)\n            else:\n                print(\"unknown operator!\")\n                return False\n                \n        def pop_top_2(stack):\n            print(len(stack))\n            if len(stack) &lt;2:\n                print(\"Stack too short!\")\n                return False\n            else:\n                top_1 = stack.pop()\n                top_2 = stack.pop()\n                top_2_items = [top_2,top_1]\n                print(top_2_items)\n            return top_2_items\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                operator = curr_chr\n                top_2_items = pop_top_2(stack) \n                res   = operate(operator, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        print(stack)\n        return stack\nsoln = Solution()"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#test-functionality",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#test-functionality",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "5. Test Functionality",
    "text": "5. Test Functionality\n\n5.1 Case 1 Expected 9\n\nsoln.evalRPN([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n2\n[2, 1]\noperator: +, top2:2, top1:1\n2\n[3, 3]\noperator: *, top2:3, top1:3\n[9]\n\n\n[9]\n\n\n\n\n5.2 Case 2 Expected 6\n\nsoln.evalRPN([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n3\n[13, 5]\noperator: /, top2:13, top1:5\n2\n[4, 2]\noperator: +, top2:4, top1:2\n[6]\n\n\n[6]\n\n\n\n\n5.3 Case 2 Expected 22\n\nsoln.evalRPN([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])  \n\n4\n[9, 3]\noperator: +, top2:9, top1:3\n4\n[12, -11]\noperator: *, top2:12, top1:-11\n3\n[6, -132]\noperator: /, top2:6, top1:-132\n2\n[10, 0]\noperator: *, top2:10, top1:0\n2\n[0, 17]\noperator: +, top2:0, top1:17\n2\n[17, 5]\noperator: +, top2:17, top1:5\n[22]\n\n\n[22]"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#clean-version",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#clean-version",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "6. Clean Version",
    "text": "6. Clean Version\n\nclass Solution:\n    def evalRPN_clean(self, tokens: [str]) -&gt; int:\n        stack = []\n        stack.append(int(tokens[0])) \n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            else:\n                return int(x2/x1)\n\n        def pop_top_2(stack):\n            top_1 = stack.pop()\n            top_2 = stack.pop()\n            return [top_2,top_1]\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                top_2_items = pop_top_2(stack) \n                res   = operate(curr_chr, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        return stack[0] ############### fixed after submission 2  ###############\nsoln = Solution()\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22\n\n\n\n6.1 Clean Check\n\nsoln.evalRPN_clean([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n9\n\n\n\nsoln.evalRPN_clean([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n6\n\n\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22"
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#submit",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#submit",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "7. Submit",
    "text": "7. Submit\n\nFirst attempt Failed, because I returned the stack as a list with result as the first item.\nSecond attempt Accepted! Quick fix after indexing out the value form the list. Not a bad result.\n\nTop 40% in Speed and\nTop 20% in Memory."
  },
  {
    "objectID": "posts/leetcode/2-reverse_polish_notation/LC150.html#notes-to-self.",
    "href": "posts/leetcode/2-reverse_polish_notation/LC150.html#notes-to-self.",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "6. Notes to self.",
    "text": "6. Notes to self.\nThis took alot of time setting up the problem, the solving part was quite fast.\nI need to be more seemless in set up!\n[Future Iterations 1]: Incorporate best solutions from LC\n[Future Iterations 2]: Attempt iterations for speed and memory\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/leetcode/4-search_a_2d_matrix/LC74.html",
    "href": "posts/leetcode/4-search_a_2d_matrix/LC74.html",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/4-search_a_2d_matrix/LC74.html#problem-description",
    "href": "posts/leetcode/4-search_a_2d_matrix/LC74.html#problem-description",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an m x n integer matrix matrix with the following two properties:\nEach row is sorted in non-decreasing order.\nThe first integer of each row is greater than the last integer of the previous row.\nGiven an integer target, return true if target is in matrix or false otherwise.\nYou must write a solution in O(log(m * n)) time complexity."
  },
  {
    "objectID": "posts/leetcode/4-search_a_2d_matrix/LC74.html#code",
    "href": "posts/leetcode/4-search_a_2d_matrix/LC74.html#code",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "2. Code",
    "text": "2. Code\n\nFlatten array then\nUse code from binary search\n\n\nclass Solution:\n    def searchMatrix(self, matrix: [[int]], target: int) -&gt; bool:\n        # its a ascending matrix,\n        # 1. turn into array then \n        # 2. apply binsearch \n        arr = [element for row in matrix for element in row]\n\n        l = 0\n        r = len(arr)\n\n        if r==1:\n            if target == l[0]:\n                return True\n            else: return False\n\n        while l&lt;r:\n            m = (l+r)//2\n            if arr[m]&lt;target:\n                l = m + 1                \n            elif arr[m]&gt;target:\n                r = m\n            else:                \n                return True\n        return False\n\n\nsoln = Solution()\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],3)\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],13)\n# soln.searchMatrix([[1,3]],3)"
  },
  {
    "objectID": "posts/leetcode/4-search_a_2d_matrix/LC74.html#submit",
    "href": "posts/leetcode/4-search_a_2d_matrix/LC74.html#submit",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "3. Submit",
    "text": "3. Submit\n\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#introduction",
    "href": "posts/notes/coding/2-linux_setup.html#introduction",
    "title": "Setting up a Data Science Machine",
    "section": "1. Introduction",
    "text": "1. Introduction\nThis post shows how to set up Linux-based Python Notebooks on a Windows PC for Data Science and Deep Learning Projects.\nOne of the drawbacks of Python-based Projects are compatability issues with packages which were developed with Linux.\nLinux is often preferred for Python development due to its:\n- powerful terminal for scripting and automation\n- has a open-source philosophy fostering community-driven ecosystem\n- containerization (e.g. Docker) and orchestration (e.g. Kubernetes)\n- Has a robust package management (APT and YUM)\n- Resource efficiency suitable for running Python applications (in resource-constrained environments)\n- compatibility with production environments & real-world deployments"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#linux",
    "href": "posts/notes/coding/2-linux_setup.html#linux",
    "title": "Setting up a Data Science Machine",
    "section": "2. Linux",
    "text": "2. Linux\n\n2.1 Install Linux\nI had previously blindly installed Linux, officially named “Windows Subsystem for Linux (wsl)” and then never used it again.\nI’ll firstly uninstall the existing distribution, then install a fresh copy.\n\nCheck any existing installation: wsl -l\nIf exists, uninstall: wsl --unregister Ubuntu\nRun 1. again wsl - l\nInstall Linux wsl --install\nCreate username\nCreate passwword\n\n\nwsl -l # Run in Windows Powershell \nwsl --unregister Ubuntu # Unregister if exists\nwsl -l\nwsl --install # Install wsl\n\n\n\n\n2.2 Linux Basics\n\nUsername: whoami\nSwitch user (from admin): sudo -u user_name -i\nSwitch user (user login): su - username\nWorking directory: pwd\nMove to folder in current directory : cd /\nHome: echo $HOME\nMove to root : cd /\nMove up 1-level: cd ..\nList all in folder: ls\nMove up a level: cd ..\nPrivledges: sudo id\nCreate user: sudo adduser new_user_name\nList usernames: cut -d: -f1 /etc/passwd\nGrant “bob” permission to install a pkg:: sudo -u bob apt install pkg-name\nDownload url: wget url\nRemove: rm folder\nRemove forcefully : rm -rf folder\nMove folder: mv folder_from folder_to\nList human readable: ls -lh\nList all includes hidden: la -a\nList with permissions: ls -l\nAdd permissions to file: chmod u+x theshell.sh\nA Shell script: .sh\nRead .sh script: less scriptname.sh\nRun .sh with Bash: bash scriptname.sh\nRun .sh with Bash accept all licenses: bash scriptname.sh -b\nRun .sh with pattern with Bash: bash Miniforge3-*.sh -b\nAutomatically runs when Terminal starts: .bashrc\nEdit a script: vim .bashrc\nBash history: cat .bash_history\nSearch Bash history: ctrl r + word\nRun last command starting with: !ju (runs jupyter if you’ve previously run it)\nRerun last command: !!\nMove to start of line: ctrl+a\nMove to end of line: ctrl+e\nMove by word: alt+l, alt+r\nCreate alias: alias jl = \"jupyter lab --no-browser\"\n[vim] - enter normal mode: Esc key\n[vim] - move to front: gg\n[vim] - move to end: G\n[vim] - highlight to end: V(visual mode) G (move to end)\n[vim] - move along word: h,j,k,l,w,b,e,0\n[vim] - move along line: 0,$,^\n[vim] - move along screen: H,M,L\n[vim] - move along pages: ctrl + f,b,d,u\n[vim] - move line: zt,zz,zb\n[vim] - search: /pattern,?pattern,n,N\n[vim] - move line nbr: :[line number]\n[vim] - make changes / insert mode: i then esc\n[vim] - save changes: :w\n[vim] - quit: :q\n[vim] - quit and discard changes: :q!\n[vim] - help: self-explanatory"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#python",
    "href": "posts/notes/coding/2-linux_setup.html#python",
    "title": "Setting up a Data Science Machine",
    "section": "3. Python",
    "text": "3. Python\nThere are several options for building linux python projects:\n\nConda: For extensive package management and control or flexibility beyond deep learning/data science.\nMiniforge: For lightweight and focused option for deep learning/data science projects.\nAnaconda: For a convenient, pre-configured environment for data science and deep learning, but be mindful of its larger size.\n\nFor my purposes, I’d like to be focused on deep learning / data science projects hence I’ll install Miniforge.\nSee miniforge github\n\n3.1 Miniforge\nMiniforge offers a powerful and user-friendly environment management platform for data science and deep learning.\nSeveral reasons to use Miniforge:\n- Virtual environments: Isolate projects and manage dependencies.\n- Pre-built environments: Quickly set up optimized environments (TensorFlow, PyTorch, etc.).\n- Cross-platform compatibility: Works on Windows, macOS, and Linux.\n- Large community and support: Extensive resources and active development.\n- Performance and efficiency: Caching and optimized packages.\n- Free and open-source: No licensing costs or limitations.\n\n\n3.2 Get Miniforge download link\n\nGet amd64 (Windows) download link from Miniforge Github\nDownload link used: “https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh”\n\n\n\n\n3.3 Install Miniforge in Ubuntu\n\nOpen Windows Terminal (this should automatically open Ubuntu now)\nGo to Home directory (echo $HOME) :\n\nLogging in su - username or\nMoving up cd .. and down cd folder_name_in_curr_dir\n\nGo to your home/directory: echo $HOME\nCreate a new working directory: mkdir downloads\nMove to downloads folder: cd downloads\n\nThis folder should be empty, and your Ubuntu should be not found with these keywords: Python, Jupyter, ipython etc.\nIf they are found:\n\nUninstall: pip install ipython,\nDelete: rm -rf ipython or rm usr/bin/jyp or\nMove: mv folder_from folder_to\n\n\nDownload url: wget the_copied_url_link_from_github_above or\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n\n\n\n3.4 Run downloaded Miniforge shell script\n\n[Manual Method]:\n\nAccept All Permissions (Creates environment variables so that keywords like ‘conda’ works and automatically runs Conda when Terminal is first logged on and activates a base environment. This automation is done by editting the .bashrc file.) or\n\n[Script Method]:\n\nbash Miniforge3-*.sh -b and then\n~/miniforge3/bin/conda init bash. This runs python file conda.py within miniforge which runs another file that creates the Conda Paths and Adding Paths to Ubuntu Environment variables (same as accepting all permissions in manual method)\n\n\nThere should be two folders: downloads and miniforge3 in the Home directory (Ignore nbs, this is created later)"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#conda",
    "href": "posts/notes/coding/2-linux_setup.html#conda",
    "title": "Setting up a Data Science Machine",
    "section": "4. Conda",
    "text": "4. Conda\nPython should be now installed via miniforge3:\n- which python should be running from miniforge3 folder within your Home directory.\n- If not, something went wrong!\n\n\n4.1 Conda basics\n\nShow conda arguments: conda\n\nGeneral system info: conda info\n\nShow environments: conda env\n\nCreate new environment: conda create -n deep_learning\n\nActivate environment: conda activate deep_learning\n\nShow installed packages: conda list\n\nInstall a package: conda install package_name\n\n\n\n4.2 Install Pytorch\nGo to Official Website and choose accordingly and install\nI used conda install pytorch torchvision torchaudio cpuonly -c pytorch\nNotes: Following the website ensures all binary dependencies are install, simply typing pip install pytorch wont work as normally due to requiring to also needing to installing CUDA SDK (if you have a NVidia GPU)\n\n\n\n4.3 Checking Pytorch is working\n\nHave Ipython installed and ipython\nimport torch\ntorch. + *tab* button This should display a list of available pytorch methods.\nctrl_d to exit"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#jupyter-notebooks",
    "href": "posts/notes/coding/2-linux_setup.html#jupyter-notebooks",
    "title": "Setting up a Data Science Machine",
    "section": "5. Jupyter Notebooks",
    "text": "5. Jupyter Notebooks\nInstall Jupyter Lab to have suite of notebooks and other useful tools for testing and developing data science and deep learning projects.\n\n5.1 Install Jupyter Lab\nGo to Official Website and select appropriate install option I used conda install -c conda-forge jupyterlab.\n\n\n\n5.2 Run Jupyter Lab\n\nRun Jupyter: jupyter lab or\nRun Jupyter: jupyter lab --no-browser (avoids attempting to open a browser in linux because it cant)\n\n\n\n\n5.3 Automate Alias\nSave alias jl=\"jupyter lab --no-browser\" into .bashrc to jl works everytime:\n\nOpen bashrc: vim ~/.bashrc\nGo to End: G\nPaste: alias jl=\"jupyter lab --no-browser\nSave: :qw: (quit q and save w)\n\n\n\n\n5.4 Open in Browser\n\nOpen in Browser by [Control+Click] the link\n\n\n\n\n5.5 Save First Notebook in Linux\nTry out PyTorch in the Notebook and save it."
  },
  {
    "objectID": "posts/notes/linear_algebra/1-chg_of_bse.html#normal-mode",
    "href": "posts/notes/linear_algebra/1-chg_of_bse.html#normal-mode",
    "title": "Notes: Change of Basis",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/3-eigen_examples.html#normal-mode",
    "href": "posts/notes/linear_algebra/3-eigen_examples.html#normal-mode",
    "title": "Eigenvales and Eigenvectors Example",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/5-similar_matrices.html#normal-mode",
    "href": "posts/notes/linear_algebra/5-similar_matrices.html#normal-mode",
    "title": "It’s nice to be similar (matrices)",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  }
]