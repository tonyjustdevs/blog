[
  {
    "objectID": "designpatterns.html",
    "href": "designpatterns.html",
    "title": "Design Patterns 💻",
    "section": "",
    "text": "DP 4: Singleton Pattern\n\n\n\n\n\n\ndesign patterns\n\n\n\nA Design (or Anti) Pattern Allowing Only A Single Instance\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specificsgit\n\n\n\n\n\nDec 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 2: Interfaces [Part 1] - ABC Abstract Base Classes\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specifics\n\n\n\n\n\nDec 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 1: Encapsulation - Getter Method in Python\n\n\n\n\n\n\ndesign patterns\n\n\n\nUsing Python’s @property to create a getter method\n\n\n\n\n\nNov 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "computerscience.html",
    "href": "computerscience.html",
    "title": "Computer Science 💻",
    "section": "",
    "text": "DSA 51: Array-Based Heaps [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Cool Data Structure 😎 \n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 52: Array-Based Heaps - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Useful Data Structure 🔨\n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 50: Binary Search Trees - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCh.15 Max, Pre & Post-Order Traversals\n\n\n\n\n\nMar 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 49: Binary Search Trees - Delete Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA Thoroughly Commented Scenario-Style Coding of BST’s delete_node Function\n\n\n\n\n\nMar 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 48: Binary Search Trees - Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting BST Operations From Scratch All At Once\n\n\n\n\n\nMar 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 46: Binary Search Trees - Delete [Part 9]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCleaner Implementation with Less Code\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 47: Binary Search Trees - Traverse [Part 10]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nIn-order Traversal Implementation\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 45: Binary Search Trees - Delete [Part 8]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 2: Zero, 1 or 2 Children\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 44: Binary Search Trees - Delete [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 1: Zero or 1 Children Nodes Only\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 42: Binary Search Trees - Alternative Approaches [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nLearning to Convert between Recursion and Iterative Approaches\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 43: Binary Search Trees - Sir-Insert-A-Lot [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsert a List of Integers into a Binary-Tree\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 41: Binary Search Trees - Insertion [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsertion Attempt\n\n\n\n\n\nFeb 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 40: Binary Search Trees - Search [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nFirst Attempt Raw\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 25: locals()\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nUseful Built-in Function to Obtain Locals Variables & Their Values\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 39: Binary Search Trees - Rules [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA basic BST Implementation\n\n\n\n\n\nFeb 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 37: Singly & Doubly Linked List - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 14 Exercises 1-5, J.Wengrow Vol 2\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 38: Binary Search Trees - Basics [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTrees & Binary Trees: Useful Terms\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nGO 1: Install & G’Day World\n\n\n\n\n\n\ncoding\n\n\ngolang\n\n\n\nLet’s Go 🚤!\n\n\n\n\n\nFeb 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 36: Doubly Linked List [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAllowing for Forward and Backwards Traversal\n\n\n\n\n\nFeb 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 35: LinkedList - Insert & Delete [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nThe Two Other Important Operations\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 24: Falsy (& Truthy) Values\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Pythonic Programming with Falsy Values\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 34: LinkedList - Read & Search [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTwo Important Operations as Functions\n\n\n\n\n\nFeb 16, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 31: Quickselect [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nGetting the kth item by adapting the quicksort algorithm\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 33: Nodes & Linked Lists [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBrief introduction to node-based data structures\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 32: Quick Algorithms - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 13 Exercises, J.Wengrow Vol 1\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 30: Quicksort [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementation with Partitioning\n\n\n\n\n\nFeb 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 29: Dynamic Programming - Exercises [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAddition, Golomb & Unique Path Questions\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 28: Dynamic Programming [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving Function Efficiency with the Memoization Technique\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 27: Anagram - Call Stack\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAn introductory look at the call stack of the anagram recursive function\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 26: Recursion - Anagram Generation [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAnagram Recursive Function From Scratch\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 23: Logging\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Logs for Different Levels\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 25: Recursion - Exercises [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nMore recursion examples and exercises\n\n\n\n\n\nFeb 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 24: Recursion - 3 More Examples [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSummation, String-Reversal & Counting-Letter\n\n\n\n\n\nFeb 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 23: Recursion - In-Place Modification [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreating & Modifying Arrays\n\n\n\n\n\nFeb 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 22: Recursion - Factorial [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBase-Case\n\n\n\n\n\nFeb 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 21: Recursion - With Base-Case [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nProper structure of a recursive function\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 20: Recursion [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nComparing a simple while-loop versus a recursive function\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 19: Queues - Print [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplement a simple interface for a PrintManager class\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 18: Queues [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nQueues are like a Macca’s Drive-Thru\n\n\n\n\n\nJan 31, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 17: Stacks - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 9, J.Wengrow Vol 2\n\n\n\n\n\nJan 30, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 16: Stacks - Linter [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nRecording first attempt writing a (Braces) Linter class\n\n\n\n\n\nJan 29, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 15: Hash Tables - Exercises [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 8 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 14: Hash Table - Speed Comparisons [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving time-complexity of an algorithm with a hash table\n\n\n\n\n\nJan 26, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 13: Stacks - An Abstract Class [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSometimes it’s nice to be structured & orderly\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 12: Hash Tables - Collisions [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCollisions in Hash Tables explained with a suggestion solution\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 11: Hash Tables - Hash Functions [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreate hash tables, hash functions and replicate how the data is in memory\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 10: Insertion Sort - Shift & Insert\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\n3rd attempt which uses less variable assigning\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 9: Insertion Sort - With Test Scenarios\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nEquivalent Implementations Using for & while-loops\n\n\n\n\n\nJan 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 8: Big O - Analysing Algorithms\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nDescribing Algorithms & Functions in Big O notation - Chapter 5 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 5: 49 - Group Anagrams\n\n\n\n\n\n\nleetcode\n\n\n\nGroup Anagrams\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 7: \\(BubbleSort()\\) Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementing from scratch and charting the time complexity\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 6: Binary Search Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting binary search from scratch and testing array sizes\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 5: Big O - String Select Function\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercise 4, J.Wengrow Vol 2\n\n\n\n\n\nJan 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 4: Big-O - Chessboard & Grains Problem\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercises 3, J.Wengrow Vol 2\n\n\n\n\n\nJan 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 3: Binary Search - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 2 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 2: Array and Sets - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 1 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 5, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 1: Big-O - Arrays and Sets\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nBig-O for Array Operations\n\n\n\n\n\nJan 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 22: Python Metaclasses - Customising Class Creation\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nBeing very meta\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 4: Singleton Pattern\n\n\n\n\n\n\ndesign patterns\n\n\n\nA Design (or Anti) Pattern Allowing Only A Single Instance\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 21: Magic Method: __call__\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nAllowing instances to be called like functions\n\n\n\n\n\nDec 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 20: Unicode, UTF-8 and Bytes\n\n\n\n\n\n\ncoding\n\n\n\nConverting my (Chinese) name to bytes and back\n\n\n\n\n\nDec 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specificsgit\n\n\n\n\n\nDec 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 2: Interfaces [Part 1] - ABC Abstract Base Classes\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specifics\n\n\n\n\n\nDec 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 19: uv Python & Package Manager\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nA modern alternative to creating & managing Python projects\n\n\n\n\n\nDec 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 1: Encapsulation - Getter Method in Python\n\n\n\n\n\n\ndesign patterns\n\n\n\nUsing Python’s @property to create a getter method\n\n\n\n\n\nNov 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 15: Python Exceptions 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nDel ving into Python Exceptions, In-Builts vs Custom Exceptions, Assert, Raise and Exception-Handlers\n\n\n\n\n\nNov 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 18: Introduction to C# in Visual Studio Code\n\n\n\n\n\n\nc#\n\n\n\nCreating, Building and Running Simple C# Console Apps\n\n\n\n\n\nOct 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 17: Transfer Multiple Issues via Github API in Bash\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\nbash\n\n\n\nRun a simple loop to transfer multiple issues from one repo to another\n\n\n\n\n\nOct 29, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 16: Open Source as a Beginner\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning How To Contribute to Open Source Projects as a Beginner\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 14: Python Classes Basics 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nPython Classes, Instance Objects, Data Attributes and Method Objects\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 13: Shallow or Deep?\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning to copy the right way\n\n\n\n\n\nOct 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 12: Create new key-bindings in VSCode via JSON file\n\n\n\n\n\n\ncoding\n\n\nvscode\n\n\n\nA handy keybinding to switch between Terminals in VSCode\n\n\n\n\n\nOct 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 11: Using Github API via Python\n\n\n\n\n\n\ngithub\n\n\napi\n\n\npython\n\n\n\nLearn to update an Issue Description with Github’s API\n\n\n\n\n\nOct 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 10: Add a script to PATH\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nRun a script without specifying its path\n\n\n\n\n\nSep 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 9: Creating and using Symlinks\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nAvoiding unnecessarily duplicating files with Symlinks\n\n\n\n\n\nSep 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 8: How to install Quarto via WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nMigrating quarto blog from windows to wsl\n\n\n\n\n\nSep 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 7: Virtual Environments\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nSetting up virtual environments to produce reproducible work\n\n\n\n\n\nJul 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 6: Measuring Model Accuracy\n\n\n\n\n\n\nmachine learning\n\n\n\nStep-by-step guide on how to measure accuracy of a deeplearning model\n\n\n\n\n\nApr 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 5: Debugging a 1-Hidden-Layer Neural Network Model\n\n\n\n\n\n\ncoding\n\n\ndebugging\n\n\n\nDocumenting my debugging of a neural network model I built from scratch\n\n\n\n\n\nApr 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 4: Create new Users in WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nQuick instructions to set up a new user in wsl\n\n\n\n\n\nMar 15, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 3: Bash Basics\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\nbash\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2: Data Science Machine\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 1: Github Issues Automation\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 4: 74 - Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 3: 704 - Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 2: 150 - Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 1: 155 - Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "mathematics.html",
    "href": "mathematics.html",
    "title": "Mathematics 🧮",
    "section": "",
    "text": "Calculus 17: Simple Pendulum\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.3-6 Ex.103 Chain-Rule, Thomas 13e pp.170\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 16: More Sequence Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.39-49 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 15: Convergence & Divergence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.27-37 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 14: n’th Derivative with % (modulo) & sympy\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3-5 Derivatives of Trigonometric Functions, Thomas 13e pp.161\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 13: Limit of Cosine\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch2-4 One-Sided Limits, Thomas 13e pp.91\n\n\n\n\n\nJan 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 12: Derivatives Of Trigonometric Functions\n\n\n\n\n\n\ncalculus\n\n\n\nUsing Python’s sympy library to find numeric & exact solutions\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 11: More Sequences\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 10: Generating & Coding A Sequence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 20, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 9: Terms of Sequences - Selected Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 8: Derivative of An Exponential\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.3 Derivatives, Thomas 13e pp.140\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 7: Rates of Change Applications\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex25-31, Thomas 13e pp.126-127\n\n\n\n\n\nJan 8, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 6: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex23, Thomas 13e pp.126\n\n\n\n\n\nJan 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 5: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex17, Thomas 13e pp.126\n\n\n\n\n\nJan 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 4: Applying Binomial Theorem\n\n\n\n\n\n\ncalculus\n\n\nbinomialtheorem\n\n\n\nFind the derivative and plot the tangent (from Ch3.1.Ex9, Thomas 13e pp.126)\n\n\n\n\n\nJan 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 3: Synthetic Division\n\n\n\n\n\n\ncalculus\n\n\n\nLearning a factoring technique (from Ex 2.2.85, Thomas 13e pp.77)\n\n\n\n\n\nDec 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 2: Plotting functions with limits\n\n\n\n\n\n\ncalculus\n\n\n\nCh2.2: Limit of a Function & Limit Laws (Ex2.2.11-21, Thomas 13e pp.74)\n\n\n\n\n\nDec 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 1: Inverse Properties of \\(a^x\\) and \\(\\log_a x\\)\n\n\n\n\n\n\ncalculus\n\n\n\nExploring the compositions of \\(a^x\\), \\(\\log_a x\\), \\(e^x\\) and \\(\\ln x\\) and deriving the Change of Base formula\n\n\n\n\n\nOct 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 6: More Eigen examples\n\n\n\n\n\n\nlinearalgebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 4: Diagonal Matrices are trivial\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 5: It’s nice to be similar (matrices)\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 3: Eigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinearalgebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 2: Eigen is my valentines in 2024\n\n\n\n\n\n\nlinearalgebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 1: Change of Basis\n\n\n\n\n\n\nlinearalgebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 2)",
    "section": "",
    "text": "Automation of finding the best parameters (lowest loss) based on Mean Average Error (MAE) using Gradient Descent for our Quadratic Function"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#import-libraries",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 2)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd\nfrom functools import partial"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "title": "Neural Network Basics (Part 2)",
    "section": "2. Upload Data and Convert Data to Pytorch Tensors",
    "text": "2. Upload Data and Convert Data to Pytorch Tensors\n\ndf = pd.read_csv(\"upload_dataset.csv\")\nx_trch = torch.tensor(df.x) \ny_trch = torch.tensor(df.y)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "title": "Neural Network Basics (Part 2)",
    "section": "3. Create Customisable Quadratic functions and Interactively Plot with MAE",
    "text": "3. Create Customisable Quadratic functions and Interactively Plot with MAE\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\ndef torch_mae(prediction, actual): return (torch.abs(prediction-actual).mean())\ndef torch_mse(prediction, actual): return ((prediction-actual)**2).mean()\n\n\n# def mae(prediction, actual): return np.mean(abs(prediction-actual))\n# def torch_mae(prediction, actual): return np.mean(torch.abs(prediction-actual))\n# def mae(prediction, actual): return (torch.abs(prediction-actual).mean())\n# def mae2(prediction, actual): return abs(prediction-actual).mean()\n# def mae_jh(prediction, actual): return (abs(prediction-actual)).mean()\n# def mse_jh(prediction, actual): return ((prediction-actual)**2).mean()\n# def mae(preds, acts): return (torch.abs(preds-acts)).mean()\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,2.1,0.1),b=(0,2.1,0.1),c=(0,2.1,0.1))\ndef interactive_plot(a,b,c):\n# 1.    plot scatter\n    plt.scatter(x_trch, y_trch)\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = x_trch\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n# 4.    calc mae\n    y_actual     = y_trch\n    y_predicted  = custom_quad_fn(a,b,c)(x_trch)\n    interact_mae = torch_mae(y_predicted,y_actual)\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae:.2f}\")"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "title": "Neural Network Basics (Part 2)",
    "section": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)",
    "text": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)\nThe key thing to understand if whether the loss function gets better or worse when you increase the parameters a little.\nThere are two ways we can try: 1. Manually adjust the parameter: Move each parameter each way and observe the impact to MAE.\n2. Calculate the Derivative of the parameter: A Derivative iS a function that tells you if you increase the input the: - direction in which output changes (increases or decreases) and the;\n- magnitude of the change to the output\n\n4.1 Create Mean-Absolute-Error (mae) Quadratic Function\nThis function will take in the parameters or coefficients of a quadratic function and output the MSE. - Input: coeffiicents of quadratic - Output: MAE (between the prediction of the quadratic with the coffecients of the quadratic and the actual predictsions)\n\ndef mae_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mae(y_predicted_trch,y_actual_trch)\n\ndef mse_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mse(y_predicted_trch,y_actual_trch)\n\nThe chart shows MAE(2,2,2) = 1.4501 loss Our mae_function also calculates 1.491 loss.\n\nmae_quad_fn(x_trch=x_trch,y_trch=y_trch,abc_params=[1.0,1.0,1.0])\n\ntensor(2.6103, dtype=torch.float64)\n\n\nA tensor is a pytorch type that works with: - lists (1D tensors) - tables (2D tensors) - layers of tables of numbers (3D tensors) and etc\n\n\n4.2 Telling PyTorch to calculate gradients\nBy calling method .requires_grad_(), our abc_rg tensor is not will calculate gradients whenever we use the tensor.\n\n# rank 1 tensor\nabc_rg = torch.tensor([1.0,1.0,1.0])\nabc_rg.requires_grad_()\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\nabc_rg\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\n4.2.1 Method .requires_grad_()\ngrad_fn=&lt;MeanBackward0&gt; shows the gradients are calculated to for each parameter (our inputs)\n\nloss = mae_quad_fn(x_trch, y_trch, abc_rg)\nloss\n\ntensor(2.6103, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n\n4.2.2 Method .backward()\nThis adds an attribute .grad to our abc_rg tensor.\n\nloss.backward()\n\n\n\n4.2.3 Attribute .grad\nThis attributes tells us if we increase the input slightly in the same position of this tensor, the loss will increase (if its positive) or decrease (if negative)\n\nabc_rg.grad\n\ntensor([-1.3529, -0.0316, -0.5000])\n\n\n\n\n4.2.4 Increase our abc parameters and recalculate loss\n\nwith torch.no_grad():\n    print(f\"loss before: {loss}\")\n    abc_rg -= abc_rg.grad * 0.01\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    print(f\"loss after: {loss}\")\n\nloss before: 2.61030324932801\nloss after: 2.5894896953092177\n\n\n\n\n4.2.5 Automate it\nCreate a loop that decreases the loss by iteratively increasing the parameters (since the gradients are negative, or vice versa)\n\nfor i in range(10):\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    loss.backward()\n    with torch.no_grad(): abc_rg -= abc_rg.grad * 0.01\n    print(f\"step {i}: {loss} - {abc_rg.grad}\") \n\nstep 0: 2.5894896953092177 - tensor([-2.7058, -0.0632, -1.0000])\nstep 1: 2.547862587271633 - tensor([-4.0587, -0.0947, -1.5000])\nstep 2: 2.4854217639359875 - tensor([-5.4116, -0.1263, -2.0000])\nstep 3: 2.4021673865815485 - tensor([-6.7645, -0.1579, -2.5000])\nstep 4: 2.2980994552083187 - tensor([-8.1175, -0.1895, -3.0000])\nstep 5: 2.173217969816296 - tensor([-9.4704, -0.2211, -3.5000])\nstep 6: 2.0300959430578267 - tensor([-10.6892,  -0.3684,  -3.9000])\nstep 7: 1.883669135864714 - tensor([-11.9080,  -0.5158,  -4.3000])\nstep 8: 1.740979068220988 - tensor([-12.9396,  -0.8000,  -4.6000])\nstep 9: 1.5914231086209807 - tensor([-13.9712,  -1.0842,  -4.9000])\n\n\n\n\n\n5 Parameters are getting closer\nThe parameters started as 1,1,1 and now are 1.9, 1.0, 1.3, the underlying function was modelled with 3, 2, 1 so its getting there!\n[Future Iteration] How to just fix a parameter and just move the others?\n\nabc_rg\n\ntensor([1.8739, 1.0365, 1.3170], requires_grad=True)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "href": "posts/datascience/machinelearning/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nNext A universal function called the ReLU Function (rather than a quadratric function) is used for our modelling.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "1. Download Kaggle Data",
    "text": "1. Download Kaggle Data\nLog into Kaggle:\n1. Competitions\n2. Titanic\n3. Data\n4. Train.csv and Download"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "2. Clean Dataset",
    "text": "2. Clean Dataset\nEach single passenger is represented by a single row with demographics and information across the columns.\nFor this first attempt, I’ll keep the model simple and used 8 columns and discarded the rest.\n[Future Iteration]: Would using more columns increase my accuracy?\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger - Kaggle Data Description\nNote: There are originally 891 Passengers (rows) in the training dataset.\nThere were a few steps taken to clean the data:\n1. Keep Certain Columns Only:\n- Survived\n- Pclass - Sex - Age - SibSp - Parch - Fare - Embarked 2. Remove blanks from: - Sex (177 rows removed) - Embarked (2 rows removed) Columns: Remaining Passengers (712 = 891-177-2)\n\nCreate a New Sheet and Copy over the editted Dataset"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "3. Binary Categorical Variables",
    "text": "3. Binary Categorical Variables\nRecall a Function has inputs and parameters. The output is calculated by adding the all the inputs which are weighted (multiplied) by the parameters.\nIn neural network basics: - the inputs were a single variable x and the output was a single y (or f(x)).\n- the parameters (coefficients of x) could be optimised against a Loss Function (Mean Squared Error) to achieve a high accuracy (good predictability) for that function, called Gradient Descent - an arbitrary number of Rectified Linear Unit (ReLU) could be added together to form any function to fit a given set of data and parameter (weights) can be optimised to minimise the loss function as above with gradient descent.\nSimilarly, the inputs in the Titanic model will be the information describing the passengers, i.e. columns in our spreadsheet, are multiplied by the parameters (weights or coefficients) to represents its importance.\n\nQuestion: But how can a parameter (number) be multiplied to word (text) such as male or female from the Sex Column or Letter S or C or Q from the Embarked Column?\nAnswer: You Can’t.\n\nHowever, Categorical Variables (unordered) can be converted into Binary Categorical Variables:\n- IsMale will indicate a 1 for True (Male) and 0 for False (Female)\n- Embarked has 3 categories “S, C and Q: Having two columns (S and C) to represent the 3 categories will suffice. If both S and C columns have 0’s, this implies it is a Q, so we do not need the extra column to have all the information.\n- PClass (1, 2 and 3) also has 3 categories and is treated the same as above.\n- Age and Fare are continuous values and left them as is for now"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "4. Regression",
    "text": "4. Regression\nI created random variables (coefficients or weights for our parameters) with rand() and multiplied them to each parameter. I did this for several rows to and looked at the output.\nLooks like Age and Fare columns are dominating our function.\n\n\n4.1 Dealing with Continuous Variables Age and Fare\nIts probably fair (see what I did there) that a Passenger’s age (or fare) shouldn’t be the only two defining factors to determine their survivability as the above model suggests.\nThese values need to be normalised: - For Age, I divided each passengers age by the maximum age. - For Fare, I took the Logarithm of each passengers fare. Taking the Log of a variable where there are very small values and a few large ones distributes the values more evenly.\n\n\n\n4.2 Prediction and Loss and Average Loss\nPrediction: Multiply each parameter by the random coefficient created and sum it up to have our prediction.\n- I used the SumProduct() function. - I also created a manual linear version from scratch to see test my understanding was correct and sumproduct was working as expected. It was.\nLoss: It’s the survival (0 No, 1 Yes) minus the Prediction, then squared. - This is the squared error. If the errors are not squared, the errors end up cancelling each other off. Alternatively, the absolute errors could be taken done previously.\nAverage Loss: Self-explanatory.\n\nNote: Current Average Loss is 0.886 with random parameters.\n\n\n4.3 Gradient Descent (or Solver)\nSetting the Solver to Minimise our Average Loss, our parameters have been adjusted and Average Loss has come down to: 0.535!\nNot but but this isn’t a neural net yet, its just a regression."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "5. Neural Network",
    "text": "5. Neural Network\nParams_2: Add another set of random coefficients.\nLinear_2: Calculate the linear model on this set of coefficients.\nReLU: ReLUs are calculated with an IF() statement, if it is below zero, then set to zero, otherwise keep the value.\nPrediction: Add the ReLUs.\nLoss Prediction minus Survived.\nAverage Loss: Run Solver, but this time allow the change of both sets of coefficients Params_1 and Params_2\nNote: Current Neural Network Average Loss is 0.527 with random parameters.\n\n[Future Iteration]: To be honest, I haven’t quite understood fully whats going on here. The concept of adding a second set of parameters and then having two Linear Models and adding together their reLUs will give a prediction that can be optimised, just dont get it yet. be fair, I just learnt Gradient Descent a day or two ago.\n\n5.1 Error In Optimisation - All ReLUs going to Zero\nHaving no constraints on whether coefficients can be negative or positive, the Solver found the most convenient result of making all parameters less than zero, hence making outputs a negative linear output, which makes all the ReLUs Zero, hence simply making the prediction that everyone died! A quick and dirty prediction thats not too bad but very scientific…\nNote: I’m currently using WPS Solver rather than Excel Solver (Don’t own paid version of Excel). Not sure if I did a mistake in my model or its a Solver thing.\n\n\n\n5.2 Setting Constraints (Coefficients &gt; 0)\nBy placing the constraint the Solver seems to finally do what is expected.\nThe Average Loss has come down from the Regresssion 0.535 to 0.235!\n\n\n\n5.3 Added Ones Columns\nBut this didn’t fix the Solver Issuer.\n\n\n\n5.4 Matrix Multiplication\nI made a Matrix Multiplication version and optimised with the same silly negative parameters solution"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "href": "posts/datascience/machinelearning/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "6. Mission Failed.",
    "text": "6. Mission Failed.\nHaving downloaded the spreadsheet from Jeremy and ran the Solver, the Zero ReLUs error persists. This is a WPS Sheets issue.\nI also tried getting Solver on Google Sheets with no Luck however my emails permissions didn’t allow the install. Will give it a go to fix it next time.\nFor now, today I’ll admit defeat. Onwards to tomorrow…\nI’ll upload this notebook anyway because I want to record my failures as well as my triumphs."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "",
    "text": "I’ve just created my first multi-category classifier using Jeremy Howard’s popular fast ai which is an astraction layer library built on top of the most world’s used deep-learning library PyTorch. I’ve documented the process including the issues I faced (i.e. bugs)\nI found it more easier to digest and understand this process by splitting the steps into 3 parts:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "Part 1: Create Learner (.pkl file)",
    "text": "Part 1: Create Learner (.pkl file)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.1 Install and import libraries",
    "text": "1.1 Install and import libraries\n\n!pip install timm\n!pip install fastai \n\n\nfrom fastai.vision.all import *\nimport timm"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.2 Download Pets Breed Data",
    "text": "1.2 Download Pets Breed Data\n\npath = untar_data(URLs.PETS)/'images'"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.3 Create Data Loader",
    "text": "1.3 Create Data Loader\n\n1.3.1 (A different) Labelling Function\nHere a different method to label our data was used:\n\nIn ‘noodles vs rice’ model: There were two parent folders separating two categories of data: get_y=parent_label\nIn ‘saving a fast ai’ model: There was a custom labelling function that looked for capital letters for cat breeds def is_cat(x): return x[0].isupper()\nIn this model, I used Regex to find breed names before the last ’_’ in the file name: label_func=RegexLabeller(pat=r'^([^/]+)_\\d). See show_batch() output to see the file names examples.\n\nDid you notice this is the same dataset as the is_cat model? So changing our label resulted in a different model!\n\n\n1.3.2 Data Loader Code\n\npets_dataloaders =  ImageDataLoaders.from_name_func(\n    '.',\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat=r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.4 Batch Examples, Create Learner, Fine-Tune and Export",
    "text": "1.4 Batch Examples, Create Learner, Fine-Tune and Export\nI grouped these steps as the code are exactly the same in previous posts.\n\n1.4.1 Batch Examples\nThis function is also a good way to find out what is the file name structure if we were not sure.\n\npets_dataloaders.show_batch(max_n=8)\n\n\n\n\n\n\n\n\n\n\n1.4.2 Create Learner\nI am still using resnet model architecture for starters for reasons mentioned previously by Jeremy Howard\n\npets_learner = vision_learner(pets_dataloaders, resnet34, metrics=error_rate)\n\n\n\n1.4.3 Fine-Tune\n\npets_learner.fine_tune(3) \n\n\n\n1.4.4 Export\n\npets_learner.export('pets_learner.pkl')"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "href": "posts/datascience/machinelearning/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#numpy.maximum",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#numpy.maximum",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.1 numpy.maximum",
    "text": "2.1 numpy.maximum\n\nimport numpy as np\n\ndef sgl_relu_np(m,b,x):\n    y = m*x+b\n    relu_y = np.maximum(y,0)\n    return relu_y \n\nsgl_relu_np(1,1,1)\n\n2"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.clip---version-1",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.clip---version-1",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.2 torch.clip - version 1",
    "text": "2.2 torch.clip - version 1\nNote: torch.clip won’t work because it accepts tensors only, and the below function is inputting python native types\n\nimport torch\n\ndef sgl_relu_pytclip_v1(m,b,x):\n    y = m*x+b # input to torch needs to be a tensor, ie y=mx+b doesnt work as seen in error:\n    print(type(y))\n    return torch.clip(y,0.)\n    \n\nsgl_relu_pytclip_v1(1,1,1)\n\n&lt;class 'int'&gt;\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[3], line 9\n      5     print(type(y))\n      6     return torch.clip(y,0.)\n----&gt; 9 sgl_relu_pytclip_v1(1,1,1)\n\nCell In[3], line 6, in sgl_relu_pytclip_v1(m, b, x)\n      4 y = m*x+b # input to torch needs to be a tensor, ie y=mx+b doesnt work as seen in error:\n      5 print(type(y))\n----&gt; 6 return torch.clip(y,0.)\n\nTypeError: clip() received an invalid combination of arguments - got (int, float), but expected one of:\n * (Tensor input, Tensor min, Tensor max, *, Tensor out)\n * (Tensor input, Number min, Number max, *, Tensor out)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.clip---version-2",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.clip---version-2",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.3 torch.clip - version 2",
    "text": "2.3 torch.clip - version 2\n\ndef sgl_relu_pytclip_v2(m,b,x):\n    xs_tsr = torch.tensor(x)\n    y = m*xs_tsr+b # convert inputs to tensor first\n    print(type(y))\n    return torch.clip(y,0.)\n    \nsgl_relu_pytclip_v2(1,1,1)\n\n&lt;class 'torch.Tensor'&gt;\n\n\ntensor(2.)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.nn.functional.relu",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#torch.nn.functional.relu",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.4 torch.nn.functional.relu",
    "text": "2.4 torch.nn.functional.relu\nnn.relu also only takes Tensor input. I’ll use this function going forward.\n\nimport torch.nn.functional as nn\n\ndef sgl_relu_nn(m,b,x):\n    xs_tsr = torch.tensor(x)\n    ys_tsr = m*xs_tsr+b # convert inputs to tensor first\n    relu_y = nn.relu(ys_tsr)\n    print(type(relu_y))\n    return relu_y\n\nsgl_relu_nn(1,1,1)\n\n&lt;class 'torch.Tensor'&gt;\n\n\ntensor(2)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#create-noisey-data-we-wish-to-model",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#create-noisey-data-we-wish-to-model",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.1 Create noisey data we wish to model",
    "text": "5.1 Create noisey data we wish to model\n\nimport torch\nimport torch.nn.functional as nn\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact\n\ndef quad_fn(a,b,c,x): return a*x**2 + b*x + c\ndef quad_abc_fn(a,b,c): return partial(quad_fn,a,b,c)\n\nog_a= 3\nog_b= 2\nog_c= 1\n\nxs_100_tsr = torch.linspace(-2.1,2.1,steps=100)\nquad_og_model = quad_abc_fn(og_a,og_b,og_c)\n\nnp.random.seed(42)\n\ndef noise(tsr, scale): return np.random.normal(scale=scale,size=tsr.shape)\ndef add_scale_noise_to_tsr(tsr,scale,additive):\n    tsr = tsr+tsr*noise(tsr, scale)\n    tsr = tsr+noise(tsr, additive)\n    return tsr\n\nxs_20_tsr = torch.linspace(-2,2,steps=20)\nys_20_og_tsr = quad_og_model(xs_20_tsr)\nys_20_noisey_tsr = add_scale_noise_to_tsr(ys_20_og_tsr,0.15,1.5)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#recreate-double-relu-functions-learnt-earlier",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#recreate-double-relu-functions-learnt-earlier",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.2 Recreate Double ReLU functions learnt earlier",
    "text": "5.2 Recreate Double ReLU functions learnt earlier\n\ndef relu_dbl_fn(m1,b1,m2,b2,x):\n    y1 = m1*x+b1\n    y2 = m2*x+b2\n    return nn.relu(y1) + nn.relu(y2)\n\n\ndef relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2): return partial(relu_dbl_fn,m1,b1,m2,b2)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#create-mae-calculate-and-loss-function",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#create-mae-calculate-and-loss-function",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.3 Create MAE calculate and Loss Function",
    "text": "5.3 Create MAE calculate and Loss Function\n\ndef calc_mae(actual, preds): return torch.abs(actual-preds).mean()\n\ndef relu_2_loss_function(params):\n    def relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2): return partial(relu_dbl_fn,m1,b1,m2,b2)\n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(*params)\n    ys_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    return calc_mae(ys_20_noisey_tsr,ys_preds_20_tsr)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#loss-is-4.1318-with-original-input-tensor0.50.5-0.5-0.5",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#loss-is-4.1318-with-original-input-tensor0.50.5-0.5-0.5",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.4 Loss is 4.1318 with original input tensor([0.5,0.5,-0.5,-0.5])",
    "text": "5.4 Loss is 4.1318 with original input tensor([0.5,0.5,-0.5,-0.5])\nOriginal model predictions (blue line) are not great, not very close to our data (red dots)\nThat makes sense since I arbitrarily chose the parameters of 0.5 and -0.5\n\nm1b1_m2b2_tsr = torch.tensor([0.5,0.5,-0.5,-0.5],requires_grad=True)\nrelu_2_loss_function(m1b1_m2b2_tsr)\n\ntensor(4.1318, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n# @interact(m1=0.5,b1=0.5,m2=-.5,b2=-.5)\ndef relu_dbl_interactive_plotter_fn(m1,b1,m2,b2):\n    xs_sgl_100_tsr = torch.linspace(-4.1,4.1,steps=100)\n    \n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2)\n    ys_dbl_m1b1m2b2_100_tsr = relu_dbl_m1b1m2b2_model(xs_sgl_100_tsr)\n\n    plt.xlim((-2,2))\n    plt.ylim((-1,15))\n    plt.plot(xs_sgl_100_tsr, ys_dbl_m1b1m2b2_100_tsr)\n    plt.scatter(xs_20_tsr,ys_20_noisey_tsr, color='r')\n\n    # print(ys_20_noisey_tsr)\n    ys_dbl_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    mae = calc_mae(ys_20_noisey_tsr, ys_dbl_preds_20_tsr)\n    plt.title(label=f\"mae: {mae:.2f}\")\nrelu_dbl_interactive_plotter_fn(0.5,0.5,-0.5,-0.5)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#loss-with-gradient-descent-after-40-epochs",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#loss-with-gradient-descent-after-40-epochs",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.5 1.96 Loss with Gradient Descent after 40 epochs",
    "text": "5.5 1.96 Loss with Gradient Descent after 40 epochs\n\nm1b1_m2b2_tsr = torch.tensor([0.5,0.5,-0.5,-0.5],requires_grad=True)\n\nfor i in range(40):\n    loss = relu_2_loss_function(m1b1_m2b2_tsr)\n    loss.backward()\n\n    with torch.no_grad():\n        m1b1_m2b2_tsr -= m1b1_m2b2_tsr.grad*0.01\n        print(f\"loss_{i+1}: {loss:.2f} - [{m1b1_m2b2_tsr}]\")\n\nloss_1: 4.13 - [tensor([ 0.5049,  0.5045, -0.5039, -0.4975], requires_grad=True)]\nloss_2: 4.13 - [tensor([ 0.5147,  0.5135, -0.5118, -0.4925], requires_grad=True)]\nloss_3: 4.11 - [tensor([ 0.5295,  0.5260, -0.5237, -0.4850], requires_grad=True)]\nloss_4: 4.09 - [tensor([ 0.5493,  0.5420, -0.5399, -0.4745], requires_grad=True)]\nloss_5: 4.07 - [tensor([ 0.5741,  0.5615, -0.5606, -0.4610], requires_grad=True)]\nloss_6: 4.04 - [tensor([ 0.6038,  0.5845, -0.5857, -0.4445], requires_grad=True)]\nloss_7: 4.00 - [tensor([ 0.6386,  0.6110, -0.6153, -0.4250], requires_grad=True)]\nloss_8: 3.95 - [tensor([ 0.6784,  0.6410, -0.6488, -0.4030], requires_grad=True)]\nloss_9: 3.90 - [tensor([ 0.7237,  0.6740, -0.6865, -0.3785], requires_grad=True)]\nloss_10: 3.85 - [tensor([ 0.7744,  0.7100, -0.7282, -0.3515], requires_grad=True)]\nloss_11: 3.78 - [tensor([ 0.8306,  0.7490, -0.7742, -0.3215], requires_grad=True)]\nloss_12: 3.71 - [tensor([ 0.8916,  0.7900, -0.8245, -0.2885], requires_grad=True)]\nloss_13: 3.65 - [tensor([ 0.9573,  0.8330, -0.8791, -0.2525], requires_grad=True)]\nloss_14: 3.57 - [tensor([ 1.0277,  0.8780, -0.9379, -0.2140], requires_grad=True)]\nloss_15: 3.50 - [tensor([ 1.1028,  0.9250, -1.0008, -0.1730], requires_grad=True)]\nloss_16: 3.41 - [tensor([ 1.1827,  0.9740, -1.0679, -0.1295], requires_grad=True)]\nloss_17: 3.33 - [tensor([ 1.2674,  1.0250, -1.1392, -0.0835], requires_grad=True)]\nloss_18: 3.24 - [tensor([ 1.3567,  1.0780, -1.2146, -0.0355], requires_grad=True)]\nloss_19: 3.15 - [tensor([ 1.4508,  1.1330, -1.2941,  0.0145], requires_grad=True)]\nloss_20: 3.05 - [tensor([ 1.5497,  1.1900, -1.3776,  0.0665], requires_grad=True)]\nloss_21: 2.94 - [tensor([ 1.6533,  1.2490, -1.4653,  0.1205], requires_grad=True)]\nloss_22: 2.84 - [tensor([ 1.7616,  1.3100, -1.5559,  0.1755], requires_grad=True)]\nloss_23: 2.74 - [tensor([ 1.8746,  1.3730, -1.6496,  0.2310], requires_grad=True)]\nloss_24: 2.65 - [tensor([ 1.9926,  1.4375, -1.7457,  0.2860], requires_grad=True)]\nloss_25: 2.57 - [tensor([ 2.1154,  1.5035, -1.8419,  0.3385], requires_grad=True)]\nloss_26: 2.51 - [tensor([ 2.2432,  1.5710, -1.9384,  0.3885], requires_grad=True)]\nloss_27: 2.45 - [tensor([ 2.3758,  1.6400, -2.0349,  0.4360], requires_grad=True)]\nloss_28: 2.39 - [tensor([ 2.5133,  1.7105, -2.1317,  0.4810], requires_grad=True)]\nloss_29: 2.33 - [tensor([ 2.6552,  1.7815, -2.2286,  0.5235], requires_grad=True)]\nloss_30: 2.27 - [tensor([ 2.8015,  1.8530, -2.3256,  0.5635], requires_grad=True)]\nloss_31: 2.23 - [tensor([ 2.9509,  1.9240, -2.4228,  0.6010], requires_grad=True)]\nloss_32: 2.19 - [tensor([ 3.1036,  1.9945, -2.5202,  0.6360], requires_grad=True)]\nloss_33: 2.16 - [tensor([ 3.2595,  2.0645, -2.6177,  0.6685], requires_grad=True)]\nloss_34: 2.12 - [tensor([ 3.4186,  2.1340, -2.7154,  0.6985], requires_grad=True)]\nloss_35: 2.07 - [tensor([ 3.5809,  2.2030, -2.8133,  0.7260], requires_grad=True)]\nloss_36: 2.05 - [tensor([ 3.7455,  2.2705, -2.9113,  0.7510], requires_grad=True)]\nloss_37: 2.03 - [tensor([ 3.9124,  2.3365, -3.0094,  0.7735], requires_grad=True)]\nloss_38: 2.01 - [tensor([ 4.0815,  2.4010, -3.1077,  0.7935], requires_grad=True)]\nloss_39: 1.98 - [tensor([ 4.2528,  2.4640, -3.2062,  0.8110], requires_grad=True)]\nloss_40: 1.96 - [tensor([ 4.4251,  2.5245, -3.3031,  0.8250], requires_grad=True)]"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-13-relu/index.html#predictions-blue-line-vs-data-red-dots",
    "href": "posts/datascience/machinelearning/2024-03-13-relu/index.html#predictions-blue-line-vs-data-red-dots",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.6 Predictions (blue line) vs Data (red dots)",
    "text": "5.6 Predictions (blue line) vs Data (red dots)\nNew Parameters has created a Double ReLU predictions shaped closer to the Noisey Data as seen below!\n\ndef relu_dbl_interactive_plotter_fn(m1,b1,m2,b2):\n    xs_sgl_100_tsr = torch.linspace(-4.1,4.1,steps=100)\n    \n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2)\n    ys_dbl_m1b1m2b2_100_tsr = relu_dbl_m1b1m2b2_model(xs_sgl_100_tsr)\n\n    plt.xlim((-2,2))\n    plt.ylim((-1,15))\n    plt.plot(xs_sgl_100_tsr, ys_dbl_m1b1m2b2_100_tsr)\n    plt.scatter(xs_20_tsr,ys_20_noisey_tsr, color='r')\n\n    # print(ys_20_noisey_tsr)\n    ys_dbl_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    mae = calc_mae(ys_20_noisey_tsr, ys_dbl_preds_20_tsr)\n    plt.title(label=f\"mae: {mae:.2f}\")\nrelu_dbl_interactive_plotter_fn(m1=4.4251,  b1=2.5245, m2=-3.3031,  b2=0.8250)"
  },
  {
    "objectID": "posts/datascience/machinelearning/ml-001-string-cleaning.html",
    "href": "posts/datascience/machinelearning/ml-001-string-cleaning.html",
    "title": "ML 1: String Cleaning",
    "section": "",
    "text": "1. Import Data as a String\n\nplayer_str = \"\"\"\nid,   name,   dob\n8, iniesta  , 1984 \n 10,   messi , 1987  \n 16   ,pedri, 2003\n \"\"\"\n\nplayer_str\n\n'\\nid,   name,   dob\\n8, iniesta  , 1984 \\n 10,   messi , 1987  \\n 16   ,pedri, 2003\\n '\n\n\n\n\n1. split() each players by row\n\nSplit strings by a chosen delimiter\nA list is returned with each item or element as its own string\n\n\nplayer_str.split(\"\\n\") # split by \\n special character but theres white space items at start and beginning!\n# ie there are two items with just empty spaces at first and last entries.\n\n['',\n 'id,   name,   dob',\n '8, iniesta  , 1984 ',\n ' 10,   messi , 1987  ',\n ' 16   ,pedri, 2003',\n ' ']\n\n\n\n\n2. strip() white spaces before splitting\nRemove white space at the begininer and end of a string\n\nplayer_list = player_str.strip().split(\"\\n\") # split by \\n special character but theres white spaces!\nplayer_list # the list no longer has the first and last white space elements\n\n['id,   name,   dob',\n '8, iniesta  , 1984 ',\n ' 10,   messi , 1987  ',\n ' 16   ,pedri, 2003']\n\n\n\n\n3. iterate through players\nEach line is a single long string for each player or one column.\n\nfor i,player_line in enumerate(player_list): # iterate through each item of list and do something\n    print(i, repr(player_line), type(player_line)) # showing that they're indeed strings\n\n0 'id,   name,   dob' &lt;class 'str'&gt;\n1 '8, iniesta  , 1984 ' &lt;class 'str'&gt;\n2 ' 10,   messi , 1987  ' &lt;class 'str'&gt;\n3 ' 16   ,pedri, 2003' &lt;class 'str'&gt;\n\n\n\n\n4. Split player info for each player\nSplit each player string into separate items, so theres 3 columns, one for each players information.\n\nfor i,player_line in enumerate(player_list): # recall can split string into a list delimited \n    player_item = player_line.split(\",\") # str: 'some,cool,string' -&gt; list: ['some','cool','string']\n    print(player_item)\n\n['id', '   name', '   dob']\n['8', ' iniesta  ', ' 1984 ']\n[' 10', '   messi ', ' 1987  ']\n[' 16   ', 'pedri', ' 2003']\n\n\n\n\n5. repr shows each strings values\nNotice there are unnecessary white space to be removed\n\nfor i,player_line in enumerate(player_list): # recall can split string into a list delimited \n    player_item = player_line.split(\",\") # str: 'some,cool,string' -&gt; list: ['some','cool','string']\n    [print(repr(player_info)) for player_info in player_item] # need to clean each player_info\n    \n\n'id'\n'   name'\n'   dob'\n'8'\n' iniesta  '\n' 1984 '\n' 10'\n'   messi '\n' 1987  '\n' 16   '\n'pedri'\n' 2003'\n\n\n\n\n6. strip each players information\n\nfor i,player_line in enumerate(player_list): \n    player_item = player_line.split(\",\")\n    [print(repr(player_info.strip())) for player_info in player_item] \n    \n\n'id'\n'name'\n'dob'\n'8'\n'iniesta'\n'1984'\n'10'\n'messi'\n'1987'\n'16'\n'pedri'\n'2003'\n\n\n\n\n7. Append each player to to create a players clean list\n\nplayers = []\nfor player_line in player_list: \n    # each_str_list = line.split(\",\")  \n    # [print(strg.strip()) for strg in each_str_list] # strip() all the white spaces away\n    player = [strg.strip() for strg in player_line.split(\",\")] # strip() all the white spaces away\n    print(player)\n    players.append(player)\n\n['id', 'name', 'dob']\n['8', 'iniesta', '1984']\n['10', 'messi', '1987']\n['16', 'pedri', '2003']"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html",
    "title": "Saving a Fast AI Model",
    "section": "",
    "text": "This is a short tutorial to save (export) down a fast ai model (pkl file)."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "title": "Saving a Fast AI Model",
    "section": "1. Load Fast AI Libaries and Download Dataset",
    "text": "1. Load Fast AI Libaries and Download Dataset\n\n!pip install -Uqq fastai\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath\n\nPath('C:/Users/tonyp/.fastai/data/oxford-iiit-pet/images')\n\n\nIf you ran it in GoogleColab or Kaggle (recommended, its faster) then it’ll be stored in the cloud. \nIf you ran it locally, its stored on your machine and you can take a look at the all the cute images! (Not recommended, its slow)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "title": "Saving a Fast AI Model",
    "section": "2. Labelling Function",
    "text": "2. Labelling Function\n\ndef is_cat(x): return x[0].isupper()\n\nOur data must be consistently labelled and parsed through into the model.\nFor this particular dataset, filenames starting with a Capital letter denotes a Cat, vice versa for a Non-Cat (Dog, in this case).\n\n\n\nPet Filenames\n\n\nLets write a function to handle the files names to get our labels (psuedo-code):\n1. Parse in file name and\n2. Obtain the first character and\n3. Check whether it is an upper case,\n4. If True, then it is a Cat.\nThere are various ways for us to supply the labelling to our model, in a previous blog Rice vs Noodles, the label was supplied via the parent folders name (rice folder and noodle folder).\n\nFast AI provides various helpful functions for common ways data is labelled to parse into our models\nFast AI Docs - Transforms - Label"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "title": "Saving a Fast AI Model",
    "section": "3. DataLoader",
    "text": "3. DataLoader\nCreate the Dataloader and supply the labelling function we wrote into label_func.\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "title": "Saving a Fast AI Model",
    "section": "4. Fine-tune (Non-GPU vs GPU)",
    "text": "4. Fine-tune (Non-GPU vs GPU)\nI attempted to fine-tune via Kaggle (GPU) and Locally (No GPU) and not suprisingly it is incredibly faster with a GPU setup.\nNvidia (and maybe other) GPUs are designed to be able to take multiple images at once (batches) grouped together (tensors) (I think 64 images at once), whereas a laptop without a GPU like mine will be processing 1 image at a time.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\nGPU took 35 seconds an epoch \nNon-GPU took 8 minutes an epoch"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "href": "posts/datascience/machinelearning/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "title": "Saving a Fast AI Model",
    "section": "5. Export the model",
    "text": "5. Export the model\n\nlearn.export('catdogmodel.pkl')\n\nIn Kaggle, the model will be saved on their cloud and you can access it by using right-hand sidebar under Notebook -&gt; Data -&gt; Output\n\nIt’s only 46 Mb!, not too shabby!\n\nThats it! We’ll go through how to use a saved/exported model in an upcoming post."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#available-files",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#available-files",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.1 Available files",
    "text": "2.1 Available files\n\npath = untar_data(URLs.ML_100k)\nos.listdir(path)\n\n['ub.base',\n 'u.data',\n 'u4.test',\n 'u3.test',\n 'ua.test',\n 'ub.test',\n 'u2.base',\n 'u1.test',\n 'u.info',\n 'README',\n 'mku.sh',\n 'u.genre',\n 'u3.base',\n 'u4.base',\n 'u.item',\n 'u.occupation',\n 'u5.base',\n 'ua.base',\n 'allbut.pl',\n 'u5.test',\n 'u2.test',\n 'u1.base',\n 'u.user']"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#checking-out-the-readme",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#checking-out-the-readme",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.2 Checking out the README",
    "text": "2.2 Checking out the README\n\ndef get_info(folder_name):\n    info_path = os.path.join(path,folder_name)\n    with open(info_path) as f:\n        info_content = f.read()\n    print(info_content)  \n\n# get_info('README')\n\n\n2.2.1 README - u.data\n\nThe full u data set, 100000 ratings by 943 users on 1682 items etc…\nThis is a tab separated list of user id | item id | rating | timestamp.\n\n\n\n2.2.2 README - u.item\n\nInformation about the items (movies);\nThis is a tab separated list of movie id | movie title | release date | video release date | etc…"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#movies-data",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#movies-data",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3 Movies data",
    "text": "2.3 Movies data"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#codecencoding-import-problem",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#codecencoding-import-problem",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.1 Codec/Encoding import problem",
    "text": "2.3.1 Codec/Encoding import problem\nThere is a code problem with importing the movies dataset.\n\nmovies_df = pd.read_csv(path/'u.item')\n\n\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 movies_df = pd.read_csv(path/'u.item')\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898, in TextFileReader._make_engine(self, f, engine)\n   1895     raise ValueError(msg)\n   1897 try:\n-&gt; 1898     return mapping[engine](f, **self.options)\n   1899 except Exception:\n   1900     if self.handles is not None:\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93, in CParserWrapper.__init__(self, src, **kwds)\n     90 if kwds[\"dtype_backend\"] == \"pyarrow\":\n     91     # Fail here loudly instead of in cython after reading\n     92     import_optional_dependency(\"pyarrow\")\n---&gt; 93 self._reader = parsers.TextReader(src, **kwds)\n     95 self.unnamed_cols = self._reader.unnamed_cols\n     97 # error: Cannot determine type of 'names'\n\nFile parsers.pyx:574, in pandas._libs.parsers.TextReader.__cinit__()\n\nFile parsers.pyx:663, in pandas._libs.parsers.TextReader._get_header()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2053, in pandas._libs.parsers.raise_parser_error()\n\nFile &lt;frozen codecs&gt;:322, in decode(self, input, final)\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 76620: invalid continuation byte"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#chardet-library",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#chardet-library",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.2 chardet library",
    "text": "2.3.2 chardet library\nLets use chardet library to decode encoding automatically.\nWe find that data is in ‘ISO-8859-1’ encoding.\n\nimport chardet\n\nread_mode   = 'rb' #'rb' means \"open the file in read mode, and read it as a binary file\".\nmovie_path  = path/'u.item'\n\nwith open(movie_path, read_mode) as f: #'rb' means \"open the file in read mode, and read it as a binary file\".\n    result = chardet.detect(f.read())\nencoding_id = result['encoding']\nencoding_id\n\n'ISO-8859-1'"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#updating-codec-error-persists",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#updating-codec-error-persists",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.3 Updating Codec (error persists)",
    "text": "2.3.3 Updating Codec (error persists)\n\nmovies_df = pd.read_csv(path/'u.item', encoding=encoding_id)\n\n\n---------------------------------------------------------------------------\nParserError                               Traceback (most recent call last)\nCell In[17], line 1\n----&gt; 1 movies_df = pd.read_csv(path/'u.item', encoding=encoding_id)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626, in _read(filepath_or_buffer, kwds)\n    623     return parser\n    625 with parser:\n--&gt; 626     return parser.read(nrows)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923, in TextFileReader.read(self, nrows)\n   1916 nrows = validate_integer(\"nrows\", nrows)\n   1917 try:\n   1918     # error: \"ParserBase\" has no attribute \"read\"\n   1919     (\n   1920         index,\n   1921         columns,\n   1922         col_dict,\n-&gt; 1923     ) = self._engine.read(  # type: ignore[attr-defined]\n   1924         nrows\n   1925     )\n   1926 except Exception:\n   1927     self.close()\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234, in CParserWrapper.read(self, nrows)\n    232 try:\n    233     if self.low_memory:\n--&gt; 234         chunks = self._reader.read_low_memory(nrows)\n    235         # destructive to chunks\n    236         data = _concatenate_chunks(chunks)\n\nFile parsers.pyx:838, in pandas._libs.parsers.TextReader.read_low_memory()\n\nFile parsers.pyx:905, in pandas._libs.parsers.TextReader._read_rows()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2061, in pandas._libs.parsers.raise_parser_error()\n\nParserError: Error tokenizing data. C error: Expected 1 fields in line 12, saw 3"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#update-delimiter",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#update-delimiter",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.4 Update Delimiter",
    "text": "2.3.4 Update Delimiter\nBy adding the delimiter we’ve resolved the issue.\n\nmovies_df = pd.read_csv(path/'u.item', encoding=encoding_id, delimiter='|')\nmovies_df[0:3]\n\n\n\n\n\n\n\n\n1\nToy Story (1995)\n01-Jan-1995\nUnnamed: 3\nhttp://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\n0\n0.1\n0.2\n1.1\n1.2\n...\n0.6\n0.7\n0.8\n0.9\n0.10\n0.11\n0.12\n0.13\n0.14\n0.15\n\n\n\n\n0\n2\nGoldenEye (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?GoldenEye%20(1995)\n0\n1\n1\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n1\n3\nFour Rooms (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n4\nGet Shorty (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)\n0\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n3 rows × 24 columns"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#import-movies-and-ratings-and-merging",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#import-movies-and-ratings-and-merging",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4 Import Movies and Ratings and Merging",
    "text": "2.4 Import Movies and Ratings and Merging"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#movies",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#movies",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.1 Movies",
    "text": "2.4.1 Movies\n\nmovies_df = pd.read_csv(path/'u.item', delimiter='|', encoding=encoding_id, header=None, usecols=(0,1),\n            names =['movie_id','movie_title'])\nmovies_df[0:5]\n\n\n\n\n\n\n\n\nmovie_id\nmovie_title\n\n\n\n\n0\n1\nToy Story (1995)\n\n\n1\n2\nGoldenEye (1995)\n\n\n2\n3\nFour Rooms (1995)\n\n\n3\n4\nGet Shorty (1995)\n\n\n4\n5\nCopycat (1995)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#user-ratings",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#user-ratings",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.2 User Ratings",
    "text": "2.4.2 User Ratings\n\nusr_ratings_df = pd.read_csv(path/'u.data',delimiter='\\t', header=None,\n                       names=['user_id','movie_id','rating','timestamp'])\nusr_ratings_df[0:5]\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ntimestamp\n\n\n\n\n0\n196\n242\n3\n881250949\n\n\n1\n186\n302\n3\n891717742\n\n\n2\n22\n377\n1\n878887116\n\n\n3\n244\n51\n2\n880606923\n\n\n4\n166\n346\n1\n886397596"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#merged",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#merged",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.3 Merged",
    "text": "2.4.3 Merged\n\nratings_merged = usr_ratings_df.merge(movies_df)\nratings_merged[0:5]\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ntimestamp\nmovie_title\n\n\n\n\n0\n196\n242\n3\n881250949\nKolya (1996)\n\n\n1\n186\n302\n3\n891717742\nL.A. Confidential (1997)\n\n\n2\n22\n377\n1\n878887116\nHeavyweights (1994)\n\n\n3\n244\n51\n2\n880606923\nLegends of the Fall (1994)\n\n\n4\n166\n346\n1\n886397596\nJackie Brown (1997)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-1-all-users-by-1-latent-factor",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-1-all-users-by-1-latent-factor",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.1 Excel Matrix-Multiply-1: All Users by 1-Latent-Factor",
    "text": "4.1 Excel Matrix-Multiply-1: All Users by 1-Latent-Factor\nNote: When matrix-multipying:\n\nuser_factors matrix [user (m) by factors (n)] by\n\none_hot encoded matrix [each column is one_hot_encoded vector of required index]\n\nThe result is a matrix where each column is the chosen factor index, i.e:\n\neach column of the resultant matrix: [every user m by the single factor]: [m,1]"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-2-individual-users-by-all-latent-factors",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-2-individual-users-by-all-latent-factors",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.2 Excel Matrix-Multiply-2: Individual Users by All-Latent-Factors",
    "text": "4.2 Excel Matrix-Multiply-2: Individual Users by All-Latent-Factors\nHowever, what we want is the transpose of this result, i.e:\n\neach column representing [1 user and all its factors]"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#one-hot-encoded-vector",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#one-hot-encoded-vector",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3 One-Hot-Encoded Vector",
    "text": "4.3 One-Hot-Encoded Vector\nConvert our index of our latent factor matrix into one-hot-encoded vectors using:\n\nfrom fastai.torch_core import one_hot"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#steps",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#steps",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.1 Steps",
    "text": "4.3.1 Steps\n\nConvert some all indices of our matrix (944) to one-hot-encoded vectors (i.e. 944 individual vectors).\nFor e.g. Index [3] becomes a 1D-vector of length (n_users) or torch.Size([944])\nMatrix-Multiplying two single vectors is equivalent to the dot-product\n\n\nn_users_integer = len(dls.classes['user_id']) # get number of users ids\nn_movies_integer = len(dls.classes['movie_title']) # get number of users ids\nn_latent_factors_integer = 5\n\n\none_hot_2 = one_hot(2, n_users_integer).float()\n\n\nusers_latent_factors = torch.rand(n_users_integer, n_latent_factors_integer) # 944,5\nmovie_latent_factors = torch.rand(n_movies_integer, n_latent_factors_integer) # 1665,5"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#index2-of-user-latent-factors",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#index2-of-user-latent-factors",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.2 Index[2] of User-Latent-Factors",
    "text": "4.3.2 Index[2] of User-Latent-Factors\n\nusers_latent_factors[2]\n\ntensor([0.1049, 0.5802, 0.1599, 0.2081, 0.5760])\n\n\n\nusers_latent_factors.shape # [m,n] - [944,5]\nusr_t = users_latent_factors.t()\nusr_t.shape #[5,944]\none_hot_2.shape #[944]\n\ntorch.Size([944])"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#matrix-multiply-user-latent-factorsone_hot_idx2",
    "href": "posts/datascience/machinelearning/2024-05-07_latent_factors_matrix/index.html#matrix-multiply-user-latent-factorsone_hot_idx2",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.3 Matrix-Multiply [User-Latent-Factors@One_Hot_IDX2]",
    "text": "4.3.3 Matrix-Multiply [User-Latent-Factors@One_Hot_IDX2]\nEquivalent to Index 2 of Original User-Latent-Factors\n\nusr_t@one_hot_2 # [5,944]@[944] ~ [m_x_n]@[n] =  \none_hot_user_factors_1d_tsr = users_latent_factors.t() @ one_hot_2 #[n_x_m]\none_hot_user_factors_1d_tsr\n\ntensor([0.1049, 0.5802, 0.1599, 0.2081, 0.5760])"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-24-one_r_classifier/index.html",
    "href": "posts/datascience/machinelearning/2024-04-24-one_r_classifier/index.html",
    "title": "Random Forests - OneR Classifier (Part 1)",
    "section": "",
    "text": "1. Introduction\nIn order to build Random Forests, we need to build Decision Trees.\nIn order to build Decisions-Trees, we need to build Binary Splits.\nThis post will show how to do find the best binary split per column, also known as OneR Classifier\n\n\n2. Data Cleaning\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n\n\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\n\n\n3. Binary Splits\nA binary split is where all rows are placed into one of two groups, based on whether they’re above or below some threshold of some column.\n\n\n4. 1R Classifier model\nIn laymens:\n1. Get all unique values of each idependent value.\n2. Split on the value, ie. binary split.\n3. Make predictions on survivability using the above split.\n4. Calculate standard deviation for each split and add them.\n5. If std.dev is high, than its a bad split since survived and perished within each split. A good split results in low-variability.\n6. find the split point for each column with lowest std.dev.\n7. This is the 1R model.\n\n\n5. Code\n\ndef _side_score(side, y):\n    tot = side.sum()\n    if tot&lt;=1: return 0\n    return y[side].std()*tot\n\ndef score(idep_col, dep, split_val):\n    lhs_bool_list = idep_col &lt;= split_val\n    return (_side_score(lhs_bool_list, dep) + _side_score(~lhs_bool_list, dep)) / len(dep)\n\ndef min_col(df, idep_col_name):\n    idep_col    = df[idep_col_name]\n    dep         = df[dep_col]\n\n    col_uniques = idep_col.dropna().unique() # get all unique values of idep col\n    \n    scores = np.array( # get score for each unique value in idep_col\n        [score(idep_col, dep, col_val) \n         for col_val in col_uniques \n         if not np.isnan(col_val)\n         ])\n    \n    idx = scores.argmin() # get index of min score\n    return col_uniques[idx],scores[idx]\nall_cols = cat_list+cont_list \n{col:min_col(trn_df, col) for col in all_cols}\n\n{'Sex': (0, 0.40787530982063946),\n 'Embarked': (0, 0.47883342573147836),\n 'Age': (6.0, 0.478316717508991),\n 'SibSp': (4, 0.4783740258817434),\n 'Parch': (0, 0.4805296527841601),\n 'LogFare': (2.4390808375825834, 0.4620823937736597),\n 'Pclass': (2, 0.46048261885806596)}\n\n\n\n\n6. The Best Binary-Split\nThus, Sex&lt;=0 is best single binary split."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html",
    "href": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 3)",
    "section": "",
    "text": "In Neural Network Basics: Part 2, the parameters of a function were found (optimised) to Minimise the Loss Function. The Loss Function chosen was the Mean Absolute Error, it could have been chosen to be the Mean Squared Error.\nBut What is the mathematical function if the wish to model something more complex like predicting the breed of Cat?\nUnfortunately, its unlikely the relationship between the parameters and whether a pixel is part of a Maine Coon 🐈 is a Quadratic, its going to be something more complicated.\nThankfully, there exists the infinitely flexible function known as Rectified Linear Unit (ReLU)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "href": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "title": "Neural Network Basics (Part 3)",
    "section": "1. Rectified Linear Unit (ReLU)",
    "text": "1. Rectified Linear Unit (ReLU)\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nfrom functools import partial\n\n\n1.1 Function\nThe function does two things:\n1. Calculate the output of a line\n2. If the output is smaller than zero, return zero\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y,0.)\n\n\n\n1.2 Create A Custom ReLU Method\n\ndef custom_relu_fn(m,b): return partial(rectified_linear,m,b)\n\n\n\n1.3 Create y = 1x + 1 with Custom ReLU Method\n\nfn_11 = custom_relu_fn(1,1)\nfn_11\n\nfunctools.partial(&lt;function rectified_linear at 0x00000220331C9D00&gt;, 1, 1)\n\n\n\n\n1.4 ReLU y = 1x+ 1 Plot\n\nx = torch.linspace(-2.1,2.1,20)\nplt.plot(x,fn_11(x))\n\n\n\n\n\n\n\n\n\n1.4.1 Interactive ReLU\n\nplt.rc('figure', dpi=90)\n\n@interact(m=1.2, b=1.2)\ndef plot_relu(m, b):\n    min, max = -4.1, 4.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(rectified_linear, m,b)\n    ylim=(-1,4)\n    plt.ylim(ylim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n\n1.5 Double ReLU Function\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1) + rectified_linear(m2,b2) \n\n\n1.5.1 Interactive Double ReLU\n\nplt.rc('figure', dpi=90)\n\ndef dbl_rectified_linear(m1, b1,m2,b2,x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2)\ndef plot_dbl_relu(m1,b1,m2,b2):\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(dbl_rectified_linear, m1,b1,m2,b2)\n    ylim=(-1,4)\n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n1.5.1 Triple ReLU for Good Measure!\n\ndef trple_rectified_linear(m1, b1, m2, b2, m3, b3, x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x) + rectified_linear(m3,b3,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2, m3=0.5, b3=0.5)\ndef plot_trple_relu(m1,b1,m2,b2,m3,b3):\n# static variables\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    \n# update partial to include extra parameters m3, b3\n    triple_relu_fn_y = partial(trple_rectified_linear, m1,b1,m2,b2,m3,b3)\n\n# static variables\n    ylim=(-1,4) \n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, triple_relu_fn_y(x))"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "href": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "title": "Neural Network Basics (Part 3)",
    "section": "2. ReLU is An Infinitely Flexible Function",
    "text": "2. ReLU is An Infinitely Flexible Function\nThere could be arbitrarily many ReLus added together to form any function!\nThe previous functions are of a single input x i.e. 2-Dimensions.\nReLU’s could be added together over as many dimensions as desired, i.e. ReLU’s over surfaces or ReLU’s over 3D, 4D 5D etc.\nBut adding these ReLU’s, this means there are arbitrary amount of parameters related to each ReLU, how can these parameters be calculated?\nIn Part 2, a optimisation method called Gradient Descent was used to determine Parameters.\nThat’s Deep Learning in a nutshell. Beyond this, Tweaks are to:\n- make it faster\n- require less data"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "href": "posts/datascience/machinelearning/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "title": "Neural Network Basics (Part 3)",
    "section": "Neural Network Basics Completed.",
    "text": "Neural Network Basics Completed.\nGo back to a previous post:\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html",
    "href": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "",
    "text": "Today I’ll go through how to find and test different deep-learning architectures from Pytorch Image Models (timm) library made available here by Ross Wightman and use them in our models."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "href": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "1. Using timm - PyTorch Image Models",
    "text": "1. Using timm - PyTorch Image Models\n\n1.1 Introduction\nWhat are timm’s models? They’re mathematical functions (i.e. application of matrix multiplication, non-linearities e.g. ReLu’s)\nReference: “Which image model are best” - Jeremy Howard\nReference: “timm” - Ross Wightman\nWe want to know 3 things:\n1. how fast are they? You’d want models in top left of chart.\n2. how much memory?\n3. how accurate are they? Lower error rate the better.\n[Future iteration I]: A formalised metholodgy to decide what is fast enough, appropriate memory-use, and what is accurate enough for our use-cases.\nThere is a useful high-level chart from Jeremy’s notebook charting accuracy (Y-axis) vs secs per sample (X-axis):\n\nI chose to use a model from the convnext family due to its balance of high accuracy and speed.\n[Future iteration II]: Some more formalised methodology on choosing the architecture. Jeremy does mention architecture should be the one last thing things to worry about and he usually builds from resnet and tests whether it is, accurate enough and fast enough, then iterate from there.\n\n\n1.2 Import timm library\n\nimport timm\n\n\n\n1.3 List available model architectures and choose one\n\ntimm.list_models('convnext*') # * wild card searches \n\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "href": "posts/datascience/machinelearning/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "2. Create your Learner with a timm model",
    "text": "2. Create your Learner with a timm model\n\n2.1 Get your data\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)/'images'\n\n\n\n2.2 Prepare your Functions\n\ndef is_cat(x): return x[0].isupper()\n\n\n\n2.3 Load your DataLoader\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\n\n\n2.4 Build your Learner\n\nlearn_conv = vision_learner(dls, 'convnext_tiny', metrics=error_rate).to_fp16()\nlearn_resn = vision_learner(dls, 'resnet18', metrics=error_rate).to_fp16()\n\n\n\n2.5 Fine-Tune: ResNet18 vs ConvNextTiny\nA 90% reduction in the error rate! (0.6766% to 0.0667%: 1-(0.000677/0.006766)). It’s noted that the resnet error rate was quite low and changing the model was probably not necessary."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-16-98_post_without_code/index.html",
    "href": "posts/datascience/machinelearning/2024-01-16-98_post_without_code/index.html",
    "title": "Post Without Code",
    "section": "",
    "text": "Learning how to quarto blog.\nThis is a post with just this sentence."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#male-training-set",
    "href": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#male-training-set",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "3.1 Male Training Set",
    "text": "3.1 Male Training Set\n\n{col_name:calc_best_bin_split_per_col(trn_males, col_name) for col_name in all_cols}\n\n{'Embarked': (0, 0.3875581870410906),\n 'Age': (6.0, 0.3739828371010595),\n 'SibSp': (4, 0.3875864227586273),\n 'Parch': (0, 0.3874704821461959),\n 'LogFare': (2.803360380906535, 0.3804856231758151),\n 'Pclass': (1, 0.38155442004360934)}"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#female-training-set",
    "href": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#female-training-set",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "3.2 Female Training Set",
    "text": "3.2 Female Training Set\n\n{col_name:calc_best_bin_split_per_col(trn_females, col_name) for col_name in all_cols}\n\n{'Embarked': (0, 0.4295252982857327),\n 'Age': (50.0, 0.4225927658431649),\n 'SibSp': (4, 0.42319212059713535),\n 'Parch': (3, 0.4193314500446158),\n 'LogFare': (4.256321678298823, 0.41350598332911376),\n 'Pclass': (2, 0.3335388911567601)}"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#max-4-nodes",
    "href": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#max-4-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.1 Max 4 nodes",
    "text": "5.1 Max 4 nodes\nStart with maximum 4 nodes.\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nm_DecTree_max4nodes = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_idep, trn_dep)\n\n\nimport graphviz\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n                      special_characters=True, rotate=False, precision=precision, **kwargs)\n    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#draw-the-decision-tree-with-4-nodes",
    "href": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#draw-the-decision-tree-with-4-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.2 Draw the Decision Tree with 4 nodes",
    "text": "5.2 Draw the Decision Tree with 4 nodes\nThe model applied 1R to two levels and determined the same splits I did. Graph terminology: - colour: Blue is high survival rate, Orange is low survival rate. - samples: rows matching the set of rules - values: how many survived or perished, hence two values. - gini: measure of impurity, 1 means the whole group is the same, 0 means all rows are different\n\ndraw_tree(m_DecTree_max4nodes, trn_idep, size=10)\n\n\n\n\n\n\n\n\n\n5.2.1 Loss (DTree, max 4 leaf nodes)\nMAE 22.4%\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(val_dep, m_DecTree_max4nodes.predict(val_idep))\n\n0.2242152466367713"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#decision-tree-with-minimum-50-leaf-nodes",
    "href": "posts/datascience/machinelearning/2024-04-25-decision_tree_classifier/index.html#decision-tree-with-minimum-50-leaf-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.3 Decision Tree with minimum 50 leaf nodes",
    "text": "5.3 Decision Tree with minimum 50 leaf nodes\n\nm_DecTree_min50nodes = DecisionTreeClassifier(min_samples_leaf=50)\nm_DecTree_min50nodes.fit(trn_idep, trn_dep)\ndraw_tree(m_DecTree_min50nodes, trn_idep, size=25)\n\n\n\n\n\n\n\n\n\n5.3.1 Loss (DTree, min 50 leaf nodes)\nMAE 18.4% (previous model 22.4%)\n\nmean_absolute_error(val_dep, m_DecTree_min50nodes.predict(val_idep))\n\n0.18385650224215247"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-16-96_post_with_git_clone/index.html",
    "href": "posts/datascience/machinelearning/2024-01-16-96_post_with_git_clone/index.html",
    "title": "Post With Git Clone",
    "section": "",
    "text": "Learning how git work and\nthis is a post initiated by cloning existing repo."
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#import-a-pretrained-language-model",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#import-a-pretrained-language-model",
    "title": "KAGG 1: A Basic NLP model",
    "section": "1. Import a Pretrained Language Model",
    "text": "1. Import a Pretrained Language Model\n\nchosen_pretrained_model = \"microsoft/deberta-v3-small\"\n\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\ndebv3_tokenizer = AutoTokenizer.from_pretrained(chosen_pretrained_model)\n\n\n\n1.1 Look Inside the Language Model\n\nprint(debv3_tokenizer)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#test-out-tokenizer",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#test-out-tokenizer",
    "title": "KAGG 1: A Basic NLP model",
    "section": "2. Test out Tokenizer",
    "text": "2. Test out Tokenizer\n\ntest_string = (\"Hey all! What's going on? It's Tony from Sydney!\")\ndebv3_tokenizer.tokenize(test_string)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#import-competition-data",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#import-competition-data",
    "title": "KAGG 1: A Basic NLP model",
    "section": "3. Import Competition Data",
    "text": "3. Import Competition Data\nTo add relevant competition data to your kaggle “Input” folder.\nThis “Input” folder is persistent when you submit to the competition. All other folders created during prior to submitting are disregarded.\n\n3.1 Via GUI:\n\nOn Kaggle, Go to [Add Data]\n\nFilter for “Competition Datasets”\n\nSearch “US Patents”\nClick [Add Competition]\n\n \n\n\n3.2 Via Programatically:\nNote: You’ll need your own GPU’s, I don’t so the rest of the notebook is ran on the Kaggle website 1. Have kaggle login + keys ready locally, explained in this post 2. Run code to download data locally.\n\nfrom pathlib import Path\npath = Path('us-patent-phrase-to-phrase-matching')\nif not path.exists():\n    import zipfile,kaggle\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\n\n\n3.3 Look Inside the Competition Data\n\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching') # Using GUI places comp-data into 'kaggle/input' folder\nimport pandas as pd\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#data-preparation",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#data-preparation",
    "title": "KAGG 1: A Basic NLP model",
    "section": "4. Data Preparation",
    "text": "4. Data Preparation\n\n4.1 Create Input Column\nCreate a contentated column of imporatant columns context, target and anchor.\n\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\ndf['input']\n\n\n\n\n4.2 Convert Pandas Dataframe to HuggingFace Dataset\n\nfrom datasets import Dataset,DatasetDict\nhf_datasets = Dataset.from_pandas(df)\nhf_datasets.keys\n\n\n\n\n4.3 Tokenize our HuggingFace Dataset\nUsing the tokenizer, we can apply pre-trained model to our new concatenated column.\nA hugging face dataset is in the form of a dictionary so we can index to get a column with dict['column']\nWe can apply the tokenization with batching, resulting in an additional few columns input_ids, token_type_ids, attention_marks, which only took 2 seconds!\n\ndef tok_func(x): return debv3_tokenizer(x[\"input\"])\ntok_ds = hf_datasets.map(tok_func, batched=True)\ntok_ds\n\n\n\n\n4.4 Rename the Columns as to what HF expects\n\ntok_ds = tok_ds.rename_columns({'score':'labels'})\n\n\n\n4.5 Training and Validation Sets\nSplit the above tokenized hugging face datasets into validation and training sets, into DatasetDicts.\nNote: The validation set here is called test and not validate\n\ntok_ds_dicts = tok_ds.train_test_split(0.25, seed=42)\ntok_ds_dicts"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#data-modelling",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#data-modelling",
    "title": "KAGG 1: A Basic NLP model",
    "section": "5. Data Modelling",
    "text": "5. Data Modelling\n\n5.1 Import libraries and set parameters\nImport modules: - TrainingArgument: to take in all the hyperparameters - Trainer class: combines the TrainingArguments and Pre-trained model Set the main hyper-parameters: - Batch Sizes: to fit on the GPU, - Number of Epochs: for each ‘experiment’ and the - Learning Rate, so it doesnt fail.\n[“Future Iteration”]: More descriptions on these and other parameters in future posts.\n\nfrom transformers import TrainingArguments,Trainer\nbs = 128\nepochs = 4\nlr = 8e-5\n\n\n\n5.2 Setup Training Arguments\n\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n\n\n\n5.3 Create Model\n\nmodel = AutoModelForSequenceClassification.from_pretrained(chosen_pretrained_model, \n                                                           num_labels=1,\n                                                           ignore_mismatched_sizes=True)\n\n\n\n5.4 Create Metrics Functions\nThe Pearson coefficient using numpy.\n\nimport numpy as np\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n\n\n\n5.5 Create Trainer\n\ntrainer = Trainer(model, \n                  args, \n                  train_dataset=tok_ds_dicts['train'], \n                  eval_dataset=tok_ds_dicts['test'],\n                  tokenizer=debv3_tokenizer, \n                  compute_metrics=corr_d)\n\n\n\n5.6 Do the Training\n\ntrainer.train()"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#predictions",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#predictions",
    "title": "KAGG 1: A Basic NLP model",
    "section": "6. Predictions",
    "text": "6. Predictions\nNow that we have a Trainer (same as Learner in FastAI), we could use it on a an unseen set of data such as a Test Set and make predictions.\n\n6.1 Import Test Dataset\n\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n\n\n\n6.2 Make Predictions\nPredictions are going beyond 0 and 1\n\npreds = trainer.predict(eval_ds).predictions.astype(float)\n\n\n\n\n6.3 Clip Predictions\nPredictions are going beyond 0 and 1\n\npreds = np.clip(preds, 0, 1)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#submission",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#submission",
    "title": "KAGG 1: A Basic NLP model",
    "section": "7. Submission",
    "text": "7. Submission\n\nimport datasets\n\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds\n})\n\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-001-us-patents/index.html#part-2",
    "href": "posts/datascience/kaggle/kagg-001-us-patents/index.html#part-2",
    "title": "KAGG 1: A Basic NLP model",
    "section": "8. Part 2",
    "text": "8. Part 2\nActually the submissiong won’t work because it is a Notebook competition is the Internet is Turned Off.\nWhat needs to be done is convert this version to one that works without installing anything from the internet.\nThat would be in Part 2."
  },
  {
    "objectID": "posts/mathematics/calculus/calc-008-derivative-exponential-ax.html",
    "href": "posts/mathematics/calculus/calc-008-derivative-exponential-ax.html",
    "title": "Calculus 8: Derivative of An Exponential",
    "section": "",
    "text": "1. Find \\(\\frac{d}{dx}a^x\\)\n\n\n2. Workout\n\n\n\n3. Plotting \\(\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h},a&gt;0\\) at various bases \\(a\\)\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n### x-values ###\nxpt = 0.01\nx_deviation = 1\nx_increments = 21\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\nprint(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\n\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\nlbl_fx = r'$\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h}$'   # LABEL\n# fx_fx = lambda x: np.log(x)  # f(x)\n# fx_fx       = lambda h:       (2**h-1)/h  # f(x)\nfx_fx0_5    = lambda h:    (0.5**h-1)/h  # f(x)\nfx_fx2_5    = lambda h:    (2.5**h-1)/h  # f(x)\nfx_fx1_5    = lambda h:    (1.5**h-1)/h  # f(x)\nfx_fx2      = lambda h:      (2**h-1)/h  # f(x)\nfx_fx3      = lambda h:      (3**h-1)/h  # f(x)\nfx_fx10      = lambda h:      (10**h-1)/h  # f(x)\n\n### y-values ###\n# ys_fx = fx_fx(xs)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\nys_fx0_5 = fx_fx0_5(xs)\nys_fx2_5 = fx_fx2_5(xs)\nys_fx1_5 = fx_fx1_5(xs)\nys_fx2 = fx_fx2(xs)\nys_fx3 = fx_fx3(xs)\nys_fx10 = fx_fx10(xs)\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=\"base 2\")\nplt.plot(xs, ys_fx0_5,  'bo-', linewidth=2, markersize=6, label=\"base $a$: 0.5\")\nplt.plot(xs, ys_fx1_5,  'y^-.', linewidth=2, markersize=6, label=\"base $a$: 1.5\")\nplt.plot(xs, ys_fx2,  'c&lt;-', linewidth=2, markersize=6, label=\"base $a$: 2\")\nplt.plot(xs, ys_fx2_5,  'gv--', linewidth=2, markersize=6, label=\"base $a$: 2.5\")\nplt.plot(xs, ys_fx3,  'm&gt;:', linewidth=2, markersize=6, label=\"base $a$: 3\")\nplt.plot(xs, ys_fx10,  'k-.', linewidth=2, markersize=6, label=\"base $a$: 10\")\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\nplot_title = lbl_fx\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\n# plt.legend(loc='lower right')\nplt.legend(loc='upper left')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\nax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n[-0.99 -0.89 -0.79 -0.69 -0.59 -0.49 -0.39 -0.29 -0.19 -0.09  0.01  0.11\n  0.21  0.31  0.41  0.51  0.61  0.71  0.81  0.91  1.01]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-007-ch3-1-ex-25-31.html",
    "href": "posts/mathematics/calculus/calc-007-ch3-1-ex-25-31.html",
    "title": "Calculus 7: Rates of Change Applications",
    "section": "",
    "text": "1. Chapter 3 Exercises: 25, 27, 29 and 31 (Hand-Written Working-Out)\n\n\n1a. Ch3-1-25 and 27\n\n\n\n1b. Ch3-1-Ex-29 and 31\n\n\n\n2. Ch3-1-Ex-27 Chart Only\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n### x-values ###\nxpt = 1\nx_deviation = 1\nx_increments = 100\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\nxs = xs[xs != 1]\n# xs = xs[xs &gt; 0]\n\n### THE FUNCTION ###\nlbl_fx = r'$f(x)=\\frac{1}{x-1}$'   # LABEL\nfx_fx = lambda x: (1)/(x-1)  # f(x)\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n\n### y-values ###\nys_fx = fx_fx(xs)            # ys=f(xs)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\nplt.plot(xs, ys_fx,  'o', markersize=3, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\nplot_title = lbl_fx + rf\" (Ch3.1.Ex27, Thomas 13e pp.126-127)\"\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\nplt.xlim(0.5, 1.5)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-017-ch3-6-ex-103.html#exercises-103",
    "href": "posts/mathematics/calculus/calc-017-ch3-6-ex-103.html#exercises-103",
    "title": "Calculus 17: Simple Pendulum",
    "section": "3-6-Exercises-103",
    "text": "3-6-Exercises-103\nGiven \\[T=2\\pi \\sqrt{L}{g}\\]\n\\[\\frac{dL}{du}=kL\\]\nFind \\[\\frac{dT}{du} \\]\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport math\n### x-values ###\nxpt = 0\nx_deviation = 10\nx_increments = 21\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 1]\nxs = xs[xs &gt; 0]\nprint(xs)\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$f(x)= log(x)$'   # LABEL\nlbl_fx = r'$T=2\\pi \\sqrt{L}{g}$'   # LABEL\n# fx_fx = lambda x,L,g: 2 * math.pi * math.sqrt(L/g)  # f(x)\nfx_fx = lambda x: 2 * np.pi * np.sqrt(x/9.81)  # f(x)\n# fx_fx = lambda x: 2 * math.pi * x  # f(x)\n\n### y-values ###\nys_fx = fx_fx(xs)            # ys=f(xs)\nypt_fx = fx_fx(xpt)\nprint(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# lbl_dydx = lbl_fx\n\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\nplt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\nplot_title = lbl_fx\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\n\n# vertical, horizontal, \n# ax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\nypt_fx_at_P(x=0): 0.0"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-009-ch10-1-ex-1-5.html",
    "href": "posts/mathematics/calculus/calc-009-ch10-1-ex-1-5.html",
    "title": "Calculus 9: Terms of Sequences - Selected Exercises",
    "section": "",
    "text": "Ex-10.1: \\(a_n= \\frac{1-n}{n^2}\\)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n### x-values ###\n# xpt = 0.01\nxpt = 0.00\nx_deviation = 30\n# x_increments = 21\nx_increments = x_deviation*2+1\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n# print(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\nxs = xs[xs &gt; 0]\n\nprint(xs)\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h}$'   # LABEL\nlbl_fx = r'$a_n= \\frac{1-n}{n^2}$'\n\n# fx_fx = lambda x: np.log(x)  # f(x)\nfx_fx       = lambda n:       (1-n)/n**2 # f(x)\n# fx_fx0_5    = lambda h:    (0.5**h-1)/h  # f(x)\n# fx_fx2_5    = lambda h:    (2.5**h-1)/h  # f(x)\n# fx_fx1_5    = lambda h:    (1.5**h-1)/h  # f(x)\n# fx_fx2      = lambda h:      (2**h-1)/h  # f(x)\n# fx_fx3      = lambda h:      (3**h-1)/h  # f(x)\n# fx_fx10      = lambda h:      (10**h-1)/h  # f(x)\n\n### y-values ###\nys_fx = fx_fx(xs)\nprint(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n# ys_fx0_5 = fx_fx0_5(xs)\n# ys_fx2_5 = fx_fx2_5(xs)\n# ys_fx1_5 = fx_fx1_5(xs)\n# ys_fx2 = fx_fx2(xs)\n# ys_fx3 = fx_fx3(xs)\n# ys_fx10 = fx_fx10(xs)\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=\"base 2\")\n# plt.plot(xs, ys_fx0_5,  'bo-', linewidth=2, markersize=6, label=\"base $a$: 0.5\")\n# plt.plot(xs, ys_fx2_5,  'gv--', linewidth=2, markersize=6, label=\"base $a$: 2.5\")\n# plt.plot(xs, ys_fx1_5,  'y^-.', linewidth=2, markersize=6, label=\"base $a$: 1.5\")\n# plt.plot(xs, ys_fx2,  'c&lt;-', linewidth=2, markersize=6, label=\"base $a$: 2\")\n# plt.plot(xs, ys_fx3,  'm&gt;:', linewidth=2, markersize=6, label=\"base $a$: 3\")\n# plt.plot(xs, ys_fx10,  'k-.', linewidth=2, markersize=6, label=\"base $a$: 10\")\nplt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\nplot_title = lbl_fx\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\n# plt.legend(loc='lower right')\nplt.legend(loc='upper left')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\nplt.xlim(1,xs_max)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\n\n# vertical, horizontal, \n# ax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]\n[ 0.         -0.25       -0.22222222 -0.1875     -0.16       -0.13888889\n -0.12244898 -0.109375   -0.09876543 -0.09       -0.08264463 -0.07638889\n -0.07100592 -0.06632653 -0.06222222 -0.05859375 -0.05536332 -0.05246914\n -0.0498615  -0.0475     -0.04535147 -0.04338843 -0.0415879  -0.03993056\n -0.0384     -0.03698225 -0.03566529 -0.03443878 -0.0332937  -0.03222222]\n\n\n/tmp/ipykernel_17130/1601808888.py:96: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(loc='upper left')\n\n\n\n\n\n\n\n\n\n\n\nEx-10.3: \\(a_n= \\frac{(-1)^{n+1}}{2n-1}\\)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n### x-values ###\n# xpt = 0.01\nxpt = 0.00\nx_deviation = 21\n# x_increments = 21\nx_increments = x_deviation*2+1\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n# print(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\nxs = xs[xs &gt; 0]\n\nprint(xs)\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h}$'   # LABEL\n# lbl_fx = r'$a_n= \\frac{1-n}{n^2}$'\nlbl_fx = r'$a_n= \\frac{(-1)^{n+1}}{2n-1}$'\n\n# fx_fx = lambda x: np.log(x)  # f(x)\n# fx_fx       = lambda n:       (1-n)/n**2 # f(x)\nfx_fx       = lambda n:       ((-1)**(n+1))/(2*n-1) # f(x)\n# fx_fx0_5    = lambda h:    (0.5**h-1)/h  # f(x)\n# fx_fx2_5    = lambda h:    (2.5**h-1)/h  # f(x)\n# fx_fx1_5    = lambda h:    (1.5**h-1)/h  # f(x)\n# fx_fx2      = lambda h:      (2**h-1)/h  # f(x)\n# fx_fx3      = lambda h:      (3**h-1)/h  # f(x)\n# fx_fx10      = lambda h:      (10**h-1)/h  # f(x)\n\n### y-values ###\nys_fx = fx_fx(xs)\nprint(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n# ys_fx0_5 = fx_fx0_5(xs)\n# ys_fx2_5 = fx_fx2_5(xs)\n# ys_fx1_5 = fx_fx1_5(xs)\n# ys_fx2 = fx_fx2(xs)\n# ys_fx3 = fx_fx3(xs)\n# ys_fx10 = fx_fx10(xs)\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=\"base 2\")\n# plt.plot(xs, ys_fx0_5,  'bo-', linewidth=2, markersize=6, label=\"base $a$: 0.5\")\n# plt.plot(xs, ys_fx2_5,  'gv--', linewidth=2, markersize=6, label=\"base $a$: 2.5\")\n# plt.plot(xs, ys_fx1_5,  'y^-.', linewidth=2, markersize=6, label=\"base $a$: 1.5\")\n# plt.plot(xs, ys_fx2,  'c&lt;-', linewidth=2, markersize=6, label=\"base $a$: 2\")\n# plt.plot(xs, ys_fx3,  'm&gt;:', linewidth=2, markersize=6, label=\"base $a$: 3\")\n# plt.plot(xs, ys_fx10,  'k-.', linewidth=2, markersize=6, label=\"base $a$: 10\")\nplt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\nplot_title = lbl_fx\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\n# plt.legend(loc='lower right')\nplt.legend(loc='upper left')\n# plt.legend(loc='upper left')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\nplt.xlim(1,xs_max)  # x-rng\nplt.ylim(-0.5, 0.5)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n 19. 20. 21.]\n[ 1.         -0.33333333  0.2        -0.14285714  0.11111111 -0.09090909\n  0.07692308 -0.06666667  0.05882353 -0.05263158  0.04761905 -0.04347826\n  0.04       -0.03703704  0.03448276 -0.03225806  0.03030303 -0.02857143\n  0.02702703 -0.02564103  0.02439024]\n\n\n/tmp/ipykernel_17130/696248824.py:99: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(loc='upper left')\n\n\n\n\n\n\n\n\n\n\n\nEx-10.5: \\(a_n= \\frac{2^{n}}{2^{n+1}}\\)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n### x-values ###\n# xpt = 0.01\nxpt = 0.00\nx_deviation = 21\n# x_increments = 21\nx_increments = x_deviation*2+1\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n# print(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\nxs = xs[xs &gt; 0]\n\nprint(xs)\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h}$'   # LABEL\nlbl_fx = r'$a_n= \\frac{2^{n}}{2^{n+1}}$'\n\n# fx_fx = lambda x: np.log(x)  # f(x)\nfx_fx       = lambda n:       ((2)**(n))/((2)**(n+1))\n\n### y-values ###\nys_fx = fx_fx(xs)\nprint(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n# ys_fx0_5 = fx_fx0_5(xs)\n# ys_fx2_5 = fx_fx2_5(xs)\n# ys_fx1_5 = fx_fx1_5(xs)\n# ys_fx2 = fx_fx2(xs)\n# ys_fx3 = fx_fx3(xs)\n# ys_fx10 = fx_fx10(xs)\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=\"base 2\")\n# plt.plot(xs, ys_fx0_5,  'bo-', linewidth=2, markersize=6, label=\"base $a$: 0.5\")\n# plt.plot(xs, ys_fx2_5,  'gv--', linewidth=2, markersize=6, label=\"base $a$: 2.5\")\n# plt.plot(xs, ys_fx1_5,  'y^-.', linewidth=2, markersize=6, label=\"base $a$: 1.5\")\n# plt.plot(xs, ys_fx2,  'c&lt;-', linewidth=2, markersize=6, label=\"base $a$: 2\")\n# plt.plot(xs, ys_fx3,  'm&gt;:', linewidth=2, markersize=6, label=\"base $a$: 3\")\n# plt.plot(xs, ys_fx10,  'k-.', linewidth=2, markersize=6, label=\"base $a$: 10\")\nplt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\nplot_title = lbl_fx\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\n# plt.legend(loc='lower right')\nplt.legend(loc='upper left')\n# plt.legend(loc='upper left')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\nplt.xlim(1,xs_max)  # x-rng\nplt.ylim(0, 1)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n 19. 20. 21.]\n[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n 0.5 0.5 0.5]\n\n\n/tmp/ipykernel_17130/566783336.py:91: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(loc='upper left')"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-005-ch3-1-ex-17.html",
    "href": "posts/mathematics/calculus/calc-005-ch3-1-ex-17.html",
    "title": "Calculus 5: Find A Derivative And Tangent",
    "section": "",
    "text": "1. Question\nAssume:\n\n\\(f(x)=\\sqrt{x}\\)\n\nAt \\((4,2)\\), Find:\n\n\\(f'(x)\\)\n\\(Tangent\\)\n\n\n\n2. Working-Out (Hand-written)\n\n\n\n3. Charts (Python)\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nx_at_c = 4\nx_deviation = 2\nx_increments = 21\nxs_min = x_at_c-x_deviation\nxs_max = x_at_c+x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)\n\n# # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 0]\nxs = xs[xs &gt;= 0]\n\nlbl_numerator = r'$f(x)=\\sqrt{x}$'\nfx_numerator = lambda x: np.sqrt(x)\nys_numerator = fx_numerator(xs)\n\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\nlbl_tangent = r'$f(x)=\\frac{x}{4}+1$ (tangent) '\nfx_tangent = lambda x: x/4+1\nys_tangent = fx_tangent(xs)\n\n\n# plot_title = lbl_numerator + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\nplot_title = lbl_numerator + \" and \" + lbl_tangent + \"at (4,2)\"\n\nplt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=6, label=lbl_numerator)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.plot(xs, ys_tangent,      'bo-', linewidth=2, markersize=6, label=lbl_tangent)\nplt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.scatter(xs, ys, marker=\"o\")\n\n# zoom and enhance!\n# plt.xlim(3.5, 4.5)  # X-axis range\n# plt.ylim(1.8, 2.2)  # Y-axis range\n# plt.xlim(-0.1, 0.1)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(plot_title, loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=4, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=2, color='grey', linestyle='--', linewidth=0.5)\n\n# # X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# # plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# # OTHER\n# # # b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# # plt.ylim(bottom=0)  # chart starts from y=0\n# # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# # ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n\n\n\n\n\n\n# ##################### FINAL FUNCTION ##################### \n# x_at_c = 3\n# x_deviation = 3\n# x_increments = 51\n# xs_min = x_at_c-x_deviation\n# xs_max = x_at_c+x_deviation\n# xs = np.linspace(xs_min, xs_max, x_increments)\n\n# # # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 2]\n\n# # lbl_numerator = r'$f(x)=x$'\n# # fx_numerator = lambda x: x\n# # ys_numerator = fx_numerator(xs)\n\n# # lbl_denom = r'$f(x)=x-2$'\n# # fx_denom = lambda x: x-2\n# # ys_denom = fx_denom(xs)\n\n# lbl_fx = r'$f(x)=\\frac{x}{x-2}$'\n# fx_fx = lambda x: (x)/(x-2)\n# ys_fx = fx_fx(xs)\n\n# # plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx\n\n# # plt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=8, label=lbl_numerator)\n# # plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(xs, ys_fx, marker=\"o\", label=lbl_fx)\n\n# # zoom and enhance!\n# # plt.xlim(-5, 1)  # X-axis range\n# plt.ylim(-8,8)  # Y-axis range\n# plt.xlim(-2, 7)  # X-axis range\n# # plt.ylim(-3.1, 3.1)  # Y-axis range\n\n# # Add grid, title, and legend\n# plt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n# plt.title(plot_title, loc='left')\n# # plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\n\n# # Optionally, add vertical and horizontal lines to highlight the zoomed area\n# ax = plt.gca()  # Get the current axis\n# ax.axvline(x=3, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=3, color='grey', linestyle='--', linewidth=0.5)"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-1",
    "href": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-1",
    "title": "Calculus 10: Generating & Coding A Sequence",
    "section": "2.1 Ex-7: Attempt 1",
    "text": "2.1 Ex-7: Attempt 1\n\na_n = 1\nn = 1\nseq_fracs_list = [(1,1)]\nfor n in range(1,10):\n    if n == 1:\n        a_n = 1\n    a_n1 = a_n + (1/2**n)\n    seq_fracs_list.append((n+1,a_n1)) # append to list\n    a_n = a_n1\nseq_fracs_list\n\n[(1, 1),\n (2, 1.5),\n (3, 1.75),\n (4, 1.875),\n (5, 1.9375),\n (6, 1.96875),\n (7, 1.984375),\n (8, 1.9921875),\n (9, 1.99609375),\n (10, 1.998046875)]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-separate-numerator-denomator",
    "href": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-separate-numerator-denomator",
    "title": "Calculus 10: Generating & Coding A Sequence",
    "section": "2.2 Ex-7: Attempt 2: separate numerator & denomator",
    "text": "2.2 Ex-7: Attempt 2: separate numerator & denomator\n\nfrom fractions import Fraction\n\na_n = 1\nn = 1\nseq_fracs_list = [(1,1)]\nnvals=30\nfor n in range(1,nvals):\n    if n == 1:\n        a_n = 1\n    a_n1 = a_n + (1/2**n)\n    seq_fracs_list.append((n+1,a_n1,Fraction(a_n1))) # append to list\n    a_n = a_n1\n    \nseq_fracs_list\n\n[(1, 1),\n (2, 1.5, Fraction(3, 2)),\n (3, 1.75, Fraction(7, 4)),\n (4, 1.875, Fraction(15, 8)),\n (5, 1.9375, Fraction(31, 16)),\n (6, 1.96875, Fraction(63, 32)),\n (7, 1.984375, Fraction(127, 64)),\n (8, 1.9921875, Fraction(255, 128)),\n (9, 1.99609375, Fraction(511, 256)),\n (10, 1.998046875, Fraction(1023, 512)),\n (11, 1.9990234375, Fraction(2047, 1024)),\n (12, 1.99951171875, Fraction(4095, 2048)),\n (13, 1.999755859375, Fraction(8191, 4096)),\n (14, 1.9998779296875, Fraction(16383, 8192)),\n (15, 1.99993896484375, Fraction(32767, 16384)),\n (16, 1.999969482421875, Fraction(65535, 32768)),\n (17, 1.9999847412109375, Fraction(131071, 65536)),\n (18, 1.9999923706054688, Fraction(262143, 131072)),\n (19, 1.9999961853027344, Fraction(524287, 262144)),\n (20, 1.9999980926513672, Fraction(1048575, 524288)),\n (21, 1.9999990463256836, Fraction(2097151, 1048576)),\n (22, 1.9999995231628418, Fraction(4194303, 2097152)),\n (23, 1.999999761581421, Fraction(8388607, 4194304)),\n (24, 1.9999998807907104, Fraction(16777215, 8388608)),\n (25, 1.9999999403953552, Fraction(33554431, 16777216)),\n (26, 1.9999999701976776, Fraction(67108863, 33554432)),\n (27, 1.9999999850988388, Fraction(134217727, 67108864)),\n (28, 1.9999999925494194, Fraction(268435455, 134217728)),\n (29, 1.9999999962747097, Fraction(536870911, 268435456)),\n (30, 1.9999999981373549, Fraction(1073741823, 536870912))]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-get-xs-ys",
    "href": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-get-xs-ys",
    "title": "Calculus 10: Generating & Coding A Sequence",
    "section": "2.3 Ex-7: Attempt 2: get xs & ys",
    "text": "2.3 Ex-7: Attempt 2: get xs & ys\n\nxs = [tple[0] for tple in seq_fracs_list[0:nvals]]\nys = [tple[1] for tple in seq_fracs_list[0:nvals]]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-chart",
    "href": "posts/mathematics/calculus/calc-010-ch10-1-ex-7-11.html#ex-7-attempt-2-chart",
    "title": "Calculus 10: Generating & Coding A Sequence",
    "section": "2.4 Ex-7: Attempt 2: Chart",
    "text": "2.4 Ex-7: Attempt 2: Chart\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n### x-values ###\n# xpt = 0.01\nxpt = 1.5\nx_deviation = 0.5\n# x_increments = 21\nx_increments = x_deviation*2+1\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\n# xs = np.linspace(xs_min, xs_max, x_increments)  # XS\nxs = xs\n# print(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\n# xs = xs[xs &gt; 0]\n# print(xs)\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$\\lim_{h \\rightarrow 0} \\frac{a^h-1}{h}$'   # LABEL\n# lbl_fx = r'$a_n= \\frac{1-n}{n^2}$'\nlbl_fx = r'$a_1=1,\\ a_{n+1}=a_n+(1/2^n)$'\n# fx_fx = lambda x: np.log(x)  # f(x)\n# fx_fx       = lambda n:       (1-n)/n**2 # f(x)\n# fx_fx       = lambda n:      1+(1/(2**n)) # f(x)\n# fx_fx0_5    = lambda h:    (0.5**h-1)/h  # f(x)\n# fx_fx2_5    = lambda h:    (2.5**h-1)/h  # f(x)\n# fx_fx1_5    = lambda h:    (1.5**h-1)/h  # f(x)\n# fx_fx2      = lambda h:      (2**h-1)/h  # f(x)\n# fx_fx3      = lambda h:      (3**h-1)/h  # f(x)\n# fx_fx10      = lambda h:      (10**h-1)/h  # f(x)\n\n### y-values ###\n# ys_fx = fx_fx(xs)\nys_fx = ys\nprint(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n# ys_fx0_5 = fx_fx0_5(xs)\n# ys_fx2_5 = fx_fx2_5(xs)\n# ys_fx1_5 = fx_fx1_5(xs)\n# ys_fx2 = fx_fx2(xs)\n# ys_fx3 = fx_fx3(xs)\n# ys_fx10 = fx_fx10(xs)\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=\"base 2\")\n# plt.plot(xs, ys_fx0_5,  'bo-', linewidth=2, markersize=6, label=\"base $a$: 0.5\")\n# plt.plot(xs, ys_fx2_5,  'gv--', linewidth=2, markersize=6, label=\"base $a$: 2.5\")\n# plt.plot(xs, ys_fx1_5,  'y^-.', linewidth=2, markersize=6, label=\"base $a$: 1.5\")\n# plt.plot(xs, ys_fx2,  'c&lt;-', linewidth=2, markersize=6, label=\"base $a$: 2\")\n# plt.plot(xs, ys_fx3,  'm&gt;:', linewidth=2, markersize=6, label=\"base $a$: 3\")\n# plt.plot(xs, ys_fx10,  'k-.', linewidth=2, markersize=6, label=\"base $a$: 10\")\nplt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\nplot_title = lbl_fx\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\n# plt.legend(loc='lower right')\nplt.legend(loc='upper left')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\n# plt.xlim(,xs_max)  # x-rng\nplt.ylim(0.9, 2.1)  # y-rng\n\n# vertical, horizontal, \n# ax = plt.gca()  # Get the current axis\n# ax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n[1, 1.5, 1.75, 1.875, 1.9375, 1.96875, 1.984375, 1.9921875, 1.99609375, 1.998046875, 1.9990234375, 1.99951171875, 1.999755859375, 1.9998779296875, 1.99993896484375, 1.999969482421875, 1.9999847412109375, 1.9999923706054688, 1.9999961853027344, 1.9999980926513672, 1.9999990463256836, 1.9999995231628418, 1.999999761581421, 1.9999998807907104, 1.9999999403953552, 1.9999999701976776, 1.9999999850988388, 1.9999999925494194, 1.9999999962747097, 1.9999999981373549]\n\n\n/tmp/ipykernel_16221/1066855485.py:98: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend(loc='upper left')"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-006-ch3-1-ex-23.html",
    "href": "posts/mathematics/calculus/calc-006-ch3-1-ex-23.html",
    "title": "Calculus 6: Find A Derivative And Tangent",
    "section": "",
    "text": "\\(f(x)=6t^2-9.28t+16.43\\)\n\n\nFind \\(f'(t)\\) at \\(t=5\\)\n\n\n1. Working-Out (Hand-written)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nxpt = 5\nx_deviation = 2\nx_increments = 21\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n# # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 1]\n# xs = xs[xs &gt;= 0]\n\nlbl_numerator = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\nfx_numerator = lambda x: 6.1*(x**2)-9.28*x+16.43   # F(X)\nys_numerator = fx_numerator(xs)             # YS = F(XS) \nypt_fx = fx_numerator(xpt)\nprint(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\nlbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\nfx_dydx = lambda x: 6.1*(2*x)-9.28\nxpt_dydx = xpt\ndydx = fx_dydx(xpt_dydx)\nprint(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\nc_tangent = ypt_fx-(dydx)*(xpt)\ntgt = \"tangent\"\nlbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at t={xpt})'\nfx_tangent = lambda x: dydx*xs+c_tangent\nys_tangent = fx_tangent(xs)\n\n\nplot_title = lbl_numerator + f\" & it's tangent at t={xpt}\"\n# plot_title = lbl_numerator + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_numerator + \" and \" + lbl_tangent + \"at (4,2)\"\n\nplt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=6, label=lbl_numerator)\n# plt.scatter(xs, ys_numerator, marker=\"o\")\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\nplt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n\n# zoom and enhance!\nplt.xlim(xpt-5,xpt+5)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(plot_title, loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=fx_numerator(xpt), color='grey', linestyle='--', linewidth=0.5)\n\nplt.scatter(x=xpt, y=fx_numerator(xpt), marker=\"o\")\n# print(fx_numerator(5))\n\nypt_fx_at_P(x=5): 122.53\nypt_dydx_at_P(x=5): 51.72\n\n\n\n\n\n\n\n\n\n\n# # X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# # plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# # OTHER\n# # # b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# # plt.ylim(bottom=0)  # chart starts from y=0\n# # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# # ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-001-chg-of-bse.html#normal-mode",
    "href": "posts/mathematics/linearalgebra/la-001-chg-of-bse.html#normal-mode",
    "title": "LA 1: Change of Basis",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-006-more-eigen-egs.html#normal-mode",
    "href": "posts/mathematics/linearalgebra/la-006-more-eigen-egs.html#normal-mode",
    "title": "LA 6: More Eigen examples",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode\n\n2.1 Exampe 1\n\n\n\n2.2 Exampe 2\n\n\n\n2.3 Exampe 3"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-003-eigen-examples.html#normal-mode",
    "href": "posts/mathematics/linearalgebra/la-003-eigen-examples.html#normal-mode",
    "title": "LA 3: Eigenvales and Eigenvectors Example",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-004-singleton-pattern.html",
    "href": "posts/computerscience/designpatterns/dp-004-singleton-pattern.html",
    "title": "DP 4: Singleton Pattern",
    "section": "",
    "text": "1. Create Singleton Class\nSingleton pattern creates a metaclass that limits the number of instance of a particular class to 1\nMetaclasses allow the customisation of object instantiation (see metaclasses post)\n\n__call__ method is overriden (see: call-magic-method post)\nself._instances list: keeps track of existence of instance\nid(cls._instances[cls]): allows us compare object instances\n\n\nclass SingleTonyCls(type):\n    _instances = {}\n    \n    def __call__(cls, *args, **kwds):\n        if cls not in cls._instances:\n            print(f\"{cls} does not exist! Creating new... \")\n            object_instance = super().__call__(*args, **kwds)\n            cls._instances[cls] = object_instance\n            print(f\"[{id(object_instance)}] added to {cls} list\")\n            # print(f\"[__name__]: {__name__}\") -- main file\n            # print(f\"[cls]: {cls}\") --  class name\n            # print(f\"[__class__]: {__class__}\") metaclass name\n        else:\n            print(f\"{cls} exists: [{id(cls._instances[cls])}] \")\n        return cls._instances[cls]\n\n\n\n2. Create Classes: Singleton\nThere should only be a single instances of any class that has metaclass following the singleton pattern.\nAll objects have the same id.\n\nclass FooSGL(metaclass = SingleTonyCls):\n    pass\n\n\n\n3. Create Classes: Regular Way\nThere is no limit to unique instances created.\nEach object should have a unique id.\n\nclass Foo():\n    pass\n\n\n\n4. Compare Object IDs: Singleton vs Regular Way\n\n\n4.1 Create Multiple Objects: Singleton\n\nfoo_sgl_a = FooSGL()\nfoo_sgl_b = FooSGL()\nfoo_sgl_c = FooSGL()\n\n&lt;class '__main__.FooSGL'&gt; does not exist! Creating new... \n[139808669538272] added to &lt;class '__main__.FooSGL'&gt; list\n&lt;class '__main__.FooSGL'&gt; exists: [139808669538272] \n&lt;class '__main__.FooSGL'&gt; exists: [139808669538272] \n\n\n\n\n4.2 Compare Object IDs: Singleton\nEach instantiation results in the returning of the first created object evidenced by the same object id\n\nprint(id(foo_sgl_a))\nprint(id(foo_sgl_b))\nprint(id(foo_sgl_c))\n\n139808669538272\n139808669538272\n139808669538272\n\n\n\n\n4.3 Create Multiple Objects: Regular Way\n\nfoo_a = Foo()\nfoo_b = Foo()\nfoo_c = Foo()\n\n\n\n4.4 Compare Object IDs: Regular Way\nEach instantiation results in a unique object id\n\nprint(id(foo_a))\nprint(id(foo_b))\nprint(id(foo_c))\n\n139808669355984\n139808669358432\n139808669357808"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-001-encapsulation-getter-python.html",
    "href": "posts/computerscience/designpatterns/dp-001-encapsulation-getter-python.html",
    "title": "DP 1: Encapsulation - Getter Method in Python",
    "section": "",
    "text": "1. Introduction\nThis post is specifically related to Issue #22 of tonyjustdevs/learning_designpatterns:\n\nadd @property decorator to enable getter\n\n\n\n2. Background\nEncapsulation is the:\n\nbundling of data (attributes) and\nmethods (functions)\ninto a single unit (class) and\nrestricting direct access to some of the object’s components.\n\nPurpose:\n\nTo hide implementation details and\nenforce controlled access to an object’s data.\n\nKey Components:\n\nAccess modifiers (private, protected, public in some languages) and\nGetters & Setters for controlled access.\n\n\n2.1 Getters and Setters:\nDefinition: These are methods used to retrieve (get) and update (set) private or protected attributes of a class.\nPurpose: To provide controlled access to the attributes while maintaining encapsulation.\nRelation to Encapsulation: They implement the idea of “controlled access” in encapsulation.\nThey are tools to implement encapsulation.\n\n\n\n3. Things To Do\n\nCreate Circle class\nInstantiate a circle instance\nTest attribute access directly: circle._radius\nTest attribute access via getter1: circle.radius_accessor\nTest attribute access via getter2: circle.radius\n\n\n\n4. Create Circle class\n\ncreate private variable: _radius\n\ncreate getter method: radius_accessor()\n\ndecorate with: @property\n\n\nclass Circle():\n  def __init__(self, name: str, radius: int):\n    self.name: str = name\n    self._radius: int = radius #21\n  \n  @property\n  def radius_accessor(self):\n    '''\n    @property\n    def radius_accessor(self):\n    \n    The name of this method becomes attribute name of an instance, or \n    (more accurately the attribute accesor?) \n    to access the private attribute we want \n    (usually defined in class init(): self._private_attribute)\n    \n    e.g. Suppose we have circle instance (type Circle)\n    with private attr: circle._radius. \n    Instead of accessing it directly (circle._radius)\n    which we can but we shouldn't, we access it via the getter created here \n    via @property with: circle.radius_accessor \n    \n    i.e. circle.radius_accessor is getter for circle._radius\n    \n    Therefore, a more suitable method name for this getter would be:\n    def radius():\n    \n    i.e.\n    \n    @property\n    def radius(self) allows us to access circle._radius via circle.radius   \n    '''\n    return self._radius\n  \n  @property\n  def radius(self):\n    '''explained in radius_accessor()'''\n    return self._radius\n  \n  def __repr__(self):\n    return f\"Circle(name={self.name!r}, _radius={self._radius!r})\"\n  \n  def __str__(self):\n    return f\"It's a circle named {self.name!r} with a round belly of {self._radius} centimeters!\"\n\n\n4.1 Notes for Tony\n\nprint(Circle.radius_accessor.__doc__)\n\n\n    @property\n    def radius_accessor(self):\n    \n    The name of this method becomes attribute name of an instance, or \n    (more accurately the attribute accesor?) \n    to access the private attribute we want \n    (usually defined in class init(): self._private_attribute)\n    \n    e.g. Suppose we have circle instance (type Circle)\n    with private attr: circle._radius. \n    Instead of accessing it directly (circle._radius)\n    which we can but we shouldn't, we access it via the getter created here \n    via @property with: circle.radius_accessor \n    \n    i.e. circle.radius_accessor is getter for circle._radius\n    \n    Therefore, a more suitable method name for this getter would be:\n    def radius():\n    \n    i.e.\n    \n    @property\n    def radius(self) allows us to access circle._radius via circle.radius   \n    \n\n\n\n\n\n5. Instantiate a circle instance\n\ncircle = Circle(\"Sir Cumference\",50)\nprint(f\"{circle}\") # calls __str__\n\nIt's a circle named 'Sir Cumference' with a round belly of 50 centimeters!\n\n\n\ncircle # defaults to __repr__\n\nCircle(name='Sir Cumference', _radius=50)\n\n\n\n\n6. Test attribute access directly: circle._radius\n\ncircle._radius # still works - because private attr dont exist in python\n\n50\n\n\n\n\n7. Test attribute access via getter1: circle.radius_accessor\n\ncircle.radius_accessor\n\n50\n\n\n\n\n8. Test attribute access via getter2: circle.radius\n\ncircle.radius\n\n50"
  },
  {
    "objectID": "posts/computerscience/coding/code-022-metaclasses.html",
    "href": "posts/computerscience/coding/code-022-metaclasses.html",
    "title": "Code 22: Python Metaclasses - Customising Class Creation",
    "section": "",
    "text": "1. bases and dcts arguments are empty\n\nTonyDynCls1Empty = type(\"TonyDynCls1Empty\",(),{})\nprint(TonyDynCls1Empty.__name__)\nprint(TonyDynCls1Empty)\nprint(TonyDynCls1Empty.__class__.__name__)\nprint(TonyDynCls1Empty.__base__)\nprint(TonyDynCls1Empty.__bases__)\nprint(TonyDynCls1Empty.__class__.__base__)\nprint(TonyDynCls1Empty.__class__.__bases__)\n\nTonyDynCls1Empty\n&lt;class '__main__.TonyDynCls1Empty'&gt;\ntype\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n\n\n\nclass Foo:\n    pass\n\n\n\n\n2. bases: (cls1,cls2) and dcts: {attr_1: ...}\nTwo inherited classes and 1 instance attribute\n\nTonyDynCls2 = type(\"TonyDynCls2\",\n                         (TonyDynCls1Empty,Foo), # existing cls\n                         {'attr_1':'222'}\n                         )\nprint(TonyDynCls2.__name__)\nprint(TonyDynCls2)\nprint(TonyDynCls2.__class__.__name__)\nprint()\nprint(TonyDynCls2.__class__.__name__)\nprint(TonyDynCls2.__base__)\nprint(TonyDynCls2.__bases__)\nprint()\nprint(TonyDynCls2.__class__.__base__)\nprint(TonyDynCls2.__class__.__bases__)\nprint()\nprint(TonyDynCls2.attr_1)\n\nTonyDynCls2\n&lt;class '__main__.TonyDynCls2'&gt;\ntype\n\ntype\n&lt;class '__main__.TonyDynCls1Empty'&gt;\n(&lt;class '__main__.TonyDynCls1Empty'&gt;, &lt;class '__main__.Foo'&gt;)\n\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n\n222\n\n\n\n\n3. Class Attribute and Lambda Instance Method\n\nTonyDynCls3 = type(\"TonyDynCls3\",\n                         (), # existing cls\n                         {'attr_1':\"333\", \n                          'get_attr_1': lambda self: self.attr_1}\n                         )\nprint(TonyDynCls3.__name__)\nprint(TonyDynCls3)\nprint(TonyDynCls3.__class__.__name__)\nprint()\nprint(TonyDynCls3.attr_1) # class attribute\n\ntony_dc3_instance = TonyDynCls3()\nprint(tony_dc3_instance.get_attr_1()) # class attribute\n\n\n\n\nTonyDynCls3\n&lt;class '__main__.TonyDynCls3'&gt;\ntype\n\n333\n333\n\n\n\n\n4. Class Attribute and Custom Instance Method\n\ndef some_method(self):\n    return self.attr\nTonyDynCls4 = type(\"TonyDynCls4\", (), {'attr': 444,\n                                       'get_attr': some_method})\n\ntony_dc4_instance = TonyDynCls4()\nprint(tony_dc4_instance.attr)\nprint(tony_dc4_instance.get_attr())\n\n444\n444\n\n\n\n\n5. Customising Instance Creation\n\nclass Foo:\n    pass\n\n    def __new__(cls):\n        x = object.__new__(cls)\n        x._secret_attr = \"555\"\n        return x\n    \na_foo = Foo() \na_foo._secret_attr\n\n'555'\n\n\n\nNote-to-self: psuedo-code steps\n\n\nby calling type() -&gt; python sees (), looks for type.__call__()\n\n\nnote type.__call__() &lt;——-&gt; type()\n\n\nor type.__call__(*args, **kwds) &lt;——-&gt; type(*args, **kwds)\n\n\ninside type.__call__(*args, **kwds)\n\n\ntype.__new__(cls, *args, **kwds)\n\n\nreturns x\n\n\ntype.__init__(x, *args, **kwds)\n\n\nreturns x\n\n\n\n\n\n6. Customising Class Creation\n\nclass TonyMetaClass(type):\n    pass\n\n    def __new__(cls, name, bases, dcts):\n        x = super().__new__(cls, name, bases, dcts)\n        \n        # calls parents type.__new__()\n        # which is usally called when you instantiate any class\n        # e.g Foo()\n        # 1. () -&gt; python looks for __call__()\n        # 2. find parents `type.__call__()`\n        # 3. inside has __new__() and __init__()\n        # 4. python will look for __new__() in our cls\n        # 5. if cant find, it uses type.__new__()\n        # 6. by defining __new__(): we can add custom behaviour\n        # 7. super().__new__(cls, name,bases, dcts) is the same\n        #    as type.__new__(...), or we are doing nothing new here\n        # 8. then we add custom beaviour x._secret_attr = ...\n        x._secret_attr = \"gday mate\"\n        \n        # 9. return object (as would default type.__new__())\n        return x\n    \nclass FooFoo(metaclass=TonyMetaClass):\n    pass\nfoofoo = FooFoo()\n\n\nfoofoo._secret_attr\n\n'gday mate'\n\n\n\n\n7. Simple Object Factory\n\nclass FooObjectFactory():\n    def __init__(self):\n        self.attr = 777\na = FooObjectFactory()        \nb = FooObjectFactory()        \nc = FooObjectFactory()        \nprint(a.attr, b.attr, c.attr) # each instance has initialised instance attr\n\n777 777 777\n\n\n\n\n8. Simple Class Factory\n\nclass MetaFooClsFactory(type):\n    def __new__(cls, name, bases, dcts): # &lt;metaclass&gt; type.__new__() creates the class\n        x = super().__new__(cls, name, bases, dcts) \n        x._attr = [\"888\"] # x, the class itself, an instance type, has class._attr\n        return x # return the x instance (the class)\n\nclass AFooCls(metaclass = MetaFooClsFactory):\n    pass\nclass BFooCls(metaclass = MetaFooClsFactory):\n    pass\nclass CFooCls(metaclass = MetaFooClsFactory):\n    pass\nprint(AFooCls._attr, BFooCls._attr, CFooCls._attr) # each cls has initialised cls attr\n\n['888'] ['888'] ['888']\n\n\n\n\n9. Simple Inheritance\n\nclass Baz():\n    cls_attr = '999'\n\nclass ABaz(Baz):\n    pass\nclass BBaz(Baz):\n    pass\nclass CBaz(Baz):\n    pass\n\nprint(ABaz.cls_attr, BBaz.cls_attr, CBaz.cls_attr)\n\n999 999 999\n\n\n\n\n10. Simple Decorator\n\ndef tony_decorator(cls):\n    class DecoratedClass(cls):\n        cls_attr = \"10\"\n    return DecoratedClass\n\n@tony_decorator\nclass QuxA:\n    pass\n@tony_decorator\nclass QuxB:\n    pass\n@tony_decorator\nclass QuxC:\n    pass\n\nprint(QuxA.cls_attr, QuxB.cls_attr, QuxC.cls_attr)\n\n10 10 10"
  },
  {
    "objectID": "posts/computerscience/coding/code-004-wsl_new_user.html",
    "href": "posts/computerscience/coding/code-004-wsl_new_user.html",
    "title": "Code 4: Create new Users in WSL",
    "section": "",
    "text": "1. Creating a new user with sudo priviledges\nsudo: allows you to run the following command with elevated privileges (like root access).\nadduser: creates a new user account in your WSL distribution.\nusermod: modifies existing user accounts.\n-aG: adds the user to a specific group.\ncut -d: -f1 /etc/passwd: list users.\nsu - username: login to username.\ngroups username: groups a user belongs to.\n\nsudo adduser tonyjustkaggles - add user\nsudo usermod -aG sudo tonyjustkaggles - add priviledges\nsudo visudo - open nano\n“tonyjustkaggles ALL=(ALL) NOPASSWD: ALL” - add more priviledges\nCtrl + O, Enter, Ctrl + X - save and exit\n\n\n\n3. VS Code (pre-installed on Windows)\nAdd PATH variable in new user so by typing code ., VS Code opens for the existing folder.\nexport PATH=\"$PATH:/mnt/c/Users/tonyp/AppData/Local/Programs/Microsoft VS Code/bin\n\n\n4. [Quick Fire] Other Useful Setup Things to do\n\n4.1 miniforge\n\nsu - tonyjustkaggles - login\nmkdir downloads + cd downloads\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\nbash Miniforge33-*.sh -b - run bash script to install\n~/miniforge3/bin/conda init bash - add paths\nwhich python - see python is from miniforge\n\n\n\n4.2 conda virtual environment\n\nconda create -n kaggle_venv - create venv for individual projects + avoid dependency issues\nconda activate kaggle_venv - create venv for individual projects + avoid dependency issues\nconda install python - install python into venv\n\n\n\n4.3 pytorch\n\nconda install pytorch torchvision torchaudio cpuonly -c pytorch - install pytorch from official site\nipython -&gt; import torch -&gt; torch + [tab] - Test pytorch works\n\n\n\n4.4 jupyter\n\nconda install -c conda-forge jupyterlab - install jlab from official site\n\n\n\n4.5 bash shortcuts\n\nvim ~/.bashrc -&gt; G,i -&gt; alias vb=\"vim ~/.bashrc\" -&gt; esc :wq - shortcut for vim bash\nvb -&gt; i -&gt; alias jl=\"jupyterlab --no-browser\" - jupyter lab short-cut\nvb -&gt; i -&gt; alias dl=\"cd ~/downloads\" -&gt; esc :wq - downloads\nvb -&gt; i -&gt; alias bl=\"cd ~/blog\" -&gt; esc :wq - blog (or :q! - don't save)\nvb -&gt; i -&gt; alias kv=\"conda activate kaggle_venv\" -&gt; esc :wq - activate venv\n\n\n\n4.6 kaggle\n\nconda install conda-forge::kaggle - install kaggle api from official site\nKaggle -&gt; Settings -&gt; Create Token -&gt; Paste into: /home/tonyjustkaggles/.kaggle\n\n\n\n4.7 ssh, github and blog\n\nssh-keygen -&gt; cat pub-key -&gt; copy into Github\ngit clone git@github.com:tonyjustdevs/blog.git with ssh option\n\n\n\n4.8 visudo\n\nsudo visudo -&gt; User privilege specification -&gt; tonyjustkaggles ALL=(ALL) NOPASSWD: ALL -&gt; ctrl O + Enter + ctrl X\nexport PATH=\"$PATH:/mnt/c/Users/tonyp/AppData/Local/Programs/Microsoft VS Code/bin\"\n\n\n\n\n5. Complete"
  },
  {
    "objectID": "posts/computerscience/coding/code-008-quarto_on_wsl.html",
    "href": "posts/computerscience/coding/code-008-quarto_on_wsl.html",
    "title": "Code 8: How to install Quarto via WSL",
    "section": "",
    "text": "How to install Quarto on WSL (Ubuntu)\n\nCheck you are indeed on ubuntu (Note: All commands in [Windows Terminal] -&gt; [Ubuntu distro]):\n\nlsb_release -a :\n\n\nGo to official site and get copy Ubuntu link:\n\nofficial quarto download site\n\nCreate (or navigate to) Downloads folder:\n\nmkdir downloads && cd downloads\n\nDownload Official Quarto Deb file (your official link from above dotpoint is newer, use that!):\n\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.5.57/quarto-1.5.57-linux-amd64.deb:\n\nInstall:\n\nsudo dpkg -i quarto-1.5.57-linux-amd64.deb\n\nTest it (prints version to terminal):\n\nquarto version"
  },
  {
    "objectID": "posts/computerscience/coding/code-005-debug_1l_nn.html",
    "href": "posts/computerscience/coding/code-005-debug_1l_nn.html",
    "title": "Code 5: Debugging a 1-Hidden-Layer Neural Network Model",
    "section": "",
    "text": "1. Introduction\nI’ve coded from scratch a neural network using Kaggle Titanic dataset based on a Jeremy Howard’s popular NN-model.\nI noticed descrepancies in Loss between my model and the reference model and will attempt debug My Model (TP) without looking at the Reference Models (RM) code.\n\n\n2. The Problem\nLoss differences (from 2nd epoch onwards):\n\nTP-Loss: 0.544 (epoch_1), 0.538 (epoch_2)\nRM-Loss: 0.543 (epoch_1), 0.532 (epoch_2)\n\nThe difference grows per epoch.\n\n\n\n3. The Approach\nThis neural network model only has one-hidden-layer.\nI’ve decided to test differences at 3 stages:\n\nInput level (input data, coefficients, and constants)\nIntermediary Calculations (hidden layers and relu)\nPredictions (predictions and sigmoid)\nUpdate Coefficients (gradients and updated coefficients)\n\n\n\n4. The Analysis\n\n4.1 Input Level - Normalised Input Data - idep_mxn\nEPOCH 1 and 2: OKAY (data-matching) \n\n\n4.2 Input Level - Coeffs - Layer 1 - L1_nxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.3 Input Level - Coeffs - Layer 2 - L2_qx1\nEPOCH 1: OKAY (data-matching) \n\n\n4.4 Input Level - Coeffs - Constant - CONST_1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.5 Intermediary Calcs - idep@L1 - pred_PSET_HL_mxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.6 Intermediary Calcs - relu(idep@L1) - PSET_HL_mxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.7 Final Preds - PSET_HL_mxq@L2 - PREDS_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.8 Final Preds - PREDS_mx1 + CONST_1 - PREDS_C_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.9 Final Preds - Sigmoid(PREDS_C_mx1) - SGM_PREDS_C_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.10 - Loss -\nEPOCH 1: NOT OKAY, Loss values different from 4th decimals\nSince Loss is created taking the absolute difference (then mean) between the:\n\npredictions and\n(actual) dependent variables\n\nLets validate across the neural network models:\n\nDependent Variable (“Survived”)\n\nPredictions\n\n\n\n\nModel\nLoss\n\n\n\n\nTP\n0.5433918237686157\n\n\nRM\n0.5439100861549377\n\n\n\n\n\n\n5. The Bug\n\n5.1 Input Level - Dep Variable - dep_mx1\nEPOCH 1: NOT OKAY:- **Dimensions are different!\nFound the Bug!\n\nTP-dimensions: [713,1]\nRM-dimensions: [713]\n\n\n\n\n\n6. The Fix\n\n6.1 Adding Trailing Dimension [:,None]\nSolution: Add trailing dimesion for dependent variables, fixing the predictions calculation, thus loss.\n\n\n\n6.2 Check New Loss\nIt matches EXACTLY!\n\n\n\n\n7. Conclusion\nIt goes to show how important getting the correct dimensions can change things so subtley and materially at the same time."
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#create-task-list-and-set-list-action-parameter",
    "href": "posts/computerscience/coding/code-011-github-api.html#create-task-list-and-set-list-action-parameter",
    "title": "Code 11: Using Github API via Python",
    "section": "4.1 Create Task List and Set List Action parameter",
    "text": "4.1 Create Task List and Set List Action parameter\n\n# 1. Choose 'New' or 'Append' to current description:\nlist_action_param = 'New'\n# list_action_param = 'Append'\n\n# 2. Enter list of tasks\nlist_of_tasks = [\n  \"A very cool new task\",\n  \"Another mad chill new task\",\n  \"A final exquisite crazy new task\"\n]"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#set-github-configs",
    "href": "posts/computerscience/coding/code-011-github-api.html#set-github-configs",
    "title": "Code 11: Using Github API via Python",
    "section": "4.2 Set Github Configs",
    "text": "4.2 Set Github Configs\n\n# 3. Set Repo and Issue\nREPO_USER = \"tonyjustdevs\"\nREPO_TOPIC = \"blog\"\nISSUE_NUMBER = 95\n\n# 4. Configs\nGITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nREPO = f\"{REPO_USER}/{REPO_TOPIC}\"\nGITHUB_API_URL = f\"https://api.github.com/repos/{REPO}/issues\"\nHEADERS = {\n    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n    \"Accept\": \"application/vnd.github.v3+json\"\n}"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#check-response-is-okay-200",
    "href": "posts/computerscience/coding/code-011-github-api.html#check-response-is-okay-200",
    "title": "Code 11: Using Github API via Python",
    "section": "4.3 Check Response is OKAY (200)",
    "text": "4.3 Check Response is OKAY (200)\n\nissue_url = f\"{GITHUB_API_URL}/{ISSUE_NUMBER}\"\nresponse = requests.get(issue_url, headers=HEADERS) #200\nresponse\n\n&lt;Response [200]&gt;"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#get-and-check-current-description-data",
    "href": "posts/computerscience/coding/code-011-github-api.html#get-and-check-current-description-data",
    "title": "Code 11: Using Github API via Python",
    "section": "4.4 Get and Check Current Description Data",
    "text": "4.4 Get and Check Current Description Data\n\nissue_data = response.json()\ndescription = issue_data['body']\ndescription\n\n'sample description'"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#prepare-description-string-objects",
    "href": "posts/computerscience/coding/code-011-github-api.html#prepare-description-string-objects",
    "title": "Code 11: Using Github API via Python",
    "section": "4.5 Prepare description string objects",
    "text": "4.5 Prepare description string objects\n\nprint(f\"List action parameter selected: '{list_action_param}'\")\nif description is not None and list_action_param==\"Append\": #\"New\" or \"Append\"\n  print(\"Description exists, no action required.\")\nelse:\n  description= \"\"\n  print(\"New (empty) description created.\") \n\nList action parameter selected: 'New'\nNew (empty) description created."
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#convert-tasks-to-single-string-object",
    "href": "posts/computerscience/coding/code-011-github-api.html#convert-tasks-to-single-string-object",
    "title": "Code 11: Using Github API via Python",
    "section": "4.6 Convert tasks to single string object",
    "text": "4.6 Convert tasks to single string object\n\nadded_description_str = \"\"\nEOL_str = \"\\r\\n\"\ngithub_check_pointer_str = \"- [ ]\"\nfor task in list_of_tasks:\n  added_description_str += f\"{github_check_pointer_str} {task}{EOL_str}\"\n  print(f\"'{task}' appended.\")\n\n'A very cool new task' appended.\n'Another mad chill new task' appended.\n'A final exquisite crazy new task' appended.\n\n\n\nadded_description_str\n\n'- [ ] A very cool new task\\r\\n- [ ] Another mad chill new task\\r\\n- [ ] A final exquisite crazy new task\\r\\n'"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#append-to-current-description",
    "href": "posts/computerscience/coding/code-011-github-api.html#append-to-current-description",
    "title": "Code 11: Using Github API via Python",
    "section": "4.7 Append to current description",
    "text": "4.7 Append to current description\n\ndescription+=added_description_str\n\n\nend_description_str = \"description added via [tony_add_tasks.ipynb]\"\ndescription += f\"{EOL_str}{end_description_str}{EOL_str}\"\n\n\nprint(description)\n\n- [ ] A very cool new task\n- [ ] Another mad chill new task\n- [ ] A final exquisite crazy new task\n\ndescription added via [tony_add_tasks.ipynb]"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#prepare-description-dictionary-object-to-send-to-api",
    "href": "posts/computerscience/coding/code-011-github-api.html#prepare-description-dictionary-object-to-send-to-api",
    "title": "Code 11: Using Github API via Python",
    "section": "4.7 Prepare description dictionary object to send to API",
    "text": "4.7 Prepare description dictionary object to send to API\n\nupdate_data = {\n    \"body\": description\n}"
  },
  {
    "objectID": "posts/computerscience/coding/code-011-github-api.html#update-description-object-via-api",
    "href": "posts/computerscience/coding/code-011-github-api.html#update-description-object-via-api",
    "title": "Code 11: Using Github API via Python",
    "section": "4.8 Update description object via API",
    "text": "4.8 Update description object via API\n\nresponse = requests.patch(issue_url, headers=HEADERS, json=update_data)\n\nif response.status_code == 200:\n    print(\"Issue description updated successfully!\")\nelse:\n    print(f\"Failed to update issue description: {response.status_code}, {response.text}\")\n\nIssue description updated successfully!"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#function-class-vs-method-class",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#function-class-vs-method-class",
    "title": "Code 14: Python Classes Basics 101",
    "section": "2.1 function class vs method class:",
    "text": "2.1 function class vs method class:\nA function becomes a method when the function is accessed via an object instance (see examples)"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#function-and-integer-class",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#function-and-integer-class",
    "title": "Code 14: Python Classes Basics 101",
    "section": "2.2 function and integer class:",
    "text": "2.2 function and integer class:\nThese two classes remain as is when declared within a Class. - Wheter standalone or - A Class attribute (e.g. ClassName.function).\n\ninteger remains as is as Object Instance attribute too."
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#class-and-instance-attributes-examples",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#class-and-instance-attributes-examples",
    "title": "Code 14: Python Classes Basics 101",
    "section": "2.3 Class and Instance Attributes Examples",
    "text": "2.3 Class and Instance Attributes Examples\n\ndelim = \": \"\n\nline0=\"type(MyClass.i)\" + delim\nline0val=type(MyClass.i)\n\nline1=\"type(MyClass.f)\" + delim\nline1val=type(MyClass.f)\n\nline2=\"type(temp_fn)\" + delim\nline2val=type(temp_fn)\n\nline3=\"type(instance_object.f)\" + delim\nline3val=type(instance_object.f)\n\nline4=\"type(instance_object.i)\" + delim\nline4val=type(instance_object.i)\n\nprint(f\"{line0:&lt;25}{str(line0val)}\") # experimenting new way to print()\nprint(f\"{line1:&lt;25}{str(line1val)}\")\nprint(f\"{line2:&lt;25}{str(line2val)}\")\nprint(f\"{line3:&lt;25}{str(line3val)}\")\nprint(f\"{line4:&lt;25}{str(line4val)}\")\n\ntype(MyClass.i):         &lt;class 'int'&gt;\ntype(MyClass.f):         &lt;class 'function'&gt;\ntype(temp_fn):           &lt;class 'function'&gt;\ntype(instance_object.f): &lt;class 'method'&gt;\ntype(instance_object.i): &lt;class 'int'&gt;"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#data-attributes",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#data-attributes",
    "title": "Code 14: Python Classes Basics 101",
    "section": "3.1 Data Attributes",
    "text": "3.1 Data Attributes\n\nNeed not be declared\ndata members in C++\nspring into existence when first assigned"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#example",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#example",
    "title": "Code 14: Python Classes Basics 101",
    "section": "3.1.1 Example",
    "text": "3.1.1 Example\nBelow counter is data_attribute of the object instance_object (which is of type MyClass).\ncounters value 16 is printed, then deleted without leaving a trace:\n\nprint(type(instance_object))  \n\ninstance_object.counter = 1\n\nprint(type(instance_object.counter))  \n\nwhile instance_object.counter &lt; 10:\n    instance_object.counter = instance_object.counter * 2\nprint(instance_object.counter)\ndel instance_object.counter\n\nprint(type(instance_object.counter))  \n\n&lt;class '__main__.MyClass'&gt;\n&lt;class 'int'&gt;\n16\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 12\n      9 print(instance_object.counter)\n     10 del instance_object.counter\n---&gt; 12 print(type(instance_object.counter))  \n\nAttributeError: 'MyClass' object has no attribute 'counter'"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#assign-a-method-object",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#assign-a-method-object",
    "title": "Code 14: Python Classes Basics 101",
    "section": "4.1 Assign a Method Object",
    "text": "4.1 Assign a Method Object\n\n# assign method object\nxf = instance_object.f\nxf\n\n&lt;bound method MyClass.f of &lt;__main__.MyClass object at 0x7fc46c36b8b0&gt;&gt;"
  },
  {
    "objectID": "posts/computerscience/coding/code-014-python-classes-101.html#call-the-method-oject",
    "href": "posts/computerscience/coding/code-014-python-classes-101.html#call-the-method-oject",
    "title": "Code 14: Python Classes Basics 101",
    "section": "4.2 Call the Method Oject",
    "text": "4.2 Call the Method Oject\n\nxf()\n\n'hello world'"
  },
  {
    "objectID": "posts/computerscience/coding/code-012-vscode-keybindings-json.html",
    "href": "posts/computerscience/coding/code-012-vscode-keybindings-json.html",
    "title": "Code 12: Create new key-bindings in VSCode via JSON file",
    "section": "",
    "text": "1. How to add a new Key-Binding via VSCode JSON file\n\n1.1 Go to Preferences\n\nGo to Preferences or\n\nctrl-shift-p then [**Preferences: Open Keyboard Shortcuts (JSON)**]\n\n\n\n1.2 Add entry JSON file\n\nThe entry is all the code below (including curly brackets).\nInsert code into the json list already existing in the json file:\n\nie in betweeen the square brackets in the json file.\n\n\n\n\n1.3 Keybinding: [Go to next terminal] - json code\n\n{\n    \"key\": \"ctrl+tab\",\n    \"command\": \"workbench.action.terminal.focusNext\",\n    \"when\": \"terminalFocus\"\n}\n\n\n\n1.4 Keybinding: [Go to next terminal] - screenshot\n\n\n\n1.5 [Bonus] Keybinding: [Kill all terminals] - json code\n\n{\n    \"key\": \"ctrl+shift+w\",\n    \"command\": \"workbench.action.terminal.killAll\",\n    \"when\": \"terminalHasBeenCreated || terminalIsOpen || terminalProcessSupported\"\n}\n\n\n\n1.6 [Bonus] Keybinding: [Kill all terminals] - screenshot"
  },
  {
    "objectID": "posts/computerscience/coding/code-020-utf-8-encoding.html#a-cool-name-梁國富",
    "href": "posts/computerscience/coding/code-020-utf-8-encoding.html#a-cool-name-梁國富",
    "title": "Code 20: Unicode, UTF-8 and Bytes",
    "section": "2.1 A Cool Name “😎梁國富⚽”",
    "text": "2.1 A Cool Name “😎梁國富⚽”\n\nmy_str = \"😎梁國富⚽\" # a cool chinese name"
  },
  {
    "objectID": "posts/computerscience/coding/code-020-utf-8-encoding.html#encode-string-to-bytes-via-utf-8",
    "href": "posts/computerscience/coding/code-020-utf-8-encoding.html#encode-string-to-bytes-via-utf-8",
    "title": "Code 20: Unicode, UTF-8 and Bytes",
    "section": "2.2 Encode string to bytes via utf-8",
    "text": "2.2 Encode string to bytes via utf-8\nConverts string into a bytes object using the UTF-8 encoding scheme.\nIf string contains non-ASCII characters, UTF-8 ensures they are represented properly in bytes.\n\nmy_str_utf8_bytes = my_str.encode(\"utf-8\") # (str -&gt; utf-8 bytes)\nmy_str_utf8_bytes\n\nb'\\xf0\\x9f\\x98\\x8e\\xe6\\xa2\\x81\\xe5\\x9c\\x8b\\xe5\\xaf\\x8c\\xe2\\x9a\\xbd'\n\n\n\n2.2.1 Why bytes?\nBytes data/objects are important in programming for several key reasons:\n\nEfficient Storage: Bytes provide an efficient way to store raw binary data. They use 8 bits per byte, which allows for compact storage of information.\nLow-Level Operations: Bytes are fundamental units of data in computer systems. Working with bytes enables low-level operations like memory manipulation, file I/O, and network communication.\nBinary Data Handling: Bytes are essential for handling binary data formats like images, audio files, and executable code. These formats are represented as sequences of bytes.\nCryptographic Operations: In cryptography and security-related tasks, working with raw byte data is often necessary. This includes generating random numbers, hashing, and encryption/decryption.\nNetwork Communication: When sending data over networks, it’s typically transmitted as byte streams. This allows for efficient transmission of various types of data.\nCompression Algorithms: Some compression algorithms work directly on byte sequences rather than text strings.\nMemory Efficiency: In scenarios where memory usage is critical (like embedded systems), working with bytes allows for more efficient use of available resources.\nPerformance Optimization: Certain operations, especially those involving large datasets, can be optimized by working directly with bytes rather than converting to and from strings repeatedly.\nInteroperability: Bytes provide a common format that can be easily converted between different programming languages and systems.\nData Integrity: When dealing with binary data that may contain non-printable characters or invalid Unicode sequences, working with bytes ensures data integrity.\nFile Handling: Many file formats, especially those used in scientific computing or specialized applications, are represented as byte streams.\nProtocol Buffers: In distributed systems and microservices architectures, protocols like Protocol Buffers often serialize data into byte streams for efficient transmission."
  },
  {
    "objectID": "posts/computerscience/coding/code-020-utf-8-encoding.html#convert-bytes-to-hexadecimal",
    "href": "posts/computerscience/coding/code-020-utf-8-encoding.html#convert-bytes-to-hexadecimal",
    "title": "Code 20: Unicode, UTF-8 and Bytes",
    "section": "2.3 Convert bytes to hexadecimal",
    "text": "2.3 Convert bytes to hexadecimal\nConverts to base-16 representation of the binary data.\n\nmy_str_hex = my_str_utf8_bytes.hex() # (utf-8-bytes -&gt; hex-#)\nmy_str_hex\n\n'f09f988ee6a281e59c8be5af8ce29abd'\n\n\n\nmy_str_bytes = bytes.fromhex(my_str_hex) # (hex-# -&gt; utf-8-bytes)\nmy_str_bytes\n\nb'\\xf0\\x9f\\x98\\x8e\\xe6\\xa2\\x81\\xe5\\x9c\\x8b\\xe5\\xaf\\x8c\\xe2\\x9a\\xbd'\n\n\n\nmy_str_bytes.decode(\"utf-8\") # '梁國富' (utf-8-bytes to str)\n\n'😎梁國富⚽'"
  },
  {
    "objectID": "posts/computerscience/coding/code-002-linux_setup.html#introduction",
    "href": "posts/computerscience/coding/code-002-linux_setup.html#introduction",
    "title": "Code 2: Data Science Machine",
    "section": "1. Introduction",
    "text": "1. Introduction\nThis post shows how to set up Linux-based Python Notebooks on a Windows PC for Data Science and Deep Learning Projects.\nOne of the drawbacks of Python-based Projects are compatability issues with packages which were developed with Linux.\nLinux is often preferred for Python development due to its:\n- powerful terminal for scripting and automation\n- has a open-source philosophy fostering community-driven ecosystem\n- containerization (e.g. Docker) and orchestration (e.g. Kubernetes)\n- Has a robust package management (APT and YUM)\n- Resource efficiency suitable for running Python applications (in resource-constrained environments)\n- compatibility with production environments & real-world deployments"
  },
  {
    "objectID": "posts/computerscience/coding/code-002-linux_setup.html#linux",
    "href": "posts/computerscience/coding/code-002-linux_setup.html#linux",
    "title": "Code 2: Data Science Machine",
    "section": "2. Linux",
    "text": "2. Linux\n\n2.1 Install Linux\nI had previously blindly installed Linux, officially named “Windows Subsystem for Linux (wsl)” and then never used it again.\nI’ll firstly uninstall the existing distribution, then install a fresh copy.\n\nCheck any existing installation: wsl -l\nIf exists, uninstall: wsl --unregister Ubuntu\nRun 1. again wsl - l\nInstall Linux wsl --install\nCreate username\nCreate passwword\n\n\nwsl -l # Run in Windows Powershell \nwsl --unregister Ubuntu # Unregister if exists\nwsl -l\nwsl --install # Install wsl\n\n\n\n\n2.2 Linux Basics\n\nUsername: whoami\nSwitch user (from admin): sudo -u user_name -i\nSwitch user (user login): su - username\nWorking directory: pwd\nMove to folder in current directory : cd /\nHome: echo $HOME\nMove to root : cd /\nMove up 1-level: cd ..\nList all in folder: ls\nMove up a level: cd ..\nPrivledges: sudo id\nCreate user: sudo adduser new_user_name\nList usernames: cut -d: -f1 /etc/passwd\nGrant “bob” permission to install a pkg:: sudo -u bob apt install pkg-name\nDownload url: wget url\nRemove: rm folder\nRemove forcefully : rm -rf folder\nMove folder: mv folder_from folder_to\nList human readable: ls -lh\nList all includes hidden: la -a\nList with permissions: ls -l\nAdd permissions to file: chmod u+x theshell.sh\nA Shell script: .sh\nRead .sh script: less scriptname.sh\nRun .sh with Bash: bash scriptname.sh\nRun .sh with Bash accept all licenses: bash scriptname.sh -b\nRun .sh with pattern with Bash: bash Miniforge3-*.sh -b\nAutomatically runs when Terminal starts: .bashrc\nEdit a script: vim .bashrc\nBash history: cat .bash_history\nSearch Bash history: ctrl r + word\nRun last command starting with: !ju (runs jupyter if you’ve previously run it)\nRerun last command: !!\nMove to start of line: ctrl+a\nMove to end of line: ctrl+e\nMove by word: alt+l, alt+r\nCreate alias: alias jl = \"jupyter lab --no-browser\"\n[vim] - enter normal mode: Esc key\n[vim] - move to front: gg\n[vim] - move to end: G\n[vim] - highlight to end: V(visual mode) G (move to end)\n[vim] - move along word: h,j,k,l,w,b,e,0\n[vim] - move along line: 0,$,^\n[vim] - move along screen: H,M,L\n[vim] - move along pages: ctrl + f,b,d,u\n[vim] - move line: zt,zz,zb\n[vim] - search: /pattern,?pattern,n,N\n[vim] - move line nbr: :[line number]\n[vim] - make changes / insert mode: i then esc\n[vim] - save changes: :w\n[vim] - quit: :q\n[vim] - quit and discard changes: :q!\n[vim] - help: self-explanatory\n[tmux] - split-right: ctrl-b %\n[tmux] - split-down: ctrl-b \"\n[tmux] - move: ctrl-b arrows\n[tmux] - detach: ctrl-b d\n[tmux] - attach: tmux a"
  },
  {
    "objectID": "posts/computerscience/coding/code-002-linux_setup.html#python",
    "href": "posts/computerscience/coding/code-002-linux_setup.html#python",
    "title": "Code 2: Data Science Machine",
    "section": "3. Python",
    "text": "3. Python\nThere are several options for building linux python projects:\n\nConda: For extensive package management and control or flexibility beyond deep learning/data science.\nMiniforge: For lightweight and focused option for deep learning/data science projects.\nAnaconda: For a convenient, pre-configured environment for data science and deep learning, but be mindful of its larger size.\n\nFor my purposes, I’d like to be focused on deep learning / data science projects hence I’ll install Miniforge.\nSee miniforge github\n\n3.1 Miniforge\nMiniforge offers a powerful and user-friendly environment management platform for data science and deep learning.\nSeveral reasons to use Miniforge:\n- Virtual environments: Isolate projects and manage dependencies.\n- Pre-built environments: Quickly set up optimized environments (TensorFlow, PyTorch, etc.).\n- Cross-platform compatibility: Works on Windows, macOS, and Linux.\n- Large community and support: Extensive resources and active development.\n- Performance and efficiency: Caching and optimized packages.\n- Free and open-source: No licensing costs or limitations.\n\n\n3.2 Get Miniforge download link\n\nGet amd64 (Windows) download link from Miniforge Github\nDownload link used: “https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh”\n\n\n\n\n3.3 Install Miniforge in Ubuntu\n\nOpen Windows Terminal (this should automatically open Ubuntu now)\nGo to Home directory (echo $HOME) :\n\nLogging in su - username or\nMoving up cd .. and down cd folder_name_in_curr_dir\n\nGo to your home/directory: echo $HOME\nCreate a new working directory: mkdir downloads\nMove to downloads folder: cd downloads\n\nThis folder should be empty, and your Ubuntu should be not found with these keywords: Python, Jupyter, ipython etc.\nIf they are found:\n\nUninstall: pip install ipython,\nDelete: rm -rf ipython or rm usr/bin/jyp or\nMove: mv folder_from folder_to\n\n\nDownload url: wget the_copied_url_link_from_github_above or\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n\n\n\n3.4 Run downloaded Miniforge shell script\n\n[Manual Method]:\n\nAccept All Permissions (Creates environment variables so that keywords like ‘conda’ works and automatically runs Conda when Terminal is first logged on and activates a base environment. This automation is done by editting the .bashrc file.) or\n\n[Script Method]:\n\nbash Miniforge3-*.sh -b and then\n~/miniforge3/bin/conda init bash. This runs python file conda.py within miniforge which runs another file that creates the Conda Paths and Adding Paths to Ubuntu Environment variables (same as accepting all permissions in manual method)\n\n\nThere should be two folders: downloads and miniforge3 in the Home directory (Ignore nbs, this is created later)"
  },
  {
    "objectID": "posts/computerscience/coding/code-002-linux_setup.html#conda",
    "href": "posts/computerscience/coding/code-002-linux_setup.html#conda",
    "title": "Code 2: Data Science Machine",
    "section": "4. Conda",
    "text": "4. Conda\nPython should be now installed via miniforge3:\n- which python should be running from miniforge3 folder within your Home directory.\n- If not, something went wrong!\n\n\n4.1 Conda basics\n\nShow conda arguments: conda\n\nGeneral system info: conda info\n\nShow environments: conda env\n\nCreate new environment: conda create -n deep_learning\n\nActivate environment: conda activate deep_learning\n\nShow installed packages: conda list\n\nInstall a package: conda install package_name\n\n\n\n4.2 Install Pytorch\nGo to Official Website and choose accordingly and install\nI used conda install pytorch torchvision torchaudio cpuonly -c pytorch\nNotes: Following the website ensures all binary dependencies are install, simply typing pip install pytorch wont work as normally due to requiring to also needing to installing CUDA SDK (if you have a NVidia GPU)\n\n\n\n4.3 Checking Pytorch is working\n\nHave Ipython installed and ipython\nimport torch\ntorch. + *tab* button This should display a list of available pytorch methods.\nctrl_d to exit"
  },
  {
    "objectID": "posts/computerscience/coding/code-002-linux_setup.html#jupyter-notebooks",
    "href": "posts/computerscience/coding/code-002-linux_setup.html#jupyter-notebooks",
    "title": "Code 2: Data Science Machine",
    "section": "5. Jupyter Notebooks",
    "text": "5. Jupyter Notebooks\nInstall Jupyter Lab to have suite of notebooks and other useful tools for testing and developing data science and deep learning projects.\n\n5.1 Install Jupyter Lab\nGo to Official Website and select appropriate install option I used conda install -c conda-forge jupyterlab.\n\n\n\n5.2 Run Jupyter Lab\n\nRun Jupyter: jupyter lab or\nRun Jupyter: jupyter lab --no-browser (avoids attempting to open a browser in linux because it cant)\n\n\n\n\n5.3 Automate Alias\nSave alias jl=\"jupyter lab --no-browser\" into .bashrc to jl works everytime:\n\nOpen bashrc: vim ~/.bashrc\nGo to End: G\nPaste: alias jl=\"jupyter lab --no-browser\nSave: :qw: (quit q and save w)\n\n\n\n\n5.4 Open in Browser\n\nOpen in Browser by [Control+Click] the link\n\n\n\n\n5.5 Save First Notebook in Linux\nTry out PyTorch in the Notebook and save it."
  },
  {
    "objectID": "posts/computerscience/coding/code-023-logging.html",
    "href": "posts/computerscience/coding/code-023-logging.html",
    "title": "Code 23: Logging",
    "section": "",
    "text": "1. Root Logger\nConfigure Root Logger that apples to whole app\n\nPros: Simple and quick & Less code\nCons: Lack of control & Limited customization\n\n\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\nlogging.debug(\"This is a debug message\")\nlogging.info(\"This is an info message\")\nlogging.warning(\"This is a warning message\")\n\n2025-02-10 13:12:50,256 - DEBUG - This is a debug message\n2025-02-10 13:12:50,259 - INFO - This is an info message\n2025-02-10 13:12:50,260 - WARNING - This is a warning message\n\n\n\n\n2. Custom Logger Instance - To File\nPros:\n\nModular and organized\nGranular control\nBetter for larger applications\n\nCons:\n* More setup * Potential for inconsistency\n\nimport logging\n\n# logger = logging.getLogger(\"my_app.module1\") #create logger named my_app.module1\nlogger = logging.getLogger(__name__) \n\nlogger.setLevel(logging.DEBUG)\nprint(logger.name)\nfile_handler = logging.FileHandler(\"app.log\")\nfile_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\nlogger.addHandler(file_handler)\n\n\n__main__\n\n\n\n\n3. Log to Console As Well\n\nconsole_handler = logging.StreamHandler()\nconsole_formatter = logging.Formatter('%(levelname)s - %(message)s')  # Simple format for console\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(console_handler)\nlogger.debug(\"a debug msg going to file and console\")\nlogger.info(\"an info msg to file and console\")\n\nDEBUG - a debug msg going to file and console\nINFO - an info msg to file and console\n\n\n\n\n4. Multiple Loggers and Hierarchy\n\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG) # root logger\n\napp_logger = logging.getLogger(\"my_app\") # main app logger\napp_logger.setLevel(logging.INFO)\n\nmodule1_logger = logging.getLogger(\"my_app.module1\")# specific module logger\nmodule1_logger.setLevel(logging.DEBUG)\n\nmodule2_logger = logging.getLogger(\"my_app.module2\") # Logger for another module\nmodule2_logger.setLevel(logging.WARNING)\n\napp_logger.info(\"This is an info message from the main app\") \nmodule1_logger.debug(\"This is a debug message from module 1\")\nmodule2_logger.warning(\"This is a warning message from module 2\")"
  },
  {
    "objectID": "posts/computerscience/coding/code-006-measuring_accuracy.html",
    "href": "posts/computerscience/coding/code-006-measuring_accuracy.html",
    "title": "Code 6: Measuring Model Accuracy",
    "section": "",
    "text": "1. Methodology\n\nCalculate Predictions with our model Coefficients with our Independent Variables (Validation Set).\n\nExpected output: Float Values (between 0 and 1).\n\nConvert Predictions to True if above 0.5 otherwise False.\n\nExpected output: Boolean Values (True and False).\n\nCompare Booled Predictions to Dependent Variables (Validation Set)\n\nExpected output: Boolean Values (True and False).\n\n\nConvert the Boolean values to Float.\n\nExpected output: Integer Values (1s and 0s).\n\nCalculate Mean of the floated values.\n\nExpected output: Single Float Value (between 0 and 1)\n\n\n\n\n2. Run Deep-Learning Model and Get Coefficients\nSee previous blog post for model and code explanation.\n\nimport kaggle, zipfile\nfrom pathlib import Path\nimport torch, numpy as np, pandas as pd\nfrom fastai.data.transforms import RandomSplitter\nimport torch.nn.functional as F\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} already exists, using this folder...\")\n!ls {path}\ndf = pd.read_csv(path/\"train.csv\")\ndef df_1_fillna_inplace(df):\n    modes = df.mode(axis=0).iloc[0] # get modes\n    df.fillna(modes, inplace=True)  # replace nas with mode per col\ndef df_2_log_numeric_data_addlogfare(df): df['LogFare'] = np.log1p(df['Fare'])\ndef df_3_create_dummy_variables_add(df):\n    return pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=int)\ndef df_clean(df):\n    df_1_fillna_inplace(df)\n    df_2_log_numeric_data_addlogfare(df)\n    return df_3_create_dummy_variables_add(df)\n\ndef get_idep_and_dep_from_df(df):\n    def normalise_idep_by_max(idep):\n        maxes, _ = idep.max(axis=0) # get max of each column\n        return idep / maxes \n    \n    added_cols          = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n    indep_cols          = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n    idep                = torch.tensor(df[indep_cols].values, dtype=torch.float)\n    idep                = normalise_idep_by_max(idep)\n    dep                 = torch.tensor(df[\"Survived\"])\n    return idep, dep\n\ndef get_trn_val_idep_dep(idep, dep):     \n    trn_idx, val_idx            = RandomSplitter(seed=42)(idep)\n    trn_dep_mx0,  val_dep_mx0   = dep[trn_idx], dep[val_idx] # 1-dimension i.e. cant matrix multiply \n    trn_idep_mxn, val_idep_mxn  = idep[trn_idx], idep[val_idx] \n    trn_dep_mx1                 = trn_dep_mx0[:,None] # add extra dimention for matrix multiply\n    val_dep_mx1                 = val_dep_mx0[:,None]\n    return trn_idep_mxn, val_idep_mxn, trn_dep_mx1, val_dep_mx1 \ndf = df_clean(df)\nidep, dep = get_idep_and_dep_from_df(df)\ntrn_idep_mxn, val_idep_mxn, trn_dep_mx1, val_dep_mx1 = get_trn_val_idep_dep(idep, dep)\ndef init_coeffs():\n    n_coeffs    = trn_idep_mxn.shape[1] # 12\n    hidden_layers = [10,10]\n    sizes = [n_coeffs] + hidden_layers + [1]    # [12,10,10,1]\n    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(len(sizes)-1)]   # 0,1,2\n    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(len(sizes)-1)]   # [0,1,2]\n    for layer in layers+consts:\n        layer.requires_grad_()\n    return layers, consts\ndef calc_preds_deeplearning(trn_idep_mxn, coeffs):    \n    layers, consts = coeffs\n    n = len(layers)\n    res = trn_idep_mxn\n    for i in range(n):\n        res = res@layers[i] + consts[i] # [mxn]@[nxq]  [713x12][12x10]\n        if i!=n-1: \n            res = F.relu(res) \n    sgm_preds_mx1 = torch.sigmoid(res)\n    return sgm_preds_mx1\ndef calc_loss(idep_mxn, dep_mx1, coeffs):\n    preds_mx1 = calc_preds_deeplearning(idep_mxn, coeffs)\n    return torch.abs(dep_mx1-preds_mx1).mean()\ndef update_coeffs(coeffs, lr):\n    layers, consts = coeffs\n    for layer in layers+consts:\n        layer.sub_(layer.grad*lr)\n        layer.grad.zero_()\ndef one_epoch(coeffs,lr):\n    loss = calc_loss(trn_idep_mxn, trn_dep_mx1, coeffs)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:.3f}\",end=';')\ndef train_model(n_epochs=30,lr=0.1):\n    torch.manual_seed(442)\n    coeffs = init_coeffs()\n    for _ in range(n_epochs):\n        one_epoch(coeffs,lr)\n    return coeffs\ncoeffs = train_model(lr=4)\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n0.521;0.483;0.427;0.379;0.379;0.379;0.379;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.377;0.376;0.371;0.333;0.239;0.224;0.208;0.204;0.203;0.203;0.207;0.197;0.196;0.195;\n\n\n\n\n3. Accuracy Function\n\ndef calculate_accuracy_deepelearning(val_idep_mxn, coeffs):\n    val_preds_mx1               = calc_preds_deeplearning(val_idep_mxn, coeffs)     # 1.\n    bool_preds_mx1              = val_preds_mx1&gt;0.5                                 # 2. \n    comp_dep_vs_preds_val_mx1   = (val_dep_mx1==bool_preds_mx1)                     # 3.\n    float_comp_mx1              = comp_dep_vs_preds_val_mx1.float()                 # 4.   \n    accuracy_mx1                = float_comp_mx1.mean()                             # 5. \n    return accuracy_mx1\n\ncalculate_accuracy_deepelearning(val_idep_mxn, coeffs)\n\ntensor(0.8258)"
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html",
    "title": "Code 16: Open Source as a Beginner",
    "section": "",
    "text": "FreeCodeCamp Open Source Beginners Guide"
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html#step-by-steps",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html#step-by-steps",
    "title": "Code 16: Open Source as a Beginner",
    "section": "4.1 Step-by-Steps",
    "text": "4.1 Step-by-Steps\n\nFork: os project becomes “https://github.com//projectname”\nClone:git clone https://github.com/&lt;YourUserName&gt;/&lt;projectname&gt;\n\nthis creates a copy of project on local machine\n\nCreate local folder + branch: cd to folder + eg git checkout -b tonyjustdev-branch\n\nsee all changes: git status\nadd all changes: git add *\ncommit changes: git commit -m \"message here\"\n\npush to remote: git push origin tonyjustdev-branch"
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html#advantages-of-above-steps",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html#advantages-of-above-steps",
    "title": "Code 16: Open Source as a Beginner",
    "section": "4.2 Advantages of Above Steps",
    "text": "4.2 Advantages of Above Steps\n\nIt allows you to contribute to another repo without needing administrative privileges to make changes to the repo.\nIt allows others to review your changes and suggest corrections, additions, edits, and so on.\nIt gives repo administrators control over what gets added to their project repo."
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html#fork-a-repo-first-contributions",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html#fork-a-repo-first-contributions",
    "title": "Code 16: Open Source as a Beginner",
    "section": "5.1 Fork a repo first contributions",
    "text": "5.1 Fork a repo first contributions\nBy forking a repo, I am creating a copy of the particular repository in my own github account:\n\nClick fork button on top right of the repo\nRename [Repository name] (if you want)\nClick Create fork\n\nRepo used: https://github.com/firstcontributions/first-contributions."
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html#clone-your-forked-repo-tonyjustdevsfirst-contributions",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html#clone-your-forked-repo-tonyjustdevsfirst-contributions",
    "title": "Code 16: Open Source as a Beginner",
    "section": "5.2 Clone your forked repo tonyjustdevs/first-contributions",
    "text": "5.2 Clone your forked repo tonyjustdevs/first-contributions\n\nCopy URL and git clone &lt;your copied url&gt;"
  },
  {
    "objectID": "posts/computerscience/coding/code-016-open-source-beginners.html#create-local-branch",
    "href": "posts/computerscience/coding/code-016-open-source-beginners.html#create-local-branch",
    "title": "Code 16: Open Source as a Beginner",
    "section": "5.3 Create local branch",
    "text": "5.3 Create local branch\n\n5.3.1 Clone to local with Windows Terminal\nMy current workflow involves firstly opening VSCode , then creating/switching to a branch in the Terminal of VSCode.\n\ncd to cloned folder\nopen vscode\ncreate/switch to new branch\n\n(I have not had a chance to test whether there a difference to creating the branch first before launching VS Code. I currently run almost all terminal commands in VSCode’s Terminal rather than Windows Terminal)\n\n\n\n5.3.2 Create Local Branch with VS Code’s Terminal\nVSCode shows which branch you’re currently in which is neat."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#pre-download",
    "href": "posts/computerscience/coding/go-001-gday-world.html#pre-download",
    "title": "GO 1: Install & G’Day World",
    "section": "2.1 Pre-download:",
    "text": "2.1 Pre-download:\n\nUpdate Packages:\n\nsudo apt update\n\nInstall necessary dependencies:\n\nsudo apt install wget tar"
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#performance-efficiency",
    "href": "posts/computerscience/coding/go-001-gday-world.html#performance-efficiency",
    "title": "GO 1: Install & G’Day World",
    "section": "4.1 Performance & Efficiency",
    "text": "4.1 Performance & Efficiency\n\nCompiled to native machine code:\n\nFaster execution than interpreted languages (e.g., Python, JavaScript)."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#concurrency-scalability",
    "href": "posts/computerscience/coding/go-001-gday-world.html#concurrency-scalability",
    "title": "GO 1: Install & G’Day World",
    "section": "4.2 Concurrency & Scalability",
    "text": "4.2 Concurrency & Scalability\n\nGoroutines:\n\nlightweight threads\nBetter concurrency handling than OS threads.\n\nChannel-based concurrency:\n\nSafer than traditional multithreading.\nIdeal for high-performance network services & APIs."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#simplicity-fast-development",
    "href": "posts/computerscience/coding/go-001-gday-world.html#simplicity-fast-development",
    "title": "GO 1: Install & G’Day World",
    "section": "4.3 Simplicity & Fast Development",
    "text": "4.3 Simplicity & Fast Development\n\nMinimalistic syntax\n\nNo complex OOP:\n\nNo inheritance.\nNo classes.\nUses simple structs & interfaces.\n\n\nFast compilation & execution:\n\nGreat for CI/CD pipelines."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#cross-platform-portability",
    "href": "posts/computerscience/coding/go-001-gday-world.html#cross-platform-portability",
    "title": "GO 1: Install & G’Day World",
    "section": "4.4 Cross-Platform & Portability",
    "text": "4.4 Cross-Platform & Portability\n\nWrite once, compile anywhere:\n\nGOOS and GOARCH allow easy cross-compilation (e.g., Linux, Windows, macOS).\n\nSmall, self-contained binaries:\n\nNo need for dependencies or interpreters."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#built-in-tools-standard-library",
    "href": "posts/computerscience/coding/go-001-gday-world.html#built-in-tools-standard-library",
    "title": "GO 1: Install & G’Day World",
    "section": "4.5 Built-in Tools & Standard Library",
    "text": "4.5 Built-in Tools & Standard Library\n\nPowerful standard library:\n\nComes with built-in support for HTTP servers, JSON handling, cryptography, concurrency, etc.\n\nGo modules for dependency management:\n\nNo external package managers needed."
  },
  {
    "objectID": "posts/computerscience/coding/go-001-gday-world.html#memory-safety-garbage-collection",
    "href": "posts/computerscience/coding/go-001-gday-world.html#memory-safety-garbage-collection",
    "title": "GO 1: Install & G’Day World",
    "section": "4.6 Memory Safety & Garbage Collection",
    "text": "4.6 Memory Safety & Garbage Collection\n\nAutomatic garbage collection:\n\nHelps manage memory efficiently.\n\nAvoids memory leaks & segmentation faults:\n\nCommon in C/C++."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html",
    "href": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html",
    "title": "LeetCode 4: 74 - Search a 2D Matrix",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#problem-description",
    "href": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#problem-description",
    "title": "LeetCode 4: 74 - Search a 2D Matrix",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an m x n integer matrix matrix with the following two properties:\nEach row is sorted in non-decreasing order.\nThe first integer of each row is greater than the last integer of the previous row.\nGiven an integer target, return true if target is in matrix or false otherwise.\nYou must write a solution in O(log(m * n)) time complexity."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#code",
    "href": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#code",
    "title": "LeetCode 4: 74 - Search a 2D Matrix",
    "section": "2. Code",
    "text": "2. Code\n\nFlatten array then\nUse code from binary search\n\n\nclass Solution:\n    def searchMatrix(self, matrix: [[int]], target: int) -&gt; bool:\n        # its a ascending matrix,\n        # 1. turn into array then \n        # 2. apply binsearch \n        arr = [element for row in matrix for element in row]\n\n        l = 0\n        r = len(arr)\n\n        if r==1:\n            if target == l[0]:\n                return True\n            else: return False\n\n        while l&lt;r:\n            m = (l+r)//2\n            if arr[m]&lt;target:\n                l = m + 1                \n            elif arr[m]&gt;target:\n                r = m\n            else:                \n                return True\n        return False\n\n\nsoln = Solution()\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],3)\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],13)\n# soln.searchMatrix([[1,3]],3)"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#submit",
    "href": "posts/computerscience/leetcode/leet-004-074-search-2d-matrix.html#submit",
    "title": "LeetCode 4: 74 - Search a 2D Matrix",
    "section": "3. Submit",
    "text": "3. Submit\n\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#problem-description",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#problem-description",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an array of strings tokens that represents an arithmetic expression in a Reverse Polish Notation (RPN).\nInput: Evaluate the input RPN arithmetic expression.\nOutput: Return an integer that represents the value of the expression.\nRules:\n1. The valid operators are ‘+’, ‘-’, ‘*’, and ‘/’.\n2. Each operand may be an integer or another expression.\n3. The division between two integers always truncates toward zero\n4. There will not be any division by zero.\n5. The input represents a valid arithmetic expression in a reverse polish notation.\n6. The answer and all the intermediate calculations can be represented in a 32-bit integer."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#leetcode-examples",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#leetcode-examples",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "2. LeetCode Examples",
    "text": "2. LeetCode Examples\n\n2.1 Example 1\nInput: tokens = [\"2\",\"1\",\"+\",\"3\",\"*\"]\nOutput: 9\nExplanation: ((2 + 1) * 3) = 9\n\n\n2.2 Example 2\nInput: tokens = [\"4\",\"13\",\"5\",\"/\",\"+\"]\nOutput: 6\nExplanation: (4 + (13 / 5)) = 6\n\n\n2.3 Example 3\nInput: tokens = [\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"]\nOutput: 22\nExplanation:\n((10 * (6 / ((9 + 3) * -11))) + 17) + 5\n= ((10 * (6 / (12 * -11))) + 17) + 5\n= ((10 * (6 / -132)) + 17) + 5\n= ((10 * 0) + 17) + 5\n= (0 + 17) + 5\n= 17 + 5\n= 22"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#background-and-analysis",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#background-and-analysis",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "3. Background and Analysis",
    "text": "3. Background and Analysis\nThe wiki explains this is also known as postfix notation, the operators follow their operands, in contrast to prefix (Polish) notation (operators precede their operands).\n\n3.1 Wiki Example\nTo add 3 and 4 together, the expression is [3 4 +] rather than [3 + 4].\n- The conventional notation expression [3 − 4 + 5] becomes [3 4 − 5 +] in reverse Polish notation:\n- 4 is first subtracted from 3, then - 5 is added to it.\n\n\n3.2 Stack Explanation\nThe concept of a stack, a last-in/first-out construct. In the example [3 4 −]:\n1. push 3 to stack: [3] 2. push 4 to stack; ie 4 is now on top, 3 below it: [3 4] 3. apply subtraction operator: - Remove top two items from the stack: - performs 3 − 4, and 4. push the result of −1 to top of stack.\n\n\n3.3 Stack Explanation Table\n\n3.3.1 Example 1: [3 4 −] with all steps\n\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nOutput_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\nnull\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\nnull\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\nnull\npush 4 to stack_top\n\n\nrpn_obj.op()[pt_1]: .pop(top 2)\n[  ]\n[3,4]\npop [3] [4] stack_top_2\n\n\nrpn_obj.op()[pt_2]: .op(top 2)\n[-1]\n[3,4]\noperate(3,4,-) on stack_top_2\n\n\nrpn_obj.op()[pt_3]: .truncate(res)\n[-1]\n-1\nint(result), truncate to zero as per Rule_3\n\n\nrpn_obj.op()[pt_4]: .return()\n[-1]\n-1\nreturn operated result\n\n\nrpn_obj.op()[pt_5]: .push(result)\n[-1]\nnull\npush results stack_top\n\n\n\n\n\n3.3.2 Example 2: [3 4 × 5 6 × +] with concise steps\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\npush 4 to stack_top\n\n\nrpn_obj.op(x)\n[12]\nrem top_2 3,4, op 3*4, push top 12\n\n\nrpn_obj.push(5)\n[12,5]\npush 5 to stack_top\n\n\nrpn_obj.push(6)\n[12,5,6]\npush 6 to stack_top\n\n\nrpn_obj.op(x)\n[12,30]\nrem top_2 5,6, op 5*6, push top 30\n\n\nrpn_obj.op(+)\n[meaning of life]\nrem top_2 12,30, op 12+30, push top 42\n\n\n\n\n\n\n3.3 Why?\nThe advantage of RPN is it:\n- removes the need for order of operations and parentheses that are required by infix notation and\n- can be evaluated linearly, left-to-right.\nFor example, the infix expression (3 × 4) + (5 × 6) becomes [3 4 × 5 6 × +] in reverse Polish notation.*"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#coding",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#coding",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "4. Coding",
    "text": "4. Coding\n\n4.1 Write pseudo-python-code\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        # Rule 5: Input expression is valid, no check required, \n        # ie doesn't start with operateor\n        if len(tokens) ==0: # check if no token \n            return 0 # Probably not needed due for R5 but wrote save time in case \n\n        stack = [] #initialise stack\n        stack.append(tokens[0])  # first item is valid due to R5 so set it to stk\n\n        ### [1]     operator functions/mapping (*,-,+,/)\n        ### [2]     .pop_top_2(stack):    \n        ### [3]     .operate(top_2_items, operator #[2.1]): \n\n        for i in range(1,len(tokens)):\n            # stack = [2]\n            curr_chr = tokens[i]\n\n            if curr_chr in operators:\n                top_2_items = [top_2, top_1] = pop_top_2(stack) # [1]\n                # [validation]: do spot check stacked removed top 2\n                res   = operate(top_2_items,curr_chr) #[2]\n                stack.append(res)\n\n            else: # is a valid integer so just append to top\n                stack.append(curr_chr)\n        return stack\n\n\n\n4.2 Write Required Functions\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        if len(tokens) == 0: \n            return 0 \n        stack = []\n        stack.append(int(tokens[0])) \n\n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            print(f\"operator: {operator}, top2:{x2}, top1:{x1}\")\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            elif operator == '/':\n                return int(x2/x1)\n            else:\n                print(\"unknown operator!\")\n                return False\n                \n        def pop_top_2(stack):\n            print(len(stack))\n            if len(stack) &lt;2:\n                print(\"Stack too short!\")\n                return False\n            else:\n                top_1 = stack.pop()\n                top_2 = stack.pop()\n                top_2_items = [top_2,top_1]\n                print(top_2_items)\n            return top_2_items\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                operator = curr_chr\n                top_2_items = pop_top_2(stack) \n                res   = operate(operator, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        print(stack)\n        return stack\nsoln = Solution()"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#test-functionality",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#test-functionality",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "5. Test Functionality",
    "text": "5. Test Functionality\n\n5.1 Case 1 Expected 9\n\nsoln.evalRPN([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n2\n[2, 1]\noperator: +, top2:2, top1:1\n2\n[3, 3]\noperator: *, top2:3, top1:3\n[9]\n\n\n[9]\n\n\n\n\n5.2 Case 2 Expected 6\n\nsoln.evalRPN([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n3\n[13, 5]\noperator: /, top2:13, top1:5\n2\n[4, 2]\noperator: +, top2:4, top1:2\n[6]\n\n\n[6]\n\n\n\n\n5.3 Case 2 Expected 22\n\nsoln.evalRPN([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])  \n\n4\n[9, 3]\noperator: +, top2:9, top1:3\n4\n[12, -11]\noperator: *, top2:12, top1:-11\n3\n[6, -132]\noperator: /, top2:6, top1:-132\n2\n[10, 0]\noperator: *, top2:10, top1:0\n2\n[0, 17]\noperator: +, top2:0, top1:17\n2\n[17, 5]\noperator: +, top2:17, top1:5\n[22]\n\n\n[22]"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#clean-version",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#clean-version",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "6. Clean Version",
    "text": "6. Clean Version\n\nclass Solution:\n    def evalRPN_clean(self, tokens: [str]) -&gt; int:\n        stack = []\n        stack.append(int(tokens[0])) \n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            else:\n                return int(x2/x1)\n\n        def pop_top_2(stack):\n            top_1 = stack.pop()\n            top_2 = stack.pop()\n            return [top_2,top_1]\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                top_2_items = pop_top_2(stack) \n                res   = operate(curr_chr, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        return stack[0] ############### fixed after submission 2  ###############\nsoln = Solution()\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22\n\n\n\n6.1 Clean Check\n\nsoln.evalRPN_clean([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n9\n\n\n\nsoln.evalRPN_clean([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n6\n\n\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#submit",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#submit",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "7. Submit",
    "text": "7. Submit\n\nFirst attempt Failed, because I returned the stack as a list with result as the first item.\nSecond attempt Accepted! Quick fix after indexing out the value form the list. Not a bad result.\n\nTop 40% in Speed and\nTop 20% in Memory."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#notes-to-self.",
    "href": "posts/computerscience/leetcode/leet-002-150-reverse-polish-notation.html#notes-to-self.",
    "title": "LeetCode 2: 150 - Evaluate Reverse Polish Notation",
    "section": "6. Notes to self.",
    "text": "6. Notes to self.\nThis took alot of time setting up the problem, the solving part was quite fast.\nI need to be more seemless in set up!\n[Future Iterations 1]: Incorporate best solutions from LC\n[Future Iterations 2]: Attempt iterations for speed and memory\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#scenario-1-test",
    "href": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#scenario-1-test",
    "title": "LeetCode 5: 49 - Group Anagrams",
    "section": "2.1 Scenario 1 Test:",
    "text": "2.1 Scenario 1 Test:\n\nInput: strs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\n\nOutput: [[\"bat\"],[\"nat\",\"tan\"],[\"ate\",\"eat\",\"tea\"]]\n\n\n\nstrs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\nseen_dict = {}\n\nfor str_item in strs:\n    str_item = str_item\n    sorted_str_list = sorted(str_item)\n    print(f\"pre-sort: {str_item}\")\n    sorted_str = ''.join(sorted_str_list)\n    print(f\"post-sort: {sorted_str}\")\n    sorted_str_dkey = sorted_str\n    if sorted_str_dkey not in seen_dict:\n        seen_dict[sorted_str] = [str_item]    # create dict entrant\n    else: \n        seen_dict[sorted_str].append(str_item) # retriev dict entrant\n    print(seen_dict)\n    print()    \n# [values for values in seen_dict.values()]\n[*seen_dict.values()]\n\npre-sort: eat\npost-sort: aet\n{'aet': ['eat']}\n\npre-sort: tea\npost-sort: aet\n{'aet': ['eat', 'tea']}\n\npre-sort: tan\npost-sort: ant\n{'aet': ['eat', 'tea'], 'ant': ['tan']}\n\npre-sort: ate\npost-sort: aet\n{'aet': ['eat', 'tea', 'ate'], 'ant': ['tan']}\n\npre-sort: nat\npost-sort: ant\n{'aet': ['eat', 'tea', 'ate'], 'ant': ['tan', 'nat']}\n\npre-sort: bat\npost-sort: abt\n{'aet': ['eat', 'tea', 'ate'], 'ant': ['tan', 'nat'], 'abt': ['bat']}\n\n\n\n[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#adapt-to-template",
    "href": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#adapt-to-template",
    "title": "LeetCode 5: 49 - Group Anagrams",
    "section": "2.2 Adapt to Template",
    "text": "2.2 Adapt to Template\n\nfrom typing import List"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#working-easy-to-understand-version",
    "href": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#working-easy-to-understand-version",
    "title": "LeetCode 5: 49 - Group Anagrams",
    "section": "2.3 Working Easy-To-Understand Version",
    "text": "2.3 Working Easy-To-Understand Version\n\nclass Solution:\n    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:\n# strs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\n        seen_dict = {}\n\n        for str_item in strs:\n            pre_sorted_str = str_item\n            sorted_str_list = sorted(pre_sorted_str)\n            # print(f\"pre-sort: {pre_sorted_str}\")\n            sorted_str = ''.join(sorted_str_list)\n            # print(f\"post-sort: {sorted_str}\")\n            sorted_str_dkey = sorted_str\n            if sorted_str_dkey not in seen_dict:\n                seen_dict[sorted_str] = [pre_sorted_str]    # create dict entrant\n            else: \n                seen_dict[sorted_str].append(pre_sorted_str) # retriev dict entrant\n            # print(seen_dict)\n            # print()    \n        # [values for values in seen_dict.values()]\n        return [*seen_dict.values()]\n\n\nstrs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\nsoln = Solution()\nsoln.groupAnagrams(strs)\n\n[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#working-less-lines-version",
    "href": "posts/computerscience/leetcode/leet-005-049-group-anagrams.html#working-less-lines-version",
    "title": "LeetCode 5: 49 - Group Anagrams",
    "section": "2.4 Working Less-Lines Version",
    "text": "2.4 Working Less-Lines Version\nSame as 2.3 but less new variables\n\nclass Solution:\n    def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]:\n        seen_dict = {}\n        for str_item in strs:\n            sorted_str = ''.join(sorted(str_item))\n            if ''.join(sorted(str_item)) not in seen_dict:\n                seen_dict[sorted_str] = [str_item]    # create dict entrant\n            else: \n                seen_dict[sorted_str].append(str_item) # retriev dict entrant\n        return [*seen_dict.values()]\n\n\nstrs = [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\nsoln = Solution()\nsoln.groupAnagrams(strs)\n\n[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-044-binary-search-trees-part-7.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-044-binary-search-trees-part-7.html",
    "title": "DSA 44: Binary Search Trees - Delete [Part 7]",
    "section": "",
    "text": "1. TreeNode, Binary Tree & insert_node: Setup\nIntroduced previously.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCannot insert duplicates\")\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE left-child : GO LEFT[{current_node.left.data}]\")\n            current_node=current_node.left\n            return insert_node(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO left-child: INSERTED LEFT CurrentLeft[{current_node.left.data}]\")\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE right-child : GO right[{current_node.right.data}]\")\n            current_node=current_node.right\n            return insert_node(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO right-child: INSERTED right Currentright[{current_node.right.data}]\")\n    pass\n\ndef insert_node_clean(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            current_node=current_node.left\n            return insert_node_clean(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            current_node=current_node.right\n            return insert_node_clean(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n    pass\n\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \ndef insert_node_list(root_node:TreeNode, node_list: list[int], show_outputs:bool=True):\n    for node in node_list: \n        if show_outputs:\n            insert_node(root_node, node) \n        else:\n            insert_node_clean(root_node, node) \nroot = None\nroot = TreeNode(50)\nnode_list = [25,75,10,33,56,89,4,11,30,40,52,61,82,95]\ninsert_node_list(root, node_list,show_outputs=True)\n\nt[25]|c[50]:        Current[50] has NO left-child: INSERTED LEFT CurrentLeft[25]\nt[75]|c[50]:        Current[50] has NO right-child: INSERTED right Currentright[75]\nt[10]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[10]|c[25]:        Current[25] has NO left-child: INSERTED LEFT CurrentLeft[10]\nt[33]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[33]|c[25]:        Current[25] has NO right-child: INSERTED right Currentright[33]\nt[56]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[56]|c[75]:        Current[75] has NO left-child: INSERTED LEFT CurrentLeft[56]\nt[89]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[89]|c[75]:        Current[75] has NO right-child: INSERTED right Currentright[89]\nt[4]|c[50]:         Current[50] has ONE left-child : GO LEFT[25]\nt[4]|c[25]:         Current[25] has ONE left-child : GO LEFT[10]\nt[4]|c[10]:         Current[10] has NO left-child: INSERTED LEFT CurrentLeft[4]\nt[11]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[11]|c[25]:        Current[25] has ONE left-child : GO LEFT[10]\nt[11]|c[10]:        Current[10] has NO right-child: INSERTED right Currentright[11]\nt[30]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[30]|c[25]:        Current[25] has ONE right-child : GO right[33]\nt[30]|c[33]:        Current[33] has NO left-child: INSERTED LEFT CurrentLeft[30]\nt[40]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[40]|c[25]:        Current[25] has ONE right-child : GO right[33]\nt[40]|c[33]:        Current[33] has NO right-child: INSERTED right Currentright[40]\nt[52]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[52]|c[75]:        Current[75] has ONE left-child : GO LEFT[56]\nt[52]|c[56]:        Current[56] has NO left-child: INSERTED LEFT CurrentLeft[52]\nt[61]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[61]|c[75]:        Current[75] has ONE left-child : GO LEFT[56]\nt[61]|c[56]:        Current[56] has NO right-child: INSERTED right Currentright[61]\nt[82]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[82]|c[75]:        Current[75] has ONE right-child : GO right[89]\nt[82]|c[89]:        Current[89] has NO left-child: INSERTED LEFT CurrentLeft[82]\nt[95]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[95]|c[75]:        Current[75] has ONE right-child : GO right[89]\nt[95]|c[89]:        Current[89] has NO right-child: INSERTED right Currentright[95]\n\n\n\n\n2. Confirm Tree\n\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95\nprint(f\"[L1] root.data: \\t\\t\\t[{root.data}] (expected: 50)\")\nprint()\nprint(f\"[L2] root.left.data: \\t\\t\\t[{root.left.data}] (expected: 25)\")\nprint(f\"[L2] root.right.data: \\t\\t\\t[{root.right.data}] (expected: 75)\")\nprint()\nprint(f\"[L3] root.left.left.data:      \\t\\t[{root.left.left.data}] (expected: 10)\")\nprint(f\"[L3] root.left.right.data:     \\t\\t[{root.left.right.data}] (expected: 33)\")\nprint(f\"[L3] root.right.left.data:     \\t\\t[{root.right.left.data}] (expected: 56)\")\nprint(f\"[L3] root.right.right.data:    \\t\\t[{root.right.right.data}] (expected: 89)\")\nprint()\nprint(f\"[L4] root.left.left.left.data: \\t\\t[{root.left.left.left.data}]  (expected:  4)\")\nprint(f\"[L4] root.left.left.right.data:  \\t[{root.left.left.right.data}] (expected: 11)\")\nprint(f\"[L4] root.left.right.left.data:  \\t[{root.left.right.left.data}] (expected: 30)\")\nprint(f\"[L4] root.left.right.right.data: \\t[{root.left.right.right.data}] (expected: 40)\")\nprint()\nprint(f\"[L4] root.right.left.left.data:  \\t[{root.right.left.left.data}] (expected: 52)\")\nprint(f\"[L4] root.right.left.right.data: \\t[{root.right.left.right.data}] (expected: 61)\")\nprint(f\"[L4] root.right.right.left.data: \\t[{root.right.right.left.data}] (expected: 82)\")\nprint(f\"[L4] root.right.right.right.data:\\t[{root.right.right.right.data}] (expected: 95)\")\n\n[L1] root.data:             [50] (expected: 50)\n\n[L2] root.left.data:            [25] (expected: 25)\n[L2] root.right.data:           [75] (expected: 75)\n\n[L3] root.left.left.data:           [10] (expected: 10)\n[L3] root.left.right.data:          [33] (expected: 33)\n[L3] root.right.left.data:          [56] (expected: 56)\n[L3] root.right.right.data:         [89] (expected: 89)\n\n[L4] root.left.left.left.data:      [4]  (expected:  4)\n[L4] root.left.left.right.data:     [11] (expected: 11)\n[L4] root.left.right.left.data:     [30] (expected: 30)\n[L4] root.left.right.right.data:    [40] (expected: 40)\n\n[L4] root.right.left.left.data:     [52] (expected: 52)\n[L4] root.right.left.right.data:    [61] (expected: 61)\n[L4] root.right.right.left.data:    [82] (expected: 82)\n[L4] root.right.right.right.data:   [95] (expected: 95)\n\n\n\n\n3. delete_node: 0 or 1 Child Nodes Only\n\ndef delete_node(root_node: TreeNode, target: int, parent_node=None):\n    current_node = root_node\n    if target == current_node.data:\n        # 2. delete_node - delete cases 1, 2 & 3.\n        print(f\"[Part 1: Search] t[{target}]==c[{current_node.data}]: \\t\\t\\t\\tNode Found...\")\n        print(f\"[Part 2: Delete] t[{target}]==c[{current_node.data}]: \\t\\t\\t\\tDetermine Number of Children...\")\n\n        if (not current_node.left and not current_node.right): # 0-kids\n            # Case A: Target has 0-kid --- [(0 left + 0 right) \n            # only 1 parent per node(p.left or p.right)\n            if parent_node.left: # if exists burn it\n                parent_node.left = None\n            elif parent_node.right: \n                parent_node.right = None\n            \n            print(f\"[Part2A: Delete] t[{target}]==c[{current_node.data}]._0_kid: \\t\\tBurn'em!🔥[{target}], Parent[{parent_node.data}] will survive 🍀.\")\n            return\n        \n        elif (current_node.left and not current_node.right) or (not current_node.left and current_node.right):\n            # Case B: 1-kid --- [(1 left + 0 right) OR (0 left + 1 right)]\n            if current_node.left:\n                target_sgl_child = current_node.left \n            else:\n                target_sgl_child = current_node.right\n                \n            print(f\"[Part2B: Delete] t[{target}]==c[{current_node.data}]._1_kid[{target_sgl_child.data}]: \\tIs it Left or Right? kids_gramps[{parent_node.data}]\")\n            if parent_node.left == current_node:\n                parent_node.left = target_sgl_child     ##### 2BI  REPLACE TARGET WITH TARGETS LEFT-CHILD\n                print(f\"[Part2B: Delete] targets.child[{target_sgl_child.data}] has now assumed the identity of the target t[{target}|c{current_node.data}] and is the kid of it's (previous) gramps[{parent_node.data}]: aka now gramps.leftkid[{parent_node.left.data}]\")\n            elif parent_node.right == current_node: # target can be a left or right child\n                parent_node.right = target_sgl_child    ##### 2BII REPLACE TARGET WITH TARGETS LEFT-CHILD\n                print(f\"[Part2B: Delete] targets.child[{target_sgl_child.data}] has now assumed the identity of the target t[{target}|c{current_node.data}] and is the kid of it's (previous) gramps[{parent_node.data}]: aka now gramps.rightkid[{parent_node.right.data}]\")\n            return\n            \n        else:\n            # Case C: 2-kid --- [(1 left + 1 right)\n            print(f\"[Part2C: Delete] t[{target}]==c[{current_node.data}]._2_kids: \\t\\twhat a shame! ☠️ [TBA IN FUTURE]\")\n            return\n    \n    # 1. search_node \n    if target &lt; current_node.data: # go left\n        if current_node.left:\n            print(f\"[Part 1: Search] t[{target}]&lt;c[{current_node.data}].left_child exists[{current_node.left.data}]: \\tgo left...\")\n            parent_node = current_node\n            current_node = current_node.left\n            return delete_node(current_node, target,parent_node)\n        else:\n            print(f\"[Part 1: Search] t[{target}]&lt;c[{current_node.data}].left_child doesnt exists[{None}]: Node Not Found!\")\n            return\n    else:\n        if current_node.right:\n            print(f\"[Part 1: Search] t[{target}]&gt;c[{current_node.data}].right_child exists[{current_node.right.data}]: \\tgo right...\")\n            parent_node = current_node\n            current_node = current_node.right\n            return delete_node(current_node, target,parent_node)\n        else:\n            print(f\"[Part 1: Search] t[{target}]&gt;c[{current_node.data}].right_child doesnt exists[{None}]: Node Not Found!\")\n            return\n\n\n\n4. Testing\n\ndelete_node(root,4)\n#             50\n#      25           75\n#    10     33     56     89  \n# [X]  11 30  40 52  61 82  95\n\nprint()\ndelete_node(root,10)\n#             50\n#      25           75\n#    11     33     56     89  \n# []  [X] 30  40 52  61 82  95\n\nprint()\ndelete_node(root,25)  # NOT READY YET\n#             50\n#      25           75\n#  11     33     56     89  \n# []  [] 30  40 52  61 82  95\n\nprint()\ndelete_node(root,11) \n#             50\n#      25           75\n#  [X]    33     56    89  \n# []  [] 30  40 52 61 82  95\n\nprint()\ndelete_node(root,25) \n#             50\n#      33             75\n#  [30]   [40]     56    89  \n# []  [] []  [] 52 61 82  95\n\nprint()\ndelete_node(root,33) \n#             50\n#      33             75\n#  [30]   [40]     56    89  \n# []  [] []  [] 52 61 82  95\n\n[Part 1: Search] t[4]&lt;c[50].left_child exists[25]:  go left...\n[Part 1: Search] t[4]&lt;c[25].left_child exists[10]:  go left...\n[Part 1: Search] t[4]&lt;c[10].left_child exists[4]:   go left...\n[Part 1: Search] t[4]==c[4]:                Node Found...\n[Part 2: Delete] t[4]==c[4]:                Determine Number of Children...\n[Part2A: Delete] t[4]==c[4]._0_kid:         Burn'em!🔥[4], Parent[10] will survive 🍀.\n\n[Part 1: Search] t[10]&lt;c[50].left_child exists[25]:     go left...\n[Part 1: Search] t[10]&lt;c[25].left_child exists[10]:     go left...\n[Part 1: Search] t[10]==c[10]:              Node Found...\n[Part 2: Delete] t[10]==c[10]:              Determine Number of Children...\n[Part2B: Delete] t[10]==c[10]._1_kid[11]:   Is it Left or Right? kids_gramps[25]\n[Part2B: Delete] targets.child[11] has now assumed the identity of the target t[10|c10] and is the kid of it's (previous) gramps[25]: aka now gramps.leftkid[11]\n\n[Part 1: Search] t[25]&lt;c[50].left_child exists[25]:     go left...\n[Part 1: Search] t[25]==c[25]:              Node Found...\n[Part 2: Delete] t[25]==c[25]:              Determine Number of Children...\n[Part2C: Delete] t[25]==c[25]._2_kids:      what a shame! ☠️ [TBA IN FUTURE]\n\n[Part 1: Search] t[11]&lt;c[50].left_child exists[25]:     go left...\n[Part 1: Search] t[11]&lt;c[25].left_child exists[11]:     go left...\n[Part 1: Search] t[11]==c[11]:              Node Found...\n[Part 2: Delete] t[11]==c[11]:              Determine Number of Children...\n[Part2A: Delete] t[11]==c[11]._0_kid:       Burn'em!🔥[11], Parent[25] will survive 🍀.\n\n[Part 1: Search] t[25]&lt;c[50].left_child exists[25]:     go left...\n[Part 1: Search] t[25]==c[25]:              Node Found...\n[Part 2: Delete] t[25]==c[25]:              Determine Number of Children...\n[Part2B: Delete] t[25]==c[25]._1_kid[33]:   Is it Left or Right? kids_gramps[50]\n[Part2B: Delete] targets.child[33] has now assumed the identity of the target t[25|c25] and is the kid of it's (previous) gramps[50]: aka now gramps.leftkid[33]\n\n[Part 1: Search] t[33]&lt;c[50].left_child exists[33]:     go left...\n[Part 1: Search] t[33]==c[33]:              Node Found...\n[Part 2: Delete] t[33]==c[33]:              Determine Number of Children...\n[Part2C: Delete] t[33]==c[33]._2_kids:      what a shame! ☠️ [TBA IN FUTURE]\n\n\n\n\nprint()\ndelete_node(root,40) \n#             50\n#      33           75\n#  [30]   [X]     56    89  \n# []  [] []  [] 52 61 82  95\n\n\nprint()\ndelete_node(root,30) \n#             50\n#      33           75\n#  [X]   []       56    89  \n# []  [] []  [] 52 61 82  95\n\nprint(\"surprisingly 30 isnt left or 33 as expected??\")\nprint(\"gotta check it out tomorrow\")\nprint()\ndelete_node(root,33) \n#             50\n#      [X]           75\n#  []   []     56    89  \n# []  [] []  [] 52 61 82  95\n\n\nprint()\ndelete_node(root,50) \n#            [X]\n#      []            75\n#  []   []        56    89  \n# []  [] []  [] 52 61 82  95\n\n\nprint()\ndelete_node(root,75) \n#            [X]\n#      []            75\n#  []   []        56    89  \n# []  [] []  [] 52 61 82  95\n\n\n[Part 1: Search] t[40]&lt;c[50].left_child exists[33]:     go left...\n[Part 1: Search] t[40]&gt;c[33].right_child exists[40]:    go right...\n[Part 1: Search] t[40]==c[40]:              Node Found...\n[Part 2: Delete] t[40]==c[40]:              Determine Number of Children...\n[Part2A: Delete] t[40]==c[40]._0_kid:       Burn'em!🔥[40], Parent[33] will survive 🍀.\n\n[Part 1: Search] t[30]&lt;c[50].left_child exists[33]:     go left...\n[Part 1: Search] t[30]&lt;c[33].left_child doesnt exists[None]: Node Not Found!\nsurprisingly 30 isnt left or 33 as expected??\ngotta check it out tomorrow\n\n[Part 1: Search] t[33]&lt;c[50].left_child exists[33]:     go left...\n[Part 1: Search] t[33]==c[33]:              Node Found...\n[Part 2: Delete] t[33]==c[33]:              Determine Number of Children...\n[Part2B: Delete] t[33]==c[33]._1_kid[40]:   Is it Left or Right? kids_gramps[50]\n[Part2B: Delete] targets.child[40] has now assumed the identity of the target t[33|c33] and is the kid of it's (previous) gramps[50]: aka now gramps.leftkid[40]\n\n[Part 1: Search] t[50]==c[50]:              Node Found...\n[Part 2: Delete] t[50]==c[50]:              Determine Number of Children...\n[Part2C: Delete] t[50]==c[50]._2_kids:      what a shame! ☠️ [TBA IN FUTURE]\n\n[Part 1: Search] t[75]&gt;c[50].right_child exists[75]:    go right...\n[Part 1: Search] t[75]==c[75]:              Node Found...\n[Part 2: Delete] t[75]==c[75]:              Determine Number of Children...\n[Part2C: Delete] t[75]==c[75]._2_kids:      what a shame! ☠️ [TBA IN FUTURE]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-047-binary-search-trees-part-10.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-047-binary-search-trees-part-10.html",
    "title": "DSA 47: Binary Search Trees - Traverse [Part 10]",
    "section": "",
    "text": "1. TreeNode, Binary Tree & insert_node: Setup\nIntroduced previously.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCannot insert duplicates\")\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE left-child : GO LEFT[{current_node.left.data}]\")\n            current_node=current_node.left\n            return insert_node(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO left-child: INSERTED LEFT CurrentLeft[{current_node.left.data}]\")\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE right-child : GO right[{current_node.right.data}]\")\n            current_node=current_node.right\n            return insert_node(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO right-child: INSERTED right Currentright[{current_node.right.data}]\")\n    pass\n\ndef insert_node_clean(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            current_node=current_node.left\n            return insert_node_clean(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            current_node=current_node.right\n            return insert_node_clean(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n    pass\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \ndef insert_node_list(root_node:TreeNode, node_list: list[int], show_outputs:bool=True):\n    for node in node_list: \n        if show_outputs:\n            insert_node(root_node, node) \n        else:\n            insert_node_clean(root_node, node) \n\ndef create_tree_from_root_node(root_node = TreeNode(50),node_list=[25,75,10,33,56,89,4,11,30,40,52,61,82,95]):\n    insert_node_list(root_node, node_list,show_outputs=False)\n    \n\n\n\n2. traverse\nSteps:\n\nCall(traverse) on node’s left child until no left child, then print node.\nCall(traverse) on node’s right child until no right child, then print node.\n\nBase-Case:\n\n(child) node does not exist, return None\n\n\ndef traverse_rec(root_node: TreeNode):\n    current_node= root_node\n    if not current_node:\n        return\n    traverse_rec(current_node.left)\n    print(current_node.data)\n    traverse_rec(current_node.right)\n#              50\n#       25           75\n#    10     33     56     89  \nroot = TreeNode(50)\ncreate_tree_from_root_node(root,node_list=[50,25,75,10,33,56,89])\ntraverse_rec(root) # expected 10,25,33,50,56,75,89\n\n10\n25\n33\n50\n56\n75\n89\n\n\n\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\ntraverse_rec(root) # expected 4,10,11,25,30,33,40,50,52,56,61,75,82,89,95\n\n4\n10\n11\n25\n30\n33\n40\n50\n52\n56\n61\n75\n82\n89\n95\n\n\n\n# binary search tree goals from scratch:\n# 1. search_node\n# 2. insert_node\n# 3. insert_node_list\n# 4. delete_node\n# 5. traverse"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-016-stacks-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-016-stacks-part-2.html",
    "title": "DSA 16: Stacks - Linter [Part 2]",
    "section": "",
    "text": "1. Create Linter Class\nBy incoporating previously created stack class.\n\n\n1.1 Objectives\n\nSyntax Error 1: Open-brace without a close-brace\n\nSyntax Error 2: Close-brace without an open-brace\n\nSyntax Error 3: Open-brace with incorrect close-brace\n\n\n\n1.2 Solution: Psuedo-Code\n\nset valid-op-braces: [({\n\nset valid-cl-braces: ])}\n\nfor char in string:\n\n[in-loop] if valid-op-brace:\n\nadd(), continue\n\n[in-loop] if valid-cl-brace:\n\nif cl-brace ])} == [({ valid-op-br: pop(), continue\nif cl-brace ])} == [({ invalid-op-br: Syntax Error 3\nif stack is empty: Syntax Error 2\n\n[out-loop] if stack is not empty: Syntax Error 1\n\nEdit: This psuedo-code was a bit off from what I ended up writing up…\n\n\n2. Solution\nFirst attempt!\n\n\n2.1 TonyStack(): Updated\nUpdated TonyStack() as required to help build and the main class Linter (from 2.2)\n\nclass TonyStack():\n    def __init__(self):\n        print(f\"empty stack created\")\n        self.data = []\n        \n    def add(self, value):\n        self.data.append(value)\n        # print(f\"{value} ({type(value)}) added. {self.data}\")\n        print(f\"\\t'{value}' added. {self.data}\")\n\n    def pop(self):\n        if len(self.data)&gt;0:\n            popped = self.data.pop() # pop() is an in-built obj-method of python's list\n            # print(f\"{popped} ({type(popped)}) removed. {self.data}\")\n            print(f\"\\t'{popped}' removed. {self.data}\\n\")\n        else:\n            print(f\"\\tstack is empty. {self.data}\\n\")\n        \n    def read(self):\n        if len(self.data)&gt;0:\n            last = self.data[-1]\n            # print(f\"{last} ({type(last)} is at top of stack. {self.data}\")\n            # print(f\"\\t'{last}' is at top of stack. {self.data}\")\n            return last\n        else:\n            print(f\"\\tstack is empty. {self.data}\\n\")\n\n    def clear(self):\n        print(\"...clearing stack...\")\n        self.__init__()\n        # self.data = []\n\n\n\n2.2 LinterCls: Commentary\nI built this raw (without looking at any solutions). In a future post, I’ll attempt to update it from feedback (from AI, I dont have anyone else to get feedback from at the moment.)\nI noticed my use python dictionaries (i.e. hash tables) instead. of if-else due to learning and being more comfortable in implementing them from this chapter.\nPrior to this chapter, I would have definitely used a bunch of if-else statements\n\n\n2.3 LinterCls: Python\n\nclass LinterCls():\n    valid_open_brace_only_dct = {'(':True, '{':True, '[':True}\n    # valid_cl_brace_dct = {')':True, '}':True, ']':True}\n    valid_op_cl_dct = {\n        ')':'(',\n        '}':'{',\n        ']':'['\n        }\n    def __init__(self):\n        print(f\"linter created\")\n        self.stack = TonyStack()\n    def lint(self, str_list: str):\n        \n        self.stack.clear() # since we are linting something, the assumption is something afresh with \n        # the fresh input, so remove existing string (issues discovered when runnin tests)\n        \n        for char in str_list:\n            print(f\"current char: '{char}'\")\n            # if char in LinterCls.valid_op_brace_dct: \n            if char in LinterCls.valid_open_brace_only_dct: \n                self.stack.add(char)# no syntax error - close okay\n                print(\"\\tmove to next character\\n\")\n                continue\n            if char in LinterCls.valid_op_cl_dct and len(self.stack.data)==0: \n                    raise SyntaxError(\"Syntax Error 2: Closing Brace without Opening Brace\")\n            elif char in LinterCls.valid_op_cl_dct and len(self.stack.data)&gt;0: # if char is [VALID_CLOSING_BRACE]\n                top_of_stack = self.stack.read() # top of stack: we look for matching open brace\n                # print(f\"\\t valid closing brace: check for matchin opening-brace at top-of-stack...\")\n                # LinterCls.valid_op_cl_dct[char] use key[close_brace] return value[open_brace] from [valid_dict]\n                if LinterCls.valid_op_cl_dct[char] == top_of_stack:\n                    # print(f\"\\t{LinterCls.valid_op_cl_dct[char]} vs {top_of_stack}\")\n                    print(f\"\\t[CORRECT] opening-brace at top-of-stack: {top_of_stack}\")\n                    self.stack.pop()\n                    continue\n                elif LinterCls.valid_op_cl_dct[char] != top_of_stack:\n                    print(f\"\\t[INCORRECT] opening-brace at top-of-stack is Incorrect: {top_of_stack}\")\n                    # print(f\"\\t{LinterCls.valid_op_cl_dct[char]} vs {top_of_stack}\")\n                    raise SyntaxError(\"Syntax Error 3: Incorrect Closing Brace\")\n            else:\n                print(\"not a brace: skip!\\n\")\n                # continue\n        if len(self.stack.data)&gt;0:\n            print(f\"end of string: current stack{self.stack.data}\")\n            raise SyntaxError(\"Syntax Error 1: Opening Brace Without Closing Brace\")\n        print(\"SYNTAX OK!\")\n\n\ntony_linter = LinterCls()\nlistify = lambda input_string: [char for char in input_string]\n\nlinter created\nempty stack created\n\n\n\n\n3. Testing\n\n\n3.1. '{': expected error 1\n\ninput_1 = \"{\"\ninput_str_list = listify(input_1)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '{'\n    '{' added. ['{']\n    move to next character\n\nend of string: current stack['{']\n\n\n\nTraceback (most recent call last):\n\n  File ~/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577 in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n\n  Cell In[6], line 3\n    tony_linter.lint(input_str_list)\n\n  Cell In[4], line 44 in lint\n    raise SyntaxError(\"Syntax Error 1: Opening Brace Without Closing Brace\")\n\n  File &lt;string&gt;\nSyntaxError: Syntax Error 1: Opening Brace Without Closing Brace\n\n\n\n\n\n\n3.2 '}': expected error - 2\n\ninput_2 = \"}\"\ninput_str_list = listify(input_2)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '}'\n\n\n\nTraceback (most recent call last):\n\n  File ~/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577 in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n\n  Cell In[8], line 3\n    tony_linter.lint(input_str_list)\n\n  Cell In[4], line 25 in lint\n    raise SyntaxError(\"Syntax Error 2: Closing Brace without Opening Brace\")\n\n  File &lt;string&gt;\nSyntaxError: Syntax Error 2: Closing Brace without Opening Brace\n\n\n\n\n\n\n3.3 '{)': expected error - 3\n\ninput_3 = \"{)\" \ninput_str_list = listify(input_3)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '{'\n    '{' added. ['{']\n    move to next character\n\ncurrent char: ')'\n    [INCORRECT] opening-brace at top-of-stack is Incorrect: {\n\n\n\nTraceback (most recent call last):\n\n  File ~/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577 in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n\n  Cell In[14], line 3\n    tony_linter.lint(input_str_list)\n\n  Cell In[4], line 38 in lint\n    raise SyntaxError(\"Syntax Error 3: Incorrect Closing Brace\")\n\n  File &lt;string&gt;\nSyntaxError: Syntax Error 3: Incorrect Closing Brace\n\n\n\n\n\n\n3.4. '()': expected okay\n\ninput_4 = \"()\"\ninput_str_list = listify(input_4)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '('\n    '(' added. ['(']\n    move to next character\n\ncurrent char: ')'\n    [CORRECT] opening-brace at top-of-stack: (\n    '(' removed. []\n\nSYNTAX OK!\n\n\n\n\n3.5. '[{}]': expected okay\n\ninput_5 = \"{[]}\"\ninput_str_list = listify(input_5)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '{'\n    '{' added. ['{']\n    move to next character\n\ncurrent char: '['\n    '[' added. ['{', '[']\n    move to next character\n\ncurrent char: ']'\n    [CORRECT] opening-brace at top-of-stack: [\n    '[' removed. ['{']\n\ncurrent char: '}'\n    [CORRECT] opening-brace at top-of-stack: {\n    '{' removed. []\n\nSYNTAX OK!\n\n\n\n\n3.6. '{([])}': expected okay\n\ninput_6 = \"{([])}\"\ninput_str_list = listify(input_6)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '{'\n    '{' added. ['{']\n    move to next character\n\ncurrent char: '('\n    '(' added. ['{', '(']\n    move to next character\n\ncurrent char: '['\n    '[' added. ['{', '(', '[']\n    move to next character\n\ncurrent char: ']'\n    [CORRECT] opening-brace at top-of-stack: [\n    '[' removed. ['{', '(']\n\ncurrent char: ')'\n    [CORRECT] opening-brace at top-of-stack: (\n    '(' removed. ['{']\n\ncurrent char: '}'\n    [CORRECT] opening-brace at top-of-stack: {\n    '{' removed. []\n\nSYNTAX OK!\n\n\n\n\n3.7 '1{a(b[2]c)3}4': expected okay\n\ninput_7 = \"1{a(b[2]c)3}4\"\ninput_str_list = listify(input_7)\ntony_linter.lint(input_str_list)\n\n...clearing stack...\nempty stack created\ncurrent char: '1'\nnot a brace: skip!\n\ncurrent char: '{'\n    '{' added. ['{']\n    move to next character\n\ncurrent char: 'a'\nnot a brace: skip!\n\ncurrent char: '('\n    '(' added. ['{', '(']\n    move to next character\n\ncurrent char: 'b'\nnot a brace: skip!\n\ncurrent char: '['\n    '[' added. ['{', '(', '[']\n    move to next character\n\ncurrent char: '2'\nnot a brace: skip!\n\ncurrent char: ']'\n    [CORRECT] opening-brace at top-of-stack: [\n    '[' removed. ['{', '(']\n\ncurrent char: 'c'\nnot a brace: skip!\n\ncurrent char: ')'\n    [CORRECT] opening-brace at top-of-stack: (\n    '(' removed. ['{']\n\ncurrent char: '3'\nnot a brace: skip!\n\ncurrent char: '}'\n    [CORRECT] opening-brace at top-of-stack: {\n    '{' removed. []\n\ncurrent char: '4'\nnot a brace: skip!\n\nSYNTAX OK!"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#linked-list-vs-tree-node-based-structures",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#linked-list-vs-tree-node-based-structures",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.1 Linked List vs Tree: Node-Based Structures",
    "text": "1.1 Linked List vs Tree: Node-Based Structures\n\nThey’re both node-base structures but are have their differences."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#classic-linked-list",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#classic-linked-list",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.2 Classic linked list",
    "text": "1.2 Classic linked list\n\nEach node contains a link connecting to a single other node."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#tree-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#tree-1",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.3 Tree",
    "text": "1.3 Tree\n\nEach node can have s to multiples nodes"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#root-of-the-tree",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#root-of-the-tree",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.4 Root of the Tree",
    "text": "1.4 Root of the Tree\n\nIs the top node of the tree\nParent node of all nodes\nIt is ascendents of all sub-sequent connected nodes (children)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#descendents",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#descendents",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.5 Descendents",
    "text": "1.5 Descendents\n\nAre nodes one or more level down from a parent node\nChildren are nodes exactly one level down from any parente node"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#balanced-tree",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#balanced-tree",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "1.6 Balanced Tree",
    "text": "1.6 Balanced Tree\n\nTrees in which all sub-trees contain the same amount of nodes (children)\nImbalanaced if vice-versa"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#binary-tree",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-038-binary-search-trees-part-1.html#binary-tree",
    "title": "DSA 38: Binary Search Trees - Basics [Part 1]",
    "section": "2. Binary Tree",
    "text": "2. Binary Tree\n\nHas zero,\nOne or\nTwo children"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#add-or-insert",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#add-or-insert",
    "title": "DSA 18: Queues [Part 1]",
    "section": "2.1 add() or insert:",
    "text": "2.1 add() or insert:\n\nback only\n\ne.g. a customer joins the queue at the back, they can’t make an order (be processed) yet."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#pop-or-delete",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#pop-or-delete",
    "title": "DSA 18: Queues [Part 1]",
    "section": "2.2 pop() or delete:",
    "text": "2.2 pop() or delete:\n\nfront only\n\ne.g. a customer at the front of queue can make & receive their order (processing) and leave the queue (order is complete, processed)."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#read",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-018-queues-part-1.html#read",
    "title": "DSA 18: Queues [Part 1]",
    "section": "2.3 read():",
    "text": "2.3 read():\n\nfront only\n\ne.g. customer service rep can only serve customer at their booth (first customer)."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#code-1-for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#code-1-for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "1.1 CODE-1: for-loop",
    "text": "1.1 CODE-1: for-loop\n\ndef insertion_sort_for(arr: list[int]):\n    for r in range(1,len(arr)):\n        print(f\"\\tidx: {[r]}\")\n        for l in range(r,0,-1):\n            if arr[l]&gt;=arr[l-1]:\n                print(f\"SKIP:\\t\\t{(l-1,l)},{arr} \")\n                break\n            arr[l-1],arr[l]=arr[l],arr[l-1]\n            print(f\"UPDATED:\\t{(l-1,l)},{arr} \")\n    # print(arr)\n    return arr"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#code-2-while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#code-2-while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "1.2 CODE-2: while-loop",
    "text": "1.2 CODE-2: while-loop\n\ndef insertion_sort_while(arr: list[int]):\n    for r in range(1,len(arr)):\n        print(f\"\\tidx: {[r]}\")\n        l=r\n        # for l in range(r,0,-1):\n        while l&gt;0 and arr[l]&lt;arr[l-1]:\n            arr[l-1],arr[l]=arr[l],arr[l-1]\n            print(f\"UPDATED:\\t{(l-1,l)},{arr} \")\n            l-=1\n        if l&gt;0 and arr[l]&gt;=arr[l-1]:\n            print(f\"SKIP:\\t\\t{(l-1,l)},{arr} \")\n    # print(arr)\n    return arr"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#helper-function",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#helper-function",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "1.3 Helper Function",
    "text": "1.3 Helper Function\nBecause I am too lazy to make the lists manually each time.\n\ndef vals_to_list(vals:int): \n    return [int(val) for val in str(vals)]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-1-sorted-unsorted-parts---for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-1-sorted-unsorted-parts---for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.1 TEST-1: Sorted & Unsorted Parts - for-loop",
    "text": "2.1 TEST-1: Sorted & Unsorted Parts - for-loop\n\narr = vals_to_list(42713)\ninsertion_sort_for(arr)\n\n    idx: [1]\nUPDATED:    (0, 1),[2, 4, 7, 1, 3] \n    idx: [2]\nSKIP:       (1, 2),[2, 4, 7, 1, 3] \n    idx: [3]\nUPDATED:    (2, 3),[2, 4, 1, 7, 3] \nUPDATED:    (1, 2),[2, 1, 4, 7, 3] \nUPDATED:    (0, 1),[1, 2, 4, 7, 3] \n    idx: [4]\nUPDATED:    (3, 4),[1, 2, 4, 3, 7] \nUPDATED:    (2, 3),[1, 2, 3, 4, 7] \nSKIP:       (1, 2),[1, 2, 3, 4, 7] \n\n\n[1, 2, 3, 4, 7]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-1-sorted-unsorted-parts---while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-1-sorted-unsorted-parts---while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.1 TEST-1: Sorted & Unsorted Parts - while-loop",
    "text": "2.1 TEST-1: Sorted & Unsorted Parts - while-loop\n\narr = vals_to_list(42713)\ninsertion_sort_while(arr)\n\n    idx: [1]\nUPDATED:    (0, 1),[2, 4, 7, 1, 3] \n    idx: [2]\nSKIP:       (1, 2),[2, 4, 7, 1, 3] \n    idx: [3]\nUPDATED:    (2, 3),[2, 4, 1, 7, 3] \nUPDATED:    (1, 2),[2, 1, 4, 7, 3] \nUPDATED:    (0, 1),[1, 2, 4, 7, 3] \n    idx: [4]\nUPDATED:    (3, 4),[1, 2, 4, 3, 7] \nUPDATED:    (2, 3),[1, 2, 3, 4, 7] \nSKIP:       (1, 2),[1, 2, 3, 4, 7] \n\n\n[1, 2, 3, 4, 7]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-2-mostly-sorted---for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-2-mostly-sorted---for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.2 TEST-2: Mostly Sorted - for-loop",
    "text": "2.2 TEST-2: Mostly Sorted - for-loop\n\narr = vals_to_list(12354)\ninsertion_sort_for(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[1, 2, 3, 5, 4] \n    idx: [2]\nSKIP:       (1, 2),[1, 2, 3, 5, 4] \n    idx: [3]\nSKIP:       (2, 3),[1, 2, 3, 5, 4] \n    idx: [4]\nUPDATED:    (3, 4),[1, 2, 3, 4, 5] \nSKIP:       (2, 3),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-2-mostly-sorted---while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-2-mostly-sorted---while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.2 TEST-2: Mostly Sorted - while-loop",
    "text": "2.2 TEST-2: Mostly Sorted - while-loop\n\narr = vals_to_list(12354)\ninsertion_sort_while(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[1, 2, 3, 5, 4] \n    idx: [2]\nSKIP:       (1, 2),[1, 2, 3, 5, 4] \n    idx: [3]\nSKIP:       (2, 3),[1, 2, 3, 5, 4] \n    idx: [4]\nUPDATED:    (3, 4),[1, 2, 3, 4, 5] \nSKIP:       (2, 3),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-3-unsorted-descending---for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-3-unsorted-descending---for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.3 TEST-3: Unsorted (Descending) - for-loop",
    "text": "2.3 TEST-3: Unsorted (Descending) - for-loop\n\narr = vals_to_list(54321)\ninsertion_sort_for(arr)\n\n    idx: [1]\nUPDATED:    (0, 1),[4, 5, 3, 2, 1] \n    idx: [2]\nUPDATED:    (1, 2),[4, 3, 5, 2, 1] \nUPDATED:    (0, 1),[3, 4, 5, 2, 1] \n    idx: [3]\nUPDATED:    (2, 3),[3, 4, 2, 5, 1] \nUPDATED:    (1, 2),[3, 2, 4, 5, 1] \nUPDATED:    (0, 1),[2, 3, 4, 5, 1] \n    idx: [4]\nUPDATED:    (3, 4),[2, 3, 4, 1, 5] \nUPDATED:    (2, 3),[2, 3, 1, 4, 5] \nUPDATED:    (1, 2),[2, 1, 3, 4, 5] \nUPDATED:    (0, 1),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-3-unsorted-descending---while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-3-unsorted-descending---while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.3 TEST-3: Unsorted (Descending) - while-loop",
    "text": "2.3 TEST-3: Unsorted (Descending) - while-loop\n\narr = vals_to_list(54321)\ninsertion_sort_while(arr)\n\n    idx: [1]\nUPDATED:    (0, 1),[4, 5, 3, 2, 1] \n    idx: [2]\nUPDATED:    (1, 2),[4, 3, 5, 2, 1] \nUPDATED:    (0, 1),[3, 4, 5, 2, 1] \n    idx: [3]\nUPDATED:    (2, 3),[3, 4, 2, 5, 1] \nUPDATED:    (1, 2),[3, 2, 4, 5, 1] \nUPDATED:    (0, 1),[2, 3, 4, 5, 1] \n    idx: [4]\nUPDATED:    (3, 4),[2, 3, 4, 1, 5] \nUPDATED:    (2, 3),[2, 3, 1, 4, 5] \nUPDATED:    (1, 2),[2, 1, 3, 4, 5] \nUPDATED:    (0, 1),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-4-duplicates---for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-4-duplicates---for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.4 TEST-4: Duplicates - for-loop",
    "text": "2.4 TEST-4: Duplicates - for-loop\n\narr = vals_to_list(88888)\ninsertion_sort_for(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[8, 8, 8, 8, 8] \n    idx: [2]\nSKIP:       (1, 2),[8, 8, 8, 8, 8] \n    idx: [3]\nSKIP:       (2, 3),[8, 8, 8, 8, 8] \n    idx: [4]\nSKIP:       (3, 4),[8, 8, 8, 8, 8] \n\n\n[8, 8, 8, 8, 8]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-4-duplicates---while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-4-duplicates---while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.4 TEST-4: Duplicates - while-loop",
    "text": "2.4 TEST-4: Duplicates - while-loop\n\narr = vals_to_list(88888)\ninsertion_sort_while(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[8, 8, 8, 8, 8] \n    idx: [2]\nSKIP:       (1, 2),[8, 8, 8, 8, 8] \n    idx: [3]\nSKIP:       (2, 3),[8, 8, 8, 8, 8] \n    idx: [4]\nSKIP:       (3, 4),[8, 8, 8, 8, 8] \n\n\n[8, 8, 8, 8, 8]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-5-already-sorted---for-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-5-already-sorted---for-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.5 TEST-5: Already Sorted - for-loop",
    "text": "2.5 TEST-5: Already Sorted - for-loop\n\narr = vals_to_list(12345)\ninsertion_sort_for(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[1, 2, 3, 4, 5] \n    idx: [2]\nSKIP:       (1, 2),[1, 2, 3, 4, 5] \n    idx: [3]\nSKIP:       (2, 3),[1, 2, 3, 4, 5] \n    idx: [4]\nSKIP:       (3, 4),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-5-already-sorted---while-loop",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-009-insertion-sort-for-while.html#test-5-already-sorted---while-loop",
    "title": "DSA 9: Insertion Sort - With Test Scenarios",
    "section": "2.5 TEST-5: Already Sorted - while-loop",
    "text": "2.5 TEST-5: Already Sorted - while-loop\n\narr = vals_to_list(12345)\ninsertion_sort_while(arr)\n\n    idx: [1]\nSKIP:       (0, 1),[1, 2, 3, 4, 5] \n    idx: [2]\nSKIP:       (1, 2),[1, 2, 3, 4, 5] \n    idx: [3]\nSKIP:       (2, 3),[1, 2, 3, 4, 5] \n    idx: [4]\nSKIP:       (3, 4),[1, 2, 3, 4, 5] \n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-050-binary-search-trees-part-exercises.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-050-binary-search-trees-part-exercises.html",
    "title": "DSA 50: Binary Search Trees - Exercises",
    "section": "",
    "text": "1. Draw a BST\nInsert into a empty BST the folloowing in this order:\n\n[1, 5, 9, 2, 4, 10, 6, 3, 8].\n\nDraw a diagram showing what the BST\n\n\n1.1 Draw a BST: Tony’s Solution\n1\n  \\ \n    5\n   /  \\\n  2     9\n   \\   / \\\n    4 6   10\n   /   \\\n  3     8\n\n\n2. Search: BST\nFind maximum number of steps to search value in Balanced BST with 1,000 values.\n\n\n2.1 Search: BST - Tony’s Solution\nSearching() value in BST is \\(\\log_2(n)\\):\n\\[steps = \\log_2(n)=\\log_2(1000)\\]\nApply change of base formula:\n\\[\\log_2(1000) = \\frac{\\log_{10}1000}{\\log_{10}2}\\]\n\\[log_{10}1000 = 3\\] \\[log_{10}2=0.301\\]\n\\[\\log_2(1000) = \\frac{3}{0.301}\\]\n\\[\\approx 9.97\\] \\[or\\ 10\\ steps\\]\n\n\n3. max() Value in BST - Tony’s Solution\nWrite the algorithm to find node with greatest value in BST.\n\n\n3.1. TreeNode & insert_node: Setup\nIntroduced previously.\n\nclass TreeNode: #4 mins\n    def __init__(self,data,left=None,right=None):\n        self.data=data\n        self.left=left\n        self.right=right\n        \ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    if current_node.data == target:\n        print(f\"t{target}==c{current_node.data}: cant insert duplicates\")\n        return current_node.data\n    elif target &lt; current_node.data:\n        print(f\"t{target}&lt;-c{current_node.data}: go left\")\n        if current_node.left:\n            current_node = current_node.left\n            return insert_node(current_node, target)\n        else:  \n            print(f\"t{target}&lt;-c{current_node.data}: no left_child insert left of c[{current_node.data}]\")\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        print(f\"t{target}-&gt;c{current_node.data}: go right\")\n        if current_node.right:\n            current_node = current_node.right\n            return insert_node(current_node, target)\n        else:  \n            print(f\"t{target}-&gt;c{current_node.data}: no right_child insert right of c[{current_node.data}]\")\n            current_node.right = TreeNode(target)\n            return current_node.right\n\ndef insert_node_clean(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    if current_node.data == target:\n        # print(f\"t{target}==c{current_node.data}: cant insert duplicates\")\n        return current_node.data\n    elif target &lt; current_node.data:\n        # print(f\"t{target}&lt;-c{current_node.data}: go left\")\n        if current_node.left:\n            current_node = current_node.left\n            return insert_node_clean(current_node, target)\n        else:  \n            # print(f\"t{target}&lt;-c{current_node.data}: no left_child insert left of c[{current_node.data}]\")\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        # print(f\"t{target}-&gt;c{current_node.data}: go right\")\n        if current_node.right:\n            current_node = current_node.right\n            return insert_node_clean(current_node, target)\n        else:  \n            # print(f\"t{target}-&gt;c{current_node.data}: no right_child insert right of c[{current_node.data}]\")\n            current_node.right = TreeNode(target)\n            return current_node.right\n        \n        \n        \ndef insert_from_list(root, node_list: list[int], show_results:bool = False):\n    for node in node_list:\n        if show_results:\n            insert_node(root, node)\n            print()\n        else:\n            insert_node_clean(root, node)\n    \n\n\n\n3.2 traverse()\n\ndef traverse(root_node: TreeNode):\n    if not root_node:\n        return\n    traverse(root_node.left)\n    print(root_node.data)\n    traverse(root_node.right)\n    \nroot = TreeNode(50)\ninsert_from_list(root, [25,75,10,35,25])\ntraverse(root)\n\n\n10\n25\n35\n50\n75\n\n\n\n\n3.3 find_max() Value in BST - Tony’s Solution\n\ndef find_max(root_node: TreeNode):\n    if not root_node:\n        return\n    while root_node.right:\n        return find_max(root_node.right)\n    return root_node.data\n\n\nroot = TreeNode(50)\ninsert_from_list(root, [25,75])\nfind_max(root)\n\n# PSUEDO\n\n#  50 \n# 25  75\n\n# [ENTERED]find_max{ [root_node==TreeNode(50)]}:\n# - [enter] while-loop: [c.r][75] exists: ---&gt; recurse find_max{[c.r][75]}:\n#   - [ENTERED]find_max{ root_node.right=TreeNode(75) }:  \n#     - [enter] while-loop: [c.r][N] DOES NOT exists\n#     - [return] c.data=75\n#   - [RETURND]{find_max{ ret[75] }\n# - [exitd] while-loop: ret[75] &lt;--- from find_max{ TreeNode(75) }\n# [return] ret[75]\n\n\n75\n\n\n\n\n3.4 find_max() Version 2 - Tony’s Solution\n\ndef GET_MAX(root_node: TreeNode):\n    if not root_node:\n        return\n    while root_node.right:\n        return GET_MAX(root_node.right) # this is hit at every level down and up\n    return root_node.data # this is only hit once\n\nroot = TreeNode(50)\ninsert_from_list(root, [25,75,80])\nGET_MAX(root)\n\n\n#  50 \n# 25  75\n#       80\n\n# PSUEDO CODE\n# [ENTERED]GET_MAX{ [rn=TreeNode(50)]}:\n# - (50)[enter] while-loop: [c.r][50.75] YES exists: \n# - (50)[enter] GET_MAX{[c.r][50.75]}:\n#   - (75)[ENTERED] {GET_MAX{  rn==TN(75) }:  \n#   - (75)[enter] while-loop: [c.r][50.75.80] YES exists: \n#   - (75)[enter] GET_MAX{[c.r][50.75.80]}:\n#       - (80)[ENTERED] {GET_MAX{ rn=TN(80) }:  \n#       - (80)[skipped] while-loop: [c.r][50.75.80.N] NO xists:\n#       - (80)[return] c.data=80 (~ return root_node.data)\n#       - (80)[EXITTED] {GET_MAX{ rn=TN(80) }               ---&gt; return 80\n#   - (75)[exitted] GET_MAX{[c.r][50.75.80]}:               ---&gt; return 80\n# - (50)[exitted] GET_MAX{[c.r][50.75]}:                    ---&gt; return 80\n# [RETURND] 80                                              ---&gt; return 80\n\n# - [exitd] while-loop: ret[75] &lt;--- from GET_MAX{ TreeNode(75) }\n# [return] ret[75]\n\n\n80\n\n\n\n\n4. PRE-order Traversal\nGiven binary serach tree:\n          50\n        /   \\ \n       25     75\n      /  \\   /  \\\n    10   30 60   80\nWhat will pre_order_traversal() print?\n\ndef pre_order_traversal(root_node: TreeNode):\n    if not root_node:\n        return\n    print(root_node.data) \n    pre_order_traversal(root_node.left)\n    pre_order_traversal(root_node.right)\n    \n\n\n\n4.1 PRE-order Traversal: Tony’s Guess without Python\n\n50\n25\n10\n30\n75\n60\n80\n        50\n      /   \\ \n     25     75\n    /  \\   /  \\\n  10   30 60   80\n\n\n\n4.2 PRE-order Traversal: Tony’s Solution with Python\n\ndef pre_order_traversal(root_node: TreeNode):\n    if not root_node:\n        return\n    print(root_node.data) \n    pre_order_traversal(root_node.left)\n    pre_order_traversal(root_node.right)\n\nroot = TreeNode(50)\nnode_list = [50,25,75,10,30,60,80]\ninsert_from_list(root, node_list, show_results=False)\nprint(\"inorder traverse\")\ntraverse(root)    \n\nprint()\nprint(\"preorder traversal\")\npre_order_traversal(root)    \n\nprint()\nprint(\"tony expected preorder traversal\")\ntony_expected = [50,25,10,30,75,60,80]\n[print(item) for item in tony_expected]\n\ninorder traverse\n10\n25\n30\n50\n60\n75\n80\n\npreorder traversal\n50\n25\n10\n30\n75\n60\n80\n\ntony expected preorder traversal\n50\n25\n10\n30\n75\n60\n80\n\n\n[None, None, None, None, None, None, None]\n\n\n      50\n    /   \\ \n   25     75\n  /  \\   /  \\\n10   30 60   80\n\n\n5. POST-order Traversal\nGiven binary serach tree:\n          50\n        /   \\ \n       25     75\n      /  \\   /  \\\n    10   30 60   80\nWhat will post_order_traversal() print?\n\n\n5.1 POST-order Traversal: Tony’s Guess without Python\n\n10\n30\n25\n60\n80\n75\n50\n\n\n\n5.2 POST-order Traversal: Tony’s Solution with Python\n\ndef post_order_traversal(root_node: TreeNode):\n    if not root_node:\n        return\n    post_order_traversal(root_node.left)\n    post_order_traversal(root_node.right)\n    print(root_node.data) \n\nroot = TreeNode(50)\nnode_list = [50,25,75,10,30,60,80]\ninsert_from_list(root, node_list, show_results=False)\nprint(\"inorder traverse\")\ntraverse(root)    \n\nprint()\nprint(\"post_order traversal\")\npost_order_traversal(root)    \n\nprint()\nprint(\"tony expected post_order traversal\")\ntony_expected = [10,30,25,60,80,75,50]\nfor value in tony_expected:\n    print(value) \n\ninorder traverse\n10\n25\n30\n50\n60\n75\n80\n\npost_order traversal\n10\n30\n25\n60\n80\n75\n50\n\ntony expected post_order traversal\n10\n30\n25\n60\n80\n75\n50"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-045-binary-search-trees-part-8.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-045-binary-search-trees-part-8.html",
    "title": "DSA 45: Binary Search Trees - Delete [Part 8]",
    "section": "",
    "text": "1. TreeNode, Binary Tree & insert_node: Setup\nIntroduced previously.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCannot insert duplicates\")\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE left-child : GO LEFT[{current_node.left.data}]\")\n            current_node=current_node.left\n            return insert_node(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO left-child: INSERTED LEFT CurrentLeft[{current_node.left.data}]\")\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE right-child : GO right[{current_node.right.data}]\")\n            current_node=current_node.right\n            return insert_node(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO right-child: INSERTED right Currentright[{current_node.right.data}]\")\n    pass\n\ndef insert_node_clean(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            current_node=current_node.left\n            return insert_node_clean(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            current_node=current_node.right\n            return insert_node_clean(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n    pass\n\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \ndef insert_node_list(root_node:TreeNode, node_list: list[int], show_outputs:bool=True):\n    for node in node_list: \n        if show_outputs:\n            insert_node(root_node, node) \n        else:\n            insert_node_clean(root_node, node) \nroot = None\nroot = TreeNode(50)\nnode_list = [25,75,10,33,56,89,4,11,30,40,52,61,82,95]\ninsert_node_list(root, node_list,show_outputs=True)\n\nt[25]|c[50]:        Current[50] has NO left-child: INSERTED LEFT CurrentLeft[25]\nt[75]|c[50]:        Current[50] has NO right-child: INSERTED right Currentright[75]\nt[10]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[10]|c[25]:        Current[25] has NO left-child: INSERTED LEFT CurrentLeft[10]\nt[33]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[33]|c[25]:        Current[25] has NO right-child: INSERTED right Currentright[33]\nt[56]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[56]|c[75]:        Current[75] has NO left-child: INSERTED LEFT CurrentLeft[56]\nt[89]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[89]|c[75]:        Current[75] has NO right-child: INSERTED right Currentright[89]\nt[4]|c[50]:         Current[50] has ONE left-child : GO LEFT[25]\nt[4]|c[25]:         Current[25] has ONE left-child : GO LEFT[10]\nt[4]|c[10]:         Current[10] has NO left-child: INSERTED LEFT CurrentLeft[4]\nt[11]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[11]|c[25]:        Current[25] has ONE left-child : GO LEFT[10]\nt[11]|c[10]:        Current[10] has NO right-child: INSERTED right Currentright[11]\nt[30]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[30]|c[25]:        Current[25] has ONE right-child : GO right[33]\nt[30]|c[33]:        Current[33] has NO left-child: INSERTED LEFT CurrentLeft[30]\nt[40]|c[50]:        Current[50] has ONE left-child : GO LEFT[25]\nt[40]|c[25]:        Current[25] has ONE right-child : GO right[33]\nt[40]|c[33]:        Current[33] has NO right-child: INSERTED right Currentright[40]\nt[52]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[52]|c[75]:        Current[75] has ONE left-child : GO LEFT[56]\nt[52]|c[56]:        Current[56] has NO left-child: INSERTED LEFT CurrentLeft[52]\nt[61]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[61]|c[75]:        Current[75] has ONE left-child : GO LEFT[56]\nt[61]|c[56]:        Current[56] has NO right-child: INSERTED right Currentright[61]\nt[82]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[82]|c[75]:        Current[75] has ONE right-child : GO right[89]\nt[82]|c[89]:        Current[89] has NO left-child: INSERTED LEFT CurrentLeft[82]\nt[95]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[95]|c[75]:        Current[75] has ONE right-child : GO right[89]\nt[95]|c[89]:        Current[89] has NO right-child: INSERTED right Currentright[95]\n\n\n\n\n2. Confirm Tree\n\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95\nprint(f\"[L1] root.data: \\t\\t\\t[{root.data}] (expected: 50)\")\nprint()\nprint(f\"[L2] root.left.data: \\t\\t\\t[{root.left.data}] (expected: 25)\")\nprint(f\"[L2] root.right.data: \\t\\t\\t[{root.right.data}] (expected: 75)\")\nprint()\nprint(f\"[L3] root.left.left.data:      \\t\\t[{root.left.left.data}] (expected: 10)\")\nprint(f\"[L3] root.left.right.data:     \\t\\t[{root.left.right.data}] (expected: 33)\")\nprint(f\"[L3] root.right.left.data:     \\t\\t[{root.right.left.data}] (expected: 56)\")\nprint(f\"[L3] root.right.right.data:    \\t\\t[{root.right.right.data}] (expected: 89)\")\nprint()\nprint(f\"[L4] root.left.left.left.data: \\t\\t[{root.left.left.left.data}]  (expected:  4)\")\nprint(f\"[L4] root.left.left.right.data:  \\t[{root.left.left.right.data}] (expected: 11)\")\nprint(f\"[L4] root.left.right.left.data:  \\t[{root.left.right.left.data}] (expected: 30)\")\nprint(f\"[L4] root.left.right.right.data: \\t[{root.left.right.right.data}] (expected: 40)\")\nprint()\nprint(f\"[L4] root.right.left.left.data:  \\t[{root.right.left.left.data}] (expected: 52)\")\nprint(f\"[L4] root.right.left.right.data: \\t[{root.right.left.right.data}] (expected: 61)\")\nprint(f\"[L4] root.right.right.left.data: \\t[{root.right.right.left.data}] (expected: 82)\")\nprint(f\"[L4] root.right.right.right.data:\\t[{root.right.right.right.data}] (expected: 95)\")\n\n[L1] root.data:             [50] (expected: 50)\n\n[L2] root.left.data:            [25] (expected: 25)\n[L2] root.right.data:           [75] (expected: 75)\n\n[L3] root.left.left.data:           [10] (expected: 10)\n[L3] root.left.right.data:          [33] (expected: 33)\n[L3] root.right.left.data:          [56] (expected: 56)\n[L3] root.right.right.data:         [89] (expected: 89)\n\n[L4] root.left.left.left.data:      [4]  (expected:  4)\n[L4] root.left.left.right.data:     [11] (expected: 11)\n[L4] root.left.right.left.data:     [30] (expected: 30)\n[L4] root.left.right.right.data:    [40] (expected: 40)\n\n[L4] root.right.left.left.data:     [52] (expected: 52)\n[L4] root.right.left.right.data:    [61] (expected: 61)\n[L4] root.right.right.left.data:    [82] (expected: 82)\n[L4] root.right.right.right.data:   [95] (expected: 95)\n\n\n\n\n3. delete_node: 0 or 1 Child Nodes Only\n\ndef delete_node(root_node: TreeNode, target: int, parent_node=None):\n    current_node = root_node\n    if target == current_node.data:\n        # 2. delete_node - delete cases 1, 2 & 3.\n        print(f\"[Part 1: Search] t[{target}]==c[{current_node.data}]: \\t\\t\\t\\tNode Found...\")\n        print(f\"[Part 2: Delete] t[{target}]==c[{current_node.data}]: \\t\\t\\t\\tDetermine Number of Children...\")\n\n        if (not current_node.left and not current_node.right): # 0-kids\n            # Case A: Target has 0-kid --- [(0 left + 0 right) \n            # only 1 parent per node(p.left or p.right)\n            if parent_node.left: # if exists burn it\n                parent_node.left = None\n            elif parent_node.right: \n                parent_node.right = None\n            \n            print(f\"[Part2A: Del_0Kid] t[{target}]==c[{current_node.data}]._0_kid: \\t\\tBurn'em!🔥[{target}], Parent[{parent_node.data}] will survive 🍀.\")\n            return\n        \n        elif (current_node.left and not current_node.right) or (not current_node.left and current_node.right):\n            # Case B: 1-kid --- [(1 left + 0 right) OR (0 left + 1 right)]\n            if current_node.left:\n                target_sgl_child = current_node.left \n            else:\n                target_sgl_child = current_node.right\n                \n            print(f\"[Part2B: Del_1Kid] t[{target}]==c[{current_node.data}]._1_kid[{target_sgl_child.data}]: \\tIs it Left or Right? kids_gramps[{parent_node.data}]\")\n            if parent_node.left == current_node:\n                parent_node.left = target_sgl_child     ##### 2BI  REPLACE TARGET WITH TARGETS LEFT-CHILD\n                print(f\"[Part2B: Del_1Kid] targets.child[{target_sgl_child.data}] has now assumed the identity of the target t[{target}|c{current_node.data}] and is the kid of it's (previous) gramps[{parent_node.data}]: aka now gramps.leftkid[{parent_node.left.data}]\")\n            elif parent_node.right == current_node: # target can be a left or right child\n                parent_node.right = target_sgl_child    ##### 2BII REPLACE TARGET WITH TARGETS LEFT-CHILD\n                print(f\"[Part2B: Del_1Kid] targets.child[{target_sgl_child.data}] has now assumed the identity of the target t[{target}|c{current_node.data}] and is the kid of it's (previous) gramps[{parent_node.data}]: aka now gramps.rightkid[{parent_node.right.data}]\")\n            return\n            \n        else:\n            # Case C: 2-kid --- [(1 left + 1 right)\n            # [deleting_node]: 2KIDS, \n            # * replace [target] with [successor_node]. \n            # The [s_node] is the [child_node]: least of all descendents that are greater than target\n            # how to: [target + all descendants in ascending order], [s_node] is next number after [target]\n            print(f\"[Part2C: Del_2Kid] t[{target}]==c[{current_node.data}]._2_kids[{current_node.left.data},{current_node.right.data}]:\\t\\tGO RIGHT-CHILD[{current_node.right.data}]\")\n            \n            #             50\n            #       25           75\n            #    11    33    [56]    89  \n            # []  [] 30  40 52  61 82  95\n\n            # STEP 1 FOR ALL NODES WITH 2 KIDS - GO RIGHT ONCE:\n            # Step 1: [GO-RIGHT] (for all scenarios)\n            target_node = parent_node = current_node\n            current_node = current_node.right  # target(aka current) always has 2_kids (right always exists)\n\n            #             50\n            #       25           75\n            #    11    33    [56]    89  \n            # []  [] 30  40 52  61 82  95\n\n            # go left as possible til no leaf (or left child)\n            # while current_node:     \n            while current_node:\n                if current_node.left:\n                    print(f\"[Part3A: 2K_SNodeLeft] t[{target}],c[{current_node.data}].left_child exists[{current_node.left.data}]: \\tgo left...Parent[{parent_node.data}]\")\n                    parent_node=current_node\n                    current_node=current_node.left\n                elif current_node.right: #no left + yes right (S_Node is Right)\n                    print(f\"[Part3B: 2K_SNodeRite] t[{target}],c[{current_node.data}].right_child exists [{current_node.right.data}]: \\t do something...1...Parent[{parent_node.data}]\")\n                    print(f\"expected c[{current_node.data}]: to [expected 52] with right[{current_node.right.data}] as [expected 55]\")\n                          \n                          \n                    # S_NODE HAS RIGHT_CHILD\n                    # S_NODE replaces TARGET\n                    # RIGHT_CHILDr replaces S_NODE\n                    \n                    # insert_node_clean(root,55)\n                    #             [X]\n                    #       25            75\n                    #    11    33     61     89  \n                    # []  [] 30  40 {52}  [] 82  95    CN: {52} -&gt; BECOMES SNODE\n                    #                 [55]\n                    \n                    #             (52)\n                    #       25            75\n                    #    11    33     61     89  \n                    # []  [] 30  40 (55)  [] 82  95    CN: {52} -&gt; BECOMES SNODE\n                    #                 [X]\n                    s_node = current_node\n                    target_node.data = s_node.data\n                    current_node.data = s_node.right.data\n                    current_node.right = None\n                    print(f\"[Part3B: 2K_SNodeRite] t[{target}] replaced w' s_node[{target_node.data}], s_node[{target_node.data}] replaced w' right_child[{current_node.data}] \")\n                    return s_node.data # \n                else:\n                    print(f\"[Part3C: 2K_SNodeLeaf] t[{target}],c[{current_node.data}].no_children): \\tParent[{parent_node.data}]\")\n                    #             50\n                    #       25           75\n                    #    11    33     [X]    89  \n                    # []  [] 30  40 52  61 82  95\n                    s_node = current_node\n                    # delete target by simply replacing the data????\n                    target_node.data = s_node.data\n                    # remove pointer from parent to current_node\n                    if parent_node.left == current_node:\n                        print(f\"[Part3C: 2K_SNodeLeaf] t[{target}],c[{current_node.data}].is_s_node[{s_node.data}]): replaces target[{target}] \\tParent[{parent_node.data}].left[{parent_node.left.data}] to be deleted\")\n                        parent_node.left=None\n                        return\n                    elif parent_node.right == current_node: # IF S_NODE IS RIGHT_CHILD WITH A CHILD, REPLACE ITSELF WITH THE CHILD\n                        print(f\"[Part3C: 2K_SNodeLeaf] t[{target}],c[{current_node.data}].is_s_node[{s_node.data}]): replaces target[{target}] \\tParent[{parent_node.data}].right[{parent_node.right.data}] to be deleted\")\n                        parent_node.right=None\n                        return\n                    \n                    return s_node.data # current is S_Node, target is deleted, s_node replaced target\n                    \n            # Step 2:[LEFT EXISTS]: keep_going_left -&gt; ... -&gt; [Leaf.F_left_child]:\n                # Step 2a:  [LEAF F_right_child]: leaf is [s_node]  -&gt; replace [target]\n                # Step 2bi: [LEAF T_right_child]: leaf is [s_node]  -&gt; replace [target]\n                # Step 2bii:                      and leaf.right_child  -&gt; replace [leaf]\n                    \n\n            # test 1: c has two kids\n            # if current_node.left and current_node.right:\n                # print(f\"[Part2C: Delete] t[{target}]==c[{current_node.data}]._2_kids: \\t\\twhat a shame! ☠️ [TBA IN FUTURE]\")\n    \n    # 1. search_node \n    if target &lt; current_node.data: # go left\n        if current_node.left:\n            print(f\"[Part 1: Search] t[{target}]&lt;c[{current_node.data}].left_child exists[{current_node.left.data}]: \\tgo left...\")\n            parent_node = current_node\n            current_node = current_node.left\n            return delete_node(current_node, target,parent_node)\n        else:\n            print(f\"[Part 1: Search] t[{target}]&lt;c[{current_node.data}].left_child doesnt exists[{None}]: Node Not Found!\")\n            return\n    else:\n        if current_node.right:\n            print(f\"[Part 1: Search] t[{target}]&gt;c[{current_node.data}].right_child exists[{current_node.right.data}]: \\tgo right...\")\n            parent_node = current_node\n            current_node = current_node.right\n            return delete_node(current_node, target,parent_node)\n        else:\n            print(f\"[Part 1: Search] t[{target}]&gt;c[{current_node.data}].right_child doesnt exists[{None}]: Node Not Found!\")\n            return\n\n\n\n4. Testing\n\nroot = None\nroot = TreeNode(50)\nnode_list = [25,75,10,33,56,89,4,11,30,40,52,61,82,95]\ninsert_node_list(root, node_list,show_outputs=False)\n\ndelete_node(root,4)\n#             50\n#      25           75\n#    10     33     56     89  \n# [X]  11 30  40 52  61 82  95\n\nprint()\ndelete_node(root,10)\n#             50\n#      25           75\n#    11     33     56     89  \n# []  [X] 30  40 52  61 82  95\n\nprint()\ndelete_node(root,56)\n#             50\n#       25           75\n#    11    33     [X]    89  \n# []  [] 30  40 52  61 82  95\n\nprint()\ndelete_node(root,56)\n#             50\n#       25             75\n#    11    33    [61]     89  \n# []  [] 30  40 52  [X] 82  95\n\nprint(f\"root.data[{root.data}]: expected[50]\")\nprint(f\"root.right.data[{root.right.data}]: expected[75]\")\nprint(f\"root.right.left.data[{root.right.left.data}]: expected[61]\")\nprint(f\"root.right.right.data[{root.right.right.data}]: expected[89]\")\nprint(f\"root.right.left.left.data[{root.right.left.left.data}]: expected[52]\")\nprint(f\"root.right.left.right.data[{root.right.left.right}]: expected[None]\") \nprint(f\"root.right.right.left.data[{root.right.right.left.data}]: expected[82]\")\nprint(f\"root.right.right.right.data[{root.right.right.right.data}]: expected[95]\")\n\nprint()\nprint(\"INSERT 55 (RIGHT OF 52)\")\ninsert_node(root,55)\n# insert_node_clean(root,55)\n#             50\n#       25            75\n#    11    33     61     89  \n# []  [] 30  40 52  [] 82  95\n#                [55]\n\nprint(root.right.left.left.right.data)\n\ndelete_node(root,50)\n# insert_node_clean(root,55)\n#             50\n#       25            75\n#    11    33     61     89  \n# []  [] 30  40 52  [] 82  95\n#                [55]\n\n[Part 1: Search] t[4]&lt;c[50].left_child exists[25]:  go left...\n[Part 1: Search] t[4]&lt;c[25].left_child exists[10]:  go left...\n[Part 1: Search] t[4]&lt;c[10].left_child exists[4]:   go left...\n[Part 1: Search] t[4]==c[4]:                Node Found...\n[Part 2: Delete] t[4]==c[4]:                Determine Number of Children...\n[Part2A: Del_0Kid] t[4]==c[4]._0_kid:       Burn'em!🔥[4], Parent[10] will survive 🍀.\n\n[Part 1: Search] t[10]&lt;c[50].left_child exists[25]:     go left...\n[Part 1: Search] t[10]&lt;c[25].left_child exists[10]:     go left...\n[Part 1: Search] t[10]==c[10]:              Node Found...\n[Part 2: Delete] t[10]==c[10]:              Determine Number of Children...\n[Part2B: Del_1Kid] t[10]==c[10]._1_kid[11]:     Is it Left or Right? kids_gramps[25]\n[Part2B: Del_1Kid] targets.child[11] has now assumed the identity of the target t[10|c10] and is the kid of it's (previous) gramps[25]: aka now gramps.leftkid[11]\n\n[Part 1: Search] t[56]&gt;c[50].right_child exists[75]:    go right...\n[Part 1: Search] t[56]&lt;c[75].left_child exists[56]:     go left...\n[Part 1: Search] t[56]==c[56]:              Node Found...\n[Part 2: Delete] t[56]==c[56]:              Determine Number of Children...\n[Part2C: Del_2Kid] t[56]==c[56]._2_kids[52,61]:     GO RIGHT-CHILD[61]\n[Part3C: 2K_SNodeLeaf] t[56],c[61].no_children):    Parent[56]\n[Part3C: 2K_SNodeLeaf] t[56],c[61].is_s_node[61]): replaces target[56]  Parent[61].right[61] to be deleted\n\n[Part 1: Search] t[56]&gt;c[50].right_child exists[75]:    go right...\n[Part 1: Search] t[56]&lt;c[75].left_child exists[61]:     go left...\n[Part 1: Search] t[56]&lt;c[61].left_child exists[52]:     go left...\n[Part 1: Search] t[56]&gt;c[52].right_child doesnt exists[None]: Node Not Found!\nroot.data[50]: expected[50]\nroot.right.data[75]: expected[75]\nroot.right.left.data[61]: expected[61]\nroot.right.right.data[89]: expected[89]\nroot.right.left.left.data[52]: expected[52]\nroot.right.left.right.data[None]: expected[None]\nroot.right.right.left.data[82]: expected[82]\nroot.right.right.right.data[95]: expected[95]\n\nINSERT 55 (RIGHT OF 52)\nt[55]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[55]|c[75]:        Current[75] has ONE left-child : GO LEFT[61]\nt[55]|c[61]:        Current[61] has ONE left-child : GO LEFT[52]\nt[55]|c[52]:        Current[52] has NO right-child: INSERTED right Currentright[55]\n55\n[Part 1: Search] t[50]==c[50]:              Node Found...\n[Part 2: Delete] t[50]==c[50]:              Determine Number of Children...\n[Part2C: Del_2Kid] t[50]==c[50]._2_kids[25,75]:     GO RIGHT-CHILD[75]\n[Part3A: 2K_SNodeLeft] t[50],c[75].left_child exists[61]:   go left...Parent[50]\n[Part3A: 2K_SNodeLeft] t[50],c[61].left_child exists[52]:   go left...Parent[75]\n[Part3B: 2K_SNodeRite] t[50],c[52].right_child exists [55]:      do something...1...Parent[61]\nexpected c[52]: to [expected 52] with right[55] as [expected 55]\n[Part3B: 2K_SNodeRite] t[50] replaced w' s_node[52], s_node[52] replaced w' right_child[55] \n\n\n55"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-012-hash-tables-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-012-hash-tables-part-2.html",
    "title": "DSA 12: Hash Tables - Collisions [Part 2]",
    "section": "",
    "text": "1. Setup\nFrom previous post: Hash Tables - Part 1\n\nthesaurus_arr = [None]*16 # create empty thesaurus\nletters_dict = {chr(i): i - 96 for i in range(97, 97 + 26)}\nprint(f\"letters_dict: \\n{letters_dict}\")\n\nletters_dict: \n{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n\n\n\ndef alphabet_multiplicative_hash_fn(input_word: str):\n    # convert some string into hash_value by multiplying all letters value\n    hash_value = 1\n    for character in input_word:\n    # dict_val = dict[char]\n        letter_val = letters_dict[character]\n        hash_value *= letter_val # cumulative product: char1 * char2 ...\n    return hash_value\nPretendDictMemoryList = [None]*16\nprint(f\"PretendDictMemoryList: {PretendDictMemoryList}\")\n\nPretendDictMemoryList: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n\n\n\nprint(f\"Test getting 'd': {letters_dict['d']}\") # 4\n\nprint(f\"Test hash_fn('bad'): {alphabet_multiplicative_hash_fn('bad')}\") # 2*1*4 = 8\nprint(f\"Test hash_fn('cab'): {alphabet_multiplicative_hash_fn('cab')}\") # 3*1*2 = 6\n\nentry_pairs_list = [(\"bad\",\"evil\"),(\"cab\",\"taxi\"),(\"aaa\",\"best\")]\nentry_pairs_list\n\nfor pair in entry_pairs_list:\n    hash_value = alphabet_multiplicative_hash_fn(pair[0])\n    PretendDictMemoryList[hash_value-1]=pair[1]\n    # print(hash_value, PretendDictMemoryList)\n    \nthesaurus_app = PretendDictMemoryList\n\nprint(f\"\\nThesaurus app:\\n{thesaurus_app}\")\n\nTest getting 'd': 4\nTest hash_fn('bad'): 8\nTest hash_fn('cab'): 6\n\nThesaurus app:\n['best', None, None, None, None, 'taxi', None, 'evil', None, None, None, None, None, None, None, None]\n\n\n\n\n2. Collisions (same hash values)\n\n\n2.1 New Entry with Same Hash Value\nNotice new entry [\"dab\",\"tap\"] will result in a hash_value of 8:\n\nprint(f\"Test hash_fn('dab'): {alphabet_multiplicative_hash_fn('dab')}\") # 4*1*2 = 8\n\nTest hash_fn('dab'): 8\n\n\n\n\n2.2 A Collision Has Occured 💥!\nIndex 8 in memory already exists from a previous entry:\n\n[\"bad\",\"evil\"].\n\nIndex 8 will be over-ridden by the new entry:\n\nfrom [\"bad\",\"evil\"]\nto [\"dab\",\"tap\"]\n\nThe current approach is sub-optimal.\n\nentry_pairs_list = [(\"dab\",\"tap\")]\n\nfor pair in entry_pairs_list:\n    hash_value = alphabet_multiplicative_hash_fn(pair[0])\n    PretendDictMemoryList[hash_value-1]=pair[1]\n    \nthesaurus_app = PretendDictMemoryList\n\n\nprint(f\"\\nThesaurus app:\\n{thesaurus_app}\")\n\n\nThesaurus app:\n['best', None, None, None, None, 'taxi', None, 'tap', None, None, None, None, None, None, None, None]\n\n\n\n\n2.3 Updated Solution: Sub-Arrays\nCreate an array with sub-arrays at the index\nFor the example: * create an array within index 8, * with each item of the array, * represented by the [input_word,synonym]\n\n\n2.4 Search Time-Complexity: Previous versus Updated Solution\nPrevious Solution:\n\nPretendDictMemoryList[8] = \"taxi\"\n\nThus, Search is \\(O(1)\\)\n\n\nUpdated Solution:\n\nPretendDictMemoryList[8] = [[\"cab\",\"taxi\"],[\"dab\",\"tap\"]]\n\nSearch \\(O(1)\\) to get value at index (or hash_value)\nThen, search array \\(O(n)\\) to find our cab or dab key\nThus, Total Search \\(O(n+1) \\to O(n)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-array-with-sub-arrays",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-array-with-sub-arrays",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "1.1 Create Array with Sub-Arrays",
    "text": "1.1 Create Array with Sub-Arrays\n\nmenu_arr = [\n    [\"Deep-Fried Chicken Wings\", 4.99],\n    [\"Malaysian Laksa\", 4.99],\n    [\"Tony Pepperoni Pizza\", 4.99],\n    [\"Cheesey Carbonara\", 4.99],\n]\n\nmenu_title = \"Tony's Cafe Menu\"\nmenu_price = \"Price ($A)\"\nprint(f\"{menu_title:25} {menu_price:&gt;10}\")\nprint(f\"{'-'*36}\")\n\nfor menu_item in menu_arr:\n    # menu_item_str = menu_item[0]+\":\"\n    print(f\"{menu_item[0]:25} {menu_item[1]:&gt;10}\")\n\nTony's Cafe Menu          Price ($A)\n------------------------------------\nDeep-Fried Chicken Wings        4.99\nMalaysian Laksa                 4.99\nTony Pepperoni Pizza            4.99\nCheesey Carbonara               4.99"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-hash-table-aka-python-dictionary-example",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-hash-table-aka-python-dictionary-example",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "2.1 Create Hash Table (aka Python Dictionary) example",
    "text": "2.1 Create Hash Table (aka Python Dictionary) example\n\nmenu_dct = {\n    \"Deep-Fried Chicken Wings\": 4.99,\n    \"Malaysian Laksa\": 4.99,\n    \"Tony Pepperoni Pizza\": 4.99,\n    \"Cheesey Carbonara\": 4.99\n}\nprint(menu_dct) # print whole dct\nprint(type(menu_dct)) # get type\nprint(menu_dct.get(\"Tony Pepperoni Pizza\")) # get food item price\nprint()\nprint(f\"{menu_title:25} {menu_price:&gt;10}\") # print menu\nprint(f\"{'-'*36}\")\nfor k,v in menu_dct.items():\n    print(f\"{k:25} {v:&gt;10}\")\n\n{'Deep-Fried Chicken Wings': 4.99, 'Malaysian Laksa': 4.99, 'Tony Pepperoni Pizza': 4.99, 'Cheesey Carbonara': 4.99}\n&lt;class 'dict'&gt;\n4.99\n\nTony's Cafe Menu          Price ($A)\n------------------------------------\nDeep-Fried Chicken Wings        4.99\nMalaysian Laksa                 4.99\nTony Pepperoni Pizza            4.99\nCheesey Carbonara               4.99"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-addition-example-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-addition-example-1",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "3.1 HF: Addition Example 1",
    "text": "3.1 HF: Addition Example 1\n\nAssume A=1, B=2, C=3, D=4, etc…\n\nInput is BAD\n\nHF(BAD) will return: 1 + 2 + 4 = 7"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-multiplication-example-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-multiplication-example-1",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "3.2 HF: Multiplication Example 1",
    "text": "3.2 HF: Multiplication Example 1\n\nAssume A=1, B=2, C=3, D=4, etc…\n\nInput is BAD\n\nHF(BAD) will return: 1 * 2 * 4 = 8"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-multiplication-example-2",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#hf-multiplication-example-2",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "3.3 HF: Multiplication Example 2",
    "text": "3.3 HF: Multiplication Example 2\n\nAssume A=1, B=2, C=3, D=4, etc…\n\nInput is DAB\n\nHF(DAB) will return: 4 * 1 * 2 = 8\n\nNote: BAD and DAB returned the same index value of 8. This issue needs and will be address later."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-letters_dict",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-letters_dict",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.1 Create letters_dict",
    "text": "4.1 Create letters_dict\nEach dict key is the letter and each dict value is the letter’s place in the alphabet\n\nthesaurus_arr = [None]*16 # create empty thesaurus\nletters_dict = {chr(i): i - 96 for i in range(97, 97 + 26)}\nprint(letters_dict)\n\n{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#test-letters_dict",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#test-letters_dict",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.2 Test letters_dict",
    "text": "4.2 Test letters_dict\n\nletters_dict[\"d\"]\n\n4"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-hash_function",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#create-hash_function",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.3 Create hash_function",
    "text": "4.3 Create hash_function\nConverts a string into a hash_value.\nThis hash_value will be the index in our thesaurus_dict.\n\ndef alphabet_multiplicative_hash_fn(input_word: str):\n    # convert some string into hash_value by multiplying all letters value\n    hash_value = 1\n    for character in input_word:\n    # dict_val = dict[char]\n        letter_val = letters_dict[character]\n        hash_value *= letter_val # cumulative product: char1 * char2 ...\n    return hash_value"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#test-hash_function",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#test-hash_function",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.4 Test hash_function",
    "text": "4.4 Test hash_function\n\nprint(alphabet_multiplicative_hash_fn(\"bad\")) # 2*1*4 = 8\nprint(alphabet_multiplicative_hash_fn(\"cab\")) # 3*1*2 = 6\n\n8\n6"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entries-into-app-mock-up-data",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entries-into-app-mock-up-data",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.5 Add entries into App (mock-up data)",
    "text": "4.5 Add entries into App (mock-up data)\nPretend the computer memorys storing our dictionary is represented by an array of 16 contiguous values like a list.\nAdd 3 entries:\n\nthesaurus[​“bad”​] = ​“evil”​\nthesaurus[​“cab”​] = ​“taxi”​\nthesaurus[​“ace”​] = ​“star”​\n\n\nPretendDictMemoryList = [None]*16\nPretendDictMemoryList\n\n[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entry-to-memory---psuedo-code",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entry-to-memory---psuedo-code",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.6 Add Entry to Memory - Psuedo-Code",
    "text": "4.6 Add Entry to Memory - Psuedo-Code\n\nGet each pair (string,synonym) entry\nCreate hash_value for each pairs string\nAdd to memory at hash_value index: memory[hash_value]=synonym"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entry-to-memory---python",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-011-hash-tables-part-1.html#add-entry-to-memory---python",
    "title": "DSA 11: Hash Tables - Hash Functions [Part 1]",
    "section": "4.7 Add Entry to Memory - Python",
    "text": "4.7 Add Entry to Memory - Python\n\nentry_pairs_list = [(\"bad\",\"evil\"),(\"cab\",\"taxi\"),(\"aaa\",\"best\")]\nentry_pairs_list\n\nfor pair in entry_pairs_list:\n    hash_value = alphabet_multiplicative_hash_fn(pair[0])\n    PretendDictMemoryList[hash_value-1]=pair[1]\n    # print(hash_value, PretendDictMemoryList)\n    \nthesaurus_app = PretendDictMemoryList"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-1",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.1 Scenario 1",
    "text": "8.1 Scenario 1\n\n# target has 1 left child\n# target child has two children\nroot =TreeNode(50)\ninsert_node_list(root, [25,10,33])\n#         [50]    &lt;-------- root_node &lt;----------------------- target_node\n#      25      [] &lt;-------- target.left &lt;--------------------- None or Integer\n#    10   33   [] &lt;-------- target_child.left or right &lt;------ Any\ndelete_node(root,50)\n#         [25]    &lt;-------- target.left replaces target \n#      10     33 &lt;-------- \nprint(f\"{traverse(root)}, expected: 10,25,33\")\nprint()\n\nprint(f\"{root.data}, expected: 25\")\nprint(f\"{root.left.data}, expected: 10\")\nprint(f\"{root.right.data}, expected: 33\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [10]\n    50 has a left-child25: going left\n    10 inserted left of c25\n\nAttempting to insert: [33]\n    50 has a left-child25: going left\n    33 inserted right of c25\n\nt[50]==c[50] found!\nt[50] to be replaced by its c[25]\n10\n25\n33\nNone, expected: 10,25,33\n\n25, expected: 25\n10, expected: 10\n33, expected: 33"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-2",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-2",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.2 Scenario 2",
    "text": "8.2 Scenario 2\n\n# target has 1 right child\n# target child has two children\nroot =TreeNode(50)\ninsert_node_list(root, [75,74,76])\n#   [50]       &lt;-------- root_node &lt;----------------------- target_node\n#       [75]   &lt;-------- target.right &lt;--------------------- None or Integer\n#     74    76 &lt;-------- target_child.left or right &lt;------ Any\ndelete_node(root,50)\n#     [75]    &lt;-------- target.right replaces target \n#  74     76  &lt;-------- \nprint(f\"{traverse(root)}, expected: 74,75,76\")\nprint()\n\nprint(f\"{root.data}, expected: 75\")\nprint(f\"{root.left.data}, expected: 74\")\nprint(f\"{root.right.data}, expected: 76\")\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [74]\n    50 has a right-child75: going left\n    74 inserted left of c75\n\nAttempting to insert: [76]\n    50 has a right-child75: going left\n    76 inserted right of c75\n\nt[50]==c[50] found!\nt[50] to be replaced by its c[75]\n74\n75\n76\nNone, expected: 74,75,76\n\n75, expected: 75\n74, expected: 74\n76, expected: 76"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-3",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-3",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.3 Scenario 3",
    "text": "8.3 Scenario 3\n\n# target has 1 right child\n# target child has 1 right children\nroot =TreeNode(50)\ninsert_node_list(root, [75,74])\n#   [50]       &lt;-------- root_node &lt;----------------------- target_node\n#       [75]   &lt;-------- target.right &lt;--------------------- None or Integer\n#     74       &lt;-------- target_child.left  &lt;------ Any\ndelete_node(root,50)\n#     [75]    &lt;-------- target.right replaces target \n#  74         &lt;-------- \nprint(f\"{traverse(root)}, expected: 74,75\")\nprint()\n\nprint(f\"{root.data}, expected: 75\")\nprint(f\"{root.left.data}, expected: 74\")\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [74]\n    50 has a right-child75: going left\n    74 inserted left of c75\n\nt[50]==c[50] found!\nt[50] to be replaced by its c[75]\n74\n75\nNone, expected: 74,75\n\n75, expected: 75\n74, expected: 74"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-4",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-4",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.4 Scenario 4",
    "text": "8.4 Scenario 4\n\n# target has 1 right child\n# target child has 1 left children\nroot =TreeNode(50)\ninsert_node_list(root, [25,10])\n#     [50]   &lt;-------- root_node &lt;----------------------- target_node\n#  [25]      &lt;-------- target.left &lt;--------------------- None or Integer\n# [10]       &lt;-------- target_child.left  &lt;------ Any\ndelete_node(root,50)\n#     [25]    &lt;-------- target.left replaces target \n#  10         &lt;-------- \nprint(f\"{traverse(root)}, expected: 10,25\")\nprint()\n\nprint(f\"{root.data}, expected: 25\")\nprint(f\"{root.left.data}, expected: 10\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [10]\n    50 has a left-child25: going left\n    10 inserted left of c25\n\nt[50]==c[50] found!\nt[50] to be replaced by its c[25]\n10\n25\nNone, expected: 10,25\n\n25, expected: 25\n10, expected: 10"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-5",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-5",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.5 Scenario 5",
    "text": "8.5 Scenario 5\n\n# target has 1 left child\n# target_child has 0 children\nroot =TreeNode(50)\ninsert_node_list(root, [25,10])\n#         50 &lt;-------- parent_node \n#      [25]  &lt;-------- target or parent.left\n#    10      &lt;-------- targets_child (or target.left) replaces target via parent.left -&gt; target_child &lt;------ 1\ndelete_node(root,25)\n#         50 &lt;-------- parent_node &lt;--------------\n#      [10]  &lt;-------- target_child\n\nprint(f\"{traverse(root)}, expected: 10,50\")\nprint()\n\nprint(f\"{root.data}, expected: 50\")\nprint(f\"{root.left.data}, expected: 10\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [10]\n    50 has a left-child25: going left\n    10 inserted left of c25\n\nt[25]&lt;-c[50]: go left...\nt[25]==c[25] found!\n10\n50\nNone, expected: 10,50\n\n50, expected: 50\n10, expected: 10"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-6",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-6",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.6 Scenario 6",
    "text": "8.6 Scenario 6\n\n# target has 1 left child\n# target_child has 2 children\nroot =TreeNode(50)\ninsert_node_list(root, [25,10,4,15])\n#         50 &lt;-------- parent_node \n#      [25]  &lt;-------- target or parent.left\n#    10      &lt;-------- targets_child (or target.left) replaces target via parent.left -&gt; target_child &lt;------ 1\n#   4 15      \ndelete_node(root,25)\n#          50 &lt;-------- parent_node &lt;--------------\n#    [10]    &lt;-------- target_child\n#  4    15\n\nprint(f\"{traverse(root)}, expected: 4,10,15,50\")\nprint()\n\nprint(f\"{root.data}, expected: 50\")\nprint(f\"{root.left.data}, expected: 10\")\nprint(f\"{root.left.left.data}, expected: 4\")\nprint(f\"{root.left.right.data}, expected: 15\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [10]\n    50 has a left-child25: going left\n    10 inserted left of c25\n\nAttempting to insert: [4]\n    50 has a left-child25: going left\n    25 has a left-child10: going left\n    4 inserted left of c10\n\nAttempting to insert: [15]\n    50 has a left-child25: going left\n    25 has a left-child10: going left\n    15 inserted right of c10\n\nt[25]&lt;-c[50]: go left...\nt[25]==c[25] found!\n4\n10\n15\n50\nNone, expected: 4,10,15,50\n\n50, expected: 50\n10, expected: 10\n4, expected: 4\n15, expected: 15"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-7",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-7",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.7 Scenario 7",
    "text": "8.7 Scenario 7\n\n# target has 1 right child\n# target_child has 2 children\nroot =TreeNode(50)\ninsert_node_list(root, [55,52,51,53])\n#   50        &lt;-------- parent_node \n#       [55]  &lt;-------- target or parent.left\n#      52     &lt;-------- targets_child (or target.left) replaces target via parent.left -&gt; target_child &lt;------ 1\n#    51  53      \ndelete_node(root,55)\n#   50       &lt;-------- parent_node \n#      [52]  &lt;-------- target_child becomes target\n#     51  53      \n\nprint(f\"{traverse(root)}, expected: 50,51,52,53\")\nprint()\n\nprint(f\"{root.data}, expected: 50\")\nprint(f\"{root.right.data}, expected: 52\")\nprint(f\"{root.right.left.data}, expected: 51\")\nprint(f\"{root.right.right.data}, expected: 53\")\n\nAttempting to insert: [55]\n    55 inserted right of c50\n\nAttempting to insert: [52]\n    50 has a right-child55: going left\n    52 inserted left of c55\n\nAttempting to insert: [51]\n    50 has a right-child55: going left\n    55 has a left-child52: going left\n    51 inserted left of c52\n\nAttempting to insert: [53]\n    50 has a right-child55: going left\n    55 has a left-child52: going left\n    53 inserted right of c52\n\nt[55]-&gt;c[50]: go right...\nt[55]==c[55] found!\n50\n51\n52\n53\nNone, expected: 50,51,52,53\n\n50, expected: 50\n52, expected: 52\n51, expected: 51\n53, expected: 53"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-8",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-8",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.8 Scenario 8",
    "text": "8.8 Scenario 8\n\nroot =TreeNode(50)\ninsert_node_list(root, [25,75])\n#             [50]x\n#      25           [75]s\ndelete_node(root,50)\n#             [50]x\n#      25           \nprint(f\"{traverse(root)}, expected: 25, 75\")\nprint()\n\nprint(f\"{root.data}, expected: 75\")\nprint(f\"{root.left.data}, expected: 25\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nt[50]==c[50] found!\n25\n75\nNone, expected: 25, 75\n\n75, expected: 75\n25, expected: 25"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-9",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-9",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.9 Scenario 9",
    "text": "8.9 Scenario 9\n\nroot =TreeNode(50)\ninsert_node_list(root, [25,75,89])\n#             [50]x\n#      25           [75]s\n#                        [89]c  \ndelete_node(root,50)\n#             [75]x\n#      25           [89]s\nprint(f\"{traverse(root)}, expected: 25, 75, 89\")\nprint()\nprint(f\"{root.data}, expected: 75\")\nprint(f\"{root.left.data}, expected: 25\")\nprint(f\"{root.right.data}, expected: 89\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [89]\n    50 has a right-child75: going left\n    89 inserted right of c75\n\nt[50]==c[50] found!\n25\n75\n89\nNone, expected: 25, 75, 89\n\n75, expected: 75\n25, expected: 25\n89, expected: 89"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-10",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-10",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.10 Scenario 10",
    "text": "8.10 Scenario 10\n\nroot =TreeNode(50)\ninsert_node_list(root, [25,75,70,89])\n#             [50]x\n#      25           [75]s\n#               [70]c  [89]c  \ndelete_node(root,50)\n#             [70]x\n#      25           [75]s\n#                      [89]c  \nprint()\nprint(f\"{traverse(root)}, expected: 25, 70, 75, 89\")\n\n\nprint()\nprint(f\"{root.data}, expected: 70\")\nprint(f\"{root.left.data}, expected: 25\")\nprint(f\"{root.right.data}, expected: 75\")\nprint(f\"{root.right.right.data}, expected: 89\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [70]\n    50 has a right-child75: going left\n    70 inserted left of c75\n\nAttempting to insert: [89]\n    50 has a right-child75: going left\n    89 inserted right of c75\n\nt[50]==c[50] found!\n\n25\n70\n75\n89\nNone, expected: 25, 70, 75, 89\n\n70, expected: 70\n25, expected: 25\n75, expected: 75\n89, expected: 89"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-11",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-11",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.11 Scenario 11",
    "text": "8.11 Scenario 11\n\nroot =TreeNode(50)\ninsert_node_list(root, [25,75,79,89,60])\n#             [50]x\n#      25           [75]s\n#                70c    89c  \n#             60\ndelete_node(root,50)\n#             [60]\n#      25           [75]s\n#                 70     [89]c  \nprint(f\"{traverse(root)}, expected: 25, 60, 70, 75, 89\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [79]\n    50 has a right-child75: going left\n    79 inserted right of c75\n\nAttempting to insert: [89]\n    50 has a right-child75: going left\n    75 has a right-child79: going left\n    89 inserted right of c79\n\nAttempting to insert: [60]\n    50 has a right-child75: going left\n    60 inserted left of c75\n\nt[50]==c[50] found!\n25\n60\n75\n79\n89\nNone, expected: 25, 60, 70, 75, 89"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-12",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-048-binary-search-trees-review.html#scenario-12",
    "title": "DSA 48: Binary Search Trees - Review",
    "section": "8.12 Scenario 12",
    "text": "8.12 Scenario 12\n\nroot =TreeNode(50)\ninsert_node_list(root, [25,75,79,89,60,65])\n#             [50]x\n#      25           [75]s\n#                70c    89c  \n#             60\n#               65\ndelete_node(root,50)\n#             [60]\n#      25           [75]s\n#                 70     [89]c  \n#               65\nprint(f\"{traverse(root)}, expected: 25, 60, 65, 70, 75, 89\")\n\nAttempting to insert: [25]\n    25 inserted left of c50\n\nAttempting to insert: [75]\n    75 inserted right of c50\n\nAttempting to insert: [79]\n    50 has a right-child75: going left\n    79 inserted right of c75\n\nAttempting to insert: [89]\n    50 has a right-child75: going left\n    75 has a right-child79: going left\n    89 inserted right of c79\n\nAttempting to insert: [60]\n    50 has a right-child75: going left\n    60 inserted left of c75\n\nAttempting to insert: [65]\n    50 has a right-child75: going left\n    75 has a left-child60: going left\n    65 inserted right of c60\n\nt[50]==c[50] found!\n25\n60\n65\n75\n79\n89\nNone, expected: 25, 60, 65, 70, 75, 89"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-010-insertion-sort-shift-and-insert.html#psuedo-code",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-010-insertion-sort-shift-and-insert.html#psuedo-code",
    "title": "DSA 10: Insertion Sort - Shift & Insert",
    "section": "1.1 Psuedo-Code",
    "text": "1.1 Psuedo-Code\nNot the greatest psuedo-code but it’lll do for now.\n\nOuter loop:\n\nfrom 1 to last index of array (or array size)\n\nFor each index r of outer loop:\n\nAllocate current-index arr[l] to temp-variable (temp-val): tmp\nwhile l&gt;0 and temp-value (tmp) to previous-value (l-1)\n\nIf temp-val &lt; prev-value: shift prev-val right by 1, then decrement l and go back to start of -loop\nIf temp-val &gt; prev-value:\n\nif: shifted previously, assign arr[l]=tmp\nelse: next r"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-010-insertion-sort-shift-and-insert.html#python-code",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-010-insertion-sort-shift-and-insert.html#python-code",
    "title": "DSA 10: Insertion Sort - Shift & Insert",
    "section": "1.2 Python-Code",
    "text": "1.2 Python-Code\n\nvals_to_list_fn = lambda vals: [int(val) for val in str(vals)]\n\ndef insert_sort_shift_and_insert(arr: list[int]):\n    print(arr)\n    for r in range(1,len(arr)):\n        shifted=False\n        l=r\n        tmp=arr[l]\n        print(f\"\\t{[r]}\")\n        while l&gt;0 and tmp&lt;arr[l-1]:\n            arr[l]=[] #uncessary - temporarily blank-out [l] - for visaul debugging-purposes\n            print(f\"(idx[{l-1}]={arr[l-1]}_vs_tmp={tmp}) COMPARE: {arr} | tmp={tmp}\")\n            arr[l]=arr[l-1] # shift-right 1\n            arr[l-1]=[] # uncessary - for visual debugging-purposes\n            print(f\"(idx[{l-1}]={arr[l-1]}_vs_tmp={tmp}) SHIFTD: {arr} | tmp={tmp}\")\n            shifted=True\n            l-=1\n        if shifted:\n            arr[l] = tmp \n            print(f\"(idx[{l})=tmp={tmp}) \\t     INSERT: {arr} | tmp={tmp}\")\n        else:\n            print(f\"SKIPPED: Already sorted from 0 to {r}: {arr[0:r+1]} of {arr}\")\n    print(arr)\n    return arr\n\n\nvals = 12354\narr = vals_to_list_fn(vals)\ninsert_sort_shift_and_insert(arr)\n\n[1, 2, 3, 5, 4]\n    [1]\nSKIPPED: Already sorted from 0 to 1: [1, 2] of [1, 2, 3, 5, 4]\n    [2]\nSKIPPED: Already sorted from 0 to 2: [1, 2, 3] of [1, 2, 3, 5, 4]\n    [3]\nSKIPPED: Already sorted from 0 to 3: [1, 2, 3, 5] of [1, 2, 3, 5, 4]\n    [4]\n(idx[3]=5_vs_tmp=4) COMPARE: [1, 2, 3, 5, []] | tmp=4\n(idx[3]=[]_vs_tmp=4) SHIFTD: [1, 2, 3, [], 5] | tmp=4\n(idx[3)=tmp=4)       INSERT: [1, 2, 3, 4, 5] | tmp=4\n[1, 2, 3, 4, 5]\n\n\n[1, 2, 3, 4, 5]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-037-nodes-exercises.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-037-nodes-exercises.html",
    "title": "DSA 37: Singly & Doubly Linked List - Exercises",
    "section": "",
    "text": "0. Setup Node, LinkedList & DoublyLinkedList Class\n\nfrom typing import Any\n\nclass NodeLL():\n    def __init__(self,data: Any|None=None):\n        self.data:          Any|None = data\n        self.next_node:     NodeLL|None = None\n\nclass NodeDLL():\n    def __init__(self,data: Any|None=None):\n        self.data:          Any|None = data\n        self.prev_node:     NodeDLL|None = None\n        self.prev_node:     NodeDLL|None = None\n\nclass LinkedList():\n    def __init__(self, first_node: NodeLL|None=None):\n        self.first_node:    NodeLL|None = first_node\n        \nclass DoublyLinkedList():\n    def __init__(self, first_node: NodeDLL|None=None,last_node: NodeDLL|None=None):\n        self.first_node:    NodeDLL|None = first_node\n        self.last_node:     NodeDLL|None = last_node\n\n\n# classic nodes setup\nnode0_ll=NodeLL(\"time\")\nnode1_ll=NodeLL(\"of\")\nnode2_ll=NodeLL(\"your\")\nnode3_ll=NodeLL(\"life\")\nnode0_ll.next_node=node1_ll\nnode1_ll.next_node=node2_ll\nnode2_ll.next_node=node3_ll\n\n\n# doubly nodes setup\nnode0_dll=NodeDLL(\"TIME\")\nnode1_dll=NodeDLL(\"OF\")\nnode2_dll=NodeDLL(\"YOUR\")\nnode3_dll=NodeDLL(\"LIFE\")\n\nnode0_dll.next_node=node1_dll\nnode1_dll.next_node=node2_dll\nnode2_dll.next_node=node3_dll\n\nnode1_dll.prev_node=node0_dll\nnode2_dll.prev_node=node1_dll\nnode3_dll.prev_node=node2_dll\n\n\n\n1. Add method: print_all to Classic LinkedList Class\n\ndef print_all_ll(linked_list: LinkedList)-&gt; None:\n    current_node = linked_list.first_node\n\n    # case 1: empty list: print empty list\n    if not current_node:\n        print(\"Empty LinkedList!\")\n        return None\n\n    # case 2: len(ll)==1: print ll[0] # captured in case 3\n    # if not current_node.next_node:\n    #     print(current_node.data)\n    #     return None\n\n    # case 3: n items \n    while current_node:\n        print(current_node.data)        # print node.data\n        current_node = current_node.next_node # go next node\n    return None\nprint_all_ll(LinkedList()) # empty list\nprint()\nprint_all_ll(LinkedList(NodeLL(\"single lonely node\"))) # empty list\nprint()\nprint_all_ll(LinkedList(node0_ll))\n\nprint()\n\nEmpty LinkedList!\n\nsingle lonely node\n\ntime\nof\nyour\nlife\n\n\n\n\n\n2a. Add method: print_all_reverse to ClassicLinkedList Class\n\n\ndef print_rev_all_ll(linked_list: LinkedList)-&gt; None:\n    current_node = linked_list.first_node\n    node_list = []\n    # case 1: empty list: print empty list\n    if not current_node:\n        print(\"Empty LinkedList!\")\n        return None\n    \n    # case n: n items \n    while current_node:\n        # print(current_node.data)        # print node.data\n        node_list.append(current_node.data)\n        current_node = current_node.next_node # go next node\n    \n    [print(node_list[i]) for i in range(len(node_list)-1,-1,-1)]\n    \n    return None\n\n# LL - REVERSE\nprint_rev_all_ll(LinkedList()) # empty list\nprint()\nprint_rev_all_ll(LinkedList(NodeLL(\"single lonely node\"))) # empty list\nprint()\nprint_rev_all_ll(LinkedList(node0_ll))\nprint()\n\n# eta: 9 mins\n# Comments: used [1.soln], create [node_list] and append each [node.data] then [reverse print]\n\nEmpty LinkedList!\n\nsingle lonely node\n\nlife\nyour\nof\ntime\n\n\n\n\n\n2b. Add method: print_all_reverse to DoublyLinkedList Class\n\ndef print_rev_all_dll(dbly_linked_list: DoublyLinkedList)-&gt; None:\n    current_node = dbly_linked_list.last_node\n\n    # case 1: empty list: print empty list\n    if not current_node:\n        print(\"Empty LinkedList!\")\n        return None\n\n    # case 3: n items \n    while current_node:\n        print(current_node.data)        # \"last\"\n        current_node = current_node.prev_node # go prev node\n    return None\n# DLL REVERSE\nprint_rev_all_dll(DoublyLinkedList()) # empty list\nprint()\nprint_rev_all_dll(DoublyLinkedList( # SINGLE NODE - DLL \n    first_node=NodeDLL(\"single lonely node\"),   # node is first_node\n    last_node=NodeDLL(\"single lonely node\")))    # and last_node\n\nprint()\nprint_rev_all_dll(DoublyLinkedList(\n    first_node=node0_dll, last_node=node3_dll))\nprint()\n\n# eta: 15 min \n# comments: \n# - found & fixed bug prev_node assignments, \n# - [2] update assn  current_node -&gt; prev_node and \n# - [12] while loop to update to current_node to prev_node\n\nEmpty LinkedList!\n\nsingle lonely node\n\nLIFE\nYOUR\nOF\nTIME\n\n\n\n\n\n3a. Add method: return_last_item to Classic LinkedList Class\n\nNumber of Elements: Unknown\n\n\n\ndef return_last_item_ll(linked_list: LinkedList)-&gt; None:\n    current_node = linked_list.first_node\n    # node_list = []\n    # case 1: empty list: print empty list\n    if not current_node:\n        print(\"Empty LinkedList!\")\n        return None\n    \n    # case n: n items \n    while current_node.next_node:\n        # print(current_node.data)        # print node.data\n        # node_list.append(current_node.data)\n        current_node = current_node.next_node # go next node\n    \n    # [print(node_list[i]) for i in range(len(node_list)-1,-1,-1)]\n    print(current_node.data)\n    # return current_node.data\n\n# LL - last item\nreturn_last_item_ll(LinkedList()) # empty list\nprint()\nreturn_last_item_ll(LinkedList(NodeLL(\"single lonely node\"))) # empty list\nprint()\nreturn_last_item_ll(LinkedList(node0_ll))\nprint()\n\n# eta: 3 mins\n# Comments: used [1.soln] [11] while current_next.next_node exist then not last and go next \n# [11/14] if c_node.next_node is falsy, its last node, leave while-loop.\n\nEmpty LinkedList!\n\nsingle lonely node\n\nlife\n\n\n\n\n\n3b. Add recursive method: return_last_item to Classic LinkedList Class\n\n# recursive attempt - 1\ndef return_last_item_ll_recursivefn(linked_list: LinkedList)-&gt; None:\n    current_node = linked_list.first_node\n    if not current_node:\n        print(\"Empty LinkedList!\")\n        return None\n    \n    if current_node.next_node:\n        current_node = current_node.next_node\n        current_linked_list = LinkedList(current_node) # start from next node\n        return return_last_item_ll_recursivefn(current_linked_list)\n    else:\n        print(current_node.data)\n        return current_node.data\n\n# 'time','of','your','life'\nreturn_last_item_ll_recursivefn(LinkedList()) # empty list\nprint()\nreturn_last_item_ll_recursivefn(LinkedList(NodeLL(\"single lonely node\")))\nprint()\nreturn_last_item_ll_recursivefn(LinkedList(node0_ll))\nprint()\n\n# eta: 20 mins\n# comments: had to remind myself how recursive functions work\n# [10] then thought of creating a new list each time current_node updates\n# bad but worked\n\nEmpty LinkedList!\n\nsingle lonely node\n\nlife\n\n\n\n\n\n3c. Add recursive method: return_last_item with Nodes\n\n# recursive attempt - 2\ndef return_last_item_nodes_recursivefn(current_node: NodeLL)-&gt; None:\n    # current_node = linked_list.first_node\n    if not current_node.data:\n        print(\"Empty Node!\")\n        return None\n    \n    if current_node.next_node:\n        current_node = current_node.next_node\n        # current_linked_list = LinkedList(current_node) # start from next node\n        return return_last_item_nodes_recursivefn(current_node)\n    else:\n        print(current_node.data)\n        return current_node.data\n\n# 'time','of','your','life'\nreturn_last_item_nodes_recursivefn(NodeLL()) # empty list\nprint()\nreturn_last_item_nodes_recursivefn((NodeLL(\"single lonely node\")))\nprint()\nreturn_last_item_nodes_recursivefn(node0_ll)\nprint()\n\n# eta: 2mins\n# comments: adapt first attempt and remove the creation of lists.\n\nEmpty Node!\n\nsingle lonely node\n\nlife\n\n\n\n\n[ignore] 3d. Re-wrote to help me attempt 3b and 3c\n\ndef max_val(arr):\n    if len(arr)==1:\n        return arr[0]\n    \n    if arr[0]&gt;max_val(arr[1:]):\n        return arr[0]\n    else:    \n        return max_val(arr[1:])\n    \narr=[1,7,3,5,9,4,8,3]    \nmax_val(arr)\n\n9\n\n\n\n\n\n4. Add method: reverse_linkedlist\n\noriginal list: A -&gt; B -&gt; C\n\nreversed list: C -&gt; B -&gt; A.\n\n\ndef reverse_ll(linked_list: LinkedList):\n    current_node = linked_list.first_node\n    previous_node = None\n    \n    if not current_node:\n        print(\"Empty Linked List!\")\n        \n    while current_node:\n        # A-&gt;B-&gt;C-&gt;\n        # 1. &lt;-A POINT A TO PREVIOUS NODE\n        # 1.  BUT CANT DO THAT YET, BECAUSE WONT HAVE ACCESS\n        #     TO NEXT NODE FOR ITERATION\n        # 1A. SO SAVE [NEXT_NODE], \n        # 1B. then CURR.NEXT IS [PREV]  &lt;-A \n        # 2.  update [PREV]\n        # 3.  update [CURR]  \n        next_node=current_node.next_node        # 1A.   B=A.NEXT\n        previous_node = current_node.next_node  # 1B.   A.NEXT=PREV\n        current_node = previous_node            # 2.    PREV = A   \n        current_node = next_node                # 3.    CURR = CURR.NEXT\n        \n    return linked_list\n\n# 'time','of','your','life'\nreverse_ll(LinkedList()) # empty list\nprint()\n\nll = LinkedList(NodeLL(\"single lonely node\"))\nreverse_ll(ll)\nprint_rev_all_ll(ll)\n\nprint()\nll = LinkedList(node0_ll)\nreverse_ll(ll)\nprint_rev_all_ll(ll)\nprint()\n\n#eta: 25m\n#comments: definitely helped writign it down step by step \n# rather than trying to do it all in my head, see the comments\n\nEmpty Linked List!\n\nsingle lonely node\n\nlife\nyour\nof\ntime\n\n\n\n\n\n5. Delete Current Node Puzzle\nList-Type:\n\nLinkedList Class\n\nScenario:\n\nYou have access to a node from somewhere in the middle of a classic linked list but not to the linked list itself;\nYou have a variable that points to an instance of Node, but you don’t have access to the LinkedList instance.\nWrite code that will effectively delete this node from the list.\nThe entire remaining list should remain complete, with only this node removed.\n\n\ndef delete_node_ll(current_node: NodeLL)-&gt;None:\n    # A -&gt; B -&gt; C -&gt; D\n    # Delete current_node: [B]\n    # A -&gt;   -&gt; C -&gt; D\n    # A -&gt; C -&gt; D\n        \n    # C.data into B.data\n    # D.data into C.data\n    # None into D.data\n    if not current_node.data:\n        print(\"Empty Node!\")\n        return None\n    \n    while current_node.next_node: # STOPS AT CN=D, LAST ENTERS CN=C\n        current_node.data = current_node.next_node.data #B, C,\n        # print(f\"NEW_CURRENT_DATA: {current_node.data}\")\n        current_node=current_node.next_node\n    current_node.data = None \n    # print(f\"NEW_CURRENT_DATA: {current_node.data}\")\n    return None\n\n# classic nodes setup\nnode0_ll=NodeLL(\"A\")\nnode1_ll=NodeLL(\"B\")\nnode2_ll=NodeLL(\"C\")\nnode3_ll=NodeLL(\"D\")\nnode0_ll.next_node=node1_ll\nnode1_ll.next_node=node2_ll\nnode2_ll.next_node=node3_ll\nll = LinkedList(node0_ll)\nprint(f\"Before Deleting 'B'\")\nprint_all_ll(ll)\ndelete_node_ll(node1_ll)\nprint()\nprint(f\"After Deleting 'B'\")\nprint_all_ll(ll)\n# print()\n# print()\n# ll = LinkedList(node0_ll)\n# reverse_ll(ll)\n# print_rev_all_ll(ll)\n# print()\n\nBefore Deleting 'B'\nA\nB\nC\nD\n\nAfter Deleting 'B'\nA\nC\nD\nNone"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#written-solution",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#written-solution",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.1 Written Solution",
    "text": "3.1 Written Solution\nWe can define:\n\nFor each step (chessboard square), it is incremented by one,\n\nplaced_grains is the number grains placed down on the square\n\nThis number doubles at each step.\n\nplaced_grains is calculated by an algorithm of \\(log\\ time\\) or \\(O(\\log{N})\\)\n\nIncreases one step each time the data doubles,\nand so equivalently,\nMove to next chessboard square, double placed grains\n\n\n\nIn other words:\n\n\\(O(\\log{N})\\) means that for N data elements, the algorithm would take \\(\\log_{2}{N}\\) steps."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#expected-results-placed-grains-table",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#expected-results-placed-grains-table",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.2 Expected Results: Placed Grains Table",
    "text": "3.2 Expected Results: Placed Grains Table\nTo find out:\n\nWhich chessboard square (step)\nContains 16 grains on the square (n_grains=16)\nDouble the number of grains placed (placed_grain) at each step until we reached the desired amount of grains (placed_grain==n_grains):\n\nchessboard square: 5 (step=5)\n\n\n\n\n\nstep\nplaced_grain\nn_grains\n\n\n\n\n1\n1\n16\n\n\n2\n2\n16\n\n\n3\n4\n16\n\n\n4\n8\n16\n\n\n5\n16\n16"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#python-for-loop-explainer",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#python-for-loop-explainer",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.3 Python for-loop explainer",
    "text": "3.3 Python for-loop explainer\nfor-loops are useful when:\n\nScenario: The range of iteration is known:\n\nor min and max of our iteration\nor start (arg 1) and stop (arg 2) indexes are known in advance\nboolean rule not required.\n\nThe loop will stop automatically when the limit is reached\n\n\nThe chessboard has \\(64\\) squares: the range would be:\n\nfrom 1 to 64\nNote: The loop counts up to but does not include the stop value\n\nrange(1,64): counts 1,2,..63, thus use\nrange(1,65): counts 1,2,..64"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#python-while-loop-explainer",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#python-while-loop-explainer",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.4 Python while-loop explainer",
    "text": "3.4 Python while-loop explainer\nwhile-loops are useful when:\n\nScenario: The range of iteration is unknown:\n\na min or start argument required\n\nmanual iteration required\n\nboolean rule is required.\n\nThe loop will exit when rule is not True or False anymore (i.e. goal has been reached)\nThe loop will continue forever unless the goal is reached\n\nNote: careful consideration to ensure the boolean test is reachable\n\n\n\nThe loop does not care how many squares the chessboard has (unless manually placed as a requirement)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#for-loop-solution",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#for-loop-solution",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.5 for-loop Solution",
    "text": "3.5 for-loop Solution\n\n### Answer 1: for-loop ###\nidx=1\nmax_squares = 64\nplaced_grains = 1\ntarget_grains = 16\nfor i in range(1,max_squares+1):\n    if placed_grains == target_grains:\n        print(idx)\n        break\n        # return idx\n    idx+=1\n    placed_grains=placed_grains*2\n# [1,2,3,4, 5, 6, 7]\n# [1,2,4,8,16,32,64]\n\n5"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#while-loop-solution",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-004-chessboard-grains.html#while-loop-solution",
    "title": "DSA 4: Big-O - Chessboard & Grains Problem",
    "section": "3.6 while-loop Solution",
    "text": "3.6 while-loop Solution\n\n### Answer 2: while-loop ###\nidx = 1\nplaced_grains = 1\ntarget_grains = 16\n\nwhile placed_grains&lt;target_grains:\n    idx+=1\n    placed_grains*=2\n\nprint(idx)\n\n5"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-020-recursion-part-1.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-020-recursion-part-1.html",
    "title": "DSA 20: Recursion [Part 1]",
    "section": "",
    "text": "1. Use while-loop: to Count-Down\n\ndef count_down_while(value):\n    if value&lt;0:\n        raise ValueError(f\"Value must be positive: {value}\")\n    while value &gt; 0:\n        print(f\"{value}...\")\n        value-=1\n    print(f\"{value}...Launch whilely 🚀\")\n\n\n\n1.1 Test-1: 5\n\ncount_down_while(5)\n\n5...\n4...\n3...\n2...\n1...\n0...Launch whilely 🚀\n\n\n\n\n1.2 Test-2: -5\n\ncount_down_while(-5)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 count_down_while(-5)\n\nCell In[18], line 3, in count_down_while(value)\n      1 def count_down_while(value):\n      2     if value&lt;0:\n----&gt; 3         raise ValueError(f\"Value must be positive: {value}\")\n      4     while value &gt; 0:\n      5         print(f\"{value}...\")\n\nValueError: Value must be positive: -5\n\n\n\n\n\n2. Use recursion: to Count-Down\n\ndef count_down_recursion(value):\n        if value&lt;0:\n            raise ValueError(f\"Value must be positive: {value}\")\n        elif value&gt;0: #5\n            print(f\"{value}...\")\n            count_down_recursion(value-1) #5-1\n        else:\n            print(f\"{value}...Launch recursively 🛰️!!!\")\n\n\n\n2.1 Test-1: 5\n\ncount_down_recursion(5)\n\n5...\n4...\n3...\n2...\n1...\n0...Launch recursively 🛰️!!!\n\n\n\n\n2.2 Test-2: -5\n\ncount_down_recursion(-5)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[23], line 1\n----&gt; 1 count_down_recursion(-5)\n\nCell In[21], line 3, in count_down_recursion(value)\n      1 def count_down_recursion(value):\n      2         if value&lt;0:\n----&gt; 3             raise ValueError(f\"Value must be positive: {value}\")\n      4         elif value&gt;0: #5\n      5             print(f\"{value}...\")\n\nValueError: Value must be positive: -5"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-030-quicksort-part-1.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-030-quicksort-part-1.html",
    "title": "DSA 30: Quicksort [Part 1]",
    "section": "",
    "text": "1. partition Function\n\ndef partition(arr, l, r):\n    p=r\n    pivot=arr[p]\n    r-=1\n\n    print(arr, l,r,pivot)\n    \n    while True:\n        while arr[l]&lt;pivot:\n            l+=1\n        while arr[r]&gt;pivot:\n            r-=1\n        if l&gt;=r:\n            break\n        else:\n            arr[l],arr[r]=arr[r],arr[l]    \n            l+=1\n    arr[l],arr[p]=arr[p],arr[l]    \n    print(arr)\n    return l\n\narr = [int(char) for char in \"052163\"]\n\npartition(arr,0,len(arr)-1)\n\n[0, 5, 2, 1, 6, 3] 0 4 3\n[0, 1, 2, 3, 6, 5]\n\n\n3\n\n\n\n\n2. quick_sort Function\n\nRecursive function\nIncludes partition function\n\n\ndef quick_sort(arr, l, r):\n    if r-l&lt;=0:\n        return \n    p = partition(arr, l,r)\n    quick_sort(arr, l, p-1)\n    quick_sort(arr, p+1, r)\n\n\narr = [int(char) for char in \"052163\"]\nquick_sort(arr,0,len(arr)-1)\n\n[0, 5, 2, 1, 6, 3] 0 4 3\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 0 1 2\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 0 0 1\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 4 4 5\n[0, 1, 2, 3, 5, 6]\n\n\n\n\n3. SortableArray Class with partition Instance Method\n\nInstance attribute: array\n\n\nclass SortableArray():\n    def __init__(self,array):\n        self.array=array\n        \n    def partition(self, l, r):\n        p=r\n        pivot=self.array[p]\n        r-=1\n\n        print(self.array, l,r,pivot)\n        \n        while True:\n            while self.array[l]&lt;pivot:\n                l+=1\n            while self.array[r]&gt;pivot:\n                r-=1\n            if l&gt;=r:\n                break\n            else:\n                self.array[l],self.array[r]=self.array[r],self.array[l]    \n                l+=1\n        self.array[l],self.array[p]=self.array[p],self.array[l]    \n        print(self.array)\n        return l\n\n\n\n3.1 Test: partition Instance Method\n\narr = [int(char) for char in \"052163\"]\nmy_array = SortableArray(arr)\nmy_array.array\nmy_array.partition(l=0,r=len(my_array.array)-1)\nmy_array.array\n\n[0, 5, 2, 1, 6, 3] 0 4 3\n[0, 1, 2, 3, 6, 5]\n\n\n[0, 1, 2, 3, 6, 5]\n\n\n\n\n4. SortableArray Class with quick_sort Instance Method\n\nclass SortableArray():\n    def __init__(self,array):\n        self.array=array\n        \n    def partition(self, l, r):\n        p=r\n        pivot=self.array[p]\n        r-=1\n\n        print(self.array, l,r,pivot)\n        \n        while True:\n            while self.array[l]&lt;pivot:\n                l+=1\n            while self.array[r]&gt;pivot:\n                r-=1\n            if l&gt;=r:\n                break\n            else:\n                self.array[l],self.array[r]=self.array[r],self.array[l]    \n                l+=1\n        self.array[l],self.array[p]=self.array[p],self.array[l]    \n        print(self.array)\n        return l\n\n    def quick_sort(self, l, r):\n        if r-l&lt;=0:\n            return \n        p = partition(self.array, l,r)\n        quick_sort(self.array, l, p-1)\n        quick_sort(self.array, p+1, r)\n\n\n\n4.1 Test: quick_sort Instance Method\n\narr = [int(char) for char in \"052163\"]\nmy_array = SortableArray(arr)\nmy_array.array\n# my_array.partition(l=0,r=len(my_array.array)-1)\nmy_array.quick_sort(l=0,r=len(my_array.array)-1)\nmy_array.array\n\n[0, 5, 2, 1, 6, 3] 0 4 3\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 0 1 2\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 0 0 1\n[0, 1, 2, 3, 6, 5]\n[0, 1, 2, 3, 6, 5] 4 4 5\n[0, 1, 2, 3, 5, 6]\n\n\n[0, 1, 2, 3, 5, 6]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-028-dp-part-1.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-028-dp-part-1.html",
    "title": "DSA 28: Dynamic Programming [Part 1]",
    "section": "",
    "text": "1. Max Value (No DP Technique)\n\ndef max_val(arr):\n    if len(arr)==1:\n        return arr[0]\n    if arr[0]&gt;max_val(arr[1:]):\n        return arr[0]\n    return max_val(arr[1:])\n\nmax_val([1,8,5,7,3,6])\n\n8\n\n\n\n\n1.1 Repeated Recursive Calls: with print()\nWithout any dynamic programming techniques, the function runs uncessarily slow:\n\nrepeated and unncessary calls to obtain calculated previously calculated max values:\n\nThese values were calculated used for the comparison then disregarded\n\nmax_val_no_dp(4) is called 14-times!\nTime-complexity: \\[O(2^n)\\]\n\n\ndef max_val_no_dp(arr):\n    print(f\"max_val_no_dp called on: {arr}\")\n    if len(arr)==1:\n        return arr[0]\n    if arr[0]&gt;max_val_no_dp(arr[1:]):\n        return arr[0]\n    return max_val_no_dp(arr[1:])\n\nmax_val_no_dp([1,2,3,4])\n\nmax_val_no_dp called on: [1, 2, 3, 4]\nmax_val_no_dp called on: [2, 3, 4]\nmax_val_no_dp called on: [3, 4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [3, 4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [2, 3, 4]\nmax_val_no_dp called on: [3, 4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [3, 4]\nmax_val_no_dp called on: [4]\nmax_val_no_dp called on: [4]\n\n\n4\n\n\n\n\n1.2 Repeated Recursive Calls: Chart\n\n\n\n2. Memoization\nBy setting the most recent call of max_val_memo to a variable max_val_remainder:\n\nThe function can recall previous max value at O(1)\nmax_val_memo(4) is called 4-times only\nAvoiding repeated and unncessary calls\nTime-complexity: \\[O(N)\\]\n\nThis is a variation of the Dynamic Programming technique called Memoization!\nBy using memoization, our time-complexity reduced from:\n\n\\(O(2^N)\\to O(N)\\)\n\nAmazing 🥂!\n\ndef max_val_memo(arr):\n    print(f\"max_val_memo called on: {arr}\")\n    if len(arr)==1:\n        return arr[0]\n    max_val_remainder = max_val_memo(arr[1:])\n    # if arr[0]&gt;max_val_memo(arr[1:]):\n    if arr[0]&gt;max_val_remainder:\n        return arr[0]\n    return max_val_remainder\n\nmax_val_memo([1,2,3,4])\n\nmax_val_memo called on: [1, 2, 3, 4]\nmax_val_memo called on: [2, 3, 4]\nmax_val_memo called on: [3, 4]\nmax_val_memo called on: [4]\n\n\n4"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#search-whole-list-of-arrays-n",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#search-whole-list-of-arrays-n",
    "title": "DSA 5: Big O - String Select Function",
    "section": "2.1 \\(Search()\\) whole list of arrays \\(N\\):",
    "text": "2.1 \\(Search()\\) whole list of arrays \\(N\\):\n\n\\(Search_{all-cases}\\): N steps\nor \\(O(N)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#compare_and_insert-test-string0-is-a-then-insert-into-new_array-if-true",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#compare_and_insert-test-string0-is-a-then-insert-into-new_array-if-true",
    "title": "DSA 5: Big O - String Select Function",
    "section": "2.2 \\(Compare\\_and\\_Insert()\\): \\(test\\) string[0] is a, then \\(Insert()\\) into new_array (if True)",
    "text": "2.2 \\(Compare\\_and\\_Insert()\\): \\(test\\) string[0] is a, then \\(Insert()\\) into new_array (if True)\n\n\\(Insert_{best-case}\\): 0 steps (e.g. zero insertions)\n\n\\(Insert_{worse-case}\\): N steps (e.g. insert every string in array)\n\nNote: \\(Big\\ O\\) always takes the \\(worse-case\\)\n\nThus, \\(O(N)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#big-o-total-steps-of-worse-case",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-005-string-selection.html#big-o-total-steps-of-worse-case",
    "title": "DSA 5: Big O - String Select Function",
    "section": "2.3 \\(Big\\ O\\) (Total Steps of Worse-Case)",
    "text": "2.3 \\(Big\\ O\\) (Total Steps of Worse-Case)\n\n\\(O(Search) + O(Compare\\_and\\_Insert)\\)\n\n\\(O(N) + O(N)\\)\n\n\\(O(2N)\\)\n\n\\(O(N)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-021-recursion-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-021-recursion-part-2.html",
    "title": "DSA 21: Recursion - With Base-Case [Part 2]",
    "section": "",
    "text": "1. while-Loop: Counting-Down\n\ndef countdown_while_fn(number):\n    while number&gt;0:\n        print(number)\n        number-=1\n    print(f\"{number}...launch whilely 🚀! \")\n\ncountdown_while_fn(5)    \n\n5\n4\n3\n2\n1\n0...launch whilely 🚀! \n\n\n\n\n2. Recursive Function 1: Counting-Down without Base-Case\nWithout a base-case, the function will run indefinitely.\n\ndef countdown_recursive_nobasecase_fn(number):\n    # no base case\n    print(number)\n    countdown_recursive_nobasecase_fn(number-1)\n    \ncountdown_recursive_nobasecase_fn(5)\n    \n\n5\n4\n3\n2\n1\n0\n-1\n-2\n-3\n-4\n-5\n-6\n-7\n-8\n-9\n-10\n-11\n-12\n-13\n-14\n-15\n-16\n-17\n-18\n-19\n-20\n-21\n-22\n-23\n-24\n-25\n-26\n-27\n-28\n-29\n-30\n-31\n-32\n-33\n-34\n-35\n-36\n-37\n-38\n-39\n-40\n-41\n-42\n-43\n-44\n-45\n-46\n-47\n-48\n-49\n-50\n-51\n-52\n-53\n-54\n-55\n-56\n-57\n-58\n-59\n-60\n-61\n-62\n-63\n-64\n-65\n-66\n-67\n-68\n-69\n-70\n-71\n-72\n-73\n-74\n-75\n-76\n-77\n-78\n-79\n-80\n-81\n-82\n-83\n-84\n-85\n-86\n-87\n-88\n-89\n-90\n-91\n-92\n-93\n-94\n-95\n-96\n-97\n-98\n-99\n-100\n-101\n-102\n-103\n-104\n-105\n-106\n-107\n-108\n-109\n-110\n-111\n-112\n-113\n-114\n-115\n-116\n-117\n-118\n-119\n-120\n-121\n-122\n-123\n-124\n-125\n-126\n-127\n-128\n-129\n-130\n-131\n-132\n-133\n-134\n-135\n-136\n-137\n-138\n-139\n-140\n-141\n-142\n-143\n-144\n-145\n-146\n-147\n-148\n-149\n-150\n-151\n-152\n-153\n-154\n-155\n-156\n-157\n-158\n-159\n-160\n-161\n-162\n-163\n-164\n-165\n-166\n-167\n-168\n-169\n-170\n-171\n-172\n-173\n-174\n-175\n-176\n-177\n-178\n-179\n-180\n-181\n-182\n-183\n-184\n-185\n-186\n-187\n-188\n-189\n-190\n-191\n-192\n-193\n-194\n-195\n-196\n-197\n-198\n-199\n-200\n-201\n-202\n-203\n-204\n-205\n-206\n-207\n-208\n-209\n-210\n-211\n-212\n-213\n-214\n-215\n-216\n-217\n-218\n-219\n-220\n-221\n-222\n-223\n-224\n-225\n-226\n-227\n-228\n-229\n-230\n-231\n-232\n-233\n-234\n-235\n-236\n-237\n-238\n-239\n-240\n-241\n-242\n-243\n-244\n-245\n-246\n-247\n-248\n-249\n-250\n-251\n-252\n-253\n-254\n-255\n-256\n-257\n-258\n-259\n-260\n-261\n-262\n-263\n-264\n-265\n-266\n-267\n-268\n-269\n-270\n-271\n-272\n-273\n-274\n-275\n-276\n-277\n-278\n-279\n-280\n-281\n-282\n-283\n-284\n-285\n-286\n-287\n-288\n-289\n-290\n-291\n-292\n-293\n-294\n-295\n-296\n-297\n-298\n-299\n-300\n-301\n-302\n-303\n-304\n-305\n-306\n-307\n-308\n-309\n-310\n-311\n-312\n-313\n-314\n-315\n-316\n-317\n-318\n-319\n-320\n-321\n-322\n-323\n-324\n-325\n-326\n-327\n-328\n-329\n-330\n-331\n-332\n-333\n-334\n-335\n-336\n-337\n-338\n-339\n-340\n-341\n-342\n-343\n-344\n-345\n-346\n-347\n-348\n-349\n-350\n-351\n-352\n-353\n-354\n-355\n-356\n-357\n-358\n-359\n-360\n-361\n-362\n-363\n-364\n-365\n-366\n-367\n-368\n-369\n-370\n-371\n-372\n-373\n-374\n-375\n-376\n-377\n-378\n-379\n-380\n-381\n-382\n-383\n-384\n-385\n-386\n-387\n-388\n-389\n-390\n-391\n-392\n-393\n-394\n-395\n-396\n-397\n-398\n-399\n-400\n-401\n-402\n-403\n-404\n-405\n-406\n-407\n-408\n-409\n-410\n-411\n-412\n-413\n-414\n-415\n-416\n-417\n-418\n-419\n-420\n-421\n-422\n-423\n-424\n-425\n-426\n-427\n-428\n-429\n-430\n-431\n-432\n-433\n-434\n-435\n-436\n-437\n-438\n-439\n-440\n-441\n-442\n-443\n-444\n-445\n-446\n-447\n-448\n-449\n-450\n-451\n-452\n-453\n-454\n-455\n-456\n-457\n-458\n-459\n-460\n-461\n-462\n-463\n-464\n-465\n-466\n-467\n-468\n-469\n-470\n-471\n-472\n-473\n-474\n-475\n-476\n-477\n-478\n-479\n-480\n-481\n-482\n-483\n-484\n-485\n-486\n-487\n-488\n-489\n-490\n-491\n-492\n-493\n-494\n-495\n-496\n-497\n-498\n-499\n-500\n-501\n-502\n-503\n-504\n-505\n-506\n-507\n-508\n-509\n-510\n-511\n-512\n-513\n-514\n-515\n-516\n-517\n-518\n-519\n-520\n-521\n-522\n-523\n-524\n-525\n-526\n-527\n-528\n-529\n-530\n-531\n-532\n-533\n-534\n-535\n-536\n-537\n-538\n-539\n-540\n-541\n-542\n-543\n-544\n-545\n-546\n-547\n-548\n-549\n-550\n-551\n-552\n-553\n-554\n-555\n-556\n-557\n-558\n-559\n-560\n-561\n-562\n-563\n-564\n-565\n-566\n-567\n-568\n-569\n-570\n-571\n-572\n-573\n-574\n-575\n-576\n-577\n-578\n-579\n-580\n-581\n-582\n-583\n-584\n-585\n-586\n-587\n-588\n-589\n-590\n-591\n-592\n-593\n-594\n-595\n-596\n-597\n-598\n-599\n-600\n-601\n-602\n-603\n-604\n-605\n-606\n-607\n-608\n-609\n-610\n-611\n-612\n-613\n-614\n-615\n-616\n-617\n-618\n-619\n-620\n-621\n-622\n-623\n-624\n-625\n-626\n-627\n-628\n-629\n-630\n-631\n-632\n-633\n-634\n-635\n-636\n-637\n-638\n-639\n-640\n-641\n-642\n-643\n-644\n-645\n-646\n-647\n-648\n-649\n-650\n-651\n-652\n-653\n-654\n-655\n-656\n-657\n-658\n-659\n-660\n-661\n-662\n-663\n-664\n-665\n-666\n-667\n-668\n-669\n-670\n-671\n-672\n-673\n-674\n-675\n-676\n-677\n-678\n-679\n-680\n-681\n-682\n-683\n-684\n-685\n-686\n-687\n-688\n-689\n-690\n-691\n-692\n-693\n-694\n-695\n-696\n-697\n-698\n-699\n-700\n-701\n-702\n-703\n-704\n-705\n-706\n-707\n-708\n-709\n-710\n-711\n-712\n-713\n-714\n-715\n-716\n-717\n-718\n-719\n-720\n-721\n-722\n-723\n-724\n-725\n-726\n-727\n-728\n-729\n-730\n-731\n-732\n-733\n-734\n-735\n-736\n-737\n-738\n-739\n-740\n-741\n-742\n-743\n-744\n-745\n-746\n-747\n-748\n-749\n-750\n-751\n-752\n-753\n-754\n-755\n-756\n-757\n-758\n-759\n-760\n-761\n-762\n-763\n-764\n-765\n-766\n-767\n-768\n-769\n-770\n-771\n-772\n-773\n-774\n-775\n-776\n-777\n-778\n-779\n-780\n-781\n-782\n-783\n-784\n-785\n-786\n-787\n-788\n-789\n-790\n-791\n-792\n-793\n-794\n-795\n-796\n-797\n-798\n-799\n-800\n-801\n-802\n-803\n-804\n-805\n-806\n-807\n-808\n-809\n-810\n-811\n-812\n-813\n-814\n-815\n-816\n-817\n-818\n-819\n-820\n-821\n-822\n-823\n-824\n-825\n-826\n-827\n-828\n-829\n-830\n-831\n-832\n-833\n-834\n-835\n-836\n-837\n-838\n-839\n-840\n-841\n-842\n-843\n-844\n-845\n-846\n-847\n-848\n-849\n-850\n-851\n-852\n-853\n-854\n-855\n-856\n-857\n-858\n-859\n-860\n-861\n-862\n-863\n-864\n-865\n-866\n-867\n-868\n-869\n-870\n-871\n-872\n-873\n-874\n-875\n-876\n-877\n-878\n-879\n-880\n-881\n-882\n-883\n-884\n-885\n-886\n-887\n-888\n-889\n-890\n-891\n-892\n-893\n-894\n-895\n-896\n-897\n-898\n-899\n-900\n-901\n-902\n-903\n-904\n-905\n-906\n-907\n-908\n-909\n-910\n-911\n-912\n-913\n-914\n-915\n-916\n-917\n-918\n-919\n-920\n-921\n-922\n-923\n-924\n-925\n-926\n-927\n-928\n-929\n-930\n-931\n-932\n-933\n-934\n-935\n-936\n-937\n-938\n-939\n-940\n-941\n-942\n-943\n-944\n-945\n-946\n-947\n-948\n-949\n-950\n-951\n-952\n-953\n-954\n-955\n-956\n-957\n-958\n-959\n-960\n-961\n-962\n-963\n-964\n-965\n-966\n-967\n-968\n-969\n-970\n-971\n-972\n-973\n-974\n-975\n-976\n-977\n-978\n-979\n-980\n-981\n-982\n-983\n-984\n-985\n-986\n-987\n-988\n-989\n-990\n-991\n-992\n-993\n-994\n-995\n-996\n-997\n-998\n-999\n-1000\n-1001\n-1002\n-1003\n-1004\n-1005\n-1006\n-1007\n-1008\n-1009\n-1010\n-1011\n-1012\n-1013\n-1014\n-1015\n-1016\n-1017\n-1018\n-1019\n-1020\n-1021\n-1022\n-1023\n-1024\n-1025\n-1026\n-1027\n-1028\n-1029\n-1030\n-1031\n-1032\n-1033\n-1034\n-1035\n-1036\n-1037\n-1038\n-1039\n-1040\n-1041\n-1042\n-1043\n-1044\n-1045\n-1046\n-1047\n-1048\n-1049\n-1050\n-1051\n-1052\n-1053\n-1054\n-1055\n-1056\n-1057\n-1058\n-1059\n-1060\n-1061\n-1062\n-1063\n-1064\n-1065\n-1066\n-1067\n-1068\n-1069\n-1070\n-1071\n-1072\n-1073\n-1074\n-1075\n-1076\n-1077\n-1078\n-1079\n-1080\n-1081\n-1082\n-1083\n-1084\n-1085\n-1086\n-1087\n-1088\n-1089\n-1090\n-1091\n-1092\n-1093\n-1094\n-1095\n-1096\n-1097\n-1098\n-1099\n-1100\n-1101\n-1102\n-1103\n-1104\n-1105\n-1106\n-1107\n-1108\n-1109\n-1110\n-1111\n-1112\n-1113\n-1114\n-1115\n-1116\n-1117\n-1118\n-1119\n-1120\n-1121\n-1122\n-1123\n-1124\n-1125\n-1126\n-1127\n-1128\n-1129\n-1130\n-1131\n-1132\n-1133\n-1134\n-1135\n-1136\n-1137\n-1138\n-1139\n-1140\n-1141\n-1142\n-1143\n-1144\n-1145\n-1146\n-1147\n-1148\n-1149\n-1150\n-1151\n-1152\n-1153\n-1154\n-1155\n-1156\n-1157\n-1158\n-1159\n-1160\n-1161\n-1162\n-1163\n-1164\n-1165\n-1166\n-1167\n-1168\n-1169\n-1170\n-1171\n-1172\n-1173\n-1174\n-1175\n-1176\n-1177\n-1178\n-1179\n-1180\n-1181\n-1182\n-1183\n-1184\n-1185\n-1186\n-1187\n-1188\n-1189\n-1190\n-1191\n-1192\n-1193\n-1194\n-1195\n-1196\n-1197\n-1198\n-1199\n-1200\n-1201\n-1202\n-1203\n-1204\n-1205\n-1206\n-1207\n-1208\n-1209\n-1210\n-1211\n-1212\n-1213\n-1214\n-1215\n-1216\n-1217\n-1218\n-1219\n-1220\n-1221\n-1222\n-1223\n-1224\n-1225\n-1226\n-1227\n-1228\n-1229\n-1230\n-1231\n-1232\n-1233\n-1234\n-1235\n-1236\n-1237\n-1238\n-1239\n-1240\n-1241\n-1242\n-1243\n-1244\n-1245\n-1246\n-1247\n-1248\n-1249\n-1250\n-1251\n-1252\n-1253\n-1254\n-1255\n-1256\n-1257\n-1258\n-1259\n-1260\n-1261\n-1262\n-1263\n-1264\n-1265\n-1266\n-1267\n-1268\n-1269\n-1270\n-1271\n-1272\n-1273\n-1274\n-1275\n-1276\n-1277\n-1278\n-1279\n-1280\n-1281\n-1282\n-1283\n-1284\n-1285\n-1286\n-1287\n-1288\n-1289\n-1290\n-1291\n-1292\n-1293\n-1294\n-1295\n-1296\n-1297\n-1298\n-1299\n-1300\n-1301\n-1302\n-1303\n-1304\n-1305\n-1306\n-1307\n-1308\n-1309\n-1310\n-1311\n-1312\n-1313\n-1314\n-1315\n-1316\n-1317\n-1318\n-1319\n-1320\n-1321\n-1322\n-1323\n-1324\n-1325\n-1326\n-1327\n-1328\n-1329\n-1330\n-1331\n-1332\n-1333\n-1334\n-1335\n-1336\n-1337\n-1338\n-1339\n-1340\n-1341\n-1342\n-1343\n-1344\n-1345\n-1346\n-1347\n-1348\n-1349\n-1350\n-1351\n-1352\n-1353\n-1354\n-1355\n-1356\n-1357\n-1358\n-1359\n-1360\n-1361\n-1362\n-1363\n-1364\n-1365\n-1366\n-1367\n-1368\n-1369\n-1370\n-1371\n-1372\n-1373\n-1374\n-1375\n-1376\n-1377\n-1378\n-1379\n-1380\n-1381\n-1382\n-1383\n-1384\n-1385\n-1386\n-1387\n-1388\n-1389\n-1390\n-1391\n-1392\n-1393\n-1394\n-1395\n-1396\n-1397\n-1398\n-1399\n-1400\n-1401\n-1402\n-1403\n-1404\n-1405\n-1406\n-1407\n-1408\n-1409\n-1410\n-1411\n-1412\n-1413\n-1414\n-1415\n-1416\n-1417\n-1418\n-1419\n-1420\n-1421\n-1422\n-1423\n-1424\n-1425\n-1426\n-1427\n-1428\n-1429\n-1430\n-1431\n-1432\n-1433\n-1434\n-1435\n-1436\n-1437\n-1438\n-1439\n-1440\n-1441\n-1442\n-1443\n-1444\n-1445\n-1446\n-1447\n-1448\n-1449\n-1450\n-1451\n-1452\n-1453\n-1454\n-1455\n-1456\n-1457\n-1458\n-1459\n-1460\n-1461\n-1462\n-1463\n-1464\n-1465\n-1466\n-1467\n-1468\n-1469\n-1470\n-1471\n-1472\n-1473\n-1474\n-1475\n-1476\n-1477\n-1478\n-1479\n-1480\n-1481\n-1482\n-1483\n-1484\n-1485\n-1486\n-1487\n-1488\n-1489\n-1490\n-1491\n-1492\n-1493\n-1494\n-1495\n-1496\n-1497\n-1498\n-1499\n-1500\n-1501\n-1502\n-1503\n-1504\n-1505\n-1506\n-1507\n-1508\n-1509\n-1510\n-1511\n-1512\n-1513\n-1514\n-1515\n-1516\n-1517\n-1518\n-1519\n-1520\n-1521\n-1522\n-1523\n-1524\n-1525\n-1526\n-1527\n-1528\n-1529\n-1530\n-1531\n-1532\n-1533\n-1534\n-1535\n-1536\n-1537\n-1538\n-1539\n-1540\n-1541\n-1542\n-1543\n-1544\n-1545\n-1546\n-1547\n-1548\n-1549\n-1550\n-1551\n-1552\n-1553\n-1554\n-1555\n-1556\n-1557\n-1558\n-1559\n-1560\n-1561\n-1562\n-1563\n-1564\n-1565\n-1566\n-1567\n-1568\n-1569\n-1570\n-1571\n-1572\n-1573\n-1574\n-1575\n-1576\n-1577\n-1578\n-1579\n-1580\n-1581\n-1582\n-1583\n-1584\n-1585\n-1586\n-1587\n-1588\n-1589\n-1590\n-1591\n-1592\n-1593\n-1594\n-1595\n-1596\n-1597\n-1598\n-1599\n-1600\n-1601\n-1602\n-1603\n-1604\n-1605\n-1606\n-1607\n-1608\n-1609\n-1610\n-1611\n-1612\n-1613\n-1614\n-1615\n-1616\n-1617\n-1618\n-1619\n-1620\n-1621\n-1622\n-1623\n-1624\n-1625\n-1626\n-1627\n-1628\n-1629\n-1630\n-1631\n-1632\n-1633\n-1634\n-1635\n-1636\n-1637\n-1638\n-1639\n-1640\n-1641\n-1642\n-1643\n-1644\n-1645\n-1646\n-1647\n-1648\n-1649\n-1650\n-1651\n-1652\n-1653\n-1654\n-1655\n-1656\n-1657\n-1658\n-1659\n-1660\n-1661\n-1662\n-1663\n-1664\n-1665\n-1666\n-1667\n-1668\n-1669\n-1670\n-1671\n-1672\n-1673\n-1674\n-1675\n-1676\n-1677\n-1678\n-1679\n-1680\n-1681\n-1682\n-1683\n-1684\n-1685\n-1686\n-1687\n-1688\n-1689\n-1690\n-1691\n-1692\n-1693\n-1694\n-1695\n-1696\n-1697\n-1698\n-1699\n-1700\n-1701\n-1702\n-1703\n-1704\n-1705\n-1706\n-1707\n-1708\n-1709\n-1710\n-1711\n-1712\n-1713\n-1714\n-1715\n-1716\n-1717\n-1718\n-1719\n-1720\n-1721\n-1722\n-1723\n-1724\n-1725\n-1726\n-1727\n-1728\n-1729\n-1730\n-1731\n-1732\n-1733\n-1734\n-1735\n-1736\n-1737\n-1738\n-1739\n-1740\n-1741\n-1742\n-1743\n-1744\n-1745\n-1746\n-1747\n-1748\n-1749\n-1750\n-1751\n-1752\n-1753\n-1754\n-1755\n-1756\n-1757\n-1758\n-1759\n-1760\n-1761\n-1762\n-1763\n-1764\n-1765\n-1766\n-1767\n-1768\n-1769\n-1770\n-1771\n-1772\n-1773\n-1774\n-1775\n-1776\n-1777\n-1778\n-1779\n-1780\n-1781\n-1782\n-1783\n-1784\n-1785\n-1786\n-1787\n-1788\n-1789\n-1790\n-1791\n-1792\n-1793\n-1794\n-1795\n-1796\n-1797\n-1798\n-1799\n-1800\n-1801\n-1802\n-1803\n-1804\n-1805\n-1806\n-1807\n-1808\n-1809\n-1810\n-1811\n-1812\n-1813\n-1814\n-1815\n-1816\n-1817\n-1818\n-1819\n-1820\n-1821\n-1822\n-1823\n-1824\n-1825\n-1826\n-1827\n-1828\n-1829\n-1830\n-1831\n-1832\n-1833\n-1834\n-1835\n-1836\n-1837\n-1838\n-1839\n-1840\n-1841\n-1842\n-1843\n-1844\n-1845\n-1846\n-1847\n-1848\n-1849\n-1850\n-1851\n-1852\n-1853\n-1854\n-1855\n-1856\n-1857\n-1858\n-1859\n-1860\n-1861\n-1862\n-1863\n-1864\n-1865\n-1866\n-1867\n-1868\n-1869\n-1870\n-1871\n-1872\n-1873\n-1874\n-1875\n-1876\n-1877\n-1878\n-1879\n-1880\n-1881\n-1882\n-1883\n-1884\n-1885\n-1886\n-1887\n-1888\n-1889\n-1890\n-1891\n-1892\n-1893\n-1894\n-1895\n-1896\n-1897\n-1898\n-1899\n-1900\n-1901\n-1902\n-1903\n-1904\n-1905\n-1906\n-1907\n-1908\n-1909\n-1910\n-1911\n-1912\n-1913\n-1914\n-1915\n-1916\n-1917\n-1918\n-1919\n-1920\n-1921\n-1922\n-1923\n-1924\n-1925\n-1926\n-1927\n-1928\n-1929\n-1930\n-1931\n-1932\n-1933\n-1934\n-1935\n-1936\n-1937\n-1938\n-1939\n-1940\n-1941\n-1942\n-1943\n-1944\n-1945\n-1946\n-1947\n-1948\n-1949\n-1950\n-1951\n-1952\n-1953\n-1954\n-1955\n-1956\n-1957\n-1958\n-1959\n-1960\n-1961\n-1962\n-1963\n-1964\n-1965\n-1966\n-1967\n-1968\n-1969\n-1970\n-1971\n-1972\n-1973\n-1974\n-1975\n-1976\n-1977\n-1978\n-1979\n-1980\n-1981\n-1982\n-1983\n-1984\n-1985\n-1986\n-1987\n-1988\n-1989\n-1990\n-1991\n-1992\n-1993\n-1994\n-1995\n-1996\n-1997\n-1998\n-1999\n-2000\n-2001\n-2002\n-2003\n-2004\n-2005\n-2006\n-2007\n-2008\n-2009\n-2010\n-2011\n-2012\n-2013\n-2014\n-2015\n-2016\n-2017\n-2018\n-2019\n-2020\n-2021\n-2022\n-2023\n-2024\n-2025\n-2026\n-2027\n-2028\n-2029\n-2030\n-2031\n-2032\n-2033\n-2034\n-2035\n-2036\n-2037\n-2038\n-2039\n-2040\n-2041\n-2042\n-2043\n-2044\n-2045\n-2046\n-2047\n-2048\n-2049\n-2050\n-2051\n-2052\n-2053\n-2054\n-2055\n-2056\n-2057\n-2058\n-2059\n-2060\n-2061\n-2062\n-2063\n-2064\n-2065\n-2066\n-2067\n-2068\n-2069\n-2070\n-2071\n-2072\n-2073\n-2074\n-2075\n-2076\n-2077\n-2078\n-2079\n-2080\n-2081\n-2082\n-2083\n-2084\n-2085\n-2086\n-2087\n-2088\n-2089\n-2090\n-2091\n-2092\n-2093\n-2094\n-2095\n-2096\n-2097\n-2098\n-2099\n-2100\n-2101\n-2102\n-2103\n-2104\n-2105\n-2106\n-2107\n-2108\n-2109\n-2110\n-2111\n-2112\n-2113\n-2114\n-2115\n-2116\n-2117\n-2118\n-2119\n-2120\n-2121\n-2122\n-2123\n-2124\n-2125\n-2126\n-2127\n-2128\n-2129\n-2130\n-2131\n-2132\n-2133\n-2134\n-2135\n-2136\n-2137\n-2138\n-2139\n-2140\n-2141\n-2142\n-2143\n-2144\n-2145\n-2146\n-2147\n-2148\n-2149\n-2150\n-2151\n-2152\n-2153\n-2154\n-2155\n-2156\n-2157\n-2158\n-2159\n-2160\n-2161\n-2162\n-2163\n-2164\n-2165\n-2166\n-2167\n-2168\n-2169\n-2170\n-2171\n-2172\n-2173\n-2174\n-2175\n-2176\n-2177\n-2178\n-2179\n-2180\n-2181\n-2182\n-2183\n-2184\n-2185\n-2186\n-2187\n-2188\n-2189\n-2190\n-2191\n-2192\n-2193\n-2194\n-2195\n-2196\n-2197\n-2198\n-2199\n-2200\n-2201\n-2202\n-2203\n-2204\n-2205\n-2206\n-2207\n-2208\n-2209\n-2210\n-2211\n-2212\n-2213\n-2214\n-2215\n-2216\n-2217\n-2218\n-2219\n-2220\n-2221\n-2222\n-2223\n-2224\n-2225\n-2226\n-2227\n-2228\n-2229\n-2230\n-2231\n-2232\n-2233\n-2234\n-2235\n-2236\n-2237\n-2238\n-2239\n-2240\n-2241\n-2242\n-2243\n-2244\n-2245\n-2246\n-2247\n-2248\n-2249\n-2250\n-2251\n-2252\n-2253\n-2254\n-2255\n-2256\n-2257\n-2258\n-2259\n-2260\n-2261\n-2262\n-2263\n-2264\n-2265\n-2266\n-2267\n-2268\n-2269\n-2270\n-2271\n-2272\n-2273\n-2274\n-2275\n-2276\n-2277\n-2278\n-2279\n-2280\n-2281\n-2282\n-2283\n-2284\n-2285\n-2286\n-2287\n-2288\n-2289\n-2290\n-2291\n-2292\n-2293\n-2294\n-2295\n-2296\n-2297\n-2298\n-2299\n-2300\n-2301\n-2302\n-2303\n-2304\n-2305\n-2306\n-2307\n-2308\n-2309\n-2310\n-2311\n-2312\n-2313\n-2314\n-2315\n-2316\n-2317\n-2318\n-2319\n-2320\n-2321\n-2322\n-2323\n-2324\n-2325\n-2326\n-2327\n-2328\n-2329\n-2330\n-2331\n-2332\n-2333\n-2334\n-2335\n-2336\n-2337\n-2338\n-2339\n-2340\n-2341\n-2342\n-2343\n-2344\n-2345\n-2346\n-2347\n-2348\n-2349\n-2350\n-2351\n-2352\n-2353\n-2354\n-2355\n-2356\n-2357\n-2358\n-2359\n-2360\n-2361\n-2362\n-2363\n-2364\n-2365\n-2366\n-2367\n-2368\n-2369\n-2370\n-2371\n-2372\n-2373\n-2374\n-2375\n-2376\n-2377\n-2378\n-2379\n-2380\n-2381\n-2382\n-2383\n-2384\n-2385\n-2386\n-2387\n-2388\n-2389\n-2390\n-2391\n-2392\n-2393\n-2394\n-2395\n-2396\n-2397\n-2398\n-2399\n-2400\n-2401\n-2402\n-2403\n-2404\n-2405\n-2406\n-2407\n-2408\n-2409\n-2410\n-2411\n-2412\n-2413\n-2414\n-2415\n-2416\n-2417\n-2418\n-2419\n-2420\n-2421\n-2422\n-2423\n-2424\n-2425\n-2426\n-2427\n-2428\n-2429\n-2430\n-2431\n-2432\n-2433\n-2434\n-2435\n-2436\n-2437\n-2438\n-2439\n-2440\n-2441\n-2442\n-2443\n-2444\n-2445\n-2446\n-2447\n-2448\n-2449\n-2450\n-2451\n-2452\n-2453\n-2454\n-2455\n-2456\n-2457\n-2458\n-2459\n-2460\n-2461\n-2462\n-2463\n-2464\n-2465\n-2466\n-2467\n-2468\n-2469\n-2470\n-2471\n-2472\n-2473\n-2474\n-2475\n-2476\n-2477\n-2478\n-2479\n-2480\n-2481\n-2482\n-2483\n-2484\n-2485\n-2486\n-2487\n-2488\n-2489\n-2490\n-2491\n-2492\n-2493\n-2494\n-2495\n-2496\n-2497\n-2498\n-2499\n-2500\n-2501\n-2502\n-2503\n-2504\n-2505\n-2506\n-2507\n-2508\n-2509\n-2510\n-2511\n-2512\n-2513\n-2514\n-2515\n-2516\n-2517\n-2518\n-2519\n-2520\n-2521\n-2522\n-2523\n-2524\n-2525\n-2526\n-2527\n-2528\n-2529\n-2530\n-2531\n-2532\n-2533\n-2534\n-2535\n-2536\n-2537\n-2538\n-2539\n-2540\n-2541\n-2542\n-2543\n-2544\n-2545\n-2546\n-2547\n-2548\n-2549\n-2550\n-2551\n-2552\n-2553\n-2554\n-2555\n-2556\n-2557\n-2558\n-2559\n-2560\n-2561\n-2562\n-2563\n-2564\n-2565\n-2566\n-2567\n-2568\n-2569\n-2570\n-2571\n-2572\n-2573\n-2574\n-2575\n-2576\n-2577\n-2578\n-2579\n-2580\n-2581\n-2582\n-2583\n-2584\n-2585\n-2586\n-2587\n-2588\n-2589\n-2590\n-2591\n-2592\n-2593\n-2594\n-2595\n-2596\n-2597\n-2598\n-2599\n-2600\n-2601\n-2602\n-2603\n-2604\n-2605\n-2606\n-2607\n-2608\n-2609\n-2610\n-2611\n-2612\n-2613\n-2614\n-2615\n-2616\n-2617\n-2618\n-2619\n-2620\n-2621\n-2622\n-2623\n-2624\n-2625\n-2626\n-2627\n-2628\n-2629\n-2630\n-2631\n-2632\n-2633\n-2634\n-2635\n-2636\n-2637\n-2638\n-2639\n-2640\n-2641\n-2642\n-2643\n-2644\n-2645\n-2646\n-2647\n-2648\n-2649\n-2650\n-2651\n-2652\n-2653\n-2654\n-2655\n-2656\n-2657\n-2658\n-2659\n-2660\n-2661\n-2662\n-2663\n-2664\n-2665\n-2666\n-2667\n-2668\n-2669\n-2670\n-2671\n-2672\n-2673\n-2674\n-2675\n-2676\n-2677\n-2678\n-2679\n-2680\n-2681\n-2682\n-2683\n-2684\n-2685\n-2686\n-2687\n-2688\n-2689\n-2690\n-2691\n-2692\n-2693\n-2694\n-2695\n-2696\n-2697\n-2698\n-2699\n-2700\n-2701\n-2702\n-2703\n-2704\n-2705\n-2706\n-2707\n-2708\n-2709\n-2710\n-2711\n-2712\n-2713\n-2714\n-2715\n-2716\n-2717\n-2718\n-2719\n-2720\n-2721\n-2722\n-2723\n-2724\n-2725\n-2726\n-2727\n-2728\n-2729\n-2730\n-2731\n-2732\n-2733\n-2734\n-2735\n-2736\n-2737\n-2738\n-2739\n-2740\n-2741\n-2742\n-2743\n-2744\n-2745\n-2746\n-2747\n-2748\n-2749\n-2750\n-2751\n-2752\n-2753\n-2754\n-2755\n-2756\n-2757\n-2758\n-2759\n-2760\n-2761\n-2762\n-2763\n-2764\n-2765\n-2766\n-2767\n-2768\n-2769\n-2770\n-2771\n-2772\n-2773\n-2774\n-2775\n-2776\n-2777\n-2778\n-2779\n-2780\n-2781\n-2782\n-2783\n-2784\n-2785\n-2786\n-2787\n-2788\n-2789\n-2790\n-2791\n-2792\n-2793\n-2794\n-2795\n-2796\n-2797\n-2798\n-2799\n-2800\n-2801\n-2802\n-2803\n-2804\n-2805\n-2806\n-2807\n-2808\n-2809\n-2810\n-2811\n-2812\n-2813\n-2814\n-2815\n-2816\n-2817\n-2818\n-2819\n-2820\n-2821\n-2822\n-2823\n-2824\n-2825\n-2826\n-2827\n-2828\n-2829\n-2830\n-2831\n-2832\n-2833\n-2834\n-2835\n-2836\n-2837\n-2838\n-2839\n-2840\n-2841\n-2842\n-2843\n-2844\n-2845\n-2846\n-2847\n-2848\n-2849\n-2850\n-2851\n-2852\n-2853\n-2854\n-2855\n-2856\n-2857\n-2858\n-2859\n-2860\n-2861\n-2862\n-2863\n-2864\n-2865\n-2866\n-2867\n-2868\n-2869\n-2870\n-2871\n-2872\n-2873\n-2874\n-2875\n-2876\n-2877\n-2878\n-2879\n-2880\n-2881\n-2882\n-2883\n-2884\n-2885\n-2886\n-2887\n-2888\n-2889\n-2890\n-2891\n-2892\n-2893\n-2894\n-2895\n-2896\n-2897\n-2898\n-2899\n-2900\n-2901\n-2902\n-2903\n-2904\n-2905\n-2906\n-2907\n-2908\n-2909\n-2910\n-2911\n-2912\n-2913\n-2914\n-2915\n-2916\n-2917\n-2918\n-2919\n-2920\n-2921\n-2922\n-2923\n-2924\n-2925\n-2926\n-2927\n-2928\n-2929\n-2930\n-2931\n-2932\n-2933\n-2934\n-2935\n-2936\n-2937\n-2938\n-2939\n-2940\n-2941\n-2942\n-2943\n-2944\n-2945\n-2946\n-2947\n-2948\n-2949\n-2950\n-2951\n-2952\n-2953\n-2954\n-2955\n-2956\n-2957\n-2958\n-2959\n-2960\n-2961\n-2962\n\n\n\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[2], line 6\n      3     print(number)\n      4     countdown_recursive_nobasecase_fn(number-1)\n----&gt; 6 countdown_recursive_nobasecase_fn(5)\n\nCell In[2], line 4, in countdown_recursive_nobasecase_fn(number)\n      1 def countdown_recursive_nobasecase_fn(number):\n      2     # no base case\n      3     print(number)\n----&gt; 4     countdown_recursive_nobasecase_fn(number-1)\n\nCell In[2], line 4, in countdown_recursive_nobasecase_fn(number)\n      1 def countdown_recursive_nobasecase_fn(number):\n      2     # no base case\n      3     print(number)\n----&gt; 4     countdown_recursive_nobasecase_fn(number-1)\n\n    [... skipping similar frames: countdown_recursive_nobasecase_fn at line 4 (2965 times)]\n\nCell In[2], line 4, in countdown_recursive_nobasecase_fn(number)\n      1 def countdown_recursive_nobasecase_fn(number):\n      2     # no base case\n      3     print(number)\n----&gt; 4     countdown_recursive_nobasecase_fn(number-1)\n\nCell In[2], line 3, in countdown_recursive_nobasecase_fn(number)\n      1 def countdown_recursive_nobasecase_fn(number):\n      2     # no base case\n----&gt; 3     print(number)\n      4     countdown_recursive_nobasecase_fn(number-1)\n\nFile ~/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/ipykernel/iostream.py:664, in OutStream.write(self, string)\n    655 def write(self, string: str) -&gt; Optional[int]:  # type:ignore[override]\n    656     \"\"\"Write to current stream after encoding if necessary\n    657 \n    658     Returns\n   (...)\n    662 \n    663     \"\"\"\n--&gt; 664     parent = self.parent_header\n    666     if not isinstance(string, str):\n    667         msg = f\"write() argument must be str, not {type(string)}\"  # type:ignore[unreachable]\n\nFile ~/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/ipykernel/iostream.py:509, in OutStream.parent_header(self)\n    505 @property\n    506 def parent_header(self):\n    507     try:\n    508         # asyncio-specific\n--&gt; 509         return self._parent_header.get()\n    510     except LookupError:\n    511         try:\n    512             # thread-specific\n\nRecursionError: maximum recursion depth exceeded while calling a Python object\n\n\n\n\n\n3. Recursive Function 2: Counting-Down with Base-Case\nWith a proper base-case, the function will stop appropriately.\n\ndef countdown_recursive_w_basecase_fn(number):\n    if number == 0: # base-case\n        print(f\"{number}....launch ☄️☄️☄️!\")\n        return \n    else:\n        print(number)\n        countdown_recursive_w_basecase_fn(number-1)\n\ncountdown_recursive_w_basecase_fn(5)\n\n5\n4\n3\n2\n1\n0....launch ☄️☄️☄️!"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-051-heaps-part-1.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-051-heaps-part-1.html",
    "title": "DSA 51: Array-Based Heaps [Part 1]",
    "section": "",
    "text": "1. Array-Based Heap\n\nclass Heaps:\n    def __init__(self):\n        self.data = []\n    \n    def root_node(self):\n        return self.data[0]\n\n    def last_node(self):\n        return self.data[-1]\n\n\n\n2. Traversing an Array-Based Heap\n\n\n2.1 Child of Any Node\nTo find the child of any node in an array-based heap, the following formula is always True:\nleft_child:\n\n(index*2)+1\n\nright_child:\n\n(index*2)+2\n\n\n\n2.2 Child of Any Node: Code\n\ndef left_child_index(self, index):\n    return (index*2)+1\n\ndef right_child_index(self, index):\n    return (index*2)+2\n\n\n\n2.3 Parent of Any Node\nAny node’s parent:\n\n(index-1)//2 (Note // is floor division)\n\n\ndef parent_index(self, index):\n    return (index-1)//2\n\n\n\n3. Insertion\n\ndef insert(self, value):\n    self.data.append(value)\n    new_node_index = len(self.data)-1\n    \n    while(new_node_index&gt;0 and \n          (self.data[new_node_index] &gt; self.data[self.parent_index(new_node_index)])):\n        parent_index = self.parent_index(new_node_index)\n        self.data[parent_index], self.data[new_node_index] = self.data[new_node_index], self.data[parent_index]\n        \n        new_node_index=parent_index"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-006-bin-search-practice.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-006-bin-search-practice.html",
    "title": "DSA 6: Binary Search Practice",
    "section": "",
    "text": "1. Odd Array-Size [11,22,33,44,55,66,77]\n\narr = [11,22,33,44,55,66,77]\n# [1 ]: l  .  t  m  .  .  r\n# [2 ]: l  m  tr x  x  x  x\n# [3 ]: x  x  ltr x  x  x  x\ntarget = 33\nl, r = 0, len(arr)-1  # r=6\nctr=0\nfound=False\nwhile l&lt;=r:\n    ctr+=1\n    print(f\"[step {ctr}]: {arr[l:r+1]}\")\n    m=(l+r)//2\n    if target == arr[m]:\n        found=True\n        print(f\"Target:[{target}] found, index:[{m}] in {ctr} steps!\")\n        break\n    elif target&gt;arr[m]:\n        l=m+1\n    elif target&lt;arr[m]:\n        r=m-1\nif not found:\n    print(f\"Target:[{target}] not found in {ctr} steps!\")\n    \n\n[step 1]: [11, 22, 33, 44, 55, 66, 77]\n[step 2]: [11, 22, 33]\n[step 3]: [33]\nTarget:[33] found, index:[2] in 3 steps!\n\n\n\n\n2. Even Array-Size [11,22,33,44,55,66,77,88]\n\narr = [11,22,33,44,55,66,77,88]\ntarget = 33\nl,r = 0, len(arr)-1\n\n# [0 ]  l  .  t   .  .  .  .  r\n# [1a]  l  .  t   m  .  .  .  r\n# [1b]  l  .  trm x  x  x  x  x\n# [2a]  l  m  tr  x  x  x  x  x\n# [2b]  l  m  ltr x  x  x  x  x\n# [3 ]  x  x  ltr x  x  x  x  x\nfound=False\nctr = 0\nwhile l&lt;=r:\n    ctr+=1\n    print(f\"[{ctr}] Searching array: {arr[l:r+1]}, steps:[{ctr}]\")\n    m=(l+r)//2\n    if target == arr[m]:\n        found=True\n        print(f\"{target} found: index[{m}] in {ctr} steps\")\n        break\n    elif target &lt; arr[m]:\n        r=m-1\n    elif target &gt; arr[m]:\n        l=m+1\nif not target:\n    print(f\"{target} not found: index[{m}] in {ctr} steps\")\n\n[1] Searching array: [11, 22, 33, 44, 55, 66, 77, 88], steps:[1]\n[2] Searching array: [11, 22, 33], steps:[2]\n[3] Searching array: [33], steps:[3]\n33 found: index[2] in 3 steps\n\n\n\n\n3. Binary Search Function\n\nfrom typing import List\ndef binary_search_01(arr: List[int], target: int):\n    ctr = 0\n    l,r = 0, len(arr)-1\n    \n    while l &lt;= r:\n        print(f\"Searching array: {arr[l:r+1]}\")\n        m = (l + r) // 2\n        ctr+=1\n        if target == arr[m]:\n            print(f\"{target} found on index [{m}] in {ctr} steps\")\n            return True\n        elif target &gt; arr[m]:\n            l=m+1\n        elif target &lt; arr[m]:\n            r=m-1\n\n    print(f\"{target} not found in {ctr} steps\")\n    return False\n\n\n# arr = [11,22,33,44,55,66,77,88]\n# [1 ]: m44 l55  66  77  r88\n# [2a]:     l55 m66  77  r88\n# [2b]:         m66 l77  r88\n# [3a]:             l77m r88\nbinary_search_01([11,22,33,44,55,66,77,88],77)\n\nSearching array: [11, 22, 33, 44, 55, 66, 77, 88]\nSearching array: [55, 66, 77, 88]\nSearching array: [77, 88]\n77 found on index [6] in 3 steps\n\n\nTrue"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-007-bubble-sort-practice.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-007-bubble-sort-practice.html",
    "title": "DSA 7: \\(BubbleSort()\\) Practice",
    "section": "",
    "text": "1. \\(BubbleSort()\\) Function (with n_total_steps counter)\n\ndef bubble_sort(arr):\n    # print(f\"Imported array: {arr}\")\n    last_idx_unsorted = len(arr)-1\n    sorted = False\n    ctr_compare, ctr_swap = 0,0\n    while not sorted:\n        sorted = True\n        # print(f\"Sorting array: {arr[0:last_idx_unsorted+1]}\")\n        for i in range(last_idx_unsorted):\n            ctr_compare+=1\n            if arr[i]&gt;arr[i+1]:\n                arr[i],arr[i+1]=arr[i+1],arr[i]\n                ctr_swap+=1\n                sorted = False\n        last_idx_unsorted-=1\n    n_total_steps = ctr_compare+ctr_swap\n    # print(f\"sorted_array: {arr}, nsteps: {n_total_steps}\")\n    return None, n_total_steps\n    # return arr, n_total_steps\n# arr = [5,4,3,2,1] \n# bubble_sort(arr)\n\n\n\n2. Chart (very inefficient data creation)\n\nsize_param=10\narr_tbl = [None]*size_param\nto_val = 5\n\nfor i in range(size_param):\n    arr = list(range(to_val,0,-1))\n    print(f\"arr_size: {len(arr)}\")\n    _, nsteps = bubble_sort(arr)\n    arr_size = len(arr)\n    arr_tbl[i]=[arr_size,nsteps]\n    to_val=2*to_val\nxs = []\nys = []\n\narr_size: 5\narr_size: 10\narr_size: 20\narr_size: 40\narr_size: 80\narr_size: 160\narr_size: 320\narr_size: 640\narr_size: 1280\narr_size: 2560\n\n\n\nfor i,v in enumerate(arr_tbl):\n    xs.append(v[0])\n    ys.append(v[1])    \nprint(xs)\nprint(ys)    \n\n[5, 10, 20, 40, 80, 160, 320, 640, 1280, 2560]\n[20, 90, 380, 1560, 6320, 25440, 102080, 408960, 1637120, 6551040]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplot_title = rf\"Bubble Sort Time Complexity $O(N^2)$\"\nlbl_plt = rf\"$O(N^2)$\"\nplt.plot(xs, ys,  'ro-', linewidth=2, markersize=6, label=lbl_plt)\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(plot_title, loc='left')\nplt.legend(loc='lower right')"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-029-dp-part-2.html#fib",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-029-dp-part-2.html#fib",
    "title": "DSA 29: Dynamic Programming - Exercises [Part 2]",
    "section": "2.1.1 fib()",
    "text": "2.1.1 fib()\n\ndef fib(n, memo={}):\n    if n==1 or n==0:\n        return 1\n    \n    if n not in memo:\n        memo[n] = fib(n-2) + fib(n-1)\n    \n    return memo[n] \n\nfib(7)\n\n21"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-034-nodes-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-034-nodes-part-2.html",
    "title": "DSA 34: LinkedList - Read & Search [Part 2]",
    "section": "",
    "text": "1. Node and LinkedList\nIntroduced previously.\n\nclass Node():\n    def __init__(self, data):\n        self.data=data\n        self.next_node=None\n        \nnode0=Node(\"I\")\nnode1=Node(\"heard\")\nnode2=Node(\"there\")\nnode3=Node(\"was\")\n\nnode0.next_node=node1\nnode1.next_node=node2\nnode2.next_node=node3\n\nclass LinkedList():\n    def __init__(self, first_node: Node):\n        self.first_node=first_node\n\n\nll = LinkedList(first_node=node0)\n\n\n\n2. Type-Annotations\nI started using Type-Annotations (E.g. linked_list: LinkedList) in my function arguments:\n\nbecause when I typed something like current_node. (an instance with a . attribute-accessor), then,\nI will be presented with current_node’s attributes to choose from in Visual Studio Code (VSC).\nThis is because of the linting by Pylance extension that comes with VSC.\n\nNotice data and next_node are at the top of the list.\n\n\n\n3. LinkedList: Read() at Index & Return Node.data\n\ndef read_ll_tp1(linked_list: LinkedList, idx: int) -&gt; str | None:\n    current_node = linked_list.first_node\n    for i in range(idx):\n        # print(i)\n        current_node = current_node.next_node\n        if not current_node:\n            # raise IndexError(\"LinkedList exhausted!\")\n            return None\n    return current_node.data\n\nprint(read_ll_tp1(ll,0))\nprint(read_ll_tp1(ll,1))\nprint(read_ll_tp1(ll,2))\nprint(read_ll_tp1(ll,3))\nprint(read_ll_tp1(ll,4))\n\nI\nheard\nthere\nwas\nNone\n\n\n\n\n4. LinkedList: Search() for Value & Return Index\n\ndef search_ll_tp1(linked_list: LinkedList, value: str) -&gt; int | None:\n    current_node = linked_list.first_node\n    i=0\n    while current_node:\n        if current_node.data == value:\n            return i\n        current_node = current_node.next_node\n        # if not current_node: &lt;- redundant since inside while current_node\n        #     return None \n        i+=1\n    return None # &lt;- if current_node is false return None\n\nprint(search_ll_tp1(ll,\"I\"))\nprint(search_ll_tp1(ll,\"heard\"))\nprint(search_ll_tp1(ll,\"there\"))\nprint(search_ll_tp1(ll,\"was\"))\nprint(search_ll_tp1(ll,\"a\"))\n\n0\n1\n2\n3\nNone"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-027-anagram-call-stack.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-027-anagram-call-stack.html",
    "title": "DSA 27: Anagram - Call Stack",
    "section": "",
    "text": "1. Install showcallstack\n\npip install showcallstack or\nuv add showcallstack (if using uv)\n\n\n\n2. Save anagrams function to a .py (python script)\n\n# dsa-anagram-call-stack.py\nimport showcallstack as ss\n\ndef anagrams(string):\n    # ss.showcallstack()\n    if len(string)==1:\n        return string[0]\n    collection = []\n    substr_anagrams = anagrams(string[1:])\n    for anagram in substr_anagrams:\n        ss.showcallstack()\n        for i in range(len(anagram)+1):\n            new_string = anagram[:i]+string[0]+anagram[i:]\n            collection.append(new_string)\n    return collection\n\nanagrams(\"abc\")\n\n\n\n3. Run .py script from terminal\n\nuv run dsa-anagram-call-stack.py\n\n\n\n4. showcallstack(): High-Level\nThis function shows information about callstack.\nNote:\n\nThe local variables to the showcallstack() depends where the function call is placed\n\n\n\n\n5. showcallstack(): Low-Level\nPlacing the function call inside the for loop shows the a greater granularity of local variables of each call in the call stack.\n\n# dsa-anagram-call-stack2.py\nimport showcallstack as ss\n\ndef anagrams(string):\n    # ss.showcallstack()\n    if len(string)==1:\n        return string[0]\n    collection = []\n    substr_anagrams = anagrams(string[1:])\n    for anagram in substr_anagrams:\n        ss.showcallstack()\n        for i in range(len(anagram)+1):\n            new_string = anagram[:i]+string[0]+anagram[i:]\n            collection.append(new_string)\n    return collection\n\nanagrams(\"abc\")\n\nNote:\n\nThe iteration of i below"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-008-analysing-algos.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-008-analysing-algos.html",
    "title": "DSA 8: Big O - Analysing Algorithms",
    "section": "",
    "text": "1. \\(4N + 16\\) Steps\n\n1.1 Tony’s Solution: \\(O(N)\\)\n\\(O(4N+16) \\rightarrow O(4N) \\rightarrow O(N)\\)\n\n\n\n2. \\(2N^2\\) Steps\n\n2.1 Tony’s Solution: \\(O(N^2)\\)\n\\(O(2N^2) \\rightarrow O(N^2)\\)\n\n\n\n3. double_then_sum Function\n\n​def​ ​double_then_sum​(array):\n    doubled_array = []\n    ​for​ number ​in​ array:\n        doubled_array.append(number * 2)\n    sum = 0\n    ​for​ number ​in​ doubled_array:\n        sum += number\n    ​return​ sum\n\n\n3.1 Tony’s Solution: \\(O(N)\\)\n\nLoop through array: \\(N\\) steps\n\nLoop through doubled_array: \\(N\\) steps\n\nTotal steps: \\(2N\\)\n\nBig O: \\(O(2N) \\rightarrow O(N)\\)\n\n\n\n\n4. mutiple_cases Function\n\n​def​ ​multiple_cases​(array):\n    ​for​ string ​in​ array:\n        ​print​(string.upper())\n        ​print​(string.lower())\n        ​print​(string.capitalize())\n\n\n4.1 Tony’s Solution: \\(O(N)\\)\nThe function performs multiple operations on each string in the input array:\n\n\\(3\\) operations or steps per string or \\(N\\)\n\nTotal Steps: \\(3N\\) steps\nBig O: \\(O(3N) \\rightarrow O(N)\\)\n\n\n\n\n5. every_other Function\n\n​def​ ​every_other​(array):\n        ​for​ index, number ​in​ enumerate(array):\n            ​if​ index % 2 == 0:\n                ​for​ other_number ​in​ array:\n                    ​print​(number + other_number)\n\n\n5.1 Tony’s Solution: \\(O(N)\\)\n\n\\(N\\) operations to iterate through array\n\\(N/2\\) operations applies in the if statement\nTotal Steps: \\(N*N/2=N^2/2\\) steps\nBig O: \\(O(N^2/2) \\rightarrow O(N^2)\\)"
  },
  {
    "objectID": "machinelearning.html",
    "href": "machinelearning.html",
    "title": "Machine Learning 🧪",
    "section": "",
    "text": "ML 1: String Cleaning\n\n\n\n\n\n\nmachine learning\n\n\n\nWith Python’s split() and strip()\n\n\n\n\n\nJan 14, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCollaborative Filtering - Latent Factor Matrix (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nCreating Latent Factors Matrix using set of Users, Items and Ratings\n\n\n\n\n\nMay 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Feature Importance Plot (Part 4)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Feature Importance Plot in a few lines of code\n\n\n\n\n\nApr 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Random Forest Classifier (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Random Forest Classifier with the Sklearn framework\n\n\n\n\n\nApr 26, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Decision Tree Classifier (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Decision Tree Classifier from scratch and then a framework called Sklearn\n\n\n\n\n\nApr 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - OneR Classifier (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a OneR classifier model from scratch\n\n\n\n\n\nApr 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTabular Deep-Learning Model\n\n\n\n\n\n\ndeeplearning\n\n\nmachinelearning\n\n\nai\n\n\n\nBuilding a Deep-Learning Neural Network Model from scratch based on tabular data\n\n\n\n\n\nApr 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRectified Linear Unit (ReLU)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nReLU from scratch with Gradient Descent\n\n\n\n\n\nMar 13, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Make Some Noise\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nA function to add gaussian noise\n\n\n\n\n\nMar 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in a Spreadsheet (Attempt 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\nspreadsheet\n\n\n\nA failed attempt to apply neural network concepts in a spreadsheet\n\n\n\n\n\nFeb 4, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nCreating the ReLU Function \n\n\n\n\n\nFeb 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nOptimising with Gradient Descent\n\n\n\n\n\nFeb 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nManually fitting a Line (Quadratic Function) to a dataset\n\n\n\n\n\nJan 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Setup a Kaggle API\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\ncoding\n\n\n\nContinuing my Data Science journey with Kaggle\n\n\n\n\n\nJan 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nHost a neural network app live on HuggingFace\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a local neural network Gradio App\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a simple neural network model\n\n\n\n\n\nJan 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to choose a different Deep-Learning Model Architecture\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSaving a Fast AI Model\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying My First Live App & it’s a Neural Network!\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classifier 1: Noodles vs Rice\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Git Clone\n\n\n\n\n\n\ntest\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Sample Jupyter Notebook\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost Without Code\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "coding.html",
    "href": "coding.html",
    "title": "Coding 💻",
    "section": "",
    "text": "Code 25: locals()\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nUseful Built-in Function to Obtain Locals Variables & Their Values\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nGO 1: Install & G’Day World\n\n\n\n\n\n\ncoding\n\n\ngolang\n\n\n\nLet’s Go 🚤!\n\n\n\n\n\nFeb 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 24: Falsy (& Truthy) Values\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Pythonic Programming with Falsy Values\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 23: Logging\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Logs for Different Levels\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 22: Python Metaclasses - Customising Class Creation\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nBeing very meta\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 21: Magic Method: __call__\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nAllowing instances to be called like functions\n\n\n\n\n\nDec 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 20: Unicode, UTF-8 and Bytes\n\n\n\n\n\n\ncoding\n\n\n\nConverting my (Chinese) name to bytes and back\n\n\n\n\n\nDec 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 19: uv Python & Package Manager\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nA modern alternative to creating & managing Python projects\n\n\n\n\n\nDec 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 15: Python Exceptions 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nDel ving into Python Exceptions, In-Builts vs Custom Exceptions, Assert, Raise and Exception-Handlers\n\n\n\n\n\nNov 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 18: Introduction to C# in Visual Studio Code\n\n\n\n\n\n\nc#\n\n\n\nCreating, Building and Running Simple C# Console Apps\n\n\n\n\n\nOct 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 17: Transfer Multiple Issues via Github API in Bash\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\nbash\n\n\n\nRun a simple loop to transfer multiple issues from one repo to another\n\n\n\n\n\nOct 29, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 16: Open Source as a Beginner\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning How To Contribute to Open Source Projects as a Beginner\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 14: Python Classes Basics 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nPython Classes, Instance Objects, Data Attributes and Method Objects\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 13: Shallow or Deep?\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning to copy the right way\n\n\n\n\n\nOct 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 12: Create new key-bindings in VSCode via JSON file\n\n\n\n\n\n\ncoding\n\n\nvscode\n\n\n\nA handy keybinding to switch between Terminals in VSCode\n\n\n\n\n\nOct 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 11: Using Github API via Python\n\n\n\n\n\n\ngithub\n\n\napi\n\n\npython\n\n\n\nLearn to update an Issue Description with Github’s API\n\n\n\n\n\nOct 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 10: Add a script to PATH\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nRun a script without specifying its path\n\n\n\n\n\nSep 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 9: Creating and using Symlinks\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nAvoiding unnecessarily duplicating files with Symlinks\n\n\n\n\n\nSep 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 8: How to install Quarto via WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nMigrating quarto blog from windows to wsl\n\n\n\n\n\nSep 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 7: Virtual Environments\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nSetting up virtual environments to produce reproducible work\n\n\n\n\n\nJul 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 6: Measuring Model Accuracy\n\n\n\n\n\n\nmachine learning\n\n\n\nStep-by-step guide on how to measure accuracy of a deeplearning model\n\n\n\n\n\nApr 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 5: Debugging a 1-Hidden-Layer Neural Network Model\n\n\n\n\n\n\ncoding\n\n\ndebugging\n\n\n\nDocumenting my debugging of a neural network model I built from scratch\n\n\n\n\n\nApr 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 4: Create new Users in WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nQuick instructions to set up a new user in wsl\n\n\n\n\n\nMar 15, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 3: Bash Basics\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\nbash\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2: Data Science Machine\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 1: Github Issues Automation\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "dsa.html",
    "href": "dsa.html",
    "title": "Data Structures & Algorithms 💻",
    "section": "",
    "text": "DSA 51: Array-Based Heaps [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Cool Data Structure 😎 \n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 52: Array-Based Heaps - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Useful Data Structure 🔨\n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 50: Binary Search Trees - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCh.15 Max, Pre & Post-Order Traversals\n\n\n\n\n\nMar 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 49: Binary Search Trees - Delete Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA Thoroughly Commented Scenario-Style Coding of BST’s delete_node Function\n\n\n\n\n\nMar 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 48: Binary Search Trees - Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting BST Operations From Scratch All At Once\n\n\n\n\n\nMar 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 46: Binary Search Trees - Delete [Part 9]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCleaner Implementation with Less Code\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 47: Binary Search Trees - Traverse [Part 10]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nIn-order Traversal Implementation\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 45: Binary Search Trees - Delete [Part 8]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 2: Zero, 1 or 2 Children\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 44: Binary Search Trees - Delete [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 1: Zero or 1 Children Nodes Only\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 42: Binary Search Trees - Alternative Approaches [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nLearning to Convert between Recursion and Iterative Approaches\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 43: Binary Search Trees - Sir-Insert-A-Lot [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsert a List of Integers into a Binary-Tree\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 41: Binary Search Trees - Insertion [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsertion Attempt\n\n\n\n\n\nFeb 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 40: Binary Search Trees - Search [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nFirst Attempt Raw\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 39: Binary Search Trees - Rules [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA basic BST Implementation\n\n\n\n\n\nFeb 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 37: Singly & Doubly Linked List - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 14 Exercises 1-5, J.Wengrow Vol 2\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 38: Binary Search Trees - Basics [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTrees & Binary Trees: Useful Terms\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 36: Doubly Linked List [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAllowing for Forward and Backwards Traversal\n\n\n\n\n\nFeb 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 35: LinkedList - Insert & Delete [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nThe Two Other Important Operations\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 34: LinkedList - Read & Search [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTwo Important Operations as Functions\n\n\n\n\n\nFeb 16, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 31: Quickselect [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nGetting the kth item by adapting the quicksort algorithm\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 33: Nodes & Linked Lists [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBrief introduction to node-based data structures\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 32: Quick Algorithms - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 13 Exercises, J.Wengrow Vol 1\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 30: Quicksort [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementation with Partitioning\n\n\n\n\n\nFeb 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 29: Dynamic Programming - Exercises [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAddition, Golomb & Unique Path Questions\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 28: Dynamic Programming [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving Function Efficiency with the Memoization Technique\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 27: Anagram - Call Stack\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAn introductory look at the call stack of the anagram recursive function\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 26: Recursion - Anagram Generation [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAnagram Recursive Function From Scratch\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 25: Recursion - Exercises [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nMore recursion examples and exercises\n\n\n\n\n\nFeb 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 24: Recursion - 3 More Examples [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSummation, String-Reversal & Counting-Letter\n\n\n\n\n\nFeb 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 23: Recursion - In-Place Modification [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreating & Modifying Arrays\n\n\n\n\n\nFeb 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 22: Recursion - Factorial [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBase-Case\n\n\n\n\n\nFeb 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 21: Recursion - With Base-Case [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nProper structure of a recursive function\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 20: Recursion [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nComparing a simple while-loop versus a recursive function\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 19: Queues - Print [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplement a simple interface for a PrintManager class\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 18: Queues [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nQueues are like a Macca’s Drive-Thru\n\n\n\n\n\nJan 31, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 17: Stacks - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 9, J.Wengrow Vol 2\n\n\n\n\n\nJan 30, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 16: Stacks - Linter [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nRecording first attempt writing a (Braces) Linter class\n\n\n\n\n\nJan 29, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 15: Hash Tables - Exercises [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 8 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 14: Hash Table - Speed Comparisons [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving time-complexity of an algorithm with a hash table\n\n\n\n\n\nJan 26, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 13: Stacks - An Abstract Class [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSometimes it’s nice to be structured & orderly\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 12: Hash Tables - Collisions [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCollisions in Hash Tables explained with a suggestion solution\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 11: Hash Tables - Hash Functions [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreate hash tables, hash functions and replicate how the data is in memory\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 10: Insertion Sort - Shift & Insert\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\n3rd attempt which uses less variable assigning\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 9: Insertion Sort - With Test Scenarios\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nEquivalent Implementations Using for & while-loops\n\n\n\n\n\nJan 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 8: Big O - Analysing Algorithms\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nDescribing Algorithms & Functions in Big O notation - Chapter 5 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 7: \\(BubbleSort()\\) Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementing from scratch and charting the time complexity\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 6: Binary Search Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting binary search from scratch and testing array sizes\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 5: Big O - String Select Function\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercise 4, J.Wengrow Vol 2\n\n\n\n\n\nJan 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 4: Big-O - Chessboard & Grains Problem\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercises 3, J.Wengrow Vol 2\n\n\n\n\n\nJan 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 3: Binary Search - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 2 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 2: Array and Sets - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 1 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 5, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 1: Big-O - Arrays and Sets\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nBig-O for Array Operations\n\n\n\n\n\nJan 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tony’s Blog ✍️",
    "section": "",
    "text": "DSA 51: Array-Based Heaps [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Cool Data Structure 😎 \n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 52: Array-Based Heaps - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nHeaps Useful Data Structure 🔨\n\n\n\n\n\nMar 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 50: Binary Search Trees - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCh.15 Max, Pre & Post-Order Traversals\n\n\n\n\n\nMar 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 49: Binary Search Trees - Delete Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA Thoroughly Commented Scenario-Style Coding of BST’s delete_node Function\n\n\n\n\n\nMar 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 48: Binary Search Trees - Review\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting BST Operations From Scratch All At Once\n\n\n\n\n\nMar 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 46: Binary Search Trees - Delete [Part 9]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCleaner Implementation with Less Code\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 47: Binary Search Trees - Traverse [Part 10]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nIn-order Traversal Implementation\n\n\n\n\n\nMar 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 45: Binary Search Trees - Delete [Part 8]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 2: Zero, 1 or 2 Children\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 44: Binary Search Trees - Delete [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWip Attempt 1: Zero or 1 Children Nodes Only\n\n\n\n\n\nFeb 28, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 42: Binary Search Trees - Alternative Approaches [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nLearning to Convert between Recursion and Iterative Approaches\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 43: Binary Search Trees - Sir-Insert-A-Lot [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsert a List of Integers into a Binary-Tree\n\n\n\n\n\nFeb 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 41: Binary Search Trees - Insertion [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nInsertion Attempt\n\n\n\n\n\nFeb 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 40: Binary Search Trees - Search [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nFirst Attempt Raw\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 25: locals()\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nUseful Built-in Function to Obtain Locals Variables & Their Values\n\n\n\n\n\nFeb 23, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 39: Binary Search Trees - Rules [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nA basic BST Implementation\n\n\n\n\n\nFeb 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 37: Singly & Doubly Linked List - Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 14 Exercises 1-5, J.Wengrow Vol 2\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 38: Binary Search Trees - Basics [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTrees & Binary Trees: Useful Terms\n\n\n\n\n\nFeb 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nGO 1: Install & G’Day World\n\n\n\n\n\n\ncoding\n\n\ngolang\n\n\n\nLet’s Go 🚤!\n\n\n\n\n\nFeb 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 36: Doubly Linked List [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAllowing for Forward and Backwards Traversal\n\n\n\n\n\nFeb 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 35: LinkedList - Insert & Delete [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nThe Two Other Important Operations\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 24: Falsy (& Truthy) Values\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Pythonic Programming with Falsy Values\n\n\n\n\n\nFeb 17, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 34: LinkedList - Read & Search [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nTwo Important Operations as Functions\n\n\n\n\n\nFeb 16, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 31: Quickselect [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nGetting the kth item by adapting the quicksort algorithm\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 33: Nodes & Linked Lists [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBrief introduction to node-based data structures\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 32: Quick Algorithms - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 13 Exercises, J.Wengrow Vol 1\n\n\n\n\n\nFeb 15, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 30: Quicksort [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementation with Partitioning\n\n\n\n\n\nFeb 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 29: Dynamic Programming - Exercises [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAddition, Golomb & Unique Path Questions\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 28: Dynamic Programming [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving Function Efficiency with the Memoization Technique\n\n\n\n\n\nFeb 12, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 27: Anagram - Call Stack\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAn introductory look at the call stack of the anagram recursive function\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 26: Recursion - Anagram Generation [Part 7]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nAnagram Recursive Function From Scratch\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 23: Logging\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning Logs for Different Levels\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 17: Simple Pendulum\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.3-6 Ex.103 Chain-Rule, Thomas 13e pp.170\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 25: Recursion - Exercises [Part 6]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nMore recursion examples and exercises\n\n\n\n\n\nFeb 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 24: Recursion - 3 More Examples [Part 5]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSummation, String-Reversal & Counting-Letter\n\n\n\n\n\nFeb 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 23: Recursion - In-Place Modification [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreating & Modifying Arrays\n\n\n\n\n\nFeb 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 22: Recursion - Factorial [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nBase-Case\n\n\n\n\n\nFeb 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 21: Recursion - With Base-Case [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nProper structure of a recursive function\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 16: More Sequence Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.39-49 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 15: Convergence & Divergence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.27-37 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 20: Recursion [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nComparing a simple while-loop versus a recursive function\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 19: Queues - Print [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplement a simple interface for a PrintManager class\n\n\n\n\n\nFeb 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 18: Queues [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nQueues are like a Macca’s Drive-Thru\n\n\n\n\n\nJan 31, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 17: Stacks - Exercises [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 9, J.Wengrow Vol 2\n\n\n\n\n\nJan 30, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 16: Stacks - Linter [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nRecording first attempt writing a (Braces) Linter class\n\n\n\n\n\nJan 29, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 15: Hash Tables - Exercises [Part 4]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 8 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 27, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 14: Hash Table - Speed Comparisons [Part 3]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImproving time-complexity of an algorithm with a hash table\n\n\n\n\n\nJan 26, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 13: Stacks - An Abstract Class [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nSometimes it’s nice to be structured & orderly\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 14: n’th Derivative with % (modulo) & sympy\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3-5 Derivatives of Trigonometric Functions, Thomas 13e pp.161\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 13: Limit of Cosine\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch2-4 One-Sided Limits, Thomas 13e pp.91\n\n\n\n\n\nJan 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 12: Hash Tables - Collisions [Part 2]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCollisions in Hash Tables explained with a suggestion solution\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 12: Derivatives Of Trigonometric Functions\n\n\n\n\n\n\ncalculus\n\n\n\nUsing Python’s sympy library to find numeric & exact solutions\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 11: Hash Tables - Hash Functions [Part 1]\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nCreate hash tables, hash functions and replicate how the data is in memory\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 11: More Sequences\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 10: Generating & Coding A Sequence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 20, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 10: Insertion Sort - Shift & Insert\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\n3rd attempt which uses less variable assigning\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 9: Terms of Sequences - Selected Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 9: Insertion Sort - With Test Scenarios\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nEquivalent Implementations Using for & while-loops\n\n\n\n\n\nJan 18, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nML 1: String Cleaning\n\n\n\n\n\n\nmachine learning\n\n\n\nWith Python’s split() and strip()\n\n\n\n\n\nJan 14, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 8: Big O - Analysing Algorithms\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nDescribing Algorithms & Functions in Big O notation - Chapter 5 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 5: 49 - Group Anagrams\n\n\n\n\n\n\nleetcode\n\n\n\nGroup Anagrams\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 8: Derivative of An Exponential\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.3 Derivatives, Thomas 13e pp.140\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 7: \\(BubbleSort()\\) Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nImplementing from scratch and charting the time complexity\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 6: Binary Search Practice\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nWriting binary search from scratch and testing array sizes\n\n\n\n\n\nJan 11, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 5: Big O - String Select Function\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercise 4, J.Wengrow Vol 2\n\n\n\n\n\nJan 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 4: Big-O - Chessboard & Grains Problem\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 3 Exercises 3, J.Wengrow Vol 2\n\n\n\n\n\nJan 9, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 7: Rates of Change Applications\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex25-31, Thomas 13e pp.126-127\n\n\n\n\n\nJan 8, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 3: Binary Search - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 2 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 6: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex23, Thomas 13e pp.126\n\n\n\n\n\nJan 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 2: Array and Sets - Exercises\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nChapter 1 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 5, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 5: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex17, Thomas 13e pp.126\n\n\n\n\n\nJan 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 4: Applying Binomial Theorem\n\n\n\n\n\n\ncalculus\n\n\nbinomialtheorem\n\n\n\nFind the derivative and plot the tangent (from Ch3.1.Ex9, Thomas 13e pp.126)\n\n\n\n\n\nJan 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA 1: Big-O - Arrays and Sets\n\n\n\n\n\n\ndatastructures\n\n\nalgorithms\n\n\n\nBig-O for Array Operations\n\n\n\n\n\nJan 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 22: Python Metaclasses - Customising Class Creation\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nBeing very meta\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 4: Singleton Pattern\n\n\n\n\n\n\ndesign patterns\n\n\n\nA Design (or Anti) Pattern Allowing Only A Single Instance\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 21: Magic Method: __call__\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nAllowing instances to be called like functions\n\n\n\n\n\nDec 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 20: Unicode, UTF-8 and Bytes\n\n\n\n\n\n\ncoding\n\n\n\nConverting my (Chinese) name to bytes and back\n\n\n\n\n\nDec 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 3: Synthetic Division\n\n\n\n\n\n\ncalculus\n\n\n\nLearning a factoring technique (from Ex 2.2.85, Thomas 13e pp.77)\n\n\n\n\n\nDec 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 2: Plotting functions with limits\n\n\n\n\n\n\ncalculus\n\n\n\nCh2.2: Limit of a Function & Limit Laws (Ex2.2.11-21, Thomas 13e pp.74)\n\n\n\n\n\nDec 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specificsgit\n\n\n\n\n\nDec 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 2: Interfaces [Part 1] - ABC Abstract Base Classes\n\n\n\n\n\n\ndesign patterns\n\n\n\nProgramming to Interfaces rather than Implementation specifics\n\n\n\n\n\nDec 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 19: uv Python & Package Manager\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nA modern alternative to creating & managing Python projects\n\n\n\n\n\nDec 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDP 1: Encapsulation - Getter Method in Python\n\n\n\n\n\n\ndesign patterns\n\n\n\nUsing Python’s @property to create a getter method\n\n\n\n\n\nNov 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 15: Python Exceptions 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nDel ving into Python Exceptions, In-Builts vs Custom Exceptions, Assert, Raise and Exception-Handlers\n\n\n\n\n\nNov 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 18: Introduction to C# in Visual Studio Code\n\n\n\n\n\n\nc#\n\n\n\nCreating, Building and Running Simple C# Console Apps\n\n\n\n\n\nOct 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 17: Transfer Multiple Issues via Github API in Bash\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\nbash\n\n\n\nRun a simple loop to transfer multiple issues from one repo to another\n\n\n\n\n\nOct 29, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 16: Open Source as a Beginner\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning How To Contribute to Open Source Projects as a Beginner\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 14: Python Classes Basics 101\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nPython Classes, Instance Objects, Data Attributes and Method Objects\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 13: Shallow or Deep?\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nLearning to copy the right way\n\n\n\n\n\nOct 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 12: Create new key-bindings in VSCode via JSON file\n\n\n\n\n\n\ncoding\n\n\nvscode\n\n\n\nA handy keybinding to switch between Terminals in VSCode\n\n\n\n\n\nOct 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 1: Inverse Properties of \\(a^x\\) and \\(\\log_a x\\)\n\n\n\n\n\n\ncalculus\n\n\n\nExploring the compositions of \\(a^x\\), \\(\\log_a x\\), \\(e^x\\) and \\(\\ln x\\) and deriving the Change of Base formula\n\n\n\n\n\nOct 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 11: Using Github API via Python\n\n\n\n\n\n\ngithub\n\n\napi\n\n\npython\n\n\n\nLearn to update an Issue Description with Github’s API\n\n\n\n\n\nOct 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 10: Add a script to PATH\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nRun a script without specifying its path\n\n\n\n\n\nSep 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 9: Creating and using Symlinks\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nAvoiding unnecessarily duplicating files with Symlinks\n\n\n\n\n\nSep 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 8: How to install Quarto via WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nMigrating quarto blog from windows to wsl\n\n\n\n\n\nSep 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 7: Virtual Environments\n\n\n\n\n\n\ncoding\n\n\npython\n\n\n\nSetting up virtual environments to produce reproducible work\n\n\n\n\n\nJul 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCollaborative Filtering - Latent Factor Matrix (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nCreating Latent Factors Matrix using set of Users, Items and Ratings\n\n\n\n\n\nMay 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Feature Importance Plot (Part 4)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Feature Importance Plot in a few lines of code\n\n\n\n\n\nApr 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Random Forest Classifier (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Random Forest Classifier with the Sklearn framework\n\n\n\n\n\nApr 26, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Decision Tree Classifier (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Decision Tree Classifier from scratch and then a framework called Sklearn\n\n\n\n\n\nApr 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - OneR Classifier (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a OneR classifier model from scratch\n\n\n\n\n\nApr 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 6: Measuring Model Accuracy\n\n\n\n\n\n\nmachine learning\n\n\n\nStep-by-step guide on how to measure accuracy of a deeplearning model\n\n\n\n\n\nApr 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTabular Deep-Learning Model\n\n\n\n\n\n\ndeeplearning\n\n\nmachinelearning\n\n\nai\n\n\n\nBuilding a Deep-Learning Neural Network Model from scratch based on tabular data\n\n\n\n\n\nApr 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 5: Debugging a 1-Hidden-Layer Neural Network Model\n\n\n\n\n\n\ncoding\n\n\ndebugging\n\n\n\nDocumenting my debugging of a neural network model I built from scratch\n\n\n\n\n\nApr 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 4: Create new Users in WSL\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nQuick instructions to set up a new user in wsl\n\n\n\n\n\nMar 15, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRectified Linear Unit (ReLU)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nReLU from scratch with Gradient Descent\n\n\n\n\n\nMar 13, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Make Some Noise\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nA function to add gaussian noise\n\n\n\n\n\nMar 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 3: Bash Basics\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\nbash\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 6: More Eigen examples\n\n\n\n\n\n\nlinearalgebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 4: Diagonal Matrices are trivial\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 5: It’s nice to be similar (matrices)\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2: Data Science Machine\n\n\n\n\n\n\ncoding\n\n\nlinux\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCode 1: Github Issues Automation\n\n\n\n\n\n\ncoding\n\n\ngithub\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 3: Eigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinearalgebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nKAGG 2: A Basic NLP model - [Competition Version]\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nKAGG 1: A Basic NLP model\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 2: Eigen is my valentines in 2024\n\n\n\n\n\n\nlinearalgebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 4: 74 - Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 3: 704 - Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 1: Change of Basis\n\n\n\n\n\n\nlinearalgebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 2: 150 - Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 1: 155 - Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in a Spreadsheet (Attempt 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\nspreadsheet\n\n\n\nA failed attempt to apply neural network concepts in a spreadsheet\n\n\n\n\n\nFeb 4, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nCreating the ReLU Function \n\n\n\n\n\nFeb 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nOptimising with Gradient Descent\n\n\n\n\n\nFeb 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nManually fitting a Line (Quadratic Function) to a dataset\n\n\n\n\n\nJan 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Setup a Kaggle API\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\ncoding\n\n\n\nContinuing my Data Science journey with Kaggle\n\n\n\n\n\nJan 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nHost a neural network app live on HuggingFace\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a local neural network Gradio App\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a simple neural network model\n\n\n\n\n\nJan 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to choose a different Deep-Learning Model Architecture\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSaving a Fast AI Model\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying My First Live App & it’s a Neural Network!\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classifier 1: Noodles vs Rice\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Git Clone\n\n\n\n\n\n\ntest\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Sample Jupyter Notebook\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost Without Code\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About 🐈‍⬛",
    "section": "",
    "text": "This is a blog coinciding with my journey to becoming a developer.\nA Poem of Oreo\nIn a bustling town of Ultimo, where city lights gleam,\nA tale unfolds of Oreo, a kitten’s sweet dream.\nTony brought him home with Lilo by his side,\nA tuxedo cat, in black and white pride.\nOreo, a Maine Coon with a fluffy coat,\nBlack all over, with white around his throat.\nWhite paws that dance, a playful delight,\nA mischievous gleam in his eyes, shining bright.\nLilo, a tiny British Shorthair so fair,\nA dainty companion with a gentle air.\nThey grew up together, a dynamic pair,\nFrom Ultimo to Pyrmont, a journey to share.\nThrough the streets of Townhall, they explored,\nAdventures aplenty, their spirits soared.\nYet, runaway moments were a frequent feat,\nFound and embraced, their connection so sweet.\nOreo, a rogue, with a penchant for bins,\nA greedy delight, where the treasure begins.\nFeasting on scraps, his appetite vast,\nBut his cuteness prevails, a spell he has cast.\nLilo, petite, with a modest cuisine,\nA nibble here, a delicate routine.\nShe watches Oreo with curious eyes,\nAs he plays around, chasing butterflies.\nIn the city’s heartbeat, their story unfolds,\nThrough alleys and parks, where the tale molds.\nOreo, the player, with antics so grand,\nLilo, the watcher, in the city so grand.\nNow, in the world of influencers and fame,\nOreo has found his claim to the game.\nAn influencer cat, with followers galore,\nFrom bins to glamour, a journey to adore.\nThrough Ultimo, Pyrmont, and Townhall’s embrace,\nOreo and Lilo found their special place.\nA tale of friendship, of mischief and grace,\nIn the city’s heartbeat, a memory to trace."
  },
  {
    "objectID": "calculus.html",
    "href": "calculus.html",
    "title": "Calculus 🧮",
    "section": "",
    "text": "Calculus 17: Simple Pendulum\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.3-6 Ex.103 Chain-Rule, Thomas 13e pp.170\n\n\n\n\n\nFeb 10, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 16: More Sequence Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.39-49 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 3, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 15: Convergence & Divergence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch.10-1 Ex.27-37 Sequences, Thomas 13e pp.582\n\n\n\n\n\nFeb 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 14: n’th Derivative with % (modulo) & sympy\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3-5 Derivatives of Trigonometric Functions, Thomas 13e pp.161\n\n\n\n\n\nJan 25, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 13: Limit of Cosine\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch2-4 One-Sided Limits, Thomas 13e pp.91\n\n\n\n\n\nJan 24, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 12: Derivatives Of Trigonometric Functions\n\n\n\n\n\n\ncalculus\n\n\n\nUsing Python’s sympy library to find numeric & exact solutions\n\n\n\n\n\nJan 22, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 11: More Sequences\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 21, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 10: Generating & Coding A Sequence\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 20, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 9: Terms of Sequences - Selected Exercises\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch10-1 Sequences, Thomas 13e pp.581\n\n\n\n\n\nJan 19, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 8: Derivative of An Exponential\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.3 Derivatives, Thomas 13e pp.140\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 7: Rates of Change Applications\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex25-31, Thomas 13e pp.126-127\n\n\n\n\n\nJan 8, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 6: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex23, Thomas 13e pp.126\n\n\n\n\n\nJan 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 5: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex17, Thomas 13e pp.126\n\n\n\n\n\nJan 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 4: Applying Binomial Theorem\n\n\n\n\n\n\ncalculus\n\n\nbinomialtheorem\n\n\n\nFind the derivative and plot the tangent (from Ch3.1.Ex9, Thomas 13e pp.126)\n\n\n\n\n\nJan 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 3: Synthetic Division\n\n\n\n\n\n\ncalculus\n\n\n\nLearning a factoring technique (from Ex 2.2.85, Thomas 13e pp.77)\n\n\n\n\n\nDec 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 2: Plotting functions with limits\n\n\n\n\n\n\ncalculus\n\n\n\nCh2.2: Limit of a Function & Limit Laws (Ex2.2.11-21, Thomas 13e pp.74)\n\n\n\n\n\nDec 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus 1: Inverse Properties of \\(a^x\\) and \\(\\log_a x\\)\n\n\n\n\n\n\ncalculus\n\n\n\nExploring the compositions of \\(a^x\\), \\(\\log_a x\\), \\(e^x\\) and \\(\\ln x\\) and deriving the Change of Base formula\n\n\n\n\n\nOct 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "datascience.html",
    "href": "datascience.html",
    "title": "Data Science 🧪",
    "section": "",
    "text": "ML 1: String Cleaning\n\n\n\n\n\n\nmachine learning\n\n\n\nWith Python’s split() and strip()\n\n\n\n\n\nJan 14, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCollaborative Filtering - Latent Factor Matrix (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nCreating Latent Factors Matrix using set of Users, Items and Ratings\n\n\n\n\n\nMay 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Feature Importance Plot (Part 4)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Feature Importance Plot in a few lines of code\n\n\n\n\n\nApr 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Random Forest Classifier (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Random Forest Classifier with the Sklearn framework\n\n\n\n\n\nApr 26, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Decision Tree Classifier (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a Decision Tree Classifier from scratch and then a framework called Sklearn\n\n\n\n\n\nApr 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - OneR Classifier (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\n\nBuilding a OneR classifier model from scratch\n\n\n\n\n\nApr 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTabular Deep-Learning Model\n\n\n\n\n\n\ndeeplearning\n\n\nmachinelearning\n\n\nai\n\n\n\nBuilding a Deep-Learning Neural Network Model from scratch based on tabular data\n\n\n\n\n\nApr 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRectified Linear Unit (ReLU)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nReLU from scratch with Gradient Descent\n\n\n\n\n\nMar 13, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Make Some Noise\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nA function to add gaussian noise\n\n\n\n\n\nMar 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nKAGG 2: A Basic NLP model - [Competition Version]\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nKAGG 1: A Basic NLP model\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in a Spreadsheet (Attempt 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\nspreadsheet\n\n\n\nA failed attempt to apply neural network concepts in a spreadsheet\n\n\n\n\n\nFeb 4, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nCreating the ReLU Function \n\n\n\n\n\nFeb 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nOptimising with Gradient Descent\n\n\n\n\n\nFeb 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\nmathematics\n\n\n\nManually fitting a Line (Quadratic Function) to a dataset\n\n\n\n\n\nJan 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Setup a Kaggle API\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\ncoding\n\n\n\nContinuing my Data Science journey with Kaggle\n\n\n\n\n\nJan 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nHost a neural network app live on HuggingFace\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a local neural network Gradio App\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\nCreate a simple neural network model\n\n\n\n\n\nJan 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to choose a different Deep-Learning Model Architecture\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSaving a Fast AI Model\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying My First Live App & it’s a Neural Network!\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classifier 1: Noodles vs Rice\n\n\n\n\n\n\nmachinelearning\n\n\nai\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Git Clone\n\n\n\n\n\n\ntest\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Sample Jupyter Notebook\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost Without Code\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\ntesting\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-014-hash-tables-part-3.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-014-hash-tables-part-3.html",
    "title": "DSA 14: Hash Table - Speed Comparisons [Part 3]",
    "section": "",
    "text": "1. Is an array a subset of another array?\n\nShorter array: arr_s\nLonger array: arr_l\n\n\n\n2. Array Solution: Nested-Loops - \\(O(N*M)\\)\n\n# arr_s = [char for char in \"bdf\"]\narr_s = [char for char in \"bdfz\"]\narr_l = [char for char in \"abcdef\"]\n\nfor chr_s in arr_s: # O(N)\n    match_found = False\n    for chr_l in arr_l: #O(M)\n        # print(chr_s,chr_l)\n        if chr_s==chr_l: \n            match_found = True   \n            break\n    chr_s_not_found = chr_s # Total O(N*M)\n    \nif match_found:\n    print(f\"Subset: {match_found}\")\nelse:\n    print(f\"Subset: {match_found}. Character not found: {chr_s_not_found}\")\n\nSubset: False. Character not found: z\n\n\n\n\n3. Time-Complexity with a Hash Table - \\(O(N)\\)\nBy implementing a hash-table (python dict), the time-complexity of our algorithm improves significantly:\n\nReduced from \\(O(N*M)\\ \\to\\ O(N)\\)\n\n\n# arr_s = [char for char in \"bdf\"]\narr_s = [char for char in \"bdfz\"]\narr_l = [char for char in \"abcdef\"]\n\n# create dict_l -&gt; dctkeys= char_l of arr_l, dctvals = True\ndict_l = {}\nfor char_l in arr_l: # O(N)\n    dict_l[char_l]=True\n    \n# print(dict_l)\n\n# check char_s in dict_l\nfor char_s in arr_s: # O(N)\n    match_found = False\n    if char_s in dict_l: # O(1) \n        match_found = True\n    char_s_not_in_dict_l = char_s # Total O(N+N+1) = O(2N+1) = O(N)\n\nif match_found:\n    print(f\"Subset: {match_found}\")\nelse:\n    print(f\"Subset: {match_found}, Character not found: {char_s_not_in_dict_l}\")\n    \n\nSubset: False, Character not found: z"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-040-binary-search-trees-part-3.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-040-binary-search-trees-part-3.html",
    "title": "DSA 40: Binary Search Trees - Search [Part 3]",
    "section": "",
    "text": "1. Search\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\n\n2. Create TreeNodes & BinarySearchTree\n\n# create node instances\nnode15 = TreeNode(15, left=None, right=None)\nnode35 = TreeNode(35, left=None, right=None)\nnode65 = TreeNode(65, left=None, right=None)\nnode85 = TreeNode(85, left=None, right=None)\n\nnode25 = TreeNode(25, left=node15, right=node35)\nnode75 = TreeNode(75, left=node65, right=node85)\nnode50 = TreeNode(50, left=node25, right=node75)\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n    \n#       50\n#   25      75\n# 15  35  65  85  \n# create a basic tree\n\n# class BinarySearchTree:\n#     def __init__(self, root_node:TreeNode):\n#         self.root_node = root_node\n\n\n\n3. Search: Psuedo-Code\nPsuedo-Code: The algorithm for searching within a binary search tree is as follows:\n\nDesignate a node to be the current node (usually root node)\nInspect the value at the current node.\nIf we’ve found the value we’re looking for, great!\nIf the value we’re looking for is less than the current node, search for it in its left subtree.\nIf the value we’re looking for is greater than the current node, search for it in its right subtree.\nRepeat Steps 1 through 5 until we find the value we’re searching for, or until we hit the bottom of the tree, in which case our value must not be in the tree.\n\n\n\n\n4. Create Binary Tree\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \n\n# Level: L4\nnode04 = TreeNode( 4, left=None, right=None)\nnode11 = TreeNode(11, left=None, right=None)\nnode30 = TreeNode(30, left=None, right=None)\nnode40 = TreeNode(40, left=None, right=None)\n# Level: R4\nnode52 = TreeNode(52, left=None, right=None)\nnode61 = TreeNode(61, left=None, right=None)\nnode82 = TreeNode(82, left=None, right=None)\nnode95 = TreeNode(95, left=None, right=None)\n\n# Level: L3\nnode10 = TreeNode(10, left=node04, right=node11)\nnode33 = TreeNode(33, left=node30, right=node40)\n# Level: R3\nnode56 = TreeNode(56, left=node52, right=node61)\nnode89 = TreeNode(89, left=node82, right=node95)\n\n# Level: L2\nnode25 = TreeNode(25, left=node10, right=node33)\n# Level: R2\nnode75 = TreeNode(75, left=node56, right=node89)\n\n# Level: L1\nnode50 = TreeNode(50, left=node25, right=node75)\n\n\n\n5. Search Node Function:\n\ndef search_node_of_bst(root_node: TreeNode, target:int):\n    print(f\"Entered Fn: current_node[{root_node.data}], target[{target}]\")\n    current_node = root_node\n    \n    if not current_node.data:\n        print(f\"{target} NOT FOUND! node[{current_node.data}]\")\n        return False\n    \n    if current_node.data==target:\n        # print(locals().items())\n        print(f\"{target} FOUND! node[{current_node.data}]\")\n        return current_node.data\n    \n    if target &lt; current_node.data:\n        try:\n            print(f\"target[{target}] &lt; node[{current_node.data}]:\\n\\tgoing left[{current_node.left.data}])\")\n            current_node = current_node.left\n        except:\n            raise IndexError(f\"{target} NOT FOUND!\")\n    elif target &gt; current_node.data:\n        try:\n            print(f\"node[{current_node.data}] &lt; target[{target}]:\\n\\tgoing right[{current_node.right.data}]\")\n            current_node = current_node.right\n        except:\n            raise IndexError(f\"{target} NOT FOUND!\")\n    \n    return search_node_of_bst(current_node, target)\n\n\n\n6. Test 1: target 61\n\n\nsearch_node_of_bst(root_node=node50, target=61)\n\nEntered Fn: current_node[50], target[61]\nnode[50] &lt; target[61]:\n    going right[75]\nEntered Fn: current_node[75], target[61]\ntarget[61] &lt; node[75]:\n    going left[56])\nEntered Fn: current_node[56], target[61]\nnode[56] &lt; target[61]:\n    going right[61]\nEntered Fn: current_node[61], target[61]\n61 FOUND! node[61]\n\n\n61\n\n\n\n\n7. Test 2: target 11\n\nsearch_node_of_bst(root_node=node50, target=11)\n\nEntered Fn: current_node[50], target[11]\ntarget[11] &lt; node[50]:\n    going left[25])\nEntered Fn: current_node[25], target[11]\ntarget[11] &lt; node[25]:\n    going left[10])\nEntered Fn: current_node[10], target[11]\nnode[10] &lt; target[11]:\n    going right[11]\nEntered Fn: current_node[11], target[11]\n11 FOUND! node[11]\n\n\n11\n\n\n\n\n8. Test 3: target 69\n\nsearch_node_of_bst(root_node=node50, target=69)\n\nEntered Fn: current_node[50], target[69]\nnode[50] &lt; target[69]:\n    going right[75]\nEntered Fn: current_node[75], target[69]\ntarget[69] &lt; node[75]:\n    going left[56])\nEntered Fn: current_node[56], target[69]\nnode[56] &lt; target[69]:\n    going right[61]\nEntered Fn: current_node[61], target[69]\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[11], line 22, in search_node_of_bst(root_node, target)\n     21 try:\n---&gt; 22     print(f\"node[{current_node.data}] &lt; target[{target}]:\\n\\tgoing right[{current_node.right.data}]\")\n     23     current_node = current_node.right\n\nAttributeError: 'NoneType' object has no attribute 'data'\n\nDuring handling of the above exception, another exception occurred:\n\nIndexError                                Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 search_node_of_bst(root_node=node50, target=69)\n\nCell In[11], line 27, in search_node_of_bst(root_node, target)\n     24     except:\n     25         raise IndexError(f\"{target} NOT FOUND!\")\n---&gt; 27 return search_node_of_bst(current_node, target)\n\nCell In[11], line 27, in search_node_of_bst(root_node, target)\n     24     except:\n     25         raise IndexError(f\"{target} NOT FOUND!\")\n---&gt; 27 return search_node_of_bst(current_node, target)\n\nCell In[11], line 27, in search_node_of_bst(root_node, target)\n     24     except:\n     25         raise IndexError(f\"{target} NOT FOUND!\")\n---&gt; 27 return search_node_of_bst(current_node, target)\n\nCell In[11], line 25, in search_node_of_bst(root_node, target)\n     23         current_node = current_node.right\n     24     except:\n---&gt; 25         raise IndexError(f\"{target} NOT FOUND!\")\n     27 return search_node_of_bst(current_node, target)\n\nIndexError: 69 NOT FOUND!"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-041-binary-search-trees-part-4.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-041-binary-search-trees-part-4.html",
    "title": "DSA 41: Binary Search Trees - Insertion [Part 4]",
    "section": "",
    "text": "1. TreeNode\nIntroduced previously\n\nclass TreeNode:\n    def __init__(self,data,left=None,right=None):\n        self.data=data\n        self.left=left\n        self.right=right\n\n\n\n2. insert\n\nIf on the correct side (left if target less than current node else right) and\nthe child node does not exist then insert,\n\notherwise go to child node and do the comparison again.\n\n\n\ndef insert(tree_node: TreeNode, value: int):\n    current_node = tree_node\n    if not current_node:\n        print(\"cant insert empty node\")\n    if value&lt;current_node.data:\n        if not current_node.left:\n            current_node.left=TreeNode(value)\n        else:\n            insert(current_node.left, value)\n    else:\n        if not current_node.right:\n            current_node.right=TreeNode(value)\n        else:\n            insert(current_node.right, value)\n\n\n\n3. Test It\n\nroot_node = TreeNode(50)\ninsert(root_node,30)\ninsert(root_node,70)\ninsert(root_node,20)\ninsert(root_node,40)\ninsert(root_node,60)\ninsert(root_node,80)\nprint(f\"expected[50]: {root_node.data}\") #50\nprint(f\"expected[30]: {root_node.left.data}\") #30\nprint(f\"expected[70]: {root_node.right.data}\") #70\nprint(f\"expected[20]: {root_node.left.left.data}\") #20\nprint(f\"expected[40]: {root_node.left.right.data}\") #40\nprint(f\"expected[60]: {root_node.right.left.data}\") #60\nprint(f\"expected[80]: {root_node.right.left.data}\") #80\n\nexpected[50]: 50\nexpected[30]: 30\nexpected[70]: 70\nexpected[20]: 20\nexpected[40]: 40\nexpected[60]: 60\nexpected[80]: 60"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-022-recursion-part-3.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-022-recursion-part-3.html",
    "title": "DSA 22: Recursion - Factorial [Part 3]",
    "section": "",
    "text": "def factorial(nbr: int):\n    if nbr == 1:    # base-case\n        return 1    # factorial(1) \n    else:           # recursive-case\n        return nbr * factorial(nbr-1)\n\n\nimport math\nfor i in range(1,10):\n    print(f\"tony_vs_mathlib: [{factorial(i)}] vs [{math.factorial(i)}]\")\n\ntony_vs_mathlib: [1] vs [1]\ntony_vs_mathlib: [2] vs [2]\ntony_vs_mathlib: [6] vs [6]\ntony_vs_mathlib: [24] vs [24]\ntony_vs_mathlib: [120] vs [120]\ntony_vs_mathlib: [720] vs [720]\ntony_vs_mathlib: [5040] vs [5040]\ntony_vs_mathlib: [40320] vs [40320]\ntony_vs_mathlib: [362880] vs [362880]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-002-array-set-exs.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-002-array-set-exs.html",
    "title": "DSA 2: Array and Sets - Exercises",
    "section": "",
    "text": "1. Array Operations: Exercises\nFor an array \\(Arr[n_1,..n_{100}]\\) containing \\(100\\) elements.\nProvide the number_of_steps for the operation:\n\n\\(Reading()\\)\n\\(Searching()\\) target not in the array\n\\(Insertion()\\) at \\([beginning]\\)\n\\(Insertion()\\) at \\([end]\\)\n\\(Deletion()\\) at \\([beginning]\\)\n\\(Deletion()\\) at \\([end]\\)\n\nof the array.\n\n\n1.1 Array Operations: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on array \\(\\{a_i\\}^{100}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Reading()\\) any position in the array\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- Reading an array is like having a numpad and pressing/accessing the number required at the time needed.- No requirement count up to a particular number, we can see all numbers at once.\n\n\n\\(Searching()\\) target not in the array\n\\(O(n)\\)\n\\(O(100)=100\\) steps\n- Search (or iterate) through whole array- i.e. every single item is read once and checked against a target- It could be argued that \\(Comparison()\\) is an operation though but here we do not consider it as one.\n\n\n\\(Insertion()\\) at \\([beginning]\\)\n\\(O(n+1)\\)\n\\(O(101+1)=101\\) steps\n- \\(Move()\\) each item right by one- \\(Move()\\) last item \\(Arr[n] \\to Arr[n+1]\\) - \\(Move()\\) \\(2nd\\_last\\) item to last \\(Arr[n+1] \\to Arr[n],\\ ...etc\\)- After \\(MovingAll()\\) items \\(\\to\\) \\(n\\) operations - \\(Insert()\\) value into array in \\(1\\ step\\)  - \\(Total=100+1=101\\ steps\\)\n\n\n\\(Insertion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- Go to end of array and \\(Insert()\\) value in \\(1\\ step\\)\n\n\n\\(Deletion()\\) at \\([beginning]\\)\n\\(O(n)\\)\n\\(O(99+1)=100\\) steps\n- \\(Delete()\\) \\([first]\\) item in $1 step - This leaves \\((n-1)\\) items left in the array - Move each item right by 1 - Thus, \\(Arr[1] \\to Arr[0],\\ Arr[2] \\to Arr[1]...etc...(n-1)\\ times\\) - \\(Total=1+99=100\\ steps\\)\n\n\n\\(Deletion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- \\(Delete()\\) \\([last]\\) item in \\(1\\ step\\)\n\n\n\n\n\n2. Array-Based Set Operations\nFor an array-based set \\(Set\\{n_1,..n_{100}\\}\\) containing \\(100\\) elements.\nProvide the number_of_steps for the operation:\n\n\\(Reading()\\)\n\\(Searching()\\) target not in set\n\\(Insertion()\\) new_value at \\([beginning]\\)\n\\(Insertion()\\) new_value at \\([end]\\)\n\\(Deletion()\\) at \\([beginning]\\)\n\\(Deletion()\\) at \\([end]\\)\n\nof the set.\n\n\n2.1 Array-Based Set Operations: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on set \\(\\{a_i\\}^{100}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Reading()\\) any position in the set\n\\(O(1)\\)\n\\(O(1)\\)\n- Same as array\n\n\n\\(Searching()\\) target not in the set\n\\(O(n)\\)\n\\(O(100)\\)\n- Same as array\n\n\n\\(Insertion()\\) at \\([beginning]\\)\n\\(O(n+1)\\)\n\\(O(2*100+1)=O(201)\\)\n- Search whole array: \\(100\\ steps\\) - \\(Move()\\ or\\ Shift()\\) items right from \\(Set{0} \\to Set{1}, Set{1} \\to Set{2}...\\) (Same as array): \\(100\\ steps\\) - \\(Insert()\\): \\(1\\ step\\) - \\(Search(100)\\) + \\(Move(100)\\) + \\(Insert(1)\\) = \\(201\\ steps\\)\n\n\n\\(Insertion()\\) at \\([end]\\)\n\\(O(n+1)\\)\n\\(O(100+1)=O(101)\\)\n- \\(Search(100)\\) then \\(Insert(1)\\) =\\(101\\ steps\\)\n\n\n\\(Deletion()\\) at \\([beginning]\\)\n\\(O(n)\\)\n\\(O(n)\\)\n- \\(Delete(1)\\) then \\(ShiftLeft(99)\\) = \\(100\\ steps\\)\n\n\n\\(Deletion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)\\)\n- \\(Delete(1)\\)=\\(1\\ steps\\)\n\n\n\n\n\n3. \\(Search()\\) vs \\(Count()\\) In Arrays: Exercises\n\\(Search()\\):\n\nFinds the \\(first\\ instance\\) of a \\(given\\_value\\) in an array.\n\n\\(Count()\\):\n\nHow many steps to find all the target_value (\\(every\\ instance\\) of a \\(given\\_value\\)). Give your answer \\(N\\).\n\n\n\n3.1 \\(Search()\\) vs \\(Count()\\) In Arrays: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on array \\(\\{a_i\\}^{n}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Count()\\) target_value in array\n\\(O(n)\\)\n\\(O(1)=1\\) steps\n- \\(Search(n)\\) whole array - Increase \\(Counter()\\) by 1 each time an occurence of target_value is seen"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-025-recursion-part-6.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-025-recursion-part-6.html",
    "title": "DSA 25: Recursion - Exercises [Part 6]",
    "section": "",
    "text": "1. Staircase Problem\nA staircase of N steps, and a person has the ability to climb one, two, or three steps at a time.\n\nInput: Number of steps in staircase\n\nOutput: Unique possible paths.\n\n\ndef n_paths(n):\n    if n&lt;0:\n        return 0\n    if n==0 or n==1:\n        return 1\n    return n_paths(n-1) + n_paths(n-2) + n_paths(n-3)\nn_paths(3)\n\n4\n\n\n\n\n2. Count Characters\n\nInput: [\"ab\", \"c\", \"def\", \"ghij\"]\n\nOutput: 10\n\n\ndef count_chars(string):\n    if not string:\n        return 0\n    return len(string[0]) + count_chars(string[1:])\n\ncount_chars([\"ab\", \"c\", \"def\", \"ghij\"])\n\n10\n\n\n\n\n3. Even-Only Array\n\nInput: Any array of integers\n\nOutput: A new array of even values of original array\n\n\ndef even_only(arr):\n    if not arr:\n        return []\n    if arr[0]%2==0:\n        return [arr[0]] + even_only(arr[1:])\n    return even_only(arr[1:])\neven_only(arr=[1,2,3,4,5,6])\n\n[2, 4, 6]\n\n\n\n\n4. Get ‘x’ Index\n\nInput: “abcdefghijklmnopqrstuvwxyz”\n\nOutput: 23\n\n\ndef get_x_idx(string):\n    if string[0]==\"x\":\n        return 0\n    else:\n        return get_x_idx(string[1:]) + 1\nget_x_idx(\"abcdefghijklmnopqrstuvwxyz\")\n\n23\n\n\n\n\n5. Unique Paths Problem\n\nInput: number of rows & number of columns\nOutput: calculates the number of possible “shortest” paths from the upper-leftmost square to the lower-rightmost square.\n\n\ndef unique_paths(rows,cols):\n    if rows==1 or cols==1:\n        return 1\n    return unique_paths(rows-1,cols)+unique_paths(rows,cols-1)\nunique_paths(3,3)\n\n6"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-031-quickselect-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-031-quickselect-part-2.html",
    "title": "DSA 31: Quickselect [Part 2]",
    "section": "",
    "text": "1. quickselect: Function\nThe quickselect (& quicksort) uses the:\n\npartition algorithm\n\nintroduced in DSA 30: Quicksort [Part 1] post.\n\nto rearrange an array to be below and above a pivot\n\n\ndef quickselect(arr, k, l, r):\n    if r-l&lt;=0:\n        return\n    p=quickselect(arr, k, l, r)\n    if k&lt;p:\n        return quickselect(arr,k,l,p-1)\n    elif k&gt;p:\n        return quickselect(arr,k,l+1,r)\n    else:\n        return arr[p]\n\n\n\n2. quickselect: Instance Method within SortableArray class\nA SortableArray class also previously introduced:\n\nintroduced in DSA 30: Quicksort [Part 1] post.\n\n\nclass SortableArray():\n    def __init__(self, arr):\n        self.arr = arr\n        \n    def partition(self, l: int, r: int):\n        p=r\n        pivot=self.arr[p]\n        r-=1\n        while True:\n            while self.arr[l]&lt;pivot:\n                l+=1\n            while self.arr[r]&gt;pivot:\n                r-=1\n            if l&gt;=r: \n                break\n            else:\n                self.arr[l],self.arr[r]=self.arr[r],self.arr[l]\n                l+=1\n        self.arr[l],self.arr[p]=self.arr[p],self.arr[l]\n        return l\n\n    def quickselect(self, k, l, r):\n        if r-l&lt;=0:\n            return self.arr[l]\n        \n        p = self.partition(l, r)\n        \n        if k&lt;p:\n            return self.quickselect(k,l,p-1)\n        elif k&gt;p:\n            return self.quickselect(k,l+1,r)\n        else:\n            return self.arr[p]\n\n\n\n3. Testing quickselect\n\n\n\nParameter\nValues\n\n\n\n\ninput_array\n052163\n\n\nsorted_array\n012356\n\n\nindexes\n012345\n\n\nk\nindex 5 of sorted input array\n\n\nOutput\n6\n\n\n\n\narr = [int(char) for char in \"052163\"]\nsortable_arr = SortableArray(arr)\nsortable_arr.quickselect(5,l=0,r=len(sortable_arr.arr)-1)\n\n6"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-046-binary-search-trees-part-9.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-046-binary-search-trees-part-9.html",
    "title": "DSA 46: Binary Search Trees - Delete [Part 9]",
    "section": "",
    "text": "1. TreeNode, Binary Tree & insert_node: Setup\nIntroduced previously.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCannot insert duplicates\")\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE left-child : GO LEFT[{current_node.left.data}]\")\n            current_node=current_node.left\n            return insert_node(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO left-child: INSERTED LEFT CurrentLeft[{current_node.left.data}]\")\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has ONE right-child : GO right[{current_node.right.data}]\")\n            current_node=current_node.right\n            return insert_node(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n            print(f\"t[{target}]|c[{current_node.data}]: \\t\\tCurrent[{current_node.data}] has NO right-child: INSERTED right Currentright[{current_node.right.data}]\")\n    pass\n\ndef insert_node_clean(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        return  \n    if target &lt; current_node.data: # left\n        if current_node.left: # go left-child: if exists\n            current_node=current_node.left\n            return insert_node_clean(current_node, target)\n        else: # insert left-child: if not exist\n            current_node.left = TreeNode(target)\n            return current_node.left\n    else:\n        if current_node.right: # go right-child: if exists\n            current_node=current_node.right\n            return insert_node_clean(current_node, target)\n        else: # insert right-child: if not exist\n            current_node.right = TreeNode(target)\n    pass\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \ndef insert_node_list(root_node:TreeNode, node_list: list[int], show_outputs:bool=True):\n    for node in node_list: \n        if show_outputs:\n            insert_node(root_node, node) \n        else:\n            insert_node_clean(root_node, node) \n\ndef create_tree_from_root_node(root_node = TreeNode(50),node_list=[25,75,10,33,56,89,4,11,30,40,52,61,82,95]):\n    insert_node_list(root_node, node_list,show_outputs=False)\n    \n\n\n\n2. Confirm Tree\n\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95\nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\nprint(f\"[L1] root.data: \\t\\t\\t[{root.data}] (expected: 50)\")\nprint()\nprint(f\"[L2] root.left.data: \\t\\t\\t[{root.left.data}] (expected: 25)\")\nprint(f\"[L2] root.right.data: \\t\\t\\t[{root.right.data}] (expected: 75)\")\nprint()\nprint(f\"[L3] root.left.left.data:      \\t\\t[{root.left.left.data}] (expected: 10)\")\nprint(f\"[L3] root.left.right.data:     \\t\\t[{root.left.right.data}] (expected: 33)\")\nprint(f\"[L3] root.right.left.data:     \\t\\t[{root.right.left.data}] (expected: 56)\")\nprint(f\"[L3] root.right.right.data:    \\t\\t[{root.right.right.data}] (expected: 89)\")\nprint()\nprint(f\"[L4] root.left.left.left.data: \\t\\t[{root.left.left.left.data}]  (expected:  4)\")\nprint(f\"[L4] root.left.left.right.data:  \\t[{root.left.left.right.data}] (expected: 11)\")\nprint(f\"[L4] root.left.right.left.data:  \\t[{root.left.right.left.data}] (expected: 30)\")\nprint(f\"[L4] root.left.right.right.data: \\t[{root.left.right.right.data}] (expected: 40)\")\nprint()\nprint(f\"[L4] root.right.left.left.data:  \\t[{root.right.left.left.data}] (expected: 52)\")\nprint(f\"[L4] root.right.left.right.data: \\t[{root.right.left.right.data}] (expected: 61)\")\nprint(f\"[L4] root.right.right.left.data: \\t[{root.right.right.left.data}] (expected: 82)\")\nprint(f\"[L4] root.right.right.right.data:\\t[{root.right.right.right.data}] (expected: 95)\")\n\n[L1] root.data:             [50] (expected: 50)\n\n[L2] root.left.data:            [25] (expected: 25)\n[L2] root.right.data:           [75] (expected: 75)\n\n[L3] root.left.left.data:           [10] (expected: 10)\n[L3] root.left.right.data:          [33] (expected: 33)\n[L3] root.right.left.data:          [56] (expected: 56)\n[L3] root.right.right.data:         [89] (expected: 89)\n\n[L4] root.left.left.left.data:      [4]  (expected:  4)\n[L4] root.left.left.right.data:     [11] (expected: 11)\n[L4] root.left.right.left.data:     [30] (expected: 30)\n[L4] root.left.right.right.data:    [40] (expected: 40)\n\n[L4] root.right.left.left.data:     [52] (expected: 52)\n[L4] root.right.left.right.data:    [61] (expected: 61)\n[L4] root.right.right.left.data:    [82] (expected: 82)\n[L4] root.right.right.right.data:   [95] (expected: 95)\n\n\n\n\n3. find_successor_node\n\ndef find_successor_node(target_node: TreeNode):\n    successor_node  = target_node.right # go right    \n    print(f\"t{target_node.data}.tr[{successor_node.data}]: go right...{successor_node.data}\")        \n    \n    if not successor_node.left:\n        # [75] to succeed [50]\n        if successor_node.right:\n            print(f\"s{successor_node.data} has no left kids: s will t[{target_node.data}], t.right -&gt; s.right[{successor_node.right.data}]\")        \n            target_node.data = successor_node.data # no need to update targets parents because only replacing data not nodes\n            target_node.right = successor_node.right\n        else:\n            target_node.data = successor_node.data\n            print(f\"s{successor_node.data} has no left kids: s will succeed t[{target_node.data}], t.right -&gt; s.right[{None}]\")        \n        pass\n\n    while successor_node.left:\n        print(f\"s{successor_node.data}.l[{successor_node.left.data}]: s has a left_child, go left...\")        \n        \n        parent_node = successor_node\n        successor_node = successor_node.left\n    \n    print(f\"s{successor_node.data}: s no further left_childs, check is s has a right_child...\")        \n    \n    # successor_node is not left_most child\n    # 1.  has no_right_child: no further action\n    #   i.    parent_left = None instead of parent_left = s_node (removing s_node to replace target_node)\n    #   ii    target.data = s_node.data\n    \n    if not successor_node.right:\n        print(f\"s{successor_node.data}: s has 0 right_child...p[{parent_node.data}] from p.left[{parent_node.left.data}] -&gt; p.left[{None}]\")        \n        parent_node.left = None\n        \n    if successor_node.right:\n        print(f\"s{successor_node.data}: s has 1 right_child...p[{parent_node.data}] from p.left[{parent_node.left.data}] -&gt; s[{successor_node.data}].right[{successor_node.right.data}]\")        \n        # print(f\"s{successor_node.data}: succesor has 1 right_child...parent.left -&gt; successors.right[{successor_node.right.data}]\")        \n        parent_node.left = successor_node.right\n        \n    # 2. has snode has_right_child\n    #   i.  parent_left = snode_right_child\n    #   ii  target.data = s_node.data\n    \n    print(f\"s{successor_node.data} to succeed t[{target_node.data}]\")\n    target_node.data = successor_node.data\n    return successor_node\n\n\n# NO RIGHT CHILD\n#           [t50]\n#      25         [s75]\n\n# NO RIGHT CHILD\n#           [s75]\n#      25         []\n\n# RIGHT CHILD\n#           [t50]\n#      25         [s75]\n#                       [sc80]\n\n# RIGHT CHILD\n#           [s75]\n#      25         [sc80]\n#                        [scc81]\n\n\n\n4. delete_node\n\ndef delete_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    parent_node = None\n    target_node = None\n    while current_node:\n        if target == current_node.data:\n            target_node = current_node\n            print(f\"t{target}==c{current_node.data}: target found! [Determine Children Count]...\")        \n            break\n        elif target &lt; current_node.data: # go left\n            print(f\"t{target}&lt;-c{current_node.data}: go left...\")        \n            parent_node = current_node\n            current_node = current_node.left\n        else: # go right\n            print(f\"t{target}-&gt;c{current_node.data}: go right...\")        \n            parent_node = current_node\n            current_node = current_node.right\n    if not target_node:\n        print(f\"t{target}!=p{parent_node.data}: target not found because node has no more children!\")        \n        return\n    \n    if target_node.left and target_node.right:\n        print(f\"t{target}.lr[{target_node.left.data},{target_node.right.data}]: target has two kids! [Find Successor Node]...\")        \n        s_node = find_successor_node(target_node)\n        return\n    else: # 0 or 1 kid\n        targets_child = (target_node.left or target_node.right)\n        print(f\"t[{target}]: target has 0 or 1 children! [Find Successor Node]...\")        \n        \n        if not parent_node: # root node has no parents: replace parent (and its kids) with child (and its kids)\n            print(f\"t{target}.tc[{targets_child.data}]:tc[{targets_child.data}] succeeds t[{target}], no parents ptrs to update\")        \n            target_node.data = targets_child.data\n            target_node.left = targets_child.left\n            target_node.right = targets_child.right\n        elif parent_node.left == target_node:\n            if targets_child:\n                print(f\"t{target}.tc[{targets_child.data}]:tc[{targets_child.data}] succeeds t[{target}], p[{parent_node.data}]l[{parent_node.left.data}] updated to point to tc[{targets_child.data}]\")        \n                parent_node.left = targets_child\n                print(f\"t{target}.tc[{targets_child.data}]:final result p[{parent_node.data}]l[{parent_node.left.data}]\")        \n            else: \n                print(f\"t{target} has no kids: {target} deleted, parent_node.left pointing to [None]\")        \n                parent_node.left = targets_child\n            return \n\n        elif parent_node.right == target_node:\n            if targets_child:\n                print(f\"t{target}.tc[{targets_child.data}]:tc[{targets_child.data}] succeeds t[{target}], p[{parent_node.data}]r[{parent_node.right.data}] updated to point to tc[{targets_child.data}]\")        \n                parent_node.right = targets_child\n                print(f\"t{target}.tc[{targets_child.data}]:final result p[{parent_node.data}]r[{parent_node.right.data}]\")        \n            else: \n                print(f\"t{target} has no kids: {target} deleted, parent_node.right pointing to [None]\")        \n                parent_node.right = targets_child\n                \n            return \n        \n    return \n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95 \nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\ndelete_node(root, 50)\n# delete_node(root, 10)\n\nt50==c50: target found! [Determine Children Count]...\nt50.lr[25,75]: target has two kids! [Find Successor Node]...\nt50.tr[75]: go right...75\ns75.l[56]: s has a left_child, go left...\ns56.l[52]: s has a left_child, go left...\ns52: s no further left_childs, check is s has a right_child...\ns52: s has 0 right_child...p[56] from p.left[52] -&gt; p.left[None]\ns52 to succeed t[50]\n\n\n\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root, node_list=[25])\ndelete_node(root,50)\n\n\nroot.data\n\nt50==c50: target found! [Determine Children Count]...\nt[50]: target has 0 or 1 children! [Find Successor Node]...\nt50.tc[25]:tc[25] succeeds t[50], no parents ptrs to update\n\n\n25\n\n\n\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root, node_list=[25,10])\ndelete_node(root,25)\n\nt25&lt;-c50: go left...\nt25==c25: target found! [Determine Children Count]...\nt[25]: target has 0 or 1 children! [Find Successor Node]...\nt25.tc[10]:tc[10] succeeds t[25], p[50]l[25] updated to point to tc[10]\nt25.tc[10]:final result p[50]l[10]\n\n\n\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root, node_list=[51,52])\ndelete_node(root,51)\n\nt51-&gt;c50: go right...\nt51==c51: target found! [Determine Children Count]...\nt[51]: target has 0 or 1 children! [Find Successor Node]...\nt51.tc[52]:tc[52] succeeds t[51], p[50]r[51] updated to point to tc[52]\nt51.tc[52]:final result p[50]r[52]\n\n\n\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\ndelete_node(root, 4)\n\nt4&lt;-c50: go left...\nt4&lt;-c25: go left...\nt4&lt;-c10: go left...\nt4==c4: target found! [Determine Children Count]...\nt[4]: target has 0 or 1 children! [Find Successor Node]...\nt4 has no kids: 4 deleted, parent_node.left pointing to [None]\n\n\n\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root, node_list=[25,75])\ndelete_node(root,75)\n\n\n# NO RIGHT CHILD\n#           [t50]\n#      25         [s75]\n\n# NO RIGHT CHILD\n#           [s75]\n#      25         []\n\nt75-&gt;c50: go right...\nt75==c75: target found! [Determine Children Count]...\nt[75]: target has 0 or 1 children! [Find Successor Node]...\nt75 has no kids: 75 deleted, parent_node.right pointing to [None]\n\n\n\n\n# RIGHT CHILD\n#           [t50]\n#      25         [s75]\n#                       [sc80]\n\n# RIGHT CHILD\n#           [s75]\n#      25         [sc80]\n#                        [scc81]\n\n\n#             [50]X\n#      25            [75]\n#  10     33      [56]     89  \n# 4  11 30  40 [52]  61 82  95 \nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\ndelete_node(root, 50)\n\n\n#             [52]\n#      25            [75]\n#  10     33      [56]     89  \n# 4  11 30  40 []  61 82  95 \n\nprint(root.data) # expected 52\nprint(root.right.left.data) # expected 56\nprint(root.right.left.left.data) # expected error\n\nt50==c50: target found! [Determine Children Count]...\nt50.lr[25,75]: target has two kids! [Find Successor Node]...\nt50.tr[75]: go right...75\ns75.l[56]: s has a left_child, go left...\ns56.l[52]: s has a left_child, go left...\ns52: s no further left_childs, check is s has a right_child...\ns52: s has 0 right_child...p[56] from p.left[52] -&gt; p.left[None]\ns52 to succeed t[50]\n52\n56\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[20], line 18\n     16 print(root.data) # expected 52\n     17 print(root.right.left.data) # expected 56\n---&gt; 18 print(root.right.left.left.data) # expected error\n\nAttributeError: 'NoneType' object has no attribute 'data'\n\n\n\n\n#             [50]X\n#      25            [75]\n#  10     33      [56]     89  \n# 4  11 30  40 [52]  61 82  95 \n#                [55]\nroot = None\nroot = TreeNode(50)\ncreate_tree_from_root_node(root)\ninsert_node(root, 55)\ndelete_node(root, 50)\n\nroot.right.left.left.data # expected 55\n\n\n#             [52]\n#      25            [75]\n#  10     33      [56]     89  \n# 4  11 30  40 [55]  61 82  95 \n#                  []\n\nt[55]|c[50]:        Current[50] has ONE right-child : GO right[75]\nt[55]|c[75]:        Current[75] has ONE left-child : GO LEFT[56]\nt[55]|c[56]:        Current[56] has ONE left-child : GO LEFT[52]\nt[55]|c[52]:        Current[52] has NO right-child: INSERTED right Currentright[55]\nt50==c50: target found! [Determine Children Count]...\nt50.lr[25,75]: target has two kids! [Find Successor Node]...\nt50.tr[75]: go right...75\ns75.l[56]: s has a left_child, go left...\ns56.l[52]: s has a left_child, go left...\ns52: s no further left_childs, check is s has a right_child...\ns52: s has 1 right_child...p[56] from p.left[52] -&gt; s[52].right[55]\ns52 to succeed t[50]\n\n\n55"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-036-nodes-part-4.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-036-nodes-part-4.html",
    "title": "DSA 36: Doubly Linked List [Part 4]",
    "section": "",
    "text": "1. DoublyLinkedList (DLL)\nDLL always keeps track of:\n\nhead nodes,\ntail nodes,\nNot just head (Singly Linked List).\n\n\nclass Node():\n    def __init__(self, data):\n        self.data = data\n        self.next_node = None\n        self.prev_node = None\n        \nclass DoublyLinkedList():\n    def __init__(self, first_node: Node, last_node: Node):\n        self.first_node = first_node\n        self.last_node = last_node\n\n\n\n2. Nodes & DoublyLinkedList: Setup\n\n\n2.1 nodes Instances: Setup\n\nnode0 = Node(\"Once\")\nnode1 = Node(\"Upon\")\nnode2 = Node(\"A\")\nnode3 = Node(\"Time\")\n\nnode0.next_node=node1\nnode1.next_node=node2\nnode2.next_node=node3\nnode3.next_node=node0\n\nnode0.prev_node=node3\nnode1.prev_node=node0\nnode2.prev_node=node1\nnode3.prev_node=node2\n\n\n\n2.2 double_linked_list Instance: Setup\n\ndll = DoublyLinkedList(node0, node3)\n\n\n\n3. append: DLL Instance Method\n\n\n3.1 Incomplete Circular DLL (Ignore)\n\n# TURSN OUT I WAS TRYING TO DO A CIRCULAR DLL FROM SCRATCH BEFORE THE STANDARD ONE\n# def append_to_end_dll(doubly_linkedlist: DoublyLinkedList, new_node: Node)-&gt;None:\n    \n    \n#     # [\"once\",\"upon\",\"a\",\"time\"] -&gt; [\"once\",\"upon\",\"a\",\"time\",\"mate\"]\n#     ### A. Configure [new_node] to be [last_node]:\n#     # [1] [new_node] -next-&gt; [first_node]     # [2] [new_node] -prev-&gt; [last_node] (current last node)\n    \n#     ### B. Configure [previous_last_node]: [next_node] to point to [new_node]\n#     # previous_last_node.next_node -&gt; new_node\n    \n#     ### C. Configure [first_node]: [prev_node] to point to [new_node]\n#     # first_node.prev_node -&gt; new_node\n    \n    \n#     # NODE-POINTER STUFF\n#     new_node.next_node = doubly_linkedlist.first_node       # [A1] # CIRCULAR VERSION ONLY\n#     new_node.prev_node = doubly_linkedlist.last_node        # [A2]\n    \n#     doubly_linkedlist.last_node.next_node = new_node        # [B]\n#     doubly_linkedlist.first_node.prev_node = new_node       # [C] # CIRCULAR VERSION ONLY\n    \n#     # DLL-POSITION STUFF\n#     doubly_linkedlist.last_node=new_node\n    \n    \n#     return None\n\n\n\n3.2 Append for Standard DLL\n\nif not pythonic falsy syntax: previously introduced.\n\n\ndef append_to_end_dll(doubly_linkedlist: DoublyLinkedList, new_node: Node)-&gt;None:\n    \n    # [1] EMPTY DLL\n    if not doubly_linkedlist.first_node: # ie first_node is None or falsy -&gt; True\n        doubly_linkedlist.first_node=new_node\n        doubly_linkedlist.last_node=new_node\n    \n    # [2] NODE-POINTER STUFF\n    # new_node.next_node = doubly_linkedlist.first_node       # [A1] CIRCULAR-ONLY\n    new_node.prev_node = doubly_linkedlist.last_node        # [A2]\n    \n    doubly_linkedlist.last_node.next_node = new_node        # [B]\n    # doubly_linkedlist.first_node.prev_node = new_node       # [C] CIRCULAR-ONLY\n    \n    # [3] DLL-NODE-POSITION STUFF\n    doubly_linkedlist.last_node=new_node\n    \n    return None\n\n\n\n3.3 Test\n\ndll = DoublyLinkedList(node0, node3)\nprint(dll.last_node.data)\nappend_to_end_dll(dll, Node(\"mate\"))\nprint(dll.last_node.data)\nappend_to_end_dll(dll, Node(\"lads\"))\nprint(dll.last_node.data)\n\nTime\nmate\nlads"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-039-binary-search-trees-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-039-binary-search-trees-part-2.html",
    "title": "DSA 39: Binary Search Trees - Rules [Part 2]",
    "section": "",
    "text": "1. Binary Trees and Binary Search Trees\n\n\n1.1 Binary Tree\nIs a tree in which each node has either:\n\nzero,\none, or\ntwo children.\n\n\n\n1.2 Binary Search Tree\nIs a binary tree abiding to the following rules:\n\nEach node can have at most\n\none left child and\none right child.\n\nA node’s left descendants can only contain have:\n\nvalues that are less than the node itself.\n\nA node’s right descendants can only contain have:\n\nvalues that are greater than the node itself.\n\n\n\n\n2. Basic TreeNode Implementation\n\nclass TreeNode:\n    def __init__(self, data: int, left=None, right=None):\n        self.data        = data\n        self.left_child  = left\n        self.right_child = right\n\n\n\n3. Basic Binary Search Tree Implementation\n\nnode1 = TreeNode(25)\nnode2 = TreeNode(75)\nroot = TreeNode(50, node1, node2)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#linearsearch-n_steps-of-orderd_array",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#linearsearch-n_steps-of-orderd_array",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "1.1 \\(LinearSearch()\\): n_steps of orderd_array:",
    "text": "1.1 \\(LinearSearch()\\): n_steps of orderd_array:\n\nHow many steps perform a linear search for the number 8 in the ordered array [2, 4, 6, 8, 10, 12, 13]?"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "1.2 Written Answer",
    "text": "1.2 Written Answer\n\nCount up from index 0 through array to find the target.\nIt’s the 3rd index, or 4th item, therefore 4 steps."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-answer",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-answer",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "1.3 Python Answer",
    "text": "1.3 Python Answer\n\ndef calc_linear_search_n_steps(input_arr, target):\n    print(rf\"LinearSearch() began on array: {input_arr}\")\n    counter = 0\n    for i,v in enumerate(input_arr):\n        counter += 1\n        if input_arr[i] == target:\n            print(rf\"Target found [{target}]: [{counter}] steps\")\n            return counter\n    print(rf\"Target not found in [{input_arr}]\")\n    return False\nlinear_search_n_steps = calc_linear_search_n_steps([2, 4, 6, 8, 10, 12, 13], 8)\n\nLinearSearch() began on array: [2, 4, 6, 8, 10, 12, 13]\nTarget found [8]: [4] steps"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#binarysearch-n_steps-of-orderd_array",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#binarysearch-n_steps-of-orderd_array",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "2.1 \\(BinarySearch()\\): n_steps of orderd_array:",
    "text": "2.1 \\(BinarySearch()\\): n_steps of orderd_array:\nHow many steps would binary search take for the previous example?"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer-1",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "2.2 Written Answer",
    "text": "2.2 Written Answer\nChoose middle index and compare against target, here it is 1 step."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-answer-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-answer-1",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "2.3 Python Answer",
    "text": "2.3 Python Answer\n\ndef calc_binary_search_n_steps(input_arr, target):\n    print(rf\"BinarySearch() began on array: {input_arr}\")\n\n    l,r = 0, len(input_arr)-1 # set left, right index bounds\n    counter = 0\n    while l&lt;=r:\n        counter+=1\n        m=(l+r)//2 # middle-index\n        if input_arr[m] == target:\n            print(rf\"Target found [{target}]: [{counter}] steps\")\n            return counter\n        elif input_arr[m] &lt; target:\n            l=m+1\n        elif input_arr[m] &gt; target:\n            r=m-1\n    print(rf\"Target not found in [{input_arr}]\")\n    return False\ncalc_binary_search_n_steps([2, 4, 6, 8, 10, 12, 13], 8)\n    \n\nBinarySearch() began on array: [2, 4, 6, 8, 10, 12, 13]\nTarget found [8]: [1] steps\n\n\n1"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#middle-index-m---some-comments",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#middle-index-m---some-comments",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "2.4 Middle Index: m - Some Comments",
    "text": "2.4 Middle Index: m - Some Comments\nI did not fully understand how the middle-index m is calculated despite it looking simple:\n\nm=(l+r)//2"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#middle-index-m-table",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#middle-index-m-table",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "2.5 Middle-Index m Table",
    "text": "2.5 Middle-Index m Table\nSo, I created a table showing: * left and right-indices (like the algorithm) * middle-index calculation before rounding down * middle-index calculation after rounding down\nI didnt have any intuition on how it increments, so for me it’s fascinating and surprising that it increments by 2 each time…. Some math thing going on which I dont understand but at least I know how it works a bit more after this table\nTop Table: Calculates m with rounding down (as in algorithm):\n\nm = (l+r)//2\n\ni.e. the middle index chosen to compare against the target\n\n\nBottom Table: Calculates m with no rounding:\n\nm = (l+r)/2\n\nNotice the pre-rounded value increments is by 0.5\nAnd we dont have non-integer indexing so this forces us to round up or down,\nSo by rounding down, we see m goes up every 2 indices, pretty cool and also makes sense."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#binarysearch-max_n_steps-of-orderd_array",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#binarysearch-max_n_steps-of-orderd_array",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "3.1 \\(BinarySearch()\\): max_n_steps of orderd_array:",
    "text": "3.1 \\(BinarySearch()\\): max_n_steps of orderd_array:\nWhat is the maximum number of steps it would take to perform a binary search on an array of size 100,000?"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer-2",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#written-answer-2",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "3.2 Written Answer",
    "text": "3.2 Written Answer\nA characteristic of the \\(BinarySearch()\\) is that:\n\nThe number of items (array_size) searchable doubles at each \\(step\\):\n\ncan be described by an exponential function\nwith base of 2\nwhere n is the number of steps:\n\n\nDefined as: \\[array\\_size = 2^n\\]\nThat is, the questions is asking: \\[100,000 = 2^n\\] \\[\\log(100,000) = \\log(2^n)\\] \\[\\log(100,000) = n\\log(2)\\] \\[\\frac{\\log(100,000)}{\\log(2)} = n\\] \\[n=\\frac{\\log(100,000)}{\\log(2)}\\] \\[n=16.610\\ steps(3\\ d.p)\\]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-function",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#python-function",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "3.3 Python Function",
    "text": "3.3 Python Function\n\ndef calc_bin_search_nsteps(arr_size: int):\n    import numpy as np\n    # 2^n_steps = arr_size\n    # log (2^n_steps) = log (arr_size)\n    # (n_steps) * log (2) = log (arr_size)\n    # (n_steps)  = log (arr_size)/log(2)\n    # (n_steps)  = log (arr_size)/log(2)\n    # (n_steps  = log (100_000)/log(2)\n    return np.log(arr_size)/np.log(2)\n\nbin_search_nsteps = calc_bin_search_nsteps(100_000)\nbin_search_nsteps\n\nnp.float64(16.609640474436812)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#n-chart",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-003-bin-search-exs.html#n-chart",
    "title": "DSA 3: Binary Search - Exercises",
    "section": "3.4 \\(2^n\\) Chart",
    "text": "3.4 \\(2^n\\) Chart\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n### x-values ###\nxpt = 1\nx_deviation = 16\nx_no_of_increments = 32\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\n# xs = np.linspace(xs_min, xs_max, x_increments)  # XS\nxs = np.linspace(0, xs_max, x_no_of_increments)  # XS\nprint(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 1]\nxs = xs[xs &gt; 0]\n\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$f(x)= log(x)$'   # LABEL\n# fx_fx = lambda x: np.log(x)  # f(x)\n\n# ### y-values ###\n# ys_fx = fx_fx(xs)            # ys=f(xs)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### other plots ###\nlbl_fx2 = r'$f(x)=2^x$'\nfx_fx2 = lambda x: 2**x\nys_fx2 = fx_fx2(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6s(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_ta\n# ngent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'o', markersize=1, label=lbl_fx)\nplt.plot(xs, ys_fx2,  '-', markersize=1, label=lbl_fx2)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=1, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_fx2,      'bo-', linewidth=2, markersize=8, label=lbl_fx2)\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx\nplot_title = lbl_fx2\nplt.title(plot_title, loc='left')\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_fx2 + \" and \" + lbl_fx2 + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# zoom! enhance! #\n# zoom_inc = 20\n# plt.xlim(xpt-zoom_inc,xpt+zoom_inc)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\nplt.plot(bin_search_nsteps, 100_000,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(20000)) # minor ticks\n# ax.xaxis.set_minor_locator(ticker.MultipleLocator(2)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n[ 0.          0.5483871   1.09677419  1.64516129  2.19354839  2.74193548\n  3.29032258  3.83870968  4.38709677  4.93548387  5.48387097  6.03225806\n  6.58064516  7.12903226  7.67741935  8.22580645  8.77419355  9.32258065\n  9.87096774 10.41935484 10.96774194 11.51612903 12.06451613 12.61290323\n 13.16129032 13.70967742 14.25806452 14.80645161 15.35483871 15.90322581\n 16.4516129  17.        ]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#use-cases",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#use-cases",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "1.1 Use-Cases",
    "text": "1.1 Use-Cases\nS & Q’s are great for handling temporary data such as:\n\noperating system architecture\nprinting jobs\ntraversing data\na chef receiving menu orders"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#importance-of-order",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#importance-of-order",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "1.2 Importance Of Order",
    "text": "1.2 Importance Of Order\n\nStacks and Queues a special focus on the order in which the data is handled."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#temporary-data---orders-sent-to-a-kitchen",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#temporary-data---orders-sent-to-a-kitchen",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "1.3 Temporary data - Orders Sent To A Kitchen",
    "text": "1.3 Temporary data - Orders Sent To A Kitchen\n\nTemporary data are like the food orders sent to diners kitchen for a chef to cook:\n\nThe food order is important until the meal is made and delivered.\n\nThe chef only requires the food order (the items to be cooked), not a receipt.\n\nAfter order fulfilled (or processed), the food order slip is thrown away.\n\nThe food order produces a receipt but that is a separate thing from the food order itself.\nThe chef does not cook a dish based on a receipt (generally):\n\nMay include information not required by the Chef such as Prices, Taxes, Fees and other."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#it-is-temporary",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#it-is-temporary",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "1.4 It is Temporary…",
    "text": "1.4 It is Temporary…\n\nThe data will have some meaning before being processed.\nThe data will be processed.\nAfter data is processed:\n\nThe data has no meaning\nThe data is deleted (since it has no meaning, why keep it)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---array-vs-stack",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---array-vs-stack",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.1 Stacks - Array vs Stack",
    "text": "2.1 Stacks - Array vs Stack\nVisually a stack is like an array tilted rotate up 90 degrees.\n\nStart of the array 2 becomes bottom of the stack\nEnd of the array 8 becomes top of the stack"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---array-vs-stack-visual",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---array-vs-stack-visual",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.2 Stacks - Array vs Stack Visual",
    "text": "2.2 Stacks - Array vs Stack Visual"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---operation-restrictions",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---operation-restrictions",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.3 Stacks - Operation Restrictions",
    "text": "2.3 Stacks - Operation Restrictions\nA stack is an array with three restrictions:\n\nInsertion or push():\n\nonly at the end (top) of a stack.\n\nDeletion or pop():\n\nonly from the end (top) of a stack.\n\nRead or read():\n\nonly the last (top) element of a stack."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---operational-visual",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stacks---operational-visual",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.4 Stacks - Operational Visual",
    "text": "2.4 Stacks - Operational Visual\n\n\n2.4.1 My Psuedo\n\n1a. Create [stack] class\n2a. [instance attribute] [self.data]: [] (type: list)\n3a. [instance method] push(element):\n\n3b. add [element] to [self.data]\n\n4a. [instance method] pop():\n\n4b. check len(self.data) &gt; 0\n4c. return [self.data.pop()]\n\n5a. [instance method] read():\n\n5b. check len(self.data) &gt; 0\n5c. return self.data[-1]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stack-class-implementation",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#stack-class-implementation",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.5 Stack Class Implementation",
    "text": "2.5 Stack Class Implementation\n\nclass TonyIntStack:\n    def __init__(self):\n        self.data = []\n        print(\"A stack object has been created!\")\n    \n    def push(self, new_element:int):\n        \n        self.data.append(new_element)\n        print(f\"push({new_element}): {new_element} added to stack: {self.data}\")\n        \n        \n    def pop(self):\n        if len(self.data)&gt;0:\n            popped = self.data.pop()\n            print(f\"pop(): {popped} removed from stack: {self.data}\")\n        else:\n            print(f\"pop(): it's empty stack: {self.data}\")\n        \n    def read(self):\n        if len(self.data)&gt;0:\n            top = self.data[-1]\n            print(f\"read(): {top} is at the top of the stack: {self.data}\")\n            return self.data[-1]    \n        else:\n            print(f\"read(): it's empty stack! {self.data}\")"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#test-the-stack-object",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-013-stacks-part-1.html#test-the-stack-object",
    "title": "DSA 13: Stacks - An Abstract Class [Part 1]",
    "section": "2.6 Test the stack object",
    "text": "2.6 Test the stack object\n\ntony_stack = TonyIntStack()\ntony_stack.read()\ntony_stack.push(12)\ntony_stack.push(345)\ntony_stack.pop()\ntony_stack.read()\ntony_stack.push(666)\ntony_stack.push(789)\ntony_stack.read()\ntony_stack.pop()\ntony_stack.read()\ntony_stack.pop()\ntony_stack.pop()\ntony_stack.pop()\ntony_stack.pop()\n\n\nA stack object has been created!\nread(): it's empty stack! []\npush(12): 12 added to stack: [12]\npush(345): 345 added to stack: [12, 345]\npop(): 345 removed from stack: [12]\nread(): 12 is at the top of the stack: [12]\npush(666): 666 added to stack: [12, 666]\npush(789): 789 added to stack: [12, 666, 789]\nread(): 789 is at the top of the stack: [12, 666, 789]\npop(): 789 removed from stack: [12, 666]\nread(): 666 is at the top of the stack: [12, 666]\npop(): 666 removed from stack: [12]\npop(): 12 removed from stack: []\npop(): it's empty stack: []\npop(): it's empty stack: []"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-042-binary-search-trees-part-5.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-042-binary-search-trees-part-5.html",
    "title": "DSA 42: Binary Search Trees - Alternative Approaches [Part 5]",
    "section": "",
    "text": "1. Create TreeNode class: Setup\nPreviously introduced.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data=data\n        self.left=left\n        self.right=right\n\n\n\n2. Create BinaryTree: Setup\nBy connecting individual TreeNodes.\nPreviously introduced.\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \n\ndef create_custom_binary_tree()-&gt;TreeNode:\n    # Level: L4\n    node04 = TreeNode( 4, left=None, right=None)\n    node11 = TreeNode(11, left=None, right=None)\n    node30 = TreeNode(30, left=None, right=None)\n    node40 = TreeNode(40, left=None, right=None)\n    # Level: R4\n    node52 = TreeNode(52, left=None, right=None)\n    node61 = TreeNode(61, left=None, right=None)\n    node82 = TreeNode(82, left=None, right=None)\n    node95 = TreeNode(95, left=None, right=None)\n\n    # Level: L3\n    node10 = TreeNode(10, left=node04, right=node11)\n    node33 = TreeNode(33, left=node30, right=node40)\n    # Level: R3\n    node56 = TreeNode(56, left=node52, right=node61)\n    node89 = TreeNode(89, left=node82, right=node95)\n\n    # Level: L2\n    node25 = TreeNode(25, left=node10, right=node33)\n    # Level: R2\n    node75 = TreeNode(75, left=node56, right=node89)\n\n    # Level: L1\n    root_node = node50 = TreeNode(50, left=node25, right=node75)\n    return root_node\n\n\n\n3. search_node\n\n\n3.1 search_node: Recursive Approach\n\ndef search_node_recursive(root_node: TreeNode, target: int):\n    current_node = root_node\n    if target == current_node.data:\n        print(f\"Target Found! tgt{target}|node{current_node.data} \")\n        return   \n    if target &lt; current_node.data: # go left\n        if current_node.left:\n            current_node=current_node.left\n            return search_node_recursive(current_node, target)\n        else:\n            print(f\"Target Not Found! tgt{target}|node{current_node.data} has no left-child \")\n            return current_node\n    else:\n        if current_node.right:\n            current_node=current_node.right\n            return search_node_recursive(current_node, target)\n        else:\n            print(f\"Target Not Found! tgt{target}|node{current_node.data} has no right-child \")\n            return current_node\n\n\n\n3.2 search_node: Iterative Approach\n\ndef search_node_iterative(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    while current_node:\n        if target == current_node.data:\n            print(f\"Target Found! tgt{target}|node{current_node.data} \")\n            return   \n        if target &lt; current_node.data: # go left\n            if current_node.left:\n                current_node=current_node.left\n                # return search_node_while(current_node, target)\n            else:\n                print(f\"Target Not Found! tgt{target}|node{current_node.data} has no left-child \")\n                return current_node\n        else:\n            if current_node.right:\n                current_node=current_node.right\n                # return search_node_while(current_node, target)\n            else:\n                print(f\"Target Not Found! tgt{target}|node{current_node.data} has no right-child \")\n                return current_node\n\n\n\n3.3 search_node: Testing Both Approaches\n\n# create a basic tree\n#             50\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \n\nroot = create_custom_binary_tree()\n\nsearch_node_recursive(root, 61)\nsearch_node_iterative(root, 61)\n\nprint()\nprint()\nsearch_node_recursive(root, 3)\nsearch_node_iterative(root, 3)\n\nTarget Found! tgt61|node61 \nTarget Found! tgt61|node61 \n\n\nTarget Not Found! tgt3|node4 has no left-child \nTarget Not Found! tgt3|node4 has no left-child \n\n\n&lt;__main__.TreeNode at 0x7fbaf855f9d0&gt;\n\n\n\n\n4. insert_node\n\n\n4.1 insert_node: Recursive Approach\n\ndef insert_node_recursion(root_node:TreeNode, target: int):\n    current_node = root_node\n    if target==current_node.data:\n        print(f\"Duplicate! Can't insert! value{target}|node{current_node.data}\")\n        return current_node\n    # search \n    if target&lt;current_node.data: # go left\n        if current_node.left:\n            current_node=current_node.left\n            return insert_node_recursion(current_node,target)\n        else: # insert\n            current_node.left = TreeNode(target)\n            print(f\"Inserted target{target} as left-child of node{current_node.data} successfully!\")\n            return current_node.left\n    else:\n        if current_node.right: # go right\n            current_node=current_node.right\n            return insert_node_recursion(current_node,target)\n        else: # insert\n            current_node.right = TreeNode(target)\n            print(f\"Inserted target{target} as right-child of node{current_node.data} successfully!\")\n            return current_node.right\n\n\n\n4.2 insert_node: Iterative Approach\n\ndef insert_node_iterative(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    while current_node:\n        if target == current_node.data:\n            print(f\"Duplicate! Can't insert! value{target}|node{current_node.data}\")\n            return current_node\n        if target &lt; current_node.data: # go left\n            if current_node.left:\n                current_node=current_node.left\n                # return insert_node_while(current_node, target)\n            else: # INSERT LEFT\n                current_node.left = TreeNode(target)\n                print(f\"Inserted target{target} as left-child of node{current_node.data} successfully!\")\n                return current_node.left\n        else:\n            if current_node.right:\n                current_node=current_node.right\n                # return insert_node_while(current_node, target)\n            else: # INSERT RIGHT\n                current_node.right = TreeNode(target)\n                print(f\"Inserted target{target} as right-child of node{current_node.data} successfully!\")\n                return current_node.right\n\n\n\n4.3 insert_node: Testing Both Approaches\n\n#             50            # create a basic tree\n#      25           75\n#  10     33     56     89  \n# 4  11 30  40 52  61 82  95  \nroot = create_custom_binary_tree()\ninsert_node_recursion(root, 12)\ninsert_node_recursion(root, 12)\n\nprint()\nprint()\nroot = create_custom_binary_tree()\ninsert_node_iterative(root, 12)\ninsert_node_iterative(root, 12)\n\nInserted target12 as right-child of node11 successfully!\nDuplicate! Can't insert! value12|node12\n\n\nInserted target12 as right-child of node11 successfully!\nDuplicate! Can't insert! value12|node12\n\n\n&lt;__main__.TreeNode at 0x7fbaf8363190&gt;"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-035-nodes-part-3.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-035-nodes-part-3.html",
    "title": "DSA 35: LinkedList - Insert & Delete [Part 3]",
    "section": "",
    "text": "1. Setup Linkedlist and Node Objects\nPreviously introduced.\n\nclass Node():\n    def __init__(self, data):\n        self.data=data\n        self.next_node=None\n\nclass LinkedList():\n    def __init__(self, first_node:Node|None=None):\n        self.first_node: Node|None = first_node\n\n\nnode0=Node(\"Hey\")\nnode1=Node(\"I\")\nnode2=Node(\"Just\")\nnode3=Node(\"Met\")\nnode0.next_node=node1\nnode1.next_node=node2\nnode2.next_node=node3\n\n\n\n2. Read from LinkedList\nPreviously introduced\n\n\n2.1 Read(0) or Top\n\ndef read_top_ll(linked_list: LinkedList, index: int):\n    current_node = linked_list.first_node \n    return current_node.data\n\nll = LinkedList(node0)\nread_top_ll(ll,0)\n\n'Hey'\n\n\n\n\n2.2 Read Index of LinkedList\n\n\n2.3 Add Base-Case: Read(0)\n\ndef read_ll_forloop(linked_list: LinkedList, index: int):\n    current_node = linked_list.first_node \n    \n    if index==0:\n        return current_node.data\n    \n    for i in range(index+1):\n        print(i)\n        if i==index:\n            return current_node.data\n        current_node=current_node.next_node\n    return None\n\nll = LinkedList(node0)\nread_ll_forloop(ll,0)\n\n'Hey'\n\n\n\n\n2.4 Read(1)\n\ndef read_ll_whileloop(linked_list: LinkedList, index: int):\n    current_node = linked_list.first_node \n    \n    if index==0:\n        return current_node.data\n    i=0    \n    while current_node: # for i in range(index+1):\n        if i==index:\n            return current_node.data\n        current_node=current_node.next_node\n        i+=1\n    return None\n\nll = LinkedList(node0)\nread_ll_whileloop(ll,1)\n\n'I'\n\n\n\n\n2.5 Read All - LinkedList to Python List\n\ndef read_all_ll_whileloop(linked_list: LinkedList):\n    current_node = linked_list.first_node \n    ll_list = []\n    while current_node: # for i in range(index+1):\n        ll_list.append(current_node.data)\n        current_node=current_node.next_node\n        \n    return ll_list\n\nll = LinkedList(node0)\nread_all_ll_whileloop(ll)\n\n['Hey', 'I', 'Just', 'Met']\n\n\n\n\n3. Insert from LinkedList\n\n\n3.1 Insert(0) or Top\n\ndef insert_front_ll_forloop(linked_list: LinkedList, index: int,\n                            new_node: Node):\n    \n    current_node = linked_list.first_node \n    if index==0:\n        new_node.next_node = current_node\n        linked_list.first_node=new_node\n    \n    # for i in range(index+1):\n    #     print(i)\n    #     if i==index:\n    #         return current_node.data\n    #     current_node=current_node.next_node\n    # return None\n\n\nll = LinkedList(node0)\ninsert_front_ll_forloop(ll,0,Node(\"mate\"))\nprint(read_all_ll_whileloop(ll))\n\n['mate', 'Hey', 'I', 'Just', 'Met']\n\n\n\n\n3.2 Create New LinkedList for Each Test\n\ndef reset_ll():\n    node0=Node(\"Hey\")\n    node1=Node(\"I\")\n    node2=Node(\"Just\")\n    node3=Node(\"Met\")\n    node0.next_node=node1\n    node1.next_node=node2\n    node2.next_node=node3\n    ll = LinkedList(node0)\n    return ll\n\n\n\n3.3 Insert(Index)\n\n\n3.3.1 Insert(Index): for-loop version\n\ndef insert_ll_forloop(linked_list: LinkedList, index: int,\n                            new_node: Node):\n    \n    current_node = linked_list.first_node \n    if index==0:\n        new_node.next_node = current_node\n        linked_list.first_node=new_node\n    \n    for i in range(index+1):\n        if i==index-1:\n            new_node.next_node = current_node.next_node\n            current_node.next_node = new_node\n            # return current_node.data\n        current_node=current_node.next_node\n    return None\n\nll = reset_ll()\ninsert_ll_forloop(ll,0,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_forloop(ll,1,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_forloop(ll,2,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_forloop(ll,3,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_forloop(ll,4,Node(\"YOU\")) \nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\nprint(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\ninsert_ll_forloop(ll,5,Node(\"YOU\"))  # OUT OF INDEX ERROR EXPECTED \nprint(read_all_ll_whileloop(ll))\n\n#hey i just met\n\n['YOU', 'Hey', 'I', 'Just', 'Met']\n['Hey', 'YOU', 'I', 'Just', 'Met']\n['Hey', 'I', 'YOU', 'Just', 'Met']\n['Hey', 'I', 'Just', 'YOU', 'Met']\n['Hey', 'I', 'Just', 'Met', 'YOU']\nOUT-OF-INDEX ERROR EXPECTED NEXT RUN\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[41], line 39\n     37 ll = reset_ll()\n     38 print(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\n---&gt; 39 insert_ll_forloop(ll,5,Node(\"YOU\"))  # OUT OF INDEX ERROR EXPECTED \n     40 print(read_all_ll_whileloop(ll))\n     42 #hey i just met\n\nCell In[41], line 11, in insert_ll_forloop(linked_list, index, new_node)\n      9 for i in range(index+1):\n     10     if i==index-1:\n---&gt; 11         new_node.next_node = current_node.next_node\n     12         current_node.next_node = new_node\n     13         # return current_node.data\n\nAttributeError: 'NoneType' object has no attribute 'next_node'\n\n\n\n\n\n3.3.2 Insert(Index): while-loop version 1 (No Out-of-Index Error)\n\ndef insert_ll_WHILELOOP_v1(linked_list: LinkedList, index: int,\n                            new_node: Node):\n    \n    current_node = linked_list.first_node \n    if index==0:\n        new_node.next_node = current_node\n        linked_list.first_node=new_node\n    i=0\n    while current_node:\n        if i==index-1:\n            new_node.next_node = current_node.next_node\n            current_node.next_node = new_node\n        current_node=current_node.next_node\n        i+=1\n    return None\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ninsert_ll_WHILELOOP_v1(ll,0,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP_v1(ll,1,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP_v1(ll,2,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP_v1(ll,3,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP_v1(ll,4,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\nprint(\"NO ERROR EXPECTED NEXT RUN DESPITE OUT OF INDEX - NEED TO UPDATE FN\")\ninsert_ll_WHILELOOP_v1(ll,5,Node(\"YOU\"))  # ERROR EXPECTED BUT NO ERROR DUE TO while current_node\nprint(read_all_ll_whileloop(ll))\n\n['Hey', 'I', 'Just', 'Met']\n['YOU', 'Hey', 'I', 'Just', 'Met']\n['Hey', 'YOU', 'I', 'Just', 'Met']\n['Hey', 'I', 'YOU', 'Just', 'Met']\n['Hey', 'I', 'Just', 'YOU', 'Met']\n['Hey', 'I', 'Just', 'Met', 'YOU']\nNO ERROR EXPECTED NEXT RUN DESPITE OUT OF INDEX - NEED TO UPDATE FN\n['Hey', 'I', 'Just', 'Met']\n\n\n\n\n3.3.3 Insert(Index): while-loop version 2 (Includes Out-of-Index Error)\n\ndef insert_ll_WHILELOOP(linked_list: LinkedList, index: int,\n                            new_node: Node):\n    \n    current_node = linked_list.first_node \n    if index==0:\n        new_node.next_node = current_node\n        linked_list.first_node=new_node\n        return None\n    i=0\n    while i&lt;index-1:\n        current_node=current_node.next_node\n        i+=1\n    # print(current_node.data)    \n    new_node.next_node = current_node.next_node\n    current_node.next_node = new_node\n    return None\n#i=1, index=1\n#exit while at (index-1) 0 -&gt; 'Hey'\n# ['Hey', 'I', 'Just', 'Met']\n\n# ll = reset_ll()\n# print(read_all_ll_whileloop(ll))\n# insert_ll_WHILELOOP(ll,0,Node(\"YOU\"))\n# print(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP(ll,1,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP(ll,2,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP(ll,3,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\ninsert_ll_WHILELOOP(ll,4,Node(\"YOU\"))\nprint(read_all_ll_whileloop(ll))\n\nll = reset_ll()\nprint(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\ninsert_ll_WHILELOOP(ll,5,Node(\"YOU\")) # OUT OF INDEX ERROR EXPECTED \nprint(read_all_ll_whileloop(ll))\n\n['Hey', 'YOU', 'I', 'Just', 'Met']\n['Hey', 'I', 'YOU', 'Just', 'Met']\n['Hey', 'I', 'Just', 'YOU', 'Met']\n['Hey', 'I', 'Just', 'Met', 'YOU']\nOUT-OF-INDEX ERROR EXPECTED NEXT RUN\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[45], line 44\n     42 ll = reset_ll()\n     43 print(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\n---&gt; 44 insert_ll_WHILELOOP(ll,5,Node(\"YOU\")) # OUT OF INDEX ERROR EXPECTED \n     45 print(read_all_ll_whileloop(ll))\n\nCell In[45], line 14, in insert_ll_WHILELOOP(linked_list, index, new_node)\n     12     i+=1\n     13 # print(current_node.data)    \n---&gt; 14 new_node.next_node = current_node.next_node\n     15 current_node.next_node = new_node\n     16 return None\n\nAttributeError: 'NoneType' object has no attribute 'next_node'\n\n\n\n\n\n4. Delete from LinkedList\n\n\n4.1 Delete(0) or Top\n\n# [Hey', 'I', 'Just', 'Met']\n# del 0 -&gt;  'I', 'Just', 'Met'\n\ndef delete_top_ll(linked_list: LinkedList, index=0):\n    current_node = linked_list.first_node\n    if index==0:\n        linked_list.first_node=current_node.next_node\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_top_ll(ll,index=0)\nprint(read_all_ll_whileloop(ll))\n\n['Hey', 'I', 'Just', 'Met']\n['I', 'Just', 'Met']\n\n\n\n\n4.2 Delete(Index)\n\n\n\n4.2.1 Delete(Index): for-loop version\n\ndef delete_node_ll_FORLOOP(linked_list: LinkedList, index=0):\n    current_node = linked_list.first_node\n    if index==0:\n        linked_list.first_node=current_node.next_node\n\n    for i in range(index):\n        if i==index-1:\n            next_node = current_node.next_node\n            current_node.next_node = next_node.next_node\n        current_node=current_node.next_node\n\n# ['Hey', 'I', 'Just', 'Met']\n# ['Hey'     , 'Just', 'Met']\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_FORLOOP(ll,index=0)\nprint(read_all_ll_whileloop(ll))\n\nprint()\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_FORLOOP(ll,index=1)\nprint(read_all_ll_whileloop(ll))\n\nprint()\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_FORLOOP(ll,index=2)\nprint(read_all_ll_whileloop(ll))\n\nprint()\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_FORLOOP(ll,index=3)\nprint(read_all_ll_whileloop(ll))\n\nprint()\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\nprint(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\ndelete_node_ll_FORLOOP(ll,index=4) # OUT OF INDEX ERROR EXPECTED \nprint(read_all_ll_whileloop(ll))\n\n\n['Hey', 'I', 'Just', 'Met']\n['I', 'Just', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'Just', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'I', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'I', 'Just']\n\n['Hey', 'I', 'Just', 'Met']\nOUT-OF-INDEX ERROR EXPECTED NEXT RUN\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[46], line 42\n     40 print(read_all_ll_whileloop(ll))\n     41 print(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\n---&gt; 42 delete_node_ll_FORLOOP(ll,index=4) # OUT OF INDEX ERROR EXPECTED \n     43 print(read_all_ll_whileloop(ll))\n\nCell In[46], line 9, in delete_node_ll_FORLOOP(linked_list, index)\n      7 if i==index-1:\n      8     next_node = current_node.next_node\n----&gt; 9     current_node.next_node = next_node.next_node\n     10 current_node=current_node.next_node\n\nAttributeError: 'NoneType' object has no attribute 'next_node'\n\n\n\n\n\n4.2.2 Delete(Index): while-loop version\n\ndef delete_node_ll_WHILELOOP(linked_list: LinkedList, index=0):\n    current_node = linked_list.first_node\n    if index==0:\n        linked_list.first_node=current_node.next_node\n    i=0\n    while current_node: # for i in range(index):\n        if i==index-1:\n            # next_node = current_node.next_node.next_node\n            # current_node.next_node = next_node.next_node\n            current_node.next_node = current_node.next_node.next_node\n            # current_node.next_node = next_node.next_node\n        current_node=current_node.next_node\n        i+=1\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_WHILELOOP(ll,index=0)\nprint(read_all_ll_whileloop(ll))\nprint()\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_WHILELOOP(ll,index=1)\nprint(read_all_ll_whileloop(ll))\nprint()\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_WHILELOOP(ll,index=2)\nprint(read_all_ll_whileloop(ll))\nprint()\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\ndelete_node_ll_WHILELOOP(ll,index=3)\nprint(read_all_ll_whileloop(ll))\nprint()\n\nll = reset_ll()\nprint(read_all_ll_whileloop(ll))\nprint(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\ndelete_node_ll_WHILELOOP(ll,index=4) # OUT OF INDEX ERROR EXPECTED \nprint(read_all_ll_whileloop(ll))\n\n['Hey', 'I', 'Just', 'Met']\n['I', 'Just', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'Just', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'I', 'Met']\n\n['Hey', 'I', 'Just', 'Met']\n['Hey', 'I', 'Just']\n\n['Hey', 'I', 'Just', 'Met']\nOUT-OF-INDEX ERROR EXPECTED NEXT RUN\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[47], line 41\n     39 print(read_all_ll_whileloop(ll))\n     40 print(\"OUT-OF-INDEX ERROR EXPECTED NEXT RUN\")\n---&gt; 41 delete_node_ll_WHILELOOP(ll,index=4) # OUT OF INDEX ERROR EXPECTED \n     42 print(read_all_ll_whileloop(ll))\n\nCell In[47], line 10, in delete_node_ll_WHILELOOP(linked_list, index)\n      6 while current_node: # for i in range(index):\n      7     if i==index-1:\n      8         # next_node = current_node.next_node.next_node\n      9         # current_node.next_node = next_node.next_node\n---&gt; 10         current_node.next_node = current_node.next_node.next_node\n     11         # current_node.next_node = next_node.next_node\n     12     current_node=current_node.next_node\n\nAttributeError: 'NoneType' object has no attribute 'next_node'"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-049-binary-search-trees-review-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-049-binary-search-trees-review-2.html",
    "title": "DSA 49: Binary Search Trees - Delete Review",
    "section": "",
    "text": "1. delete_node Again! (ETA: A very long time)\n\n\n2. TreeNode() class\n\nclass TreeNode():\n    def __init__(self,data,left=None,right=None):\n        self.data=data\n        self.left=left\n        self.right=right\n\n\n\n3. insert_node() & insert_node_list() methods\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    if target == current_node.data:\n        print(f\"Cant insert duplicates: t{target}c{current_node.data}\")\n        return\n    \n    if target &lt; current_node.data: # go left\n        if current_node.left:\n            print(f\"t{target}&lt;-c{current_node.data}: going left...\")\n            current_node = current_node.left\n            return insert_node(current_node, target)       \n        else:\n            # insert left\n            current_node.left = TreeNode(target)\n            print(f\"t{target}&lt;-c{current_node.data}: inserted left of c{current_node.data} at cl{current_node.left.data}\",end=\"\\n\\n\")\n            return current_node.left\n    else:\n        if current_node.right:\n            print(f\"t{target}-&gt;c{current_node.data}: going left...\")\n            current_node = current_node.right\n            return insert_node(current_node, target)       \n        else:\n            # insert right\n            current_node.right = TreeNode(target)\n            print(f\"t{target}-&gt;c{current_node.data}: inserted right of c{current_node.data} at cl{current_node.right.data}\",end=\"\\n\\n\")\n            return current_node.right    \n        \ndef insert_node_clean2(root_node: TreeNode, target: int):\n    current_node = root_node\n    \n    if target == current_node.data:\n        print(f\"Cant insert duplicates: t{target}c{current_node.data}\")\n        return\n    \n    if target &lt; current_node.data: # go left\n        if current_node.left:\n            # print(f\"t{target}&lt;-c{current_node.data}: going left...\")\n            current_node = current_node.left\n            return insert_node_clean2(current_node, target)       \n        else:\n            # insert left\n            current_node.left = TreeNode(target)\n            # print(f\"t{target}&lt;-c{current_node.data}: inserted left of c{current_node.data} at cl{current_node.left.data}\",end=\"\\n\\n\")\n            return current_node.left\n    else:\n        if current_node.right:\n            # print(f\"t{target}-&gt;c{current_node.data}: going left...\")\n            current_node = current_node.right\n            return insert_node_clean2(current_node, target)       \n        else:\n            # insert right\n            current_node.right = TreeNode(target)\n            # print(f\"t{target}-&gt;c{current_node.data}: inserted right of c{current_node.data} at cl{current_node.right.data}\",end=\"\\n\\n\")\n            return current_node.right    \n        \ndef insert_node_list(root: TreeNode, node_list: list[int], show_results: bool=False):\n    for node_int in node_list:\n        if show_results:\n            insert_node(root, node_int)\n        else:\n            insert_node_clean2(root, node_int)\n\n\n\n4. traverse() method\n\ndef traverse(root: TreeNode):\n    if not root:\n        return\n    traverse(root.left)\n    print(root.data)\n    traverse(root.right)\n\n\n\n5. find_successor_node() method\n\n\n5.1 Psuedo-Code Scenarios Only\n\ndef find_succ_node(target_node):\n    print(f\"t{target_node.data} has two kids[{target_node.left.data}][{target_node.right.data}]!...Find the successor child!\")\n    # Target has 2 kids: Determine s_node to replace t_node\n    successor_node = target_node.right # because must be at least greater than target\n    \n    # [Case_1]  @[t.r]:             [s_node] has {0 left-child}, [s_node] replaces [t_node]\n    # i. FIND S_SNODE:\n    #                                 [50]t         - target to delete\n    #                               X    [75]s      - current [s_node]\n    # ii. REPLACE T_NODE:\n    #                                 [75]s         - [target] &lt;- [s_node] \n    #                               X    []         \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    \n    # [Case_2]  @[t.r...l]:         [s_node] has {a left-child}, go to {left-most-child}\n    #                               [s_node] is now {left-most-child} of {target.right}\n    #                                 [50]t         - [target] to delete\n    #                               X       [75]s   - prev [s_node] (target.right)\n    #                                     [70]l...\n    #                                    [60]l...   - new [s_node] (left-most-child of target.right)\n    \n    # [Case_2A] @[t.r...l]:         [s_node] has no {right-child}\n    # i. FIND S_NODE:\n    #                                 [50]t         - [target] to delete\n    #                               X       [75]   - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is currently s_node}\n    #                                    [60]s...   - current [s_node] (left-most-child of target.right)\n    #                                   []  []      - [s_node] has no kids\n    # ii. REPLACE T_NODE:\n    #                                 [60]s         - [target] &lt;- s_node\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is None} now!\n    #                                    []...       \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    \n    # [Case_2B] @[t.r...l]:         [s_node] has a {right-child}\n    # i. FIND S_NODE:\n    #                                 [50]t         - [target] to delete\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is currently s_node}\n    #                                    [60]s...   - current [s_node] (left-most-child of target.right)\n    #                                   []  [65]sr  - [s_node] has a [right-child]\n    # ii. REPLACE T_NODE:\n    #                                 [60]s         - [target] &lt;- s_node\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is 65 (s_node.right)} \n    #                                    [65]sr...  - {s_node.right} replaces {s_node}       \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    \n    \n    \n    target_node = s_node\n    \n    return s_node\n\n\n\n5.2 The Code\n\ndef find_succ_node_final(t_node):\n    print(f\"t{t_node.data} has two kids[{t_node.left.data}][{t_node.right.data}]!...Find the successor child!\")\n    # Target has 2 kids: Determine s_node to replace t_node\n    s_node = t_node.right # because must be at least greater than target\n    \n    # [Case_1]  @[t.r]:                 [s_node] has {0 left-child}, [s_node] replaces [t_node]\n    if not s_node.left:             \n        # i. FIND S_SNODE:\n        #                                 [50]t         - target to delete\n        #                               X    [75]s      - current [s_node]\n        # ii. REPLACE T_NODE:\n        #                                 [75]s         - [target] &lt;- [s_node] \n        #                               X    []         \n        # s_node = t_node\n        print(f\"[1]s_node[{s_node.data}] is our successor node!! will replace target_node[{t_node.data}]\")\n        t_node.data = s_node.data\n        t_node.right = None\n\n        # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n        return \n    \n    # [Case_2]  @[t.r...l]:         [s_node] has {a left-child}, go to {left-most-child}\n    while s_node.left:\n        print(f\"[2]s{s_node.data} has left_child[{s_node.left.data}]: keep going left...!\")\n        #                               [s_node] is now {left-most-child} of {target.right}\n        #                                 [50]t         - [target] to delete\n        #                               X       [75]s   - prev [s_node] (target.right)\n        #                                     [70]l...\n        #                                    [60]l...   - new [s_node] (left-most-child of target.right)\n        parent_node = s_node\n        s_node = s_node.left\n    \n    # [Case_2A] @[t.r...l]:         [s_node] has no {right-child}\n    # i. FIND S_NODE:\n    #                                 [50]t         - [target] to delete\n    #                               X       [75]   - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is currently s_node}\n    #                                    [60]s...   - current [s_node] (left-most-child of target.right)\n    #                                   []  []      - [s_node] has right kids (and left thats alwyays cause we went the most left already)\n    # ii. REPLACE T_NODE:\n    if not s_node.right:\n        print(f\"[2A]s{s_node.data} has NO right child: p.left[{parent_node.left.data}] to None\")\n    #                                 [60]s         - [target] &lt;- s_node\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is None} now!\n    #                                    []...       \n        parent_node.left = None\n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    # [Case_2B] @[t.r...l]:         [s_node] has a {right-child}\n    # i. FIND S_NODE:\n    elif s_node.right:\n        print(f\"[2B]s{s_node.data} has a right child: p.left[{parent_node.left.data}] to [{s_node.right.data}]\")\n        parent_node.left = s_node.right\n    #                                 [50]t         - [target] to delete\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is currently s_node}\n    #                                    [60]s...   - current [s_node] (left-most-child of target.right)\n    #                                   []  [65]sr  - [s_node] has a [right-child]\n    #                                   [] [a] [b]\n    # ii. REPLACE T_NODE:\n    #                                 [60]s         - [target] &lt;- s_node\n    #                               X       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is 65 (s_node.right)} \n    #                                    [65]sr...  - {s_node.right} replaces {s_node}       \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    \n    print(f\"[3]s_node[{s_node.data}] is our successor node!! will replace target_node[{t_node.data}]\")\n    t_node.data = s_node.data\n\n    return\n\n\n\n6. delete_node() method\n\ndef delete_node_final(root_node: TreeNode, target: int):\n    current_node = root_node\n    target_node = None\n    parent_node = None\n    \n    ### ----------------------------------- A. SEARCH ----------------------------------- ###\n    while current_node:\n        if target == current_node.data:\n            target_node = current_node # t_node & c_node both point to target   \n            print(f\"t{target}c{current_node.data}: t_node{target_node.data} found, determine kids...\")\n            break\n        elif target &lt; current_node.data: # go left\n            parent_node = current_node\n            current_node = current_node.left\n        else:\n            parent_node = current_node\n            current_node = current_node.right    \n    \n    if not target_node:\n        print(f\"{target} not found!\")\n        return\n    # print(\"WTF\")\n    ### ----------------------------------- B. DELETE ----------------------------------- ###\n    ### ----- I. 2 KIDS ----- ###\n    if target_node.left and target_node.right:\n        find_succ_node_final(target_node)\n        return\n    else:\n        # root node: no parents\n        targets_child_node = (target_node.left or target_node.right)\n        if not parent_node:\n            root_node.data = targets_child_node.data  # 50-&gt;25 cn and tn points\n            \n            ### ADD LOGIC: if Tchild.left or Tchild.right exists: assign\n            root_node.left = targets_child_node.left\n            root_node.right = targets_child_node.right\n                #        [] no p - root\n                #     [50]t  |     [25]c\n                #   [25]c    |  {10}  {15}\n                # 10 15      | \n            return\n        elif parent_node.left == target_node: # target is non-root, left of parent\n            parent_node.left = targets_child_node\n                #       [45]p   or p\n                #     [40]t  |  or p.left -&gt; p.left=t.child\n                #   [25]c    |  or t.child\n                # 10 15      | \n            return\n        elif parent_node.right == target_node: # target is non-root, right of parent\n            parent_node.right = targets_child_node\n            return\n    return\n\n\n# [Case_1]  @[t.r]:                 [s_node] has {0 left-child}, [s_node] replaces [t_node]\n    # i. FIND S_SNODE:\n    #                                 [50]t         - target to delete\n    #                               25    [75]s      - current [s_node]\n    # ii. REPLACE T_NODE:\n    #                                 [75]s         - [target] &lt;- [s_node] \n    #                               25    []         \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n    \nroot = TreeNode(50)\nnode_list = [25,75]\ninsert_node_list(root, node_list)   \ntraverse(root) # 25,75\nprint()\ndelete_node_final(root, 50)\nprint()\n\nprint(\"expected: 25,75\")\ntraverse(root) # 25,75\nprint()\nprint(f\"{root.data},75\")\nprint(f\"{root.left.data},25\")\n# print(root.right.data)\n\n25\n50\n75\n\nt50c50: t_node50 found, determine kids...\nt50 has two kids[25][75]!...Find the successor child!\n[1]s_node[75] is our successor node!! will replace target_node[50]\n\nexpected: 25,75\n25\n75\n\n75,75\n25,25\n\n\n\n    # [Case_2]  @[t.r...l]:         [s_node] has {a left-child}, go to {left-most-child}\n        #                               [s_node] is now {left-most-child} of {target.right}\n        #                                 [50]t         - [target] to delete\n        #                              25       [75]s   - prev [s_node] (target.right)\n        #                                     [70]l...\n        #                                    [60]l...   - new [s_node] (left-most-child of target.right)\n    \n    # [Case_2A] @[t.r...l]:         [s_node] has no {right-child}\n    # i. FIND S_NODE:\n    #                                 [50]t         - [target] to delete\n    #                              25       [75]   - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is currently s_node}\n    #                                    [60]s...   - current [s_node] (left-most-child of target.right)\n    #                                   []  []      - [s_node] has right kids (and left thats alwyays cause we went the most left already)\n    # ii. REPLACE T_NODE:\n    #                                 [60]s         - [target] &lt;- s_node\n    #                              25       [75]    - prev [s_node] (target.right)\n    #                                     [70]p...  - {parent.left is None} now!\n    #                                    []...       \n    # iii. LOGIC CHECK:             is it next number after target in tree if in sequential order?\n\n    \nroot = TreeNode(50)\nnode_list = [25,75,70,60]\ninsert_node_list(root, node_list)   \ntraverse(root) # 25,50,60,70,75\nprint()\ndelete_node_final(root, 50)\nprint()\nprint(\"expected: 25,60,70,75\")\ntraverse(root) # 25,60,70,75\nprint()\nprint(f\"{root.data},60\") # \nprint(f\"{root.left.data},25\") \nprint(f\"{root.right.data},75\") \nprint(f\"{root.right.left.data},70\") \n\n\n25\n50\n60\n70\n75\n\nt50c50: t_node50 found, determine kids...\nt50 has two kids[25][75]!...Find the successor child!\n[2]s75 has left_child[70]: keep going left...!\n[2]s70 has left_child[60]: keep going left...!\n[2A]s60 has NO right child: p.left[60] to None\n[3]s_node[60] is our successor node!! will replace target_node[50]\n\nexpected: 25,60,70,75\n25\n60\n70\n75\n\n60,60\n25,25\n75,75\n70,70\n\n\n\n    # [Case_2B] @[t.r...l]:         [s_node] has a {right-child}\n    # i. FIND S_NODE:\n\n    #                         [50]t             - [target] to delete\n    #                     25          [75]      - prev [s_node] (target.right)\n    #                              [70]p...     - {parent.left is currently s_node}\n    #                          [60]s...         - current [s_node] (left-most-child of target.right)\n    #                         [] [65]sr         - [s_node] has a [right-child]\n    # ii. REPLACE T_NODE:       \n    #                        [60]s              - [target] &lt;- s_node\n    #                     25       [75]         - prev [s_node] (target.right)\n    #                            [70]p...       - {parent.left is 65 (s_node.right)} \n    #                           [65]sr...       - {s_node.right} replaces {s_node}       \n    # iii. LOGIC CHECK:                         - is it next number after target in tree if in sequential order?\n\nroot = TreeNode(50)\nnode_list = [25,75,70,60,65]\ninsert_node_list(root, node_list)   \ntraverse(root) # 25,50,60,70,75\nprint()\ndelete_node_final(root, 50)\nprint()\nprint(\"expected: 25,60,65,70,75\")\ntraverse(root) # 25,60,65,70,75\nprint()\nprint(f\"{root.data},60\") # \nprint(f\"{root.left.data},25\") \nprint(f\"{root.right.data},75\") \nprint(f\"{root.right.left.data},70\") \nprint(f\"{root.right.left.left.data},65\") \n\n\n25\n50\n60\n65\n70\n75\n\nt50c50: t_node50 found, determine kids...\nt50 has two kids[25][75]!...Find the successor child!\n[2]s75 has left_child[70]: keep going left...!\n[2]s70 has left_child[60]: keep going left...!\n[2B]s60 has a right child: p.left[60] to [65]\n[3]s_node[60] is our successor node!! will replace target_node[50]\n\nexpected: 25,60,65,70,75\n25\n60\n65\n70\n75\n\n60,60\n25,25\n75,75\n70,70\n65,65"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert55-22-34-10-22",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert55-22-34-10-22",
    "title": "DSA 52: Array-Based Heaps - Exercises",
    "section": "4.1.1 insert(55, 22, 34, 10, 22)",
    "text": "4.1.1 insert(55, 22, 34, 10, 22)\ninsert(55, 22, 34, 10, 22) keeping the tree complete\n        55  \n    22      34\n10      2   \nRecall, a Complete Tree:\n\nis a tree that is:\ncompletely filled with nodes\nno nodes are missing."
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert99",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert99",
    "title": "DSA 52: Array-Based Heaps - Exercises",
    "section": "4.1.2 insert(99)",
    "text": "4.1.2 insert(99)\n        55  \n    22       (34)  \n10      2 [99]  \n\n        55\n    22       [99]  \n10      2 (34)  \n\n       [99]  \n    22       (55)  \n10      2 (34)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert68",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-052-heaps-exercises.html#insert68",
    "title": "DSA 52: Array-Based Heaps - Exercises",
    "section": "4.1.3 insert(68)",
    "text": "4.1.3 insert(68)\n        99  \n    22       (55)  \n10      2 34    [68]  \n\n        99  \n    22       [68]  \n10      2 34    (55)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-033-nodes-part-1.html#node-data-structure-advantages",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-033-nodes-part-1.html#node-data-structure-advantages",
    "title": "DSA 33: Nodes & Linked Lists [Part 1]",
    "section": "1.1. Node Data Structure: Advantages",
    "text": "1.1. Node Data Structure: Advantages\n\nNot being contiguous in memory is nodes, thus\nWill not have the same issues as arrays to find slots of memory"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-033-nodes-part-1.html#node-data-structure-disadvantages",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-033-nodes-part-1.html#node-data-structure-disadvantages",
    "title": "DSA 33: Nodes & Linked Lists [Part 1]",
    "section": "1.2 Node Data Structure: Disadvantages",
    "text": "1.2 Node Data Structure: Disadvantages\n\nThe drawback is nodes take up more memory.\n\n\nclass Node():\n    def __init__(self, data):\n        self.data = data\n        self.next_node = None\n        \nnode0 = Node(\"I've\")\nnode1 = Node(\"paid\")\nnode2 = Node(\"my\")\nnode3 = Node(\"dues\")\n\nnode0.next_node = node1\nnode1.next_node = node2\nnode2.next_node = node3\nnode3.next_node = None\n\nprint(node0.data, node0.next_node.data,sep=\"\\t\")\nprint(node1.data, node1.next_node.data,sep=\"\\t\")\nprint(node2.data, node2.next_node.data,sep=\"\\t\")\nprint(node3.data)\n\nI've    paid\npaid    my\nmy  dues\ndues"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-023-recursion-part-4.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-023-recursion-part-4.html",
    "title": "DSA 23: Recursion - In-Place Modification [Part 4]",
    "section": "",
    "text": "1. New Array: iterative for approach\n\ndef dbl_new_array(arr:list):\n    new_arr = []\n    for ar in arr:\n        new_arr.append(ar*2)\n    return new_arr\n\narr=[1,2,3,4,5]\nnew_arr = dbl_new_array(arr)\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {new_arr}\")\n\n(id:140442015412800: [1, 2, 3, 4, 5]\n(id:140442143645760: [2, 4, 6, 8, 10]\n\n\n\n\n2. Same Array with In-Place modification: iterative for approach\n\ndef dbl_arr_iter(arr:list):\n    for i in range(len(arr)):\n        # print(arr[i])\n        arr[i]*=2\n    return arr\n\narr=[1,2,3,4,5]\nnew_arr = dbl_arr_iter(arr)\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {new_arr}\")\n\n(id:140442015415744: [2, 4, 6, 8, 10]\n(id:140442015415744: [2, 4, 6, 8, 10]\n\n\n\n\n3. Same Array with In-Place modification: iterative while approach\n\ndef dbl_arr_while(arr: int, i=0):\n    while i &lt; len(arr):\n        arr[i]*=2\n        i+=1\n    return arr\n    \narr=[1,2,3,4,5]\nnew_arr = dbl_arr_while(arr)\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {new_arr}\")\n\n(id:140442015475456: [2, 4, 6, 8, 10]\n(id:140442015475456: [2, 4, 6, 8, 10]\n\n\n\n\n4. Recursive approach\n\n\n4.1 In-Place modification: nothing returned\n\ndef dbl_array_recurse1(arr, i = 0):\n    if i &gt;= len(arr):\n        return \n    arr[i]*=2 \n    dbl_array_recurse1(arr,i+1)\n\narr=[1,2,3,4,5]\n\nnew_arr = dbl_array_recurse1(arr) # nothing returned as in-place modification\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {new_arr}\")\n\nid:139727162733888: [2, 4, 6, 8, 10]\nid:139727776920536: None\n\n\n\n\n4.1 In-Place modification & Same Array return\n\ndef dbl_arr_recurse2(arr: int, i=0):\n    if i &gt;= len(arr):\n        return arr\n    arr[i]*=2\n    return dbl_arr_recurse2(arr,i+1) # fixed\n\narr=[1,2,3,4,5]\nnew_arr = dbl_arr_recurse2(arr)\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {arr}\")\n\n(id:140442015584000: [2, 4, 6, 8, 10]\n(id:140442015584000: [2, 4, 6, 8, 10]\n\n\n\ndef dbl_arr_recurse3(arr: int, i=0):\n    if i &gt;= len(arr):\n        return\n    arr[i]*=2\n    dbl_arr_recurse3(arr,i+1) # fixed\n\narr=[1,2,3,4,5]\nnew_arr = dbl_arr_recurse3(arr)\nprint(f\"id:{id(arr)}: {arr}\")\nprint(f\"id:{id(new_arr)}: {arr}\")\n\nid:139727162734144: [2, 4, 6, 8, 10]\nid:139727776920536: [2, 4, 6, 8, 10]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#naive-solution-nested-loop---onm",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#naive-solution-nested-loop---onm",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "1.1 Naive Solution: Nested Loop - \\(O(N*M)\\)",
    "text": "1.1 Naive Solution: Nested Loop - \\(O(N*M)\\)\n\narr_a = [1,2,3,4,5]\narr_b = [0,2,4,6,8]\n# arr_b = [0,2,2]\n\nintersect_list = []\nfor chr_a in set(arr_a):        # O(N)\n    for chr_b in set(arr_b):    # multiply: O(M)\n        # print(chr_a,chr_b)\n        if chr_a==chr_b:        # add: O(N)\n            intersect_list.append(chr_a)  # total = O(N*M + max(N,M))\n            break\n\nintersect_list\n\n[2, 4]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#dict-solution-nested-loop---omn",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#dict-solution-nested-loop---omn",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "1.2 Dict Solution: Nested Loop - \\(O(M+N)\\)",
    "text": "1.2 Dict Solution: Nested Loop - \\(O(M+N)\\)\n\narr_a = [1,2,3,4,5]\narr_b = [0,2,4,6,8]\n\ndct_a = {}\n\nfor chr_a in set(arr_a):\n    dct_a[chr_a]=True\n\nintersect_list = []\nfor chr_b in set(arr_b):    # O(N) \n    if chr_b in dct_a:      # add: O(M)\n        intersect_list.append(chr_b) # O(M+N)\n\nprint(intersect_list)\n\n[2, 4]"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-psuedo-code",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-psuedo-code",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "2.1 Solution: Psuedo-Code",
    "text": "2.1 Solution: Psuedo-Code\nCheck if chr_a of str_a is in dct_a:\n\ntrue: return chr_a\n\nfalse: add to dct_a"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-python-code",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-python-code",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "2.2 Solution: Python-Code",
    "text": "2.2 Solution: Python-Code\n\n# str_a = \"abcdef\"\n# str_a = \"abcdeaf\"\nstr_a = \"abcdeff\"\ndct_a = {}\nfor chr_a in str_a: #O(N)\n    # print(chr_a)\n    if chr_a in dct_a: #xO(1)\n        print(chr_a)\n        break\n    else:\n        dct_a[chr_a]=True\n\nf"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-python-code-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-python-code-1",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "3.1 Solution: Python-Code",
    "text": "3.1 Solution: Python-Code\n\nalphabet = \"abcdefghijklmnopqrstuvwxyz\" \n\ninput_arr = \"the quick brown box jumps over a lazy dog\"\ninput_dct = {}\nfor ltr_s in set(input_arr.replace(\" \", \"\")):\n    input_dct[ltr_s]=True\n\nfor alphabet_ltr in alphabet:\n    # if not input_dct.get(alphabet_ltr): \n    if alphabet_ltr not in input_dct:\n        print(alphabet_ltr)\n        break\n\nf"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-psuedo-code-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-015-hash-tables-part-4.html#solution-psuedo-code-1",
    "title": "DSA 15: Hash Tables - Exercises [Part 4]",
    "section": "4.1 Solution: Psuedo-Code",
    "text": "4.1 Solution: Psuedo-Code\nA. Create letter counter dict: \\(O(N)\\)\n\nfor each letter of input_str, add create key and (add) value by 1\n\nB. Find first letter with only one occurence: \\(O(N)\\)\n\nfor each letter of input_str, find key with value: 1\n\nTime-complexity:\n\n\\(O(N+N)=O(2N)=O(N)\\)\n\n\ninput_str = \"minimum\"\nltr_dict = {}\n\nfor ltr in input_str: # 4.1.A\n    ltr_dict[ltr] = ltr_dict.get(ltr,0)+1\n\nctr=0\nprint(f\"Input-string: '{input_str}'\")\nprint(f\"Letter-counter dictionary: {ltr_dict}\")\nfor ltr in input_str: # 4.1.B\n    if ltr_dict[ltr]==1:\n        ctr+=1\n        print(f\"{ctr}: Non-duplicate: '{ltr}' in {input_str}\")\n\nInput-string: 'minimum'\nLetter-counter dictionary: {'m': 3, 'i': 2, 'n': 1, 'u': 1}\n1: Non-duplicate: 'n' in minimum\n2: Non-duplicate: 'u' in minimum"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-017-stacks-part-3.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-017-stacks-part-3.html",
    "title": "DSA 17: Stacks - Exercises [Part 3]",
    "section": "",
    "text": "1. Question 1 to 3: simple scenarios\n\n1.1 Call Centre Callers\nIf you were writing software for a call center that places callers on hold and then assigns them to “the next available representative,” would you use a stack or a queue?\n\nQueue\n\n\n\n1.2 stack: push, pop & read\nIf you pushed numbers onto a stack in the following order: 1, 2, 3, 4, 5, 6, and then popped two items, which number would you be able to read from the stack?\n\n4: 5 and 6 are popped.\n\n\n\n1.3 queue: enque, deque & read\nIf you inserted numbers into a queue in the following order: 1, 2, 3, 4, 5, 6, and then dequeued two items, which number would you be able to read from the queue?\n\n3: 1 and 2 dequed.\n\n\n\n\n2. Question 4: Use stack to reverse a string\nWrite a function that uses a stack to reverse a string. (For example, “abcde” would become “edcba”.) You can work with our earlier implementation of the Stack class.\n\n\n4.1 Psuedo-Code Solution\n\nfor-loop a-to-e: add “abcde” to stack via add().\noutput = while read() is True, pop() and append() to output list i.e. e-to-a.\n\n\n\n4.2 Create Stack() class\n\nclass Stack():\n    def __init__(self):\n        self.data=[]\n    def add(self,value:str):\n        self.data.append(value)\n    def pop(self):\n        if len(self.data)&gt;0:\n            return self.data.pop()\n        else:\n            return None\n    def read(self):\n        if len(self.data)&gt;0:\n            return self.data[-1]\n        else:\n            return None\n\n\n\n4.3 Use Stack instance to reverse a string\n\ntony_stack = Stack()\ninput_string = \"abcde\"\nlistify = lambda string: [char for char in string]\n\n# add string into stack\n# for char in listify(input_string): \n# just realised I dont need to convert string\n# to list because its an iterable... oops.\nfor char in input_string:\n    tony_stack.add(char)\n    print(f\"{char} added: {tony_stack.data!r}\")\n\n# pop string out of stack\nreversed_string = ''\nwhile tony_stack.read():\n    reversed_string+= tony_stack.pop()\n    print(reversed_string)\n\na added: ['a']\nb added: ['a', 'b']\nc added: ['a', 'b', 'c']\nd added: ['a', 'b', 'c', 'd']\ne added: ['a', 'b', 'c', 'd', 'e']\ne\ned\nedc\nedcb\nedcba"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-026-recursion-part-7.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-026-recursion-part-7.html",
    "title": "DSA 26: Recursion - Anagram Generation [Part 7]",
    "section": "",
    "text": "def anags(string):\n    if len(string)==1:\n        return string[0]\n    \n    anags_list = []\n    substring_anags = anags(string[1:])\n    \n    for anag in substring_anags:\n        for i in range(len(anag)+1):\n            new_string = anag[:i] + string[0] + anag[i:]\n            anags_list.append(new_string)\n    \n    return anags_list\nanags(\"tea\")\n\n['tea', 'eta', 'eat', 'tae', 'ate', 'aet']\n\n\n\nanags(\"mate\")\n\n['mate',\n 'amte',\n 'atme',\n 'atem',\n 'mtae',\n 'tmae',\n 'tame',\n 'taem',\n 'mtea',\n 'tmea',\n 'tema',\n 'team',\n 'maet',\n 'amet',\n 'aemt',\n 'aetm',\n 'meat',\n 'emat',\n 'eamt',\n 'eatm',\n 'meta',\n 'emta',\n 'etma',\n 'etam']"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-operation---summary",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-operation---summary",
    "title": "DSA 1: Big-O - Arrays and Sets",
    "section": "1.1 Array Operation - Summary",
    "text": "1.1 Array Operation - Summary\n\nRead \\((1)\\)\n\nSearch \\((n)\\)\n\nInsert \\((n+1)\\)\n\nDelete \\((n)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-operation---details",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-operation---details",
    "title": "DSA 1: Big-O - Arrays and Sets",
    "section": "1.2 Array Operation - Details",
    "text": "1.2 Array Operation - Details\n\n1.2.1 Read \\((1)\\):\n\n\\(1\\) (worse)\n\\(1\\) (best)\n\n\n\n1.2.2 Search \\((n)\\):\n\n\\(n\\) (worse: target is last value found)\n\n\\(1\\) (best: target is first value found)\n\n\n\n1.2.3 Delete \\((n)\\):\n\n\n1.2.3a Delete \\((n)\\) - Worse:\n{\\(n\\)}=({\\(1\\)} \\(+\\) {\\(n-1\\)}): worse - delete \\(first\\) item or \\(arr[0]\\):\n\n{\\(1\\)}: delete item at \\(arr[0]\\)\n{\\(n-1\\)}: shift whole array, left one item at a time:\n\n\\(arr[1] \\to arr[0]\\) (\\(index\\_1 \\to index\\_0\\))\n\\(arr[2] \\to arr[1]\\) (\\(index\\_2 \\to index\\_1\\))\n\\(...\\)\n\\(arr[n] \\to arr[n-1]\\) (\\(inde`x\\_[n] \\to index\\_[n-1]\\))\n\n\n\n\n1.2.3b Delete \\((1)\\) - Best\n{\\(1\\)}: best - delete \\(last\\) item or \\(arr[-1]\\)\n\n\n1.2.4 Insert \\((n+1)\\)\n\n\n1.2.4a Insert \\((n+1)\\) - Worse:\n{\\(n + 1\\)}: worse - insert at \\(front\\) or \\(arr[0]\\):\n\n{\\(n\\)}: whole existing array of length {\\(n\\)} needs to move right by {\\(1\\)}:\n\nstarts at {\\(n\\)}, moves it right to {\\(n+1\\)}\nthen {\\(n-1\\)} moves to {\\(n\\)}… {\\(n\\_times\\)} or {\\(n\\_steps\\)}\n\nindex \\([0]\\) becomes empty\n\nindex \\([0]\\) retains same memory address (might change for diff languages)\n\n{\\(1\\)}: insert the finally vacant spot at index 0, same memory address\n\n\n\n1.2.4b Insert \\((1)\\) - Best:\n{\\(1\\)}: best - insert at \\(end\\) or \\(arr[-1]\\):\nComputers may have to allocate additional memory cells toward this array (language specific)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---differences",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---differences",
    "title": "DSA 1: Big-O - Arrays and Sets",
    "section": "2.1 Classic Arrays vs Array-Based Sets - Differences",
    "text": "2.1 Classic Arrays vs Array-Based Sets - Differences\nAn array-based set:\n\nis an array\nwith one additional constraint\nof barring duplicates"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---operations-comparison-table",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---operations-comparison-table",
    "title": "DSA 1: Big-O - Arrays and Sets",
    "section": "2.2 Classic Arrays vs Array-Based Sets - Operations Comparison Table",
    "text": "2.2 Classic Arrays vs Array-Based Sets - Operations Comparison Table\n\n\n\n\n\n\n\n\n\n\nOperation\nArray\nArray-Based Set\nDifference\nChange\n\n\n\n\nRead\n\\(O(1,1)\\)\n\\(O(1,1)\\)\nSame\nNone\n\n\nSearch\n\\(O(1,n)\\)\n\\(O(1,n)\\)\nSame\nNone\n\n\nDelete\n\\(O(1,n)\\)\n\\(O(1,n)\\)\nSame\nNone\n\n\nInsert\n\\(O(1,n+1)\\)\n\\(O(n+1,n*n+1)\\)or\\(O(n+1,2n+1)\\)\n\\(O(worse,worse)\\)\n\\(O_{best}(1 \\to n+1)\\)  and  \\(O_{worse}(n+1 \\to 2n+1)\\)"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-based-set-operation---detailed",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-001-big-o-arrays-sets.html#array-based-set-operation---detailed",
    "title": "DSA 1: Big-O - Arrays and Sets",
    "section": "2.3 Array-Based Set Operation - Detailed",
    "text": "2.3 Array-Based Set Operation - Detailed\n\n2.3.1 Read \\((1)\\), Search \\((n)\\), Delete \\((n)\\)\n\nRead \\((1,1)\\)\n\nSearch \\((1,n)\\)\n\nDelete \\((1,n)\\)\n\nInsert \\((n+1,2n+1)\\)\n\n\n\n2.3.2 Insert \\((2n+1)\\): Different to Classic Arrays\n\n\n2.3.2a Insert \\((2n+1)\\) - Worse\n{\\(n*n+1\\)} - worse, insert at the \\(front\\):\n\n{\\(n\\)}: search whole array {\\(n\\_times\\)}\n\n{\\(n\\)}: shift whole array, right (one-item-at-a-time) i.e. {\\(n\\_times\\)}:\n\n\\(arr[n] \\to arr[n+1]\\) (\\(index\\_[n] \\to index\\_[n+1]\\))\n\n\\(arr[n-1] \\to arr[n]\\) (\\(index\\_[n-1] \\to index\\_[n]\\))\n\n\\(...\\)\n\n\\(arr[0] \\to arr[1]\\) (\\(index\\_[0] \\to index\\_[1]\\))\n\n{\\(1\\)}: insert at index 0, same memory address\n\n\n\n2.3.2b Insert \\((n+1)\\) - Best\n{\\(n+1\\)} - best, insert at the \\(end\\):\n\nSearch array (for dupes) + insert (at end)\n\n\n\n2.3.2c Insert \\((m*n+1)\\) - Medium\n{\\(m*n+1\\)} - medium, insert at the \\(arr[j]\\) or \\(index\\_[j]\\)):\n\n{\\(n\\)}: search whole array {\\(n\\_times\\)}\n{\\(m\\)}: shift whole array {\\(n\\_times\\)} where {\\(m\\)} \\(=\\) {\\(n-j\\)}:\n\nif want to insert at \\(index\\_[j]\\): all items after \\(index\\_[j]\\) by one\nthus we shift right {\\(m\\)} \\(=\\) {\\(n-j\\)} items\n\\(arr[n] \\to arr[n+1]\\) (\\(index\\_[n] \\to index\\_[n+1]\\))\n\\(...\\)\n\\(arr[j] \\to arr[j+1]\\) (\\(index\\_[j] \\to index\\_[j+1]\\))\nor\n\\(arr[n-m] \\to arr[n-m+1]\\) (\\(index\\_[n-m] \\to index\\_[n-m+1]\\))\n\n{\\(1\\)}: insert at \\(arr[j]\\) or \\(arr[n-m]\\)\n\n\n2.3.3 Inserting at \\(arr[j]\\) hand-drawn"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-019-queues-part-2.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-019-queues-part-2.html",
    "title": "DSA 19: Queues - Print [Part 2]",
    "section": "",
    "text": "1. Build a PrintManager class\n\n\n1.1 The Task\n\nBuild a simple Python interface for a printer that can accept printing jobs.\nEnsure print each document in the order in which it was received.\n\n\n\n2. Psuedo-Code Solution\n\n\n2.1 Add Queue class:\n\nenqueue(value): add value to queue\ndequeue(): remove first item from queue\nread(): peek at first from queue\n\n\n\n2.2 Add Printer class:\n\nadd_job_to_queue(job): add job to queue\nprint(job): print job\nrun():\n\ndequeue() each job then\nprint(job) from front to back\n\n\n\n\n3. Python-Code Solution\n\n\n3.1 Queue class\nFrom queue class implementation post.\n\nclass Queue:\n    def __init__(self):\n        self.data = []\n        \n    def enqueue(self,value):\n        self.data.append(value)\n        \n    def dequeue(self):\n        if len(self.data)&gt;0:\n            return self.data.pop(0)\n        else:\n            return None\n\n    def read(self):\n        if len(self.data)&gt;0:\n            return self.data[0]\n        else:\n            return None\n    \n    def __repr__(self):\n        return f\"{self.data!r}\"\n\n    # def __str__(self):\n    #     print(f\"{self.data!r}\")\n    \n\n\n\n3.2 Queue: Testing\n\ntp_q = Queue()\ntp_q.enqueue(1)\nprint(tp_q)\n\ntp_q.enqueue(2)\nprint(tp_q)\n\ntp_q.enqueue(3)\nprint(tp_q)\n\ntp_q.dequeue()\nprint(tp_q)\n\ntp_q.enqueue(4)\nprint(tp_q)\n\ntp_q.enqueue(5)\nprint(tp_q)\ntp_q.enqueue(6)\nprint(tp_q)\ntp_q.dequeue()\nprint(tp_q)\ntp_q.dequeue()\nprint(tp_q)\ntp_q.dequeue()\nprint(tp_q)\ntp_q.dequeue()\nprint(tp_q)\ntp_q.dequeue()\nprint(tp_q)\ntp_q.dequeue()\n\n[1]\n[1, 2]\n[1, 2, 3]\n[2, 3]\n[2, 3, 4]\n[2, 3, 4, 5]\n[2, 3, 4, 5, 6]\n[3, 4, 5, 6]\n[4, 5, 6]\n[5, 6]\n[6]\n[]\n\n\n\n\n3.3 PrintManager class\n\nclass PrintManager():\n    def __init__(self):\n        self.queue = Queue()\n    \n    def add_job(self, job):\n        self.queue.enqueue(job)\n        print(f\"{job!r} added: {self.queue}\")\n    \n    def run(self):\n        while self.queue.read():\n            current_job = self.queue.dequeue()\n            self.print_job(current_job)\n    def print_job(self,job):\n        print(job)\n    \n\n\n\n3.4 PrintManager class: Testing\n\nprinter = PrintManager()\nprinter.add_job(\"doc1.md\")\nprinter.add_job(\"doc2.docx\")\nprinter.add_job(\"doc3.pdf\")\nprinter.run()\n\n'doc1.md' added: ['doc1.md']\n'doc2.docx' added: ['doc1.md', 'doc2.docx']\n'doc3.pdf' added: ['doc1.md', 'doc2.docx', 'doc3.pdf']\ndoc1.md\ndoc2.docx\ndoc3.pdf"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-032-quickalgorithms-part-3.html#find-missing-integer-tonys-solution---test-1",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-032-quickalgorithms-part-3.html#find-missing-integer-tonys-solution---test-1",
    "title": "DSA 32: Quick Algorithms - Exercises [Part 3]",
    "section": "2.1.1 Find Missing Integer: Tony’s Solution - TEST 1",
    "text": "2.1.1 Find Missing Integer: Tony’s Solution - TEST 1\n\n# WORKS FOR INTEGERS APPEARING ONLY ONCE\narr = [int(char) for char in \"052163\"]\nprint(find_missing_integer_v1(arr)) # 4\n\ninput_array: [0, 5, 2, 1, 6, 3]\nsorted_array: [0, 1, 2, 3, 5, 6]\nmissing_integer: 4\n4"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-032-quickalgorithms-part-3.html#find-missing-integer-tonys-solution---test-2",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-032-quickalgorithms-part-3.html#find-missing-integer-tonys-solution---test-2",
    "title": "DSA 32: Quick Algorithms - Exercises [Part 3]",
    "section": "2.1.2 Find Missing Integer: Tony’s Solution - TEST 2",
    "text": "2.1.2 Find Missing Integer: Tony’s Solution - TEST 2\nNote: Solution v1 does not always work with duplicate values in the input array\n\n# FAILS AT\narr = [int(char) for char in \"01592428356\"]\nprint(find_missing_integer_v1(arr)) # 4\n\ninput_array: [0, 1, 5, 9, 2, 4, 2, 8, 3, 5, 6]\nsorted_array: [0, 1, 2, 2, 3, 4, 5, 5, 6, 8, 9]\nmissing_integer: 3\n3"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-043-binary-search-trees-part-6.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-043-binary-search-trees-part-6.html",
    "title": "DSA 43: Binary Search Trees - Sir-Insert-A-Lot [Part 6]",
    "section": "",
    "text": "1. TreeNode Class & insert_node Function: Setup\nPreviously introduced.\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data=data\n        self.left=left\n        self.right=right\n\ndef insert_node(root_node: TreeNode, target: int):\n    current_node = root_node\n    if current_node.data==target:\n        print(f\"c[{current_node.data}]|t[{target}]: \\t\\t\\t\\t\\t\\t\\tNo Duplicate Allowed!\")\n        return   \n    \n    if target&lt;current_node.data: # t&lt;c -&gt; left\n        if current_node.left: # go left: if exists \n            #   50\n            #  1\n            print(f\"c[{current_node.data}]|t[{target}]: c[{current_node.data}] has 1 left-child: \\tgoing left c[{current_node.left.data}]\")\n            current_node=current_node.left\n            return insert_node(current_node, target)\n        else: # go left: if not exist, insert\n            current_node.left=TreeNode(target)\n            print(f\"c[{current_node.data}]|t[{target}]: c[{current_node.data}] has no left-child: \\tinserted t[{target}]cl[{current_node.left.data}]\")\n            return\n    else:  #t&lt;c -&gt; go right\n        if current_node.right: # go right: if exists \n            #   50\n            #  1  51\n            print(f\"c[{current_node.data}]|t[{target}]: c[{current_node.data}] has 1 right-child: \\tgoing right c[{current_node.right.data}]\")\n            current_node=current_node.right\n            return insert_node(current_node, target)\n        else: # go right: if not exist, insert\n            current_node.right=TreeNode(target)\n            print(f\"c[{current_node.data}]|t[{target}]: c[{current_node.data}] has no right-child: \\tinserted t[{target}]cl[{current_node.right.data}]\")\n            return\n\n\n\n2. Insert: Manual\n\nroot = TreeNode(50)\ninsert_node(root, 50) \nprint()\ninsert_node(root, 10) \nprint()\ninsert_node(root, 10) \nprint()\ninsert_node(root, 51) \nprint()\ninsert_node(root, 53) \nprint()\ninsert_node(root, 52) \nprint()\ninsert_node(root, 52) \nprint()\n\n\nc[50]|t[50]:                            No Duplicate Allowed!\n\nc[50]|t[10]: c[50] has no left-child:   inserted t[10]cl[10]\n\nc[50]|t[10]: c[50] has 1 left-child:    going left c[10]\nc[10]|t[10]:                            No Duplicate Allowed!\n\nc[50]|t[51]: c[50] has no right-child:  inserted t[51]cl[51]\n\nc[50]|t[53]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[53]: c[51] has no right-child:  inserted t[53]cl[53]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has no left-child:   inserted t[52]cl[52]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has 1 left-child:    going left c[52]\nc[52]|t[52]:                            No Duplicate Allowed!\n\n\n\n\n\n3. Insert: for-loop\n\nnodes_to_insert_list = [50,10,10,51,53,52,52]\nroot = TreeNode(50)\n\nfor node in nodes_to_insert_list:\n    insert_node(root, node)\n    print()\n\nc[50]|t[50]:                            No Duplicate Allowed!\n\nc[50]|t[10]: c[50] has no left-child:   inserted t[10]cl[10]\n\nc[50]|t[10]: c[50] has 1 left-child:    going left c[10]\nc[10]|t[10]:                            No Duplicate Allowed!\n\nc[50]|t[51]: c[50] has no right-child:  inserted t[51]cl[51]\n\nc[50]|t[53]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[53]: c[51] has no right-child:  inserted t[53]cl[53]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has no left-child:   inserted t[52]cl[52]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has 1 left-child:    going left c[52]\nc[52]|t[52]:                            No Duplicate Allowed!\n\n\n\n\n\n4. Insert: Function\n\ndef insert_nodes_list(nodes_list: list[int]):\n    for node in nodes_list:\n        insert_node(root, node)\n        print()\n\nnodes_to_insert_list = [50,10,10,51,53,52,52]\nroot = TreeNode(50)\ninsert_nodes_list(nodes_to_insert_list)\n\nc[50]|t[50]:                            No Duplicate Allowed!\n\nc[50]|t[10]: c[50] has no left-child:   inserted t[10]cl[10]\n\nc[50]|t[10]: c[50] has 1 left-child:    going left c[10]\nc[10]|t[10]:                            No Duplicate Allowed!\n\nc[50]|t[51]: c[50] has no right-child:  inserted t[51]cl[51]\n\nc[50]|t[53]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[53]: c[51] has no right-child:  inserted t[53]cl[53]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has no left-child:   inserted t[52]cl[52]\n\nc[50]|t[52]: c[50] has 1 right-child:   going right c[51]\nc[51]|t[52]: c[51] has 1 right-child:   going right c[53]\nc[53]|t[52]: c[53] has 1 left-child:    going left c[52]\nc[52]|t[52]:                            No Duplicate Allowed!"
  },
  {
    "objectID": "posts/computerscience/datastructuresandalgorithms/dsa-024-recursion-part-5.html",
    "href": "posts/computerscience/datastructuresandalgorithms/dsa-024-recursion-part-5.html",
    "title": "DSA 24: Recursion - 3 More Examples [Part 5]",
    "section": "",
    "text": "1. Summation of an array\n\ndef sum(arr):\n    if not arr:\n        return 0\n    return arr[0] + sum(arr[1:])\n\narr=[1,2,3,4,5]\nsum(arr)\n\n15\n\n\n\n\n2. Reversing a string\n\ndef rev_string(string):\n    # string \"abcde\"    \n    # return rev_string(\"bcde\")\n    if not string:\n        return \"\"\n    return rev_string(string[1:]) + string[0]\n\nstring = \"abcde\"\nrev_string(string)\n\n'edcba'\n\n\n\n\n3. Count character occurence in a string\n\ndef count_ys(string):\n    if not string:\n        return 0\n    if string[0]==\"y\":\n        return 1+count_ys(string[1:])\n    else: \n        return count_ys(string[1:])\n        \nstring = \"yaybyc\"\ncount_ys(string)\n\n3"
  },
  {
    "objectID": "posts/computerscience/leetcode/index.html",
    "href": "posts/computerscience/leetcode/index.html",
    "title": "❄️LeetCode Posts❄️",
    "section": "",
    "text": "link to leetcode profile here\n\nCreated new leetcode.qmd based on front page index.qmd and\n\nDirected contents to point here: contents: posts/lc_posts.\n\nProbably not the ideal blog + folder structure but it’ll do the job👌.\nI don’t claim to be a web-designer in any sense 😂.\nI began 3 months ago with no algorithm or data structures academic background at all. The Easys were definitey not Easy to me as you can see from the number of submissions.\nThe majority of submissions were 2-3 months ago and I made no attempts in January 2024 👏.\nThis page should keep me accountable and these fingers minty as a mojito on a hot day 🍹."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-003-704-binary-search.html",
    "href": "posts/computerscience/leetcode/leet-003-704-binary-search.html",
    "title": "LeetCode 3: 704 - Binary Search",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-003-704-binary-search.html#problem-description",
    "href": "posts/computerscience/leetcode/leet-003-704-binary-search.html#problem-description",
    "title": "LeetCode 3: 704 - Binary Search",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nGiven an array of integers nums which is sorted in:\n- ascending order, and an\n- integer target,\n- write a function to search target in nums.\n\nIf target exists, then\n\nreturn its index\n\n\nOtherwise,\n\nreturn -1\n\n\nYou must write an algorithm with O(log n) runtime complexity.\n\n1.1 Example 1:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 9\nOutput: 4\nExplanation: 9 exists in nums and its index is 4\n\n\n1.2 Example 2:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 2\nOutput: -1\nExplanation: 2 does not exist in nums so return -1"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-003-704-binary-search.html#code",
    "href": "posts/computerscience/leetcode/leet-003-704-binary-search.html#code",
    "title": "LeetCode 3: 704 - Binary Search",
    "section": "3. Code",
    "text": "3. Code\nTest the cases that its larger, smaller and on the split.\n\n3.1 larger than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],  1, {2}, 3, *4*, [5]]\n           # [[-1], 0, {3}, 5, *9*, [12]] \n            if nums[m]&lt;target: #if 3&lt;9:\n                l = m + 1\n           # [[3], *4*, [5]]\n           # [[5], *9*, [12]] \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1\n    \narr = [-1,0,3,5,9,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n4\n\n\n\n\n3.2 less than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{-1}, 9, {10}, 11, 12, [12]] \n            \n            if nums[m]&lt;target:\n                l = m + 1\n\n           # [[0],*1*,{2},3,*4*,[5]]\n           # [{-1}, *9*, {10}, 11, 12, [12]] \n                \n            elif nums[m]&gt;target:\n                \n           # [[0],*1*,[2],3,*4*,[5]]\n           # [{-1}, *9*, [10], 11, 12, [12]]                \n                r = m\n            else:\n                return m\n        return -1\n\narr = [-1,9,10,11,12,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n1\n\n\n\n\n3.3 On a split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{7}, 8, {*9*}, 11, 12, [13]] \n            \n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:          \n                r = m\n            else:\n                return m\n        return -1\n    \n\narr = [7,7,9,11,12,13]\nsoln = Solution()\nsoln.search(arr, 9)\n\n2\n\n\n\n\n4.4 Clean version\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-003-704-binary-search.html#submit",
    "href": "posts/computerscience/leetcode/leet-003-704-binary-search.html#submit",
    "title": "LeetCode 3: 704 - Binary Search",
    "section": "6. Submit",
    "text": "6. Submit\nMiddle of the pack \nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#problem-description",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#problem-description",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time.\nImplement the MinStack class:\n1. MinStack() initializes the stack object.\n2. void push(int val) pushes the element val onto the stack.\n3. void pop() removes the element on the top of the stack.\n4. int top() gets the top element of the stack.\n5. int getMin() retrieves the minimum element in the stack.\n\n1.1 LeetCode example\nInput:\n[\"MinStack\",\"push\",\"push\",\"push\",\"getMin\",\"pop\",\"top\",\"getMin\"]\n[[],[-2],[0],[-3],[],[],[],[]]\nOutput:\n[null,null,null,null,-3,null,0,-2]"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#analysis",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#analysis",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "2. Analysis",
    "text": "2. Analysis\nI’ve decomposed the Inputs (code + variables) and expected outputs (stack and return values) for each line of code run.\n[Future Iteration 1]: Learn how to assert or include code that checks inputs what they are expected in an automatic way (The Output_Mine should be filled later hopefully automatically. For now, I eyeball the results and have LeetCode accept whether its passing or failing)\n[Future Iteration 2]: I’m using Python Lists, I could do the same attempt with chr and string types as parentheses are simply characters.\n\n2.1 Summary Table\n\n\n\nPython_Executed\nStack_Expected\nOutput_Expected\nOutput_Mine\n\n\n\n\nMinStack minStack = new MinStack();\n[]\nnull\nasdf\n\n\nminStack.push(-2);\n[-2]\nnull\nasdf\n\n\nminStack.push(0)\n[0,-2]\nnull\nasdf\n\n\nminStack.push(-3);\n[-3,0,-2]\nnull\nasdf\n\n\nminStack.getMin()\n[-3,0,-2]\n-3\nasdf\n\n\nminStack.pop()\n[0,-2]\nnull\nasdf\n\n\nminStack.top()\n[0,-2]\n0\nasdf\n\n\nminStack.getMin()\n[0,-2]\n-2\nasdf"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#code",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#code",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "3. Code",
    "text": "3. Code\nWrite the MinStack() class and its requried methods.\n\nclass MinStack():\n    def __init__(self):\n        self.stack = [] # create empty list\n\n    def push(self, val: int) -&gt; None:\n        self.stack.append(val) # add value to end of list\n\n    def pop(self) -&gt; None:\n        self.stack.pop() # remove last val of the list\n\n    def top(self) -&gt; int:\n        return self.stack[-1] # in a list, top of stack is the last item list[-1]\n    \n    def getMin(self) -&gt; int:\n        return min(self.stack)"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#test-functionality",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#test-functionality",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "4. Test Functionality",
    "text": "4. Test Functionality\n\nminStack = MinStack()\n\n\nminStack.push(-2);\n\n\nminStack.push(0);\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.push(-3);\nminStack.stack\n\n[-2, 0, -3]\n\n\n\nminStack.getMin() # // return -3\n# minStack.stack\n\n-3\n\n\n\nminStack.pop();\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.top() # return 0\n\n0\n\n\n\nminStack.getMin() # return -2\n\n-2"
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#submit",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#submit",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "5. Submit",
    "text": "5. Submit\nThe code is slow but great memory management.\nAt the my current level, I’m happy to simply solve the problems. I don’t usually solve Mediums that easily."
  },
  {
    "objectID": "posts/computerscience/leetcode/leet-001-155-min-stack.html#some-commentary",
    "href": "posts/computerscience/leetcode/leet-001-155-min-stack.html#some-commentary",
    "title": "LeetCode 1: 155 - Min Stack",
    "section": "6. Some Commentary",
    "text": "6. Some Commentary\nThe question is framed from a Java’s perspective hence there are types in front of each declaration:\n- void pop()\n- int top()\n- new MinStack()\nNote: I’ve never touched Java 🤭.\nJava is a Static-Typed whilst Python is a Dynamically-Type.\n\nJava requires variables and method return values be explicitly declared at compile-time.\nPython data types are determined at runtime.\n\nPython doesn’t require explicit type declarations for variables, function return types, or when creating objects.\n\n\nThat is, since I’m using Python, so I won’t need to declare my return types when creating a method of a class.\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#install-github-api-in-wsl",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#install-github-api-in-wsl",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "2.1 Install Github API in wsl",
    "text": "2.1 Install Github API in wsl\n\nRun sudo apt install gh.\nRun gh to see if install properly. Looks Good.\nSee Command: issue available for us to call."
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#get-authenticated",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#get-authenticated",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "2.2 Get Authenticated",
    "text": "2.2 Get Authenticated\n\nIf you don’t have ssh setup then here is a [Two Step Tutorial]"
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#test-out-a-single-issue-transfer",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#test-out-a-single-issue-transfer",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "2.3 Test out a single Issue Transfer",
    "text": "2.3 Test out a single Issue Transfer\n\nRun gh issue transfer 23 tonyjustdevs/learning_csharp_vs -R tonyjustdevs/learning_csharp\n\n\n\nNo error message and it looked like it [github issue event]"
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#before-transfer",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#before-transfer",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "3.1 Before Transfer",
    "text": "3.1 Before Transfer\nIssues are currently with original repo:\n\ntonyjustdevs/learning_csharp\n\nRecall, the goal is to transfer them to:\n\ntonyjustdevs/learning_csharp_vs"
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#before-transfer-1",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#before-transfer-1",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "4.1 [Before Transfer]",
    "text": "4.1 [Before Transfer]\n\n4.1.1 Part 4: Issues 32 to 39\n\n\n\n4.1.2 [Before Transfer] Part 5: Issues 40 to 45\n\n\n\n4.1.3 [Before Transfer] Part 4: Issues 46 to 52\n\n\n\n4.1.4 [Before Transfer] Part 4: Issues 53 to 54"
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#run-code-for-issues-32-to-54",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#run-code-for-issues-32-to-54",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "4.2 Run Code for Issues 32 to 54",
    "text": "4.2 Run Code for Issues 32 to 54\nLooks like theres a limit of 20 requests per minutes or something since it stopped:\n\nIssues 32 to 51 went through\nHalted at Issues 52\n\nI ran the code again for Issue 52 to 54 a minute later and everything worked fine."
  },
  {
    "objectID": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#after-transfer-example",
    "href": "posts/computerscience/coding/code-017-transfer-multiple-issues-github.html#after-transfer-example",
    "title": "Code 17: Transfer Multiple Issues via Github API in Bash",
    "section": "5.1 [After Transfer] Example",
    "text": "5.1 [After Transfer] Example"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlinks-in-linuxubuntu-optional",
    "href": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlinks-in-linuxubuntu-optional",
    "title": "Code 9: Creating and using Symlinks",
    "section": "2.1 Check existing Symlinks in Linux/Ubuntu (Optional):",
    "text": "2.1 Check existing Symlinks in Linux/Ubuntu (Optional):\n\nA symlink is represented with -&gt;:\n\n\nls -l /path/to/symlink"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlinks-in-visual-studio-code-optional",
    "href": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlinks-in-visual-studio-code-optional",
    "title": "Code 9: Creating and using Symlinks",
    "section": "2.2 Check existing Symlinks in Visual Studio Code (Optional):",
    "text": "2.2 Check existing Symlinks in Visual Studio Code (Optional):\n\nThe same symlink is represented by down-then-right-arrow (reverse L):"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#delete-existing-symlinks-optional",
    "href": "posts/computerscience/coding/code-009-symlinks.html#delete-existing-symlinks-optional",
    "title": "Code 9: Creating and using Symlinks",
    "section": "2.3 Delete existing Symlinks (Optional):",
    "text": "2.3 Delete existing Symlinks (Optional):\n\nrm /path/to/symlink"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#create-a-new-symlink",
    "href": "posts/computerscience/coding/code-009-symlinks.html#create-a-new-symlink",
    "title": "Code 9: Creating and using Symlinks",
    "section": "2.4 Create a new Symlink",
    "text": "2.4 Create a new Symlink\n\nln -s /path/to/original/file.md /chosen/path/for/symlink/file.md"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlink",
    "href": "posts/computerscience/coding/code-009-symlinks.html#check-existing-symlink",
    "title": "Code 9: Creating and using Symlinks",
    "section": "2.5 Check existing Symlink",
    "text": "2.5 Check existing Symlink\nSee the symlink has been established again.\n\nls -l"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#how-to",
    "href": "posts/computerscience/coding/code-009-symlinks.html#how-to",
    "title": "Code 9: Creating and using Symlinks",
    "section": "3.1 How-To",
    "text": "3.1 How-To\n\nCheck files in working directory (wd): ll (If symlink existing, it wont be overriden, delete it if required)\nCheck files in original directory (ogdir): ll ~/og_files\n\nMove files required for symlinks: mv tony_* ~/og_files\nCheck files no longer in wd: ll\nCheck files are in ogdir: ll ~/og_files\nFor Loop: create symlinks for files prefixed with tony_ to wd: for file in ~/og_files/tony_*; do ln -s $file .; done\nCheck files in wd: ll\nLooks all good!"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#the-code",
    "href": "posts/computerscience/coding/code-009-symlinks.html#the-code",
    "title": "Code 9: Creating and using Symlinks",
    "section": "3.2 The Code",
    "text": "3.2 The Code\n\nll\nll ~/og_files\nmv tony_* ~/og_files\nll\nll ~/og_files\nfor file in ~/og_files/tony_*; do ln -s $file .; done\nll"
  },
  {
    "objectID": "posts/computerscience/coding/code-009-symlinks.html#screenshot-of-how-to-and-code",
    "href": "posts/computerscience/coding/code-009-symlinks.html#screenshot-of-how-to-and-code",
    "title": "Code 9: Creating and using Symlinks",
    "section": "3.3 Screenshot of How-To and Code",
    "text": "3.3 Screenshot of How-To and Code"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html",
    "href": "posts/computerscience/coding/code-003-bash.html",
    "title": "Code 3: Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#basics",
    "href": "posts/computerscience/coding/code-003-bash.html#basics",
    "title": "Code 3: Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#variables",
    "href": "posts/computerscience/coding/code-003-bash.html#variables",
    "title": "Code 3: Bash Basics",
    "section": "2. Variables",
    "text": "2. Variables\nFIRST_NAME=tony: set a variable\necho FIRST_NAME: echo the variable’\n\\': escape the single quote with backtick\n\n2.1 Fixed Variables\n\nhellothere.sh # [Terminal]\n\n\n#!/bin/bash\nFIRST_NAME=Tony\nLAST_NAME=JustDevs\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere.sh # [Terminal]\n./hellothere.sh # [Terminal]\n\n\n\n2.2 Interactive Variables\n\nhellothere_interactive.sh # [Terminal]\n\n\n#/bin/bash\n\necho What is your first name?\nread FIRST_NAME\necho What is your last name?\nread LAST_NAME\n\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere_interactive.sh # [Terminal]\n./hellothere_interactive.sh # [Terminal]\n\n\n\n2.3 Positional Arguments\n\nvim hellothere_posarg.sh  # [Terminal]\n\n\n#!/bin/bash\n\necho Hello $1 $2\n\n\ncbmod u+x hellothere_posargs.sh     # [Terminal]\n./hellothere_posargs.sh Tony JustDevs # [Terminal]"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#output-redirection",
    "href": "posts/computerscience/coding/code-003-bash.html#output-redirection",
    "title": "Code 3: Bash Basics",
    "section": "3. Output redirection",
    "text": "3. Output redirection\n\n3.1 Piping |\n\nThe output of the previous command ls -l /usr/bin is forwarded to the command after the |.\nAdd grep bash to filter for bash.\n\n\nls -l /usr/bin | grep bash # [Terminal]\n\n\n\n3.2 Override &gt;\nE.g. Logging something from a script to a log-file: 1. Catch output from echo command\n2. Override of a text file\n\necho Hello World! &gt; output_override_to_text.txt\ncat output_override_to_text.txt\n\n\n\n3.3 Append &gt;&gt;\nAppend from script to a log-file: 1. Catch output from echo command\n2. Append output into a text file\n\necho Hello World! &gt; output_append_to_text.txt\ncat output_override_to_text.txt\necho Good day matey! &gt; output_append_to_text.txt\ncat output_override_to_text.txt"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#input-direction",
    "href": "posts/computerscience/coding/code-003-bash.html#input-direction",
    "title": "Code 3: Bash Basics",
    "section": "4. Input direction",
    "text": "4. Input direction\n\n&lt;: from a file\n&lt;&lt;: from multiple lines of text\n&lt;&lt;&lt;: from single string of text\n\n\n4.1 &lt; from a line\nUse word-count wc command to for number of words in text 1. Command to receive Input 2. Input direction of text\n\nwc -w &lt; output_append_to_text.txt # input direction\ncat output_append_to_text.txt | wc -w # output direction\n\n\n\n4.2 &lt;&lt; from multiple lines\nSupply multiple lines of words 1. Command to receive Input 2. Input direction to Command 3. KeywordStart 4. Actual text 5. KeywordEnd\n\ncat &lt;&lt; EOF\nthis is some text\nwith multiple\nlines\nEOF\n\n\n\n4.3 &lt;&lt;&lt; from single line\n\nwc -w &lt;&lt;&lt; \"a sentence line with 6 words\""
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#test-operators",
    "href": "posts/computerscience/coding/code-003-bash.html#test-operators",
    "title": "Code 3: Bash Basics",
    "section": "5. Test Operators",
    "text": "5. Test Operators\n\n5.1 Equality\nTests whether an express exists with 0(No issues) or 1 (Error) 1. Write expression 2. Print exit-code of last executed command\n\n[ hello = hello ]\necho $? # exits 0\n\n[ 1 = 0 ] \necho $? # exits 1\n\n[ 1 -eq 1 ] # equate numericals\necho $?\n\n\n\n5.2 If / Elif / Else\n${1,,} Parameter Expansion: Ignores lower and upper-cases when comparing to values\n\n#/bin/bash\n\nif [ ${1,,} = tonydevs ]; then\n        echo \"Oh, you're the boss here. Welcome!\"\nelif [ ${1,,} = help]; then\n        echo \"Just enter your username, duh!\"\nelse\n        echo \"I don't know who you are. But you're not the boss of me!\"\nfi\n~       \n\n\n\n5.3 Case statements\nBetter than if / elif /else: - Checking for multiple values - is easier to read\n\nvim case_stmts.sh #[Terminal]\n\n\n#!/bin/bash\n\ncase ${1,,} in\n        tony | administrator)\n                echo \"Gday, you're the boss here!\"\n                ;;\n        help)\n                echo \"Just enter your username!\"\n                ;;\n        *)\n                echo \"Hello there, you're not the boss of me. Enter a valid username!\"\nesac\n\n\nhttps://www.youtube.com/watch?v=tK9Oc6AEnR4"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#arrays",
    "href": "posts/computerscience/coding/code-003-bash.html#arrays",
    "title": "Code 3: Bash Basics",
    "section": "6. Arrays",
    "text": "6. Arrays\nStore multiple variables in a list called Arrays\n\n6.1 Indexing\n\nMY_FIRST_LIST=(one two three four five)\necho $MY_FIRST_LIST # print only first element [TERMINAL]\necho ${MY_FIRST_LIST[@]} # prints everything\necho ${MY_FIRST_LIST[1]} # prints second element\n\n\n\n6.2 Indexing\nitem: each element in loop\n${MY_FIRST_LIST[@]}: all items in list\ndo echo -n: do echo and ignore all new line characters\n$item: represents each single item in array\n|: output direction\nwc -c: count characters\ndone: finish loop\n\nfor item in ${MY_FIRST_LIST[@]}; do echo -n $item | wc -c; done"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#functions",
    "href": "posts/computerscience/coding/code-003-bash.html#functions",
    "title": "Code 3: Bash Basics",
    "section": "7. Functions",
    "text": "7. Functions\n\n7.1 Function only\n\nCreate shell\nDefine function\nCatch output for up and since with their different flags\nPrint everything between the two EOFs keywords\nCall the variables generated\nClose function\n\n\nvim first_function.sh # [Terminal]\n\n\n#!/bin/bash \nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\n\n\n\n7.2 Not Declaring Local Variables (Wrong!)\nIf variables inside a function are not declared local, they may override variables of the same name in the global variables in the global environment/\n\n#!/bin/bash \nup=\"global up\" # add global variable 1\nsince=\"global since\" # add global variable 2 \necho $up\necho $since\n\nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.3 Declaring Local Variables in a Function\nDefine variables inside functions as local variables so they’re only available to the functions and not to the entire script.\n\n#!/bin/bash \nup=\"global up\" \nsince=\"global since\" \necho $up\necho $since\n\nshowuptime(){\n    local up=$(uptime -p | cut -c4-) # add local prefix to declare local variable 1\n    local since=$(uptime -s) # add local prefix to declare local variable 2\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.4 Position Arguments\nJust like shell scripts, shell functions can also have positional arguments\n\n#!/bin/bash\n\nshowname(){\n    echo hello $1 $2\n}\nshowname Tony JustDevs"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#exit-codes",
    "href": "posts/computerscience/coding/code-003-bash.html#exit-codes",
    "title": "Code 3: Bash Basics",
    "section": "8. Exit Codes",
    "text": "8. Exit Codes\n\n#!/bin/bash\nshowname(){\n    echo hello $1\n    if [ ${1,,} = tony ]; then\n        return 0\n    else\n        return 1\n    fi\n}\nshowname() $1\nif [ $? = 1 ]; then\n    echo = \"A strange has called the function!\"\nfi"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#awk",
    "href": "posts/computerscience/coding/code-003-bash.html#awk",
    "title": "Code 3: Bash Basics",
    "section": "9. awk",
    "text": "9. awk\nFilter contents to and fro: 1. files or 2. output of a command\n\n9.1 Filter a Text File\n\necho one two three &gt; onetwothree.txt #[Terminal]\nawk '{print $1}' onetwothree.txt\n\n\n\n9.2 Filter a CSV File\n\nvim csv_test.csv \none,two,three #[csv_test.csv]\nawk -F, '{print $1 $2}'\n\n\n\n\n\n9.3 Piping into awk\n\necho \"Just get this world: Hello\" | awk '{print $5}'\necho \"Just get this world: Hello\" | awk -F: '{print $2}' | cut -c2"
  },
  {
    "objectID": "posts/computerscience/coding/code-003-bash.html#sed",
    "href": "posts/computerscience/coding/code-003-bash.html#sed",
    "title": "Code 3: Bash Basics",
    "section": "10. sed",
    "text": "10. sed\nReplace values in text files with Regular Expressions\nExample: sed 's/word1/word2/g' sedtest.txt\nsed: replace values command\ns: means subtsitute\ng: globally, across the whole text file -i.ORIGINAL: keeps original file appends .ORIGINALto file name\n\n# [terminal]\nvim sed_test.txt\n\n# [sed_test.txt]\nThe fly flies like no fly flies. \nA fly is an insect that has wings and a fly likes to eat leftovers  \n\n# Just prints into terminal \nsed 's/fly/grasshopper/g' sedtest.txt \n\n# replace og file with command + creates new file .txt.ORIGINAL of og content\nsed -i.ORIGINAL 's/fly/grasshopper/g' sedtest.txt"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#assignment",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#assignment",
    "title": "Code 13: Shallow or Deep?",
    "section": "1.1 Assignment:",
    "text": "1.1 Assignment:\n\nCode: =\nCreates a new variable name, not a new object.\nNew varaible name references for the same original object."
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#shallow-copy",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#shallow-copy",
    "title": "Code 13: Shallow or Deep?",
    "section": "1.2 Shallow Copy:",
    "text": "1.2 Shallow Copy:\n\nCode: copy.copy()\nCreates a new top level object\nMaintains original references (i.e. not new copies) of same objects"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#deep-copy",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#deep-copy",
    "title": "Code 13: Shallow or Deep?",
    "section": "1.3 Deep Copy:",
    "text": "1.3 Deep Copy:\n\nCode: copy.deepcopy()\nCreates a new object\nCreates new copies recursively of all inner objects"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-cat-class-and-object",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-cat-class-and-object",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.1 Create Cat Class and Object",
    "text": "2.1 Create Cat Class and Object\n\nclass Cat():\n    def __init__(self, name: str):\n        self.name = name\n        \n    def __repr__(self) -&gt; str:\n        return self.name\n\nMilo_obj = Cat(name=\"milo\")\nprint(f\"id: [{id(Milo_obj)}]\")\n\nid: [140517113061744]"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-cat-list-and-append-cat-object-milo",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-cat-list-and-append-cat-object-milo",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.2 Create Cat List and append Cat Object milo",
    "text": "2.2 Create Cat List and append Cat Object milo\n\nimport copy\nlistcats = ['Oreo','Lilo','Wasabi',Milo_obj]\nlistcats\n\n['Oreo', 'Lilo', 'Wasabi', milo]"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-copies-of-cat-list-with-each-method",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#create-copies-of-cat-list-with-each-method",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.3 Create Copies of Cat List with Each Method",
    "text": "2.3 Create Copies of Cat List with Each Method\nAssignment = results:\n\nGives a reference back to same origin object (same id:140517134247168)\n\nOthers results (.copy, .deepcopy, :):\n\ncreate a new (top-level) object (difference ids):\n\nNote: Only compared ids of outer layer list objects. We need to see the individual items within the list (next section).\n\n\n\nlistcats_copy_assn      = listcats               \nlistcats_copy_shallow   = copy.copy(listcats)    \nlistcats_copy_deep      = copy.deepcopy(listcats)\nlistcats_copy_slice     = listcats[:]            \nprint(f\"[id:{id(listcats)}] listcats_og: {listcats}\")                       \nprint(f\"[id:{id(listcats_copy_assn)}] listcats_cpy_assn: {listcats_copy_assn}\")       \nprint(f\"[id:{id(listcats_copy_shallow)}] listcats_cpy_shallow: {listcats_copy_shallow}\") \nprint(f\"[id:{id(listcats_copy_deep)}] listcats_cpy_deep: {listcats_copy_deep}\")      \nprint(f\"[id:{id(listcats_copy_slice)}] listcats_cpy_slice: {listcats_copy_slice}\")\n\n[id:140517134247168] listcats_og: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517134247168] listcats_cpy_assn: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517124516096] listcats_cpy_shallow: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517110270272] listcats_cpy_deep: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517124392064] listcats_cpy_slice: ['Oreo', 'Lilo', 'Wasabi', milo]"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#are-each-milo-object-new-or-copies-of-original",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#are-each-milo-object-new-or-copies-of-original",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.4 Are each milo object new or copies of original?",
    "text": "2.4 Are each milo object new or copies of original?\nShallow copies keeps the same references:\n\nAll copy methods (except deepcopy()) have the same milo object as original id: [140517113061744]\n\nDeep copies creates new objects: creates new id’s\n\nprint(f\"[{id(listcats[3])}]-[milo id] of [listcats_og]: {listcats[3]}\")                       \nprint(f\"[{id(listcats_copy_assn[3])}]-[milo id] of [listcats_cpy_assn]: {listcats_copy_assn[3]}\")       \nprint(f\"[{id(listcats_copy_shallow[3])}]-[milo id] of [listcats_cpy_shallow]: {listcats_copy_shallow[3]}\") \nprint(f\"[{id(listcats_copy_deep[3])}]-[milo id] of [listcats_cpy_deep]: {listcats_copy_deep[3]}\")      \nprint(f\"[{id(listcats_copy_slice[3])}]-[milo id] of [listcats_cpy_slice]: {listcats_copy_slice[3]}\")    \n\n[140517113061744]-[milo id] of [listcats_og]: milo\n[140517113061744]-[milo id] of [listcats_cpy_assn]: milo\n[140517113061744]-[milo id] of [listcats_cpy_shallow]: milo\n[140517115254800]-[milo id] of [listcats_cpy_deep]: milo\n[140517113061744]-[milo id] of [listcats_cpy_slice]: milo"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#update-milo-to-milo",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#update-milo-to-milo",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.5 Update milo to Milo",
    "text": "2.5 Update milo to Milo\n\nMilo_obj.name=\"Milo\"\nMilo_obj\n\nMilo"
  },
  {
    "objectID": "posts/computerscience/coding/code-013-shallow-and-deep.html#results-of-milo-the-different-methods",
    "href": "posts/computerscience/coding/code-013-shallow-and-deep.html#results-of-milo-the-different-methods",
    "title": "Code 13: Shallow or Deep?",
    "section": "2.6 Results of milo the Different Methods",
    "text": "2.6 Results of milo the Different Methods\nAs expected:\n\nThe deepcopy list milo has not updated (since its a new object, i.e. new object id: 140517115254800)\nAll other methods do update original milo since references are maintained, rather than creating new objects (i.e. same object id: 140517113061744)\n\n\nprint(f\"[{id(listcats[3])}]-[milo id] of [listcats_og]: {listcats[3]}\")                       \nprint(f\"[{id(listcats_copy_assn[3])}]-[milo id] of [listcats_cpy_assn]: {listcats_copy_assn[3]}\")       \nprint(f\"[{id(listcats_copy_shallow[3])}]-[milo id] of [listcats_cpy_shallow]: {listcats_copy_shallow[3]}\") \nprint(f\"[{id(listcats_copy_deep[3])}]-[milo id] of [listcats_cpy_deep]: {listcats_copy_deep[3]}\")      \nprint(f\"[{id(listcats_copy_slice[3])}]-[milo id] of [listcats_cpy_slice]: {listcats_copy_slice[3]}\")    \n\n[140517113061744]-[milo id] of [listcats_og]: Milo\n[140517113061744]-[milo id] of [listcats_cpy_assn]: Milo\n[140517113061744]-[milo id] of [listcats_cpy_shallow]: Milo\n[140517115254800]-[milo id] of [listcats_cpy_deep]: milo\n[140517113061744]-[milo id] of [listcats_cpy_slice]: Milo"
  },
  {
    "objectID": "posts/computerscience/coding/code-025-locals.html",
    "href": "posts/computerscience/coding/code-025-locals.html",
    "title": "Code 25: locals()",
    "section": "",
    "text": "1. Setup\n\nclass TreeNode:\n    def __init__(self, data, left=None, right=None):\n        self.data = data\n        self.left = left\n        self.right = right\n        \nnode15 = TreeNode(15, left=None, right=None)\nnode25 = TreeNode(25, left=node15, right=None)\nnode35 = TreeNode(35, left=None, right=None)\n\n\n\n2. locals(): As a Dictionary\nLocal variables and their values as a dictionary\n\ndef some_fn(): #blog it\n    current_node = node15\n    root_node = node25\n    x=777\n    y=x-1\n    z=\"a cool string\"\n    cooldict = {'a_1205': 1206,'b_x':x,\n                'c_n25':node25,\n                'd_rn':root_node,\n                'e_n15':node15,\n                'f_n25l':node25.left,\n                'g_rnl':root_node.left,\n                'h_n35':node35}\n    \n    print(f\"[local-variables dict using locals():] \\n\\t\",locals(),end=\"\\n\\n\")\n    \n    # local_keys_var_names = (locals().keys())\n    # print(f\"[local-variable-names using 'locals().keys()']: \\n\\t{local_keys_var_names}\",end=\"\\n\\n\")\n\n    # local_variable_values = (locals().values())\n    # print(f\"[local-variable-values using 'locals().values()']:\")\n    # [print(f\"\\t{val}\") for val in local_variable_values]\n    # print()\n    \n    # local_variable_name_and_values = (locals().items())\n    # print(f\"[local-variable-values using 'locals().items()']:\")\n    # [print(f\"\\t{(k,v)}\") for k,v in local_variable_name_and_values]\n    # print()\n    \nsome_fn()\n\n\n[local-variables dict using locals():] \n     {'current_node': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'root_node': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'x': 777, 'y': 776, 'z': 'a cool string', 'cooldict': {'a_1205': 1206, 'b_x': 777, 'c_n25': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'd_rn': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'e_n15': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'f_n25l': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'g_rnl': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'h_n35': &lt;__main__.TreeNode object at 0x7f2b8553ab00&gt;}}\n\n\n\n\n\n3. locals().items(): As A List\nOutputs as dict_keys, which is an iterable, then convert variable_name-value pairs to list\n\ndef some_fn(): #blog it\n    current_node = node15\n    root_node = node25\n    x=777\n    y=x-1\n    z=\"a cool string\"\n    cooldict = {'a_1205': 1206,'b_x':x,\n                'c_n25':node25,\n                'd_rn':root_node,\n                'e_n15':node15,\n                'f_n25l':node25.left,\n                'g_rnl':root_node.left,\n                'h_n35':node35}\n    \n    # print(f\"[local-variables dict using locals():] \\n\\t\",locals(),end=\"\\n\\n\")\n    \n    # local_keys_var_names = (locals().keys())\n    # print(f\"[local-variable-names using 'locals().keys()']: \\n\\t{local_keys_var_names}\",end=\"\\n\\n\")\n\n    # local_variable_values = (locals().values())\n    # print(f\"[local-variable-values using 'locals().values()']:\")\n    # [print(f\"\\t{val}\") for val in local_variable_values]\n    # print()\n\n    local_variable_name_and_values = (locals().items())\n    print(f\"[local-variable-values using 'locals().items()']:\")\n    [print(f\"\\t{(k,v)}\") for k,v in local_variable_name_and_values]\n    print()\n    \nsome_fn()\n\n\n[local-variable-values using 'locals().items()']:\n    ('current_node', &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;)\n    ('root_node', &lt;__main__.TreeNode object at 0x7f2b85538940&gt;)\n    ('x', 777)\n    ('y', 776)\n    ('z', 'a cool string')\n    ('cooldict', {'a_1205': 1206, 'b_x': 777, 'c_n25': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'd_rn': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'e_n15': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'f_n25l': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'g_rnl': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'h_n35': &lt;__main__.TreeNode object at 0x7f2b8553ab00&gt;})\n\n\n\n\n\n4. locals().keys(): Variable Names Only\nOutputs as dict_keys, an iterable, containing all names of local variables\n\ndef some_fn(): #blog it\n    current_node = node15\n    root_node = node25\n    x=777\n    y=x-1\n    z=\"a cool string\"\n    cooldict = {'a_1205': 1206,'b_x':x,\n                'c_n25':node25,\n                'd_rn':root_node,\n                'e_n15':node15,\n                'f_n25l':node25.left,\n                'g_rnl':root_node.left,\n                'h_n35':node35}\n    \n    # print(f\"[local-variables dict using locals():] \\n\\t\",locals(),end=\"\\n\\n\")\n    \n    local_keys_var_names = (locals().keys())\n    print(f\"[local-variable-names using 'locals().keys()']: \\n\\t{local_keys_var_names}\",end=\"\\n\\n\")\n\n    # local_variable_values = (locals().values())\n    # print(f\"[local-variable-values using 'locals().values()']:\")\n    # [print(f\"\\t{val}\") for val in local_variable_values]\n    # print()\n\n    # local_variable_name_and_values = (locals().items())\n    # print(f\"[local-variable-values using 'locals().items()']:\")\n    # [print(f\"\\t{(k,v)}\") for k,v in local_variable_name_and_values]\n    # print()\n    \nsome_fn()\n\n[local-variable-names using 'locals().keys()']: \n    dict_keys(['current_node', 'root_node', 'x', 'y', 'z', 'cooldict'])\n\n\n\n\n\n5. locals().values(): Variable Values Only\nOutputs as dict_keys, an iterable, containing all values of local variables\n\ndef some_fn(): #blog it\n    current_node = node15\n    root_node = node25\n    x=777\n    y=x-1\n    z=\"a cool string\"\n    cooldict = {'a_1205': 1206,'b_x':x,\n                'c_n25':node25,\n                'd_rn':root_node,\n                'e_n15':node15,\n                'f_n25l':node25.left,\n                'g_rnl':root_node.left,\n                'h_n35':node35}\n    \n    # print(f\"[local-variables dict using locals():] \\n\\t\",locals(),end=\"\\n\\n\")\n    \n    # local_keys_var_names = (locals().keys())\n    # print(f\"[local-variable-names using 'locals().keys()']: \\n\\t{local_keys_var_names}\",end=\"\\n\\n\")\n\n    local_variable_values = (locals().values())\n    print(f\"[local-variable-values using 'locals().values()']:\")\n    [print(f\"\\t{val}\") for val in local_variable_values]\n    print()\n\n    # local_variable_name_and_values = (locals().items())\n    # print(f\"[local-variable-values using 'locals().items()']:\")\n    # [print(f\"\\t{(k,v)}\") for k,v in local_variable_name_and_values]\n    # print()\n    \nsome_fn()\n\n\n[local-variable-values using 'locals().values()']:\n    &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;\n    &lt;__main__.TreeNode object at 0x7f2b85538940&gt;\n    777\n    776\n    a cool string\n    {'a_1205': 1206, 'b_x': 777, 'c_n25': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'd_rn': &lt;__main__.TreeNode object at 0x7f2b85538940&gt;, 'e_n15': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'f_n25l': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'g_rnl': &lt;__main__.TreeNode object at 0x7f2b8553a980&gt;, 'h_n35': &lt;__main__.TreeNode object at 0x7f2b8553ab00&gt;}"
  },
  {
    "objectID": "posts/computerscience/coding/code-010-add-script-to-PATH.html",
    "href": "posts/computerscience/coding/code-010-add-script-to-PATH.html",
    "title": "Code 10: Add a script to PATH",
    "section": "",
    "text": "1. Create Bash Script\nPut all the bash code below into a new bash script (e.g. do_symlinks.sh)\n\n#!/bin/bash\n\n# Check if a prefix is supplied\nif [ -z \"$1\" ]; then\n          echo \"Usage: $0 &lt;prefix&gt;\"\n            exit 1\nfi\n\n# Define the source directory and the prefix\nSOURCE_DIR=~/og_files\nPREFIX=$1\n\n# Loop through files with the specified prefix and create symlinks\nfor file in \"$SOURCE_DIR\"/\"$PREFIX\"*; do\n        if [[ $(basename \"$file\") != \"$PREFIX\"d* ]]; then\n                ln -s \"$file\" .\n                echo \"Created symlink for $(basename \"$file\")\"\n        fi\ndone\n\n\n\n2. Copy or Move /usr/local/bin and Source .bashrc\n\nsudo cp do_symlinks.sh /usr/local/bin/do_symlinks && . ~/.bashrc\n\n\n\n3. Create and change directory into test1 folder\n\nmkdir test1 && cd test1\n\n\n\n4. Run do_symlinks tony_\n\ndo_symlinks tony_\n\n\n\n5. Confirm results ll\n\nll\n\n\n\n6. Terminal Code\n\nsudo cp do_symlinks.sh /usr/local/bin/do_symlinks && . ~/.bashrc\nmkdir test1 && cd test1\ndo_symlinks tony_\nll\n\n\n\n7. Screenshots of Code"
  },
  {
    "objectID": "posts/computerscience/coding/code-001-github_resolve.html#the-setup",
    "href": "posts/computerscience/coding/code-001-github_resolve.html#the-setup",
    "title": "Code 1: Github Issues Automation",
    "section": "1. The Setup",
    "text": "1. The Setup\nTesting the automation of closing a GitHub Issue via a VSCode Commit Message shown in youtube tutorial: How to Use GitHub for Automated Kanban Project Management\n\nHigh level steps:\n\nCreate Issue\n\nAttach associated Repo\n\nAttach associated Project\n\nAttach any relevant Tags\n\nDo required changes to your repo files\n\nCommit with “resolve #” associated to Issue\n\n[Important]: to include “resolve #58” in Commit Message in order to tell Github to automatically resolve it."
  },
  {
    "objectID": "posts/computerscience/coding/code-001-github_resolve.html#issue-is-open",
    "href": "posts/computerscience/coding/code-001-github_resolve.html#issue-is-open",
    "title": "Code 1: Github Issues Automation",
    "section": "2. Issue is Open",
    "text": "2. Issue is Open"
  },
  {
    "objectID": "posts/computerscience/coding/code-001-github_resolve.html#issue-is-closed-successfully",
    "href": "posts/computerscience/coding/code-001-github_resolve.html#issue-is-closed-successfully",
    "title": "Code 1: Github Issues Automation",
    "section": "3. Issue is Closed successfully",
    "text": "3. Issue is Closed successfully\nActions: Commmited, Staged and Pushed.\n[SUCCESS]: Issue #58 has indeed been automatically closed without a manual intervention on the kanban board!"
  },
  {
    "objectID": "posts/computerscience/coding/code-001-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "href": "posts/computerscience/coding/code-001-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "title": "Code 1: Github Issues Automation",
    "section": "4. A Tick ☑️ as a little reward for work done",
    "text": "4. A Tick ☑️ as a little reward for work done"
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#download-and-install-uv",
    "href": "posts/computerscience/coding/code-019-uv-package.html#download-and-install-uv",
    "title": "Code 19: uv Python & Package Manager",
    "section": "1.1 Download and Install uv",
    "text": "1.1 Download and Install uv\n\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nmkdir NameOfNewProject && cd $_"
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#create-project",
    "href": "posts/computerscience/coding/code-019-uv-package.html#create-project",
    "title": "Code 19: uv Python & Package Manager",
    "section": "1.2 Create Project",
    "text": "1.2 Create Project\n\nuv init"
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#check-project-initialisations",
    "href": "posts/computerscience/coding/code-019-uv-package.html#check-project-initialisations",
    "title": "Code 19: uv Python & Package Manager",
    "section": "1.3 Check Project Initialisations",
    "text": "1.3 Check Project Initialisations\nInside pyproject.toml:\n\nrequires-python = \"&gt;=3.13\"\ndependencies = []\n\nThese can be updated later."
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#check-python-version",
    "href": "posts/computerscience/coding/code-019-uv-package.html#check-python-version",
    "title": "Code 19: uv Python & Package Manager",
    "section": "1.4 Check Python Version",
    "text": "1.4 Check Python Version\n\nuv run python --version\n\nThe first time uv run is executed, two files are created:\n\n.venv and\nuv.lock\n\nResponsible for keeping track of python package dependencies and versions."
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#add-a-project-dependency-via-terminal",
    "href": "posts/computerscience/coding/code-019-uv-package.html#add-a-project-dependency-via-terminal",
    "title": "Code 19: uv Python & Package Manager",
    "section": "2.1 Add a project dependency via terminal",
    "text": "2.1 Add a project dependency via terminal\n\nuv add typer\n\nAdds typer to dependencies list in .toml file and resolves all dependencies."
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#add-dev-dependency-via-terminal",
    "href": "posts/computerscience/coding/code-019-uv-package.html#add-dev-dependency-via-terminal",
    "title": "Code 19: uv Python & Package Manager",
    "section": "2.2 Add dev-dependency via terminal",
    "text": "2.2 Add dev-dependency via terminal\n\nuv add pytest --dev\n\nAdds pytest to dev dependencies list in .toml file and resolves all dependencies."
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#create-test-folder-file",
    "href": "posts/computerscience/coding/code-019-uv-package.html#create-test-folder-file",
    "title": "Code 19: uv Python & Package Manager",
    "section": "3.1 Create Test Folder & File",
    "text": "3.1 Create Test Folder & File\n\ncode tests/test_main.py\n\n\ndef test_main(): assert True"
  },
  {
    "objectID": "posts/computerscience/coding/code-019-uv-package.html#run-test",
    "href": "posts/computerscience/coding/code-019-uv-package.html#run-test",
    "title": "Code 19: uv Python & Package Manager",
    "section": "3.2 Run Test",
    "text": "3.2 Run Test\n\nuv run pytest\n\nNote: I wrote the equivalent thing but in bash\n\n\n[TBA] Updating Python versions\n\n\n[TBA] Updating Redudencies .toml\n\n\n\n\n\n\n[TBA] DEV DEP VIA UVX OR UV TOOL RUN\n\n\n\n[TBA] ADD COMPLEX PKGS"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#common-errors",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#common-errors",
    "title": "Code 15: Python Exceptions 101",
    "section": "1.1 Common Errors",
    "text": "1.1 Common Errors\nUnexpected things or errors will occur at times in Python (and in life).\nThey might happen so often they get their own names and get categorised.\nPython has done exactly that. Creating names for specific errors whilst maintaining Python’s hierarchy structure too. Some common (automatic) errors are:\n\nInvalid syntax/code:\n\nE.g. missing closing bracket, unexpected colons, or periods etc (SyntaxError exception)\n\nInvalid username or key:\n\nE.g. not existing in the database (KeyError exception)\n\nInvalid calculation or operation:\n\nE.g. dividing by zero or dividing a number by a letter (ZeroDivisionError, TypeError exception)\n\nInvalid index:\n\nE.g. indexing a value larger than the array/list length (IndexError exception)\n\nInvalid attribute or method:\n\nE.g. calling an non-existent function from an instance (AttributeError exception)\n\n….the list goes on… (pun intended)"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#python-in-built-automatic-exceptions",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#python-in-built-automatic-exceptions",
    "title": "Code 15: Python Exceptions 101",
    "section": "1.2 Python In-Built (Automatic) Exceptions",
    "text": "1.2 Python In-Built (Automatic) Exceptions\nAll the above exceptions, being automatically raised by Python, are known as In-Built exceptions.\nThat is, when something unexpected happens, Python will:\n\nAutomatically halt the program,\nAutomatically raise or create a specific type Exception object (related to the error),\n\nE.g. Syntax, KeyError, ZeriDivisionError, TypeError, IndexdError exception object\n\nAutomatically look for something that can deal with this specific type of exception,\n\ncalled an Exception Handler (EH)\n\nIf no EH in current scope, Python looks for EH in call-stack,\n\nIf no EH in call-stack, the program is terminated.\n\n\nExceptions can also manually raised by the developer (discussed later)."
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-1",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-1",
    "title": "Code 15: Python Exceptions 101",
    "section": "2.1 Example 1",
    "text": "2.1 Example 1\n\ntry:\n    print(1/0)\nexcept ZeroDivisionError as e:\n    print(f\"An specific error has occured: [{e}]\")\n\nAn specific error has occured: [division by zero]"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-2",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-2",
    "title": "Code 15: Python Exceptions 101",
    "section": "2.2 Example 2",
    "text": "2.2 Example 2\n\ncool_dict = {\"a\": 420, \"b\":69}\n\ntry:\n    a_val = cool_dict[\"a\"]\n    b_val = cool_dict[\"b\"]\n    c_val = cool_dict[\"c\"]\nexcept KeyError as e:\n    print(f\"KeyError caught: [{e}]\")\nelse:\n    print(f\"Code has run succesfully!\")\n\nKeyError caught: ['c']"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-3",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-3",
    "title": "Code 15: Python Exceptions 101",
    "section": "2.3 Example 3",
    "text": "2.3 Example 3\n\ntry:\n    print(1/\"chode\")\nexcept TypeError as e:\n    print(f\"TypeError caught: [{e}]\")\n\nTypeError caught: [unsupported operand type(s) for /: 'int' and 'str']"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-4",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-4",
    "title": "Code 15: Python Exceptions 101",
    "section": "2.4 Example 4",
    "text": "2.4 Example 4\n\ncool_list = [666,420,69]\n\ntry:\n    print(cool_list[0])\n    print(cool_list[1])\n    print(cool_list[2])\n    print(cool_list[3])\nexcept IndexError as e:\n    print(f\"Index caught: [{e}]\")\n\n666\n420\n69\nIndex caught: [list index out of range]"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-5",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-5",
    "title": "Code 15: Python Exceptions 101",
    "section": "2.5 Example 5",
    "text": "2.5 Example 5\n\nmad_int = 69\n\ntry:\n    mad_int.append(420)\nexcept AttributeError as e:\n    print(f\"Attribute error caught: [{e}]\")\n\nAttribute error caught: ['int' object has no attribute 'append']"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#bare-except-clause",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#bare-except-clause",
    "title": "Code 15: Python Exceptions 101",
    "section": "3.1 Bare except clause",
    "text": "3.1 Bare except clause\nA bare except clause:\n\nPython catches any exception that inherits from Exception (most built-in exceptions!)\nCatching parent class Exception will:\n\nHides all errors— even unexpected or previously unseen errors!"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#bare-except-clause-example",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#bare-except-clause-example",
    "title": "Code 15: Python Exceptions 101",
    "section": "3.1.1 Bare except clause example",
    "text": "3.1.1 Bare except clause example\n\ntry:\n    with open(\"file.log\") as file:\n        read_data = file.read()\nexcept:\n    print(\"Couldn't open file.log\")\n\nCouldn't open file.log"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#except-exception-clause",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#except-exception-clause",
    "title": "Code 15: Python Exceptions 101",
    "section": "3.2 except Exception clause",
    "text": "3.2 except Exception clause\nBy catching Exception as e, there are attributes the developer can use:\n\nThe error occured: specific information about the error\nThe error type: the specific class of error\nThe error trace-back: a detailed trace-back of the error\n\n\ntry:\n    with open(\"file.log\") as file:\n        read_data = file.read()\nexcept Exception as e:\n    import traceback\n    print(f\"[Error Occured 1/3]: \\n\\t[  {e}  ]\\n\")\n    print(f\"[Error Type 2/3]: \\n\\t[  {type(e).__name__}  ]\\n\")\n    print(f\"[Error Traceback 3/3]: \\n\\t[  {traceback.format_exc()}  ]\")\n\n[Error Occured 1/3]: \n    [  [Errno 2] No such file or directory: 'file.log'  ]\n\n[Error Type 2/3]: \n    [  FileNotFoundError  ]\n\n[Error Traceback 3/3]: \n    [  Traceback (most recent call last):\n  File \"/tmp/ipykernel_76566/3916192492.py\", line 2, in &lt;module&gt;\n    with open(\"file.log\") as file:\n  File \"/home/tonydevs/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 324, in _modified_open\n    return io_open(file, *args, **kwargs)\nFileNotFoundError: [Errno 2] No such file or directory: 'file.log'\n  ]"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#raising-an-in-built-exception",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#raising-an-in-built-exception",
    "title": "Code 15: Python Exceptions 101",
    "section": "3.3 Raising an in-built exception",
    "text": "3.3 Raising an in-built exception\n\ndef squared(numbers):\n    if not isinstance(numbers, list | tuple):\n        raise TypeError(\n            f\"list or tuple expected, got '{type(numbers).__name__}'\"\n        )\n    return [number**2 for number in numbers]"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#original-method-manually-raise-an-exception-when-condition-met",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#original-method-manually-raise-an-exception-when-condition-met",
    "title": "Code 15: Python Exceptions 101",
    "section": "4.1 Original Method: manually raise an Exception() (when condition met)",
    "text": "4.1 Original Method: manually raise an Exception() (when condition met)\nBelow example raises an exception when a specific value is above arbitrary value (e.g. 5)\nThis exception can only be manually raised because it is:\n\nnot a syntax error exception\nnot an in-built error exception\n\nIn a way, this is more like:\n\nmodel-error (e.g. specific to some real-world model specification)\nbusiness-logic (e.g. business application)\n\n\n# number = 1\nnumber = 6\nif number &gt; 5:\n    raise Exception(f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\")\nprint(number)\n\n\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\nCell In[9], line 4\n      2 number = 6\n      3 if number &gt; 5:\n----&gt; 4     raise Exception(f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\")\n      5 print(number)\n\nException: [Manual Exc Raised & Caught]: The number should not exceed 5. (number=6)"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#another-method-automated-assertionerror-with-assert-when-condition-met",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#another-method-automated-assertionerror-with-assert-when-condition-met",
    "title": "Code 15: Python Exceptions 101",
    "section": "4.2 Another Method: Automated AssertionError with assert (when condition met)",
    "text": "4.2 Another Method: Automated AssertionError with assert (when condition met)\n\nnumber = 1\nassert(number &lt; 5), f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\"\nprint(number)\n\n1\n\n\n\n# example: https://realpython.com/python-exceptions/\ndef linux_interaction():\n    import sys # https://docs.python.org/3.10/library/sys.html\n    if \"linux\" not in sys.platform: \n        raise RuntimeError(\"Function can only run on Linux systems.\")\n    print(f\"Running on a Linux system: [{sys.platform}]\")\nlinux_interaction()\n\nRunning on a Linux system: [linux]\n\n\n\n# example: https://realpython.com/python-exceptions/\ndef windows_interaction():\n    import sys # https://docs.python.org/3.10/library/sys.html\n    if \"windows\" not in sys.platform: \n        raise RuntimeError(\"Function can only run on Windows systems.\")\n    print(f\"Running on a Windows system: [{sys.platform}]\")\nwindows_interaction()\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 7\n      5         raise RuntimeError(\"Function can only run on Windows systems.\")\n      6     print(f\"Running on a Windows system: [{sys.platform}]\")\n----&gt; 7 windows_interaction()\n\nCell In[12], line 5, in windows_interaction()\n      3 import sys # https://docs.python.org/3.10/library/sys.html\n      4 if \"windows\" not in sys.platform: \n----&gt; 5     raise RuntimeError(\"Function can only run on Windows systems.\")\n      6 print(f\"Running on a Windows system: [{sys.platform}]\")\n\nRuntimeError: Function can only run on Windows systems."
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#create-custom-exception-ce",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#create-custom-exception-ce",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.1 Create Custom Exception (CE)",
    "text": "5.1 Create Custom Exception (CE)\nCE are created by the:\n\nclass NameOfCustomException(Exception): use class constructor and inherit from Exception.\nraise exception in a function defintion (when condition is met):\n\nwith no EH: call function outside try-except (exception is not handled): Program terminates.\nwith an EH: call function in try-except (exception is handled): Program continues."
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#raising-ce-without-eh",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#raising-ce-without-eh",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.2 Raising CE without EH",
    "text": "5.2 Raising CE without EH"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-1-platformexception",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-1-platformexception",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.2.1 Example 1: PlatformException",
    "text": "5.2.1 Example 1: PlatformException\n\nclass PlatformException(Exception):\n    \"\"\"Incompatible platform.\"\"\"\n    pass\n\ndef linux_interaction():\n    import sys\n    if \"linux\" not in sys.platform:\n        # raise RuntimeError(\"Function only for Linux systems.\")    # previous-code: in-built exception\n        raise PlatformException(\"Function only for Linux systems.\") # updated-code: custom exception     \n    print(\"Doing Linux things.\")\n    \nlinux_interaction()\n\nDoing Linux things."
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#example-2-gradevalueerror",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#example-2-gradevalueerror",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.2.2 Example 2: GradeValueError",
    "text": "5.2.2 Example 2: GradeValueError\n\nclass GradeValueError(Exception):\n    pass\n\ndef calculate_average_grade(grades):\n    total = 0\n    count = 0\n    for grade in grades:\n        if grade &lt; 0 or grade &gt; 100:\n            raise GradeValueError(\n                \"grade values must be between 0 and 100 inclusive\"\n            )\n        total += grade\n        count += 1\n    return round(total / count, 2)\n\nprint(calculate_average_grade([80,70,-90]))\nprint(\"Exception is not handled, Program is terminated by Python. This line is not printed\")\n\n\n---------------------------------------------------------------------------\nGradeValueError                           Traceback (most recent call last)\nCell In[14], line 16\n     13         count += 1\n     14     return round(total / count, 2)\n---&gt; 16 print(calculate_average_grade([80,70,-90]))\n     17 print(\"Exception is not handled, Program is terminated by Python. This line is not printed\")\n\nCell In[14], line 9, in calculate_average_grade(grades)\n      7 for grade in grades:\n      8     if grade &lt; 0 or grade &gt; 100:\n----&gt; 9         raise GradeValueError(\n     10             \"grade values must be between 0 and 100 inclusive\"\n     11         )\n     12     total += grade\n     13     count += 1\n\nGradeValueError: grade values must be between 0 and 100 inclusive"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#raising-ce-with-eh",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#raising-ce-with-eh",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.3 Raising CE with EH",
    "text": "5.3 Raising CE with EH"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#gradevalueerror-eh-less-verbosity",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#gradevalueerror-eh-less-verbosity",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.3.1 GradeValueError (EH less verbosity)",
    "text": "5.3.1 GradeValueError (EH less verbosity)\nCaptured Error output with less verbosity. This may be suitable and it may not.\n\ntry:\n    GPA = calculate_average_grade([80,70,-90])\nexcept GradeValueError as e:\n    print(f\"Captured Error: [{type(e).__name__}]:\\n\\t[{e}]\\n\")\n    # import traceback\n    # print(f\"Traceback here: \\n\\t{traceback.format_exc()}\")\nelse:\n    print(f\"Congrats, your gpa is {GPA}\")\nprint(f\"Finished Grading!\")\n\nCaptured Error: [GradeValueError]:\n    [grade values must be between 0 and 100 inclusive]\n\nFinished Grading!"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#gradevalueerror-exception-handler-more-verbosity",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#gradevalueerror-exception-handler-more-verbosity",
    "title": "Code 15: Python Exceptions 101",
    "section": "5.3.2 GradeValueError (Exception-Handler more verbosity)",
    "text": "5.3.2 GradeValueError (Exception-Handler more verbosity)\nBy using traceback, the verbose output could also be provided.\n\ntry:\n    GPA = calculate_average_grade([80,70,-90])\nexcept GradeValueError as e:\n    print(f\"Captured Error: [{type(e).__name__}]:\\n\\t[{e}]\\n\")\n    import traceback\n    print(f\"Traceback here: \\n\\t{traceback.format_exc()}\")\nelse:\n    print(f\"Congrats, your gpa is {GPA}\")\nprint(f\"Finished Grading!\")\n\nCaptured Error: [GradeValueError]:\n    [grade values must be between 0 and 100 inclusive]\n\nTraceback here: \n    Traceback (most recent call last):\n  File \"/tmp/ipykernel_76566/3646266675.py\", line 2, in &lt;module&gt;\n    GPA = calculate_average_grade([80,70,-90])\n  File \"/tmp/ipykernel_76566/2024016610.py\", line 9, in calculate_average_grade\n    raise GradeValueError(\nGradeValueError: grade values must be between 0 and 100 inclusive\n\nFinished Grading!"
  },
  {
    "objectID": "posts/computerscience/coding/code-015_exceptions_101.html#multiple-exceptions",
    "href": "posts/computerscience/coding/code-015_exceptions_101.html#multiple-exceptions",
    "title": "Code 15: Python Exceptions 101",
    "section": "6. Multiple Exceptions",
    "text": "6. Multiple Exceptions\n\ndef division(a, b):\n    try:\n        return {\n            'success': True,\n            'message': 'OK',\n            'result': a / b\n        }\n    except (TypeError, ZeroDivisionError, Exception) as e:\n        return {\n            'success': False,\n            'message': str(e),\n            'type': type(e).__name__,\n            'result': None\n        }\n\nresult1 = division(10,10)\nresult2 = division(10, 0)\nresult3 = division(\"A\", 10)\nprint(result1)\nprint(result2)\nprint(result3)\n\n{'success': True, 'message': 'OK', 'result': 1.0}\n{'success': False, 'message': 'division by zero', 'type': 'ZeroDivisionError', 'result': None}\n{'success': False, 'message': \"unsupported operand type(s) for /: 'str' and 'int'\", 'type': 'TypeError', 'result': None}"
  },
  {
    "objectID": "posts/computerscience/coding/code-024-falsy-values.html",
    "href": "posts/computerscience/coding/code-024-falsy-values.html",
    "title": "Code 24: Falsy (& Truthy) Values",
    "section": "",
    "text": "1. Python’s falsy Values\n\nNone\nFalse\n0 (integer)\n0.0 (float)\n\"\" (empty string)\n[] (empty list)\n() (empty tuple)\n{} (empty dictionary)\nset() (empty set)\n\n\n\n2. Use-Case Of falsy Values\nIf some variable is None, then:\n\nif not variable: -&gt; Will evaluate to True\n\n\n\n3. Empty Node: Code Example\nNode and LinkedList previously introduced here.\n\nclass Node():\n    def __init__(self, data):\n        self.data=data\n        self.next_node=None\n\nclass LinkedList():\n    def __init__(self, first_node:Node|None=None):\n        self.first_node: Node|None = first_node\n\nfrom typing import Optional\n\nclass LinkedList_v2():\n    def __init__(self, first_node: Optional[str|Node]=None):\n        if isinstance(first_node,str):\n            self.first_node = Node(first_node)\n        elif isinstance(first_node,Node):\n            self.first_node = first_node\n        else:\n            self.first_node = None\n            \nll =  LinkedList()\n\nprint(f\"LinkedList without an allocated initial Node means\")\nprint(f\"The [ll.first_node] is: \\n\\t{ll.first_node}\") # Empty Node\nprint()\n\nif not ll.first_node:\n    print(f\"The expression 'If not ll.first_node:' will evaluate to:\")\n    print(f\"\\t{not ll.first_node}\")\n\nLinkedList without an allocated initial Node means\nThe [ll.first_node] is: \n    None\n\nThe expression 'If not ll.first_node:' will evaluate to:\n    True"
  },
  {
    "objectID": "posts/computerscience/coding/code-021-call-magic-method.html",
    "href": "posts/computerscience/coding/code-021-call-magic-method.html",
    "title": "Code 21: Magic Method: __call__",
    "section": "",
    "text": "1. Create Tony_Counter Class\n\nInstance attribute .counter defaulted to zero.\nInstance method increment() increases .counter attribute by 1\nMagic Method __call__() calls instance method increment():\nIn other words, when an instance calls itself with (), the instance.__call__() will be called:\n\nIn this case incrementing .counter by 1 each time.\n\n\n\nclass Tony_Counter():\n    def __init__(self):\n        self.counter: int = 0\n        \n    def increment(self):\n        self.counter += 1\n        \n    def __call__(self):\n        self.increment() \n\n\nctr = Tony_Counter()\nprint(ctr.counter)\n\n0\n\n\n\nctr.increment()\nprint(ctr.counter)\n\n1\n\n\n\nctr.increment()\nprint(ctr.counter)\n\n2"
  },
  {
    "objectID": "posts/computerscience/coding/code-007-virtual_environments.html#virtual-environments",
    "href": "posts/computerscience/coding/code-007-virtual_environments.html#virtual-environments",
    "title": "Code 7: Virtual Environments",
    "section": "1. Virtual Environments",
    "text": "1. Virtual Environments\nA virtual environment in Python is a self-contained directory that contains a Python installation and a set of packages.\nThis post will go through 3 methods to create virtual environments: - venv - conda virtual environments - pipenv"
  },
  {
    "objectID": "posts/computerscience/coding/code-007-virtual_environments.html#purpose",
    "href": "posts/computerscience/coding/code-007-virtual_environments.html#purpose",
    "title": "Code 7: Virtual Environments",
    "section": "2. Purpose",
    "text": "2. Purpose\nDependency Management:\n- Different projects may require different versions of the same package.\n- Virtual environments allow you to maintain these dependencies separately.\nIsolation:\n- Packages installed in a virtual environment are isolated from those installed system-wide or in other virtual environments\n- Reducing the risk of version conflicts and compatibility issues.\nPortability:\n- A virtual environment can be easily replicated on another system by sharing the environment configuration file, such as requirements.txt."
  },
  {
    "objectID": "posts/computerscience/coding/code-007-virtual_environments.html#method-1-venv",
    "href": "posts/computerscience/coding/code-007-virtual_environments.html#method-1-venv",
    "title": "Code 7: Virtual Environments",
    "section": "3. Method 1: venv",
    "text": "3. Method 1: venv\n\nmkdir proj && cd $_         # create proj1 and cd into proj1\npython -m venv venv1        # run python module venv and create venv1\nls                          # note: venv1 folder is created (inside proj1)\nsource venv1/bin/activate   # activate venv1 by running bash script with source\n(venv1)                     # note: (venv1) appears in front of (base) in terminal\npip freeze                  # note: no packages installed so no output\npip install sqalchemy       # install packages required\npip freeze                  # see list of packages installed\ndeactivate                  # deactivate venv1"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-runtime-explained",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-runtime-explained",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "2.1 .NET Runtime Explained",
    "text": "2.1 .NET Runtime Explained\nThe .NET runtime is the: - code library - required to run your C# applications - also known as Common Language Runtime, or CLR.\n    The .NET runtime isn't required to WRITE C# code, \n    The .NET runtime is required to RUN `C#` applications."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#visual-studio-code-extensions",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#visual-studio-code-extensions",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "2.2 Visual Studio Code Extensions",
    "text": "2.2 Visual Studio Code Extensions\nVisual Studio Code provides a development environment for:\n\nwriting,\nrunning, and\ndebugging C# applications\n\nBy using Visual Studio Extenions:\n\n.NET SDK\nC# extensions"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#install-extensions",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#install-extensions",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "2.3 Install Extensions",
    "text": "2.3 Install Extensions\n\n2.3.1 [C# Dev Kit - Official C#]\nThis extensions helps to develop, edit, and debug C# code in Visual Studio Code. It also installs:\n\n[.NET Install Tool]: This extension installs & manages different versions of:\n\n.NET SDK\nRuntime.\n\n[C#]: Base language support for C#.\n[C# Dev Kit]: Official C# extension from Microsoft."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#intellicode-for-c-dev-kit",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#intellicode-for-c-dev-kit",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "2.3.2 [IntelliCode for C# Dev Kit]",
    "text": "2.3.2 [IntelliCode for C# Dev Kit]\nThis extension provides AI-assisted development for the C# Dev Kit."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-sdk",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-sdk",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "2.3.3 .NET SDK",
    "text": "2.3.3 .NET SDK\nThis is required to run and debug C# applications:\n\nCheck if already install: dotnet --version\nIf not installed:\n\ntype .NET: Install and then\nselect .NET: Install New .NET SDK.\nUnder Latest, select .NET 8, select Install."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-cli",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-cli",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "3.1 .NET CLI",
    "text": "3.1 .NET CLI\nSample .NET CLI command Code below will create new console app in specified folder.\n\ndotnet new console -o ./CsharpProjects/TestProject"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-cli-command-structure",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#net-cli-command-structure",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "3.2 .NET CLI Command Structure",
    "text": "3.2 .NET CLI Command Structure\nThere are 3 parts: [driver] [command] [command arguments]:\n\nThe driver:\n\ndotnet\n\nThe command:\n\nnew console\n\nThe command arguments:\n\n-o ./CsharpProjects/TestProjectByCLI\n\n\ncommand arguments are optional, so dotnet new console creates a new console app in the current working directory."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#c-console-application-template",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#c-console-application-template",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "3.3 C# Console Application Template",
    "text": "3.3 C# Console Application Template\n\nProgram.cs: Source Code ? (TBA)\n\nTestProject1.csproj: Project File\n\nobj: Build files and dependencies like .dlls (TBA)"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#build-application",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#build-application",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "4.1 Build Application",
    "text": "4.1 Build Application\n\nNavigate to TestProject (Ctrl + q: Folders)\nShift + F10\nOpen in Terminal\ndotnet build"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#run-application",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#run-application",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "4.2 Run Application",
    "text": "4.2 Run Application\nThe dotnet run command:\n\nruns source code without any explicit compile or launch commands.\nA convenient option to run application from the source code\n\nUseful for fast iterative development from CLI.\nThe command depends on the dotnet build command to build the code.\n\n\nCode: dotnet run"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#oldbad-version-1",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#oldbad-version-1",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "5.1 Old/Bad (Version 1)",
    "text": "5.1 Old/Bad (Version 1)\n\nCheck dotnet (exists): dotnet --version\nCreate console app with dotnet cli command: dotnet new console -o 2-CreateRunCSConsoleApps\nCheck app has been created… [Realised I made a mistake]\n\nShould have created a extra folder within the top folder, that is: 2-CreateRunCSConsoleApps\\SimpleApp\nI’ll leave screenshot below and also provide update."
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#betterupdated-version-2",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#betterupdated-version-2",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "5.2 Better/Updated (Version 2)",
    "text": "5.2 Better/Updated (Version 2)\nCurrent Project Structure:\n\n2-CreateRunCSConsoleApps\\Program.cs:\n\nOnly one project per solution, an undesirable structure.\nProgram.cs is directly under the Solution Name.\nPreferred to be able to have multiple projects within a single Solution (see next section).\n\n\nNew Project Structure:\n\n2-CreateRunCSConsoleApps\\TestProjectNo\\Program.cs:\n\nAllows for multiple projects within single Solution. Example:\n\n[Project 1]: 2-CreateRunCSConsoleApps\\TestProject1\\Program.cs\n[Project 2]: 2-CreateRunCSConsoleApps\\TestProject2\\Program.cs"
  },
  {
    "objectID": "posts/computerscience/coding/code-018-csharp_on_vscode.html#create-build-run-version-2-steps",
    "href": "posts/computerscience/coding/code-018-csharp_on_vscode.html#create-build-run-version-2-steps",
    "title": "Code 18: Introduction to C# in Visual Studio Code",
    "section": "5.3 Create, Build Run: Version 2 Steps",
    "text": "5.3 Create, Build Run: Version 2 Steps\n\nCreate TestProject1: dotnet new console -o 2-CreateRunCSConsoleApp\\TestProject1.\nCreate TestProject2: See 2.\nCheck projects created succesfully.\nUpdate Program.cs scripts and save.\nBuild.. [Realised I didnt build it first, but still works??]: No issues (see 4.3.1 dotnet run notes).\nBuild TestProject1: Go to TestProject 1 directly then: dotnet build, then dotnet run.\nBuild TestProject2: see 6.\n\nOutput for both projects are as expected.\n\n\n5.3.1 dotnet run notes\nTurns out dotnet run also runs dotnet build. GPT output:\n\nSeparate Build and Run Steps: In scenarios like continuous integration (CI) pipelines or deployment scripts, you often want to explicitly build the project first (dotnet build) and then run or test it separately. This allows for better error handling and control over each step.\nBuild Output for Distribution: dotnet build creates the build artifacts (compiled .dll files and dependencies) without running the project. If you’re distributing your code or creating deployment packages, you’ll want the output from dotnet build, not the temporary output that dotnet run uses.\nFaster Subsequent Runs: Running dotnet build first creates a compiled version that dotnet run will use as long as there are no code changes. This can make dotnet run faster on subsequent runs.\nDebugging and Optimization: dotnet build allows for setting specific build configurations, like Release or Debug, without running the program. This is useful for testing different build configurations or optimizing the final build before deployment."
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#the-scenario",
    "href": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#the-scenario",
    "title": "[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols",
    "section": "1.1 The Scenario",
    "text": "1.1 The Scenario"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#the-problem",
    "href": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#the-problem",
    "title": "[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols",
    "section": "1.2 The Problem",
    "text": "1.2 The Problem"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#one-of-the-solutions",
    "href": "posts/computerscience/designpatterns/dp-003-interfaces-2-protocols.html#one-of-the-solutions",
    "title": "[INCOMPLETE] DP 3: Interfaces [Part 2] - Protocols",
    "section": "1.3 (One of) The Solution(s):",
    "text": "1.3 (One of) The Solution(s):"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#the-scenario",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#the-scenario",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "1.1 The Scenario",
    "text": "1.1 The Scenario\nFocusing on specifics or details of Implementation"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#the-problem",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#the-problem",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "1.2 The Problem",
    "text": "1.2 The Problem\nLeads to tightly coupled or difficult to modify code."
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#one-of-the-solutions",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#one-of-the-solutions",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "1.3 (One of) The Solution(s):",
    "text": "1.3 (One of) The Solution(s):\nThe Program to Interfaces, not Implementations principle"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-1-part-1-abc-and-abstractmethod",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-1-part-1-abc-and-abstractmethod",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "6.1 Scenario 1, Part 1: ABC and @abstractmethod",
    "text": "6.1 Scenario 1, Part 1: ABC and @abstractmethod\nBy decorating do_I_exist() with @abstractmethod of ABC class TonysExistentialCrisisBase:\n\nThis applies the implementation requirement that a do_I_exist method must be implemented in all sub-classes.\n\n\nfrom abc import ABC, abstractmethod\n\nclass TonysExistentialCrisisBase(ABC):\n    def __init__(self, name: str):\n        self.name=name\n        \n    @abstractmethod\n    def do_I_exist(self, am_i_alive: bool):\n        pass"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-1-part-2-no-required-method-in-sub-class",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-1-part-2-no-required-method-in-sub-class",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "6.2 Scenario 1, Part 2: No Required Method in Sub-Class",
    "text": "6.2 Scenario 1, Part 2: No Required Method in Sub-Class\n\nclass MyHumanBeingClass(TonysExistentialCrisisBase):\n    pass\n\n\nTherefore, Python raises a very clear error, when an instance MyHumanBeingClass is attempted to be created\nSince our sub-class does not have it’s own implementation of do_I_exist method\n\n\ndave = MyHumanBeingClass(\"Dave\")\ndave\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 dave = MyHumanBeingClass(\"Dave\")\n      2 dave\n\nTypeError: Can't instantiate abstract class MyHumanBeingClass with abstract method do_I_exist"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-2-part-1-sub-class-with-required-abstract-method",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-2-part-1-sub-class-with-required-abstract-method",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "6.3 Scenario 2, Part 1: Sub-Class With Required Abstract Method",
    "text": "6.3 Scenario 2, Part 1: Sub-Class With Required Abstract Method\n\nclass MyHumanBeingClass(TonysExistentialCrisisBase):\n    def do_I_exist(self, am_i_alive: bool=True):\n        print(\"Cogito, ergo sum...👽\")"
  },
  {
    "objectID": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-2-part-2-no-errors",
    "href": "posts/computerscience/designpatterns/dp-002-interfaces-1-abc.html#scenario-2-part-2-no-errors",
    "title": "DP 2: Interfaces [Part 1] - ABC Abstract Base Classes",
    "section": "6.4 Scenario 2, Part 2: No errors",
    "text": "6.4 Scenario 2, Part 2: No errors\nBy adding the required method, an instance of MyHumanBeingClass is allowed.\n\njames = MyHumanBeingClass(\"James\")\njames.do_I_exist()\n\nCogito, ergo sum...👽"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-004-diagonlisation.html#normal-mode",
    "href": "posts/mathematics/linearalgebra/la-004-diagonlisation.html#normal-mode",
    "title": "LA 4: Diagonal Matrices are trivial",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-005-similar-matrices.html#normal-mode",
    "href": "posts/mathematics/linearalgebra/la-005-similar-matrices.html#normal-mode",
    "title": "LA 5: It’s nice to be similar (matrices)",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/mathematics/linearalgebra/la-002-eigenvalues-eigenvectors.html",
    "href": "posts/mathematics/linearalgebra/la-002-eigenvalues-eigenvectors.html",
    "title": "LA 2: Eigen is my valentines in 2024",
    "section": "",
    "text": "Note on Colours:\n- I’m colourblind (red-green). Read more here.\n- I’m using Nebo App on a Lenovo Tablet in Dark Mode. The app doesn’t actually export the way I see it, it exports in non-dark mode so it looks completely different to how I chose the colours. If the colours are an eyesore, I apologise 🤭 (It’s probably sub-optimal without the export issues already).\n- I used a website to reverse colours but it isn’t right either.\nI’ll figure it out… for now I’ve put up both unwanted versions because I havent posted in 4 days (awful).\n\n1. Dark-mode\n\n\n\n2. Normal-mode"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-012-ch3-5-ex-61.html",
    "href": "posts/mathematics/calculus/calc-012-ch3-5-ex-61.html",
    "title": "Calculus 12: Derivatives Of Trigonometric Functions",
    "section": "",
    "text": "1. Find x and \\(\\frac{dx}{dt}\\) for \\(x=10\\cos(t)\\)\nLet \\(x=10\\cos(t)\\)\n\nFind \\(x\\)\n\nFind \\(\\frac{dx}{dt}\\) for:\n\n\n\\(t=0\\)\n\\(t=\\frac{\\pi}{3}\\)\n\\(t=\\frac{3\\pi}{4}\\)\n\nReference from Ch3-5 Ex-61, Thomas 13e pp.161\n\n\n2. Hand-Written Solution\n\n\n\n3. Python Solution\n\n\n3.1 numpy solution (numeric only)\n\nimport numpy as np\n# Let $x=10\\cos(t)$. Find $x$ and $\\frac{dx}{dt}$ for: \n\nfn_10cost = lambda t: 10*np.cos(t)\nfn_a = fn_10cost(0)\nfn_b = fn_10cost(np.pi/3)\nfn_c = fn_10cost(3*np.pi/4)\n\nfn_minus_10sint = lambda t: -10*np.sin(t)\ndxdt_a = fn_minus_10sint(0)\ndxdt_b = fn_minus_10sint(np.pi/3)\ndxdt_c = fn_minus_10sint(3*np.pi/4)\n\nprint(\"-\"*25)\nprint(\"Solutions to a:\")\nprint(fn_a,fn_b,fn_c)\nprint(\"-\"*25)\nprint(\"Solutions to b:\")\n\nprint(dxdt_a,dxdt_b,dxdt_c)\n\n-------------------------\nSolutions to a:\n10.0 5.000000000000001 -7.071067811865475\n-------------------------\nSolutions to b:\n-0.0 -8.660254037844386 -7.0710678118654755\n\n\n\n\n3.2 sympy solution (numeric and exact solutions)\n\nfrom sympy import symbols, diff, sin, cos, pi\n\nx = symbols('x')\nt = symbols('t')\n# t = 10*np.cos()   # does not work with fns, need to use sympys symbol instead\nx = 10*cos(t)\ndxdt = diff(x,t)    # calc derv\nrl = 10\n\nx_t_0 = str(10*cos(0))\nx_t_pi_on_3 = str(10*cos(pi/3))\nx_t_3pi_on_4 = str(10*cos(3*pi/4))\n\nprint(\"-\"*26)\nprint(\"x Equals\")\nprint(f\"t = 0: \\t\\t{x_t_0:&gt;{rl}}\")\nprint(f\"t = π/3: \\t{x_t_pi_on_3:&gt;{rl}}\")\nprint(f\"t = 3π/4: \\t{x_t_3pi_on_4:&gt;{rl}}\")\nprint()\n\n\nvalue_at_t0 = str(dxdt.subs(t, 0))\nvalue_at_pi_over_3 = dxdt.subs(t, pi / 3)\nvalue_at_3pi_over_4 =dxdt.subs(t, 3 * pi / 4)\n\nprint(\"-\"*26)\nprint(\"Exact Solutions\")\nprint(f\"dxdt: \\t\\t{str(dxdt):&gt;{rl}}\")\nprint(f\"t = 0: \\t\\t\\t{value_at_t0}\")\nprint(f\"t = π/3: \\t{value_at_pi_over_3}\")\nprint(f\"t = 3π/4: \\t{value_at_3pi_over_4}\")\nprint()\nprint(\"-\"*26)\nprint(\"Numeric Solutions\")\nprint(f\"dxdt: \\t\\t{str(dxdt):&gt;{rl}}\")\nprint(f\"t = 0: \\t\\t{value_at_t0:&gt;{rl-1}}\")\nprint(f\"t = π/3: \\t{round(value_at_pi_over_3,1):&gt;{rl-1}}\")\nprint(f\"t = 3π/4: \\t{round(value_at_3pi_over_4,1):&gt;{rl-1}}\")\n\n--------------------------\nx Equals\nt = 0:              10\nt = π/3:             5\nt = 3π/4:   -5*sqrt(2)\n\n--------------------------\nExact Solutions\ndxdt:       -10*sin(t)\nt = 0:          0\nt = π/3:    -5*sqrt(3)\nt = 3π/4:   -5*sqrt(2)\n\n--------------------------\nNumeric Solutions\ndxdt:       -10*sin(t)\nt = 0:              0\nt = π/3:         -8.7\nt = 3π/4:        -7.1"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#synthetic-divison-x3-x2-5x-3-by-x1",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#synthetic-divison-x3-x2-5x-3-by-x1",
    "title": "Calculus 3: Synthetic Division",
    "section": "4.1 Synthetic divison \\((x^3-x^2-5x-3)\\) by \\((x+1)\\)",
    "text": "4.1 Synthetic divison \\((x^3-x^2-5x-3)\\) by \\((x+1)\\)\n\n\n\n-1\n+1\n-1\n-5\n-3\n\n\n\n\n\\(+\\)\n+0\n-1\n+2\n+3\n\n\n\\(/\\)\n+1\n-2\n-3\n+\\(0\\)\n\n\n\nRemainder is \\(0\\) (bottom right cell).\nTherefore \\((x+1)\\) is a factor of \\((x^3-x^2-5x-3)\\)\nThe final line represents the \\(coefficients\\) of the other factor, that is:\n\\[x^2-2x-3\\]\nTherefore \\[(x^3-x^2-5x-3)\\]\n\\[=(x+1)(x^2-2x-3)\\]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#back-to-the-question",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#back-to-the-question",
    "title": "Calculus 3: Synthetic Division",
    "section": "4.2 Back to the question",
    "text": "4.2 Back to the question\n\\[\\frac{x^3-x^2-5x-3}{(x+1)^2}\\] \\[\\frac{(x+1)(x^2-2x-3)}{(x+1)(x+1)}\\] \\[\\frac{(x^2-2x-3)}{(x+1)}\\] \\[\\frac{(x-3)(x+1)}{(x+1)}\\] \\[{(x-3)}\\]\n\\[\\lim_{x\\to-1}\\frac{x^3-x^2-5x-3}{(x+1)^2}\\] \\[\\lim_{x\\to-1}(x-3)\\] \\[(-1-3)\\] \\[-4\\]"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#import-libraries",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#import-libraries",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.1 Import libraries",
    "text": "5.1 Import libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#create-xs-xs",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#create-xs-xs",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.2 Create x’s: xs",
    "text": "5.2 Create x’s: xs\n\nxs = np.linspace(-1.1,-0.9,21)\nxs\n\narray([-1.1 , -1.09, -1.08, -1.07, -1.06, -1.05, -1.04, -1.03, -1.02,\n       -1.01, -1.  , -0.99, -0.98, -0.97, -0.96, -0.95, -0.94, -0.93,\n       -0.92, -0.91, -0.9 ])"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#create-function-fx",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#create-function-fx",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.3 Create function: fx",
    "text": "5.3 Create function: fx"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#lambda-method",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#lambda-method",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.3.1 lambda method",
    "text": "5.3.1 lambda method\n\nfx = lambda x: (x**3-x**2-5*x-3)/((x+1)**2)"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#def-method",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#def-method",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.3.2 def method",
    "text": "5.3.2 def method\n\ndef fx2(x): return (x**3-x**2-5*x-3)/((x+1)**2)\n\n\n5.3.3 Check definitions [optional]\n\nimport inspect\ninspect.getsource(fx)\ninspect.getsource(fx2)\n\n'def fx2(x): return (x**3-x**2-5*x-3)/((x+1)**2)\\n'"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#calculate-ys-ys",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#calculate-ys-ys",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.4 Calculate y’s: ys",
    "text": "5.4 Calculate y’s: ys\n\nys = fx(xs)\nys\n\n/tmp/ipykernel_62451/871469998.py:1: RuntimeWarning: invalid value encountered in divide\n  fx = lambda x: (x**3-x**2-5*x-3)/((x+1)**2)\n\n\narray([-4.1 , -4.09, -4.08, -4.07, -4.06, -4.05, -4.04, -4.03, -4.02,\n       -4.01,   nan, -3.99, -3.98, -3.97, -3.96, -3.95, -3.94, -3.93,\n       -3.92, -3.91, -3.9 ])"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-003-synthetic-division.html#plot",
    "href": "posts/mathematics/calculus/calc-003-synthetic-division.html#plot",
    "title": "Calculus 3: Synthetic Division",
    "section": "5.5 Plot",
    "text": "5.5 Plot\n\n# plt.scatter(xs,ys,label=\"Data Points\", color='red')\n# plt.scatter(xs,ys)\nplt.vlines(x=-1,ymin=ys[0],ymax=ys[-1],linestyles=\"dotted\", label=\"$x=-1$\", colors=\"red\")\n\n# plt.plot(xs, ys, label=r\"$\\lim_{x\\to-1}\\frac{x^3-x^2-5x-3}{(x+1)^2}$\")\nplt.plot(xs, ys, label=r'$\\lim_{x\\to-1}\\frac{x^3 - x^2 - 5x - 3}{(x+1)^2}=x-3$',)\nplt.legend()\n\n\n\n\n\n\n\n\nThe plot shows limit is \\(-4\\)"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-014-ch3-5-ex-59-nth-derivative.html",
    "href": "posts/mathematics/calculus/calc-014-ch3-5-ex-59-nth-derivative.html",
    "title": "Calculus 14: n’th Derivative with % (modulo) & sympy",
    "section": "",
    "text": "1. n’th derivatives of \\(\\cos{x}\\)\n\nFind first few derivatives of: \\[\\cos(x)\\]\nLook for a pattern, then find: \\[\\frac{d^{99}}{dx^{99}}\\cos(x)\\]\n\n\n\n2. Hand-Written Solution\n\n\n\n3. Validating n’th Derivative - Modulus 4 (Python)\n\nfor i in range(10):\n    print(f\"{i}mod4: {i%4}\")\n\n0mod4: 0\n1mod4: 1\n2mod4: 2\n3mod4: 3\n4mod4: 0\n5mod4: 1\n6mod4: 2\n7mod4: 3\n8mod4: 0\n9mod4: 1\n\n\n\n\n4. Validating n’th Derivative - sympy\n\nimport sympy as sp\nx = sp.Symbol('x')\nprint(x,type(x))\n# sp.diff(sp.sin(x), x)\n# sp.diff(sp.sin(x), x,1)\n# sp.diff(sp.sin(x), x,2)\n# sp.diff(sp.cos(x), x,3)\nfor i in range(1,6):\n    print(f\"ddx{i}(cosx): {sp.diff(sp.cos(x), x,i)}\")\n\nx &lt;class 'sympy.core.symbol.Symbol'&gt;\nddx1(cosx): -sin(x)\nddx2(cosx): -cos(x)\nddx3(cosx): sin(x)\nddx4(cosx): cos(x)\nddx5(cosx): -sin(x)\n\n\n\n\n5. Solution - sympy\n\\(\\frac{d^{99}}{dx^{99}}\\cos{x}\\)\n\nx = sp.Symbol('x')\nprint(f\"ddx{99}(cosx): {sp.diff(sp.cos(x), x,99)}\")\n\nddx99(cosx): sin(x)"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-002-limits-ch2-2-ex-11.html",
    "href": "posts/mathematics/calculus/calc-002-limits-ch2-2-ex-11.html",
    "title": "Calculus 2: Plotting functions with limits",
    "section": "",
    "text": "Jupyter Notebooks Available\n\nEx 2.2 notebooks github download link\n\n\n\nEx2.2.5: \\(\\lim_{x\\to0}\\frac{x}{|x|}\\)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nxs = np.linspace(-0.1,0.1,20)\nxs = xs[xs != 0] # remove x=0\ndef f(x): return (x)/(np.abs(x))\nys = f(xs)\nplt.scatter(xs,ys)\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n\nEx2.2.11: \\(lim_{x\\to-3}(x^2-13)\\)\n\nxs = np.linspace(-3.1, -2.9, 50)\ndef fx(x): return (x**2-13)\nys = fx(xs)\ny_x_at_c = fx(-3)# at x=-3\ny_x_at_c\nplt.scatter(xs,ys)\nplt.grid(True)\nplt.vlines(x=-3, ymax=100, ymin=-100, linestyles=\"dotted\")\n\n\n\n\n\n\n\n\n\n\nEx2.2.13: \\(\\lim_{x\\to6}8(x-5)(x-7)\\)\n\nx_at_c, abt_x = 6,0.1\nx_abt_c = (x_at_c - 0.1, x_at_c + 0.1)\nxs = np.linspace(x_abt_c[0],x_abt_c[1], 20) # same as np.linspace(5.9, 6.1)\ndef fx(x): return 8*(x-5)*(x-7)\nys=fx(xs)\nplt.scatter(xs,ys)\nplt.grid(True)\ny_x_at_c = fx(x=x_at_c)\nplt.vlines(x=x_at_c, ymax=10,ymin=-10, linestyles='dotted')\n\n\n\n\n\n\n\n\n\n\nEx2.2.15: \\(\\lim_{x\\to2}\\frac{2x+5}{11-x^3}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = 2\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return (2*x+5)/(11-x**3)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))\n\n\n\n\n\n\n\n\n\n\nEx2.2.19: \\(\\lim_{x\\to-3}(5-x)^{\\frac{4}{3}}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = -3\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return (5-x)**(4/3)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))\n\n\n\n\n\n\n\n\n\n\nEx2.2.21: \\(\\lim_{x\\to0}\\frac{3}{\\sqrt{3x+1}+1}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = 0\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return 3/(np.sqrt(3*x+1)+1)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-013-ch2-4-eg-5.html",
    "href": "posts/mathematics/calculus/calc-013-ch2-4-eg-5.html",
    "title": "Calculus 13: Limit of Cosine",
    "section": "",
    "text": "1. Show \\(lim_{h\\to0} \\frac{\\cos{h}-1}{h} = 0\\)\n\n\n2. Solution (Hand-Written)\n\n\n\n3. Chart: Any Large \\(h\\) (Python Code)\nFirstly, I’ll look at:\n\n\\(f(h)=\\frac{\\cos{h}-1}{h}\\)\n\nThen, observe behaviour as we zoom into (0,0)\n\n\\(lim_{h\\to0} \\frac{\\cos{h}-1}{h}\\)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\n### x-values ###\nxpt = 0\nx_deviation = 50\nx_increments = 501\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 1]\nxs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\n# print(xs)\n### THE FUNCTION ###\n# lbl_fx = r'$f(x)=\\frac{1}{x-1}$'   # LABEL\nlbl_fx = r'$f(h)=\\frac{\\cos{h}-1}{h}$'\n# fx_fx = lambda x: (1)/(x-1)  # f(x)\nfx_fx = lambda x: (np.cos(x)-1)/x  # f(x)\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n\n### y-values ###\nys_fx = fx_fx(xs)            # ys=f(xs)\n# print(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\nplt.plot(xs, ys_fx,  '^-', linewidth=2, markersize=2, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'o', markersize=3, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\nplot_title = lbl_fx\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend \nplt.legend(loc='upper right')\n# plt.legend(loc='lower right')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\n# plt.ylim(-0.05, 0.05)  # y-rng\n# plt.xlim(-0.05, 0.05)  # y-rng\n# plt.xlim(0.5, 1.5)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Chart: \\(\\lim_{h-&gt;0}\\) (Python Code)\nZoom into about (0,0):\n\n\\(lim_{h\\to0} \\frac{\\cos{h}-1}{h} = 0\\)\n\n\n### x-values ###\nxpt = 0\nx_deviation = 0.1\nx_increments = 51\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 1]\n# xs = xs[xs != 0]\n# xs = xs[xs &gt; 0]\n# print(xs)\n### THE FUNCTION ###\n# lbl_fx = r'$f(x)=\\frac{1}{x-1}$'   # LABEL\nlbl_fx = r'$lim_{h\\to0} \\frac{\\cos{h}-1}{h} = 0$'\n# fx_fx = lambda x: (1)/(x-1)  # f(x)\nfx_fx = lambda x: (np.cos(x)-1)/x  # f(x)\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n\n### y-values ###\nys_fx = fx_fx(xs)            # ys=f(xs)\n# print(ys_fx)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### fractions? ###\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\n# fx_dydx = lambda x: 6.1*(2*x)-9.28\n# xpt_dydx = xpt\n# dydx = fx_dydx(xpt_dydx)\n# print(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=6, label=lbl_fx)\nplt.plot(xs, ys_fx,  'o-', linewidth=2, markersize=5, label=lbl_fx)\n# plt.plot(xs, ys_fx,  'o', markersize=3, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\nplot_title = lbl_fx\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\nplt.title(plot_title, loc='left')\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend \nplt.legend(loc='upper right')\n# plt.legend(loc='lower right')\n\n# zoom! enhance! #\n# plt.xlim(xpt-5,xpt+5)  # x-rng\nplt.ylim(-0.05, 0.05)  # y-rng\nplt.xlim(-0.05, 0.05)  # y-rng\n# plt.xlim(0.5, 1.5)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# plt.plot(x_at_c, 0,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n\n/tmp/ipykernel_26339/976542632.py:18: RuntimeWarning: invalid value encountered in divide\n  fx_fx = lambda x: (np.cos(x)-1)/x  # f(x)"
  },
  {
    "objectID": "posts/mathematics/calculus/calc-004-binomial-theorem.html",
    "href": "posts/mathematics/calculus/calc-004-binomial-theorem.html",
    "title": "Calculus 4: Applying Binomial Theorem",
    "section": "",
    "text": "1. Calculate \\(f'(x) = x^3\\)\n\n\nThat is, calculate it’s Derivative.\n\n\nPlot Tangent at \\((-2,-8)\\) .\n\n\n\n\n2. Working Out (by Hand)\n\n\n\n3. Plot with Python\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nxs = np.linspace(-12, 12, 97)\n\nfx_numerator = lambda x: (x**3)\nys_numerator = fx_numerator(xs)\n\nfx_denom = lambda x: 12*x+16\nys_denom = fx_denom(xs)\n\n# Plot the lines\n# $\\lim_{x\\to0} \\frac{2x^2}{3-3\\cos{x}}$ \n\nplt.plot(xs, ys_numerator, 'r^-', linewidth=2, markersize=8, label=r'$f(x)=x^3$')\nplt.plot(xs, ys_denom, 'bo-', linewidth=2, markersize=8, label=r'$f(x)=12*x+16$')\n\n# Zoom to region\nplt.xlim(-5, 1)  # X-axis range\nplt.ylim(-30, 20)  # Y-axis range\n# plt.xlim(-0.1, 0.1)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(r\"$f(x)=x^3$ and $f(x)=12*x+16$ at (-2,-8)\", loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\nplt.legend(loc='upper right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=-2, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=-8, color='grey', linestyle='--', linewidth=0.5)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#introduction",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#introduction",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "1. Introduction",
    "text": "1. Introduction\nFrom Part 1, the Kaggle Competition: U.S. Patent Phrase to Phrase Matching was a notebook competition, that is, a simple csv upload of predictions would not suffice.\nA notebook with code needs to be submitted in order to succesfully enter and be graded.\nThis notebook will have access the kaggles cloud folders to gather the raw data, process and model it. The only catch is the notebook has no access to the internet. This means pip install package will not work.\nThus, the pre-trained models and tokenizers need to be uploaded to the inputs folder, before being installed.\nWhy? Even though transformers library is available on Kaggle via import, each time a function like AutoTokenizer is called, this accesses the internet to reach the HuggingFace Model Hub and looks for the latest available models.\nIn order to upload files though, they need to be exported first, but in order for them to be exported, they need to be downloaded first!. Well that is what I figured out, there’s probably a vastly more seemless way but I didn’t go out of my way to find out a way to do it, this way just made the most sense. In the future, I’ll find out a better way.\nSo, the idea is:\n1. create new kaggle noteook with internet access\n2. install libraries\n3. run our models\n4. export our models\n5. download our libraries\n6. create new kaggle noteook with no internet access\n7. upload downloaded libraries and exported models\n8. install libraries via uploaded files\n9. import pre-trained models vias uploaded files\n10. conduct training\n11. make predictions 12. export to csv\n13. submit notebook"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#export-model-and-tokenizer",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#export-model-and-tokenizer",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "2. Export Model and Tokenizer",
    "text": "2. Export Model and Tokenizer\n\ndebv3_tokenizer.save_pretrained(\"./tokenizer\")\nmodel.save_pretrained(\"./model\")"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#download-libraries",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#download-libraries",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "3. Download Libraries",
    "text": "3. Download Libraries\nTwo libraries are required for this notebook to run datasets and transformers\n\n!pip download datasets\n!pip download transformers"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#upload-file-to-kaggle",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#upload-file-to-kaggle",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "4. Upload File to Kaggle",
    "text": "4. Upload File to Kaggle\n\n4.1 Gather files\nPlace all json files (tokenizer and model) and whl files (libraries) in the same folder.\n\n\n\n4.2 Kaggle Upload\n\nGo to [Datasets]\nThen [New Dataset]\nName a [Dataset Title]\nChoose all files from your local folder\nClick [Create]\n\n\n\n\n4.3 Load Succesful\nUpon completion, a greeting of success should appear.\n\n\n\n4.4 Add Data\n\nClick [Add Data]\nFilter for [Your Datasets]\nFind the uploaded Dataset"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#code",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#code",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "5. Code",
    "text": "5. Code\nIt’s almost the same code as the previous post so I’ve combined it altogether.\n\n!pip install --no-index --find-links=. transformers\n!pip install --no-index --find-links=. datasets\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments,Trainer\nfrom pathlib import Path\nfrom datasets import Dataset,DatasetDict\nimport pandas as pd\nimport numpy as np\nimport datasets\n\nmodel_nm = \"microsoft/deberta-v3-small\"\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching')\nmypath = Path('/kaggle/input/us-patents-libraries-model-tokenizer')\ntokenizer_uploaded  = AutoTokenizer.from_pretrained(mypath)\nmodel_uploaded = AutoModelForSequenceClassification.from_pretrained(mypath)\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\nds = Dataset.from_pandas(df)\ndef tok_func(x): return tokenizer_uploaded(x[\"input\"])\ntok_ds = ds.map(tok_func, batched=True)\ntok_ds = tok_ds.rename_columns({'score':'labels'})\ndds = tok_ds.train_test_split(0.25, seed=42)\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\nbs = 128\nepochs = 2\nlr = 8e-5\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\nmodel = AutoModelForSequenceClassification.from_pretrained(mypath, num_labels=1,ignore_mismatched_sizes=True)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokenizer_uploaded, compute_metrics=corr_d)\ntrainer.train()\npreds = trainer.predict(eval_ds).predictions.astype(float)\npreds = np.clip(preds, 0, 1)\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds.squeeze()\n})\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#results",
    "href": "posts/datascience/kaggle/kagg-002-us-patents-offline/index.html#results",
    "title": "KAGG 2: A Basic NLP model - [Competition Version]",
    "section": "6. Results",
    "text": "6. Results\nIt worked!"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-16-97_post_with_notebook/index.html",
    "href": "posts/datascience/machinelearning/2024-01-16-97_post_with_notebook/index.html",
    "title": "Post With Sample Jupyter Notebook",
    "section": "",
    "text": "Learning how quarto works with jupyter notebooks. This is a sample editted notebook from fastai.\n\nfrom fastai.vision.all import *\nchosen_sample_seed          = 42\nchosen_sample_n             = 5\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n# useful informative functions\ndef print_useful_info():\n    global path_dir_obj, list_all_img_path_obj\n    print()\n    print(f\"path_obj_home_dir: \\t{path_dir_obj}\")\n    print(f\"image_list_count: \\t{len(list_all_img_path_obj)}\")\n    return None\n\ndef print_sample_imgs():\n    global path_dir_obj, list_all_img_path_obj, chosen_sample_seed, chosen_sample_n\n    import random\n    set_seed(chosen_sample_seed)\n    print(f\"set_seed_number: \\t{chosen_sample_seed}\")\n    rng         = len(list_all_img_path_obj)-1  # Replace 10 with the desired upper limit (exclusive)\n    random_nos  = random.sample(range(rng), chosen_sample_n)\n    print()\n    print(\"sample_images:\")\n    for index, img_path in enumerate(list_all_img_path_obj[random_nos]):\n        print(f\" {random_nos[index]:&gt;7}: \\t\\t{img_path}\")\n    \n    \n    for image_path in list_all_img_path_obj[random_nos]:\n        img = PILImage.create(image_path)\n        show_image(img)\n    return None\n\n\n# 0. get paths of images\npath_dir_obj                = untar_data(URLs.MNIST_TINY)\nlist_all_img_path_obj       = get_image_files(path_dir_obj)\n\n\n# 1. create learner\ndata_loader = ImageDataLoaders.from_folder(path_dir_obj, \n                                    img_cls=PILImageBW,\n                                    set_seed=42)\nx1,y1 = data_loader.one_batch()\ntest_eq(x1.shape, [64, 1, 28, 28])\n\nprint_useful_info()\nprint_sample_imgs()\n# check valid data sets - can check if splits are as expected\nprint(len(data_loader.valid_ds.items)) # 699 as expected\nprint(len(data_loader.train_ds.items)) # 709 as expected\n\n# can show sample pics\ndata_loader.show_batch() #show examples?\n\n\npath_obj_home_dir:  C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\nimage_list_count:   1428\nset_seed_number:    42\n\nsample_images:\n    1309:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\valid\\7\\9036.png\n     228:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\8830.png\n      51:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\731.png\n     563:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\868.png\n     501:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\8186.png\n699\n709\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnbr_learner = vision_learner(data_loader, resnet34, metrics=error_rate)\n\n\nnbr_learner.fine_tune(4)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/11 00:00&lt;?]\n    \n    \n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.303663\n0.174878\n0.054363\n00:21\n\n\n1\n0.228222\n0.127563\n0.040057\n00:20\n\n\n2\n0.172806\n0.091346\n0.027182\n00:21\n\n\n3\n0.139439\n0.056558\n0.015737\n00:21\n\n\n\n\n\n\nfrom IPython.display import Image # import image viewer\n\n\n\nuploader = SimpleNamespace(data = ['3.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [0], representing [3]\")\n\n\n\n\n\n\n\n\n3\ntensor(0)\ntensor([9.9998e-01, 2.1658e-05])\ncorrectly guessed the [0], representing [3]\n\n\n\n\nuploader = SimpleNamespace(data = ['7.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [1], representing [7]\")\n\n\n\n\n\n\n\n\n\n7\ntensor(1)\ntensor([0.0050, 0.9950])\ncorrectly guessed the [1], representing [7]"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-18-99_rice_vs_noodles/index.html",
    "href": "posts/datascience/machinelearning/2024-01-18-99_rice_vs_noodles/index.html",
    "title": "Image Classifier 1: Noodles vs Rice",
    "section": "",
    "text": "Today I’ll be attempting to build my first deep learning image classifier to distinguish between rice and noodles using knowledge gained from Jeremy Howards Fast AI course\nHigh-level steps:\n1. Search and Prepare Data\n2. Create DataLoader\n3. Create Learner\n4. Prediction\nI will detail any problems, issues, questions and resolutions during the process.\n\n!pip install -Uqq fastai\n\n\nfrom fastbook import * \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n1. Search and Prepare Data\n\n# 1.1 Get 'rice' photos\ndownload_url(search_images_ddg('rice',max_images=1)[0],'rice.jpg',show_progress=False)\nImage.open('rice.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\n\n# 1.2 Get 'noodles' photos\ndownload_url(search_images_ddg('noodles', max_images=1)[0],'noodles.jpg',show_progress=False)\nImage.open('noodles.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\nLets use 60 imagess of ‘rice’ and ‘noodles’ from DuckDuckGo.\nNote: I downloaded for 100 images of each and then taking 60 of them as some images fail so I’m leaving room for failed photos.\nQuestion: Why do we need verify and why do some photos fail?\n\n# 1.3 Prep images in folders\nsearches = ['rice', 'noodles']\npath = Path('rice_or_noodles')\n\nif not path.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=100)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:60])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n# 1.4 Remove Failed images\npath = Path('rice_or_noodles')\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\n\n2. Create DataLoader\n\n# 2.1 \ndls = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path) \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n# 2.2 We can see Paths were created for every image and split into our training and data sets\ndls.train_ds.items[:2]\ndls.valid_ds.items[:2]\n\n[Path('rice_or_noodles/rice/4280fe58-691a-4c0b-85a5-5c1c8400ecb7.jpg'),\n Path('rice_or_noodles/rice/f8a77d77-c007-4854-af8b-2af624a8da66.jpg')]\n\n\n[Question]: How does it know whether it is training set or valid set? I guess theres some indexing somewhere that I dont know how to obtain.\n\n# 2.1 Show a training batch which has an 'image' and a 'label'\ndls.show_batch(max_n=6) #batch shows input and label\n\n\n\n\n\n\n\n\n\n\n2. Create Learner using ResNet\nIn the course, we used a pre-trained model ‘ResNet18’ (RN).\nWhy Pre-trained Models?:\n- Pre-trained models is like getting an athlete who is very good basic sport related skills like hand-eye coordination, jumping, running/sprinting, changing directions etc and then - telling them to learn a specific sport (fine-tuning), - say tennis (labelled dataset provided). With a good base of skills, this person should be able to learn tennis to a good level…\nResNet18:\n- ResNet18 is trained on 1.28 million images with 1000 object categories. - 18 layers\n- Trained on ImageNet dataset\n[Future iterations 1]: Perhaps there are alternative pre-trained models specialising in food?\n[Future iterations 2]: - Read up and try understand the various architectures Fast AI’s TIMM model architectures - Try different architectures and different versions\n\nlearner_RN18 = vision_learner(dls, resnet18, metrics=error_rate)\n\n\n2.1 Learner Model Times:\nThey all took under 10 seconds to create the general learner. Now to fine-tune them!\n\nlearner_RN18.fine_tune(8)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.840357\n4.676042\n0.476190\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.763106\n3.761843\n0.476190\n00:04\n\n\n1\n1.517361\n2.798523\n0.476190\n00:04\n\n\n2\n1.202234\n2.308116\n0.428571\n00:04\n\n\n3\n0.953227\n1.637496\n0.428571\n00:04\n\n\n4\n0.770979\n1.034023\n0.380952\n00:04\n\n\n5\n0.662257\n0.641428\n0.190476\n00:04\n\n\n6\n0.563239\n0.405057\n0.142857\n00:04\n\n\n7\n0.490904\n0.285846\n0.095238\n00:04\n\n\n\n\n\n\nOur learner is performing at 90% accuracy (9% error rate) by looking at only 60 photos!\nLets try predict some random photos of rice and noodles I’ve found on the internet.\n\nfrom IPython.display import Image # import image viewer\n\n\n# noodle predictor\nuploader = SimpleNamespace(data = ['test_noodle.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nnoodles: 99.98%\n\n\n\n\nPrediction 1: Noodles\nThe model predicted noodles correctly with 99.98% confidence!\n\n# rice predictor 1\nuploader = SimpleNamespace(data = ['test_rice.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\n\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 66.22%\n\n\n\n\nPrediction and Results 2: Rice 1\nThe model predicted rice incorrectly with 66.22% confidence!\nI was a bit confused so I decided to provide another image of rice to make\n\n# rice predictor 2\nuploader = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path)) # show image\n\n# get\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 98.51%\n\n\n\n\nPrediction and Results 3: Rice 2\nThe model predicted rice incorrectly with 98.51% confidence!\nOkay now there is clearly something wrong going on. I decide to take a gander at the photos in my ‘rice’ folder.\n\nIt looks like we’ve trained a learner specialises in bowled or white rice. I was testing the model with fried rice since that is my favourite rice dish.\nLets test out a couple photos on bowled rice.\n\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice: 88.73%\n\n\n\n\n\n\n\n\n\nnoodles: 92.57%\n\n\nNow I’m confused as its predicting incorrectly with 92.57% confidence.\nPerhaps the model isnt seeing enough data?\nLets train a new model with:\n- 300 images instead of 60\n- ‘rice food’ and ‘noodle food’ as keyword insteads of just ‘rice’ and ‘noodles’\n\nsearches = ['rice food', 'noodles food']\npath_200 = Path('rice_or_noodles_300')\n\nif not path_200.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path_200/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=300)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:200])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n\n# 1.4 Remove Failed images\npath_200 = Path('rice_or_noodles_300')\nfailed = verify_images(get_image_files(path_200))\nfailed.map(Path.unlink)\n\n\n(#10) [None,None,None,None,None,None,None,None,None,None]\n\n\n\n\ndls_200 = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path_200) \n\n\nlearner_RN18_200 = vision_learner(dls_200, resnet18, metrics=error_rate)\n\n\nlearner_RN18_200.fine_tune(4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.155098\n0.872050\n0.338462\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.625260\n0.402908\n0.169231\n00:15\n\n\n1\n0.442973\n0.289800\n0.138462\n00:14\n\n\n2\n0.317375\n0.328805\n0.153846\n00:14\n\n\n3\n0.235606\n0.327507\n0.123077\n00:15\n\n\n\n\n\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18_200.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 100.00%\n\n\n\n\n\n\n\n\n\nrice food: 99.95%\n\n\nSo it’s now 100 and 99.95% confident they’re rice, which is great!\nLets try some fried rice!\nWe’ll retest now at the fried rice photo which the initial model guessed to be noodles with 98.5% confidence\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path1 = uploader1.data[0]\n\ndisplay(Image(filename=image_path1)) \n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 99.56%\n\n\nGreat! It is correct with 99.56% confidence.\nI think we’ve created a great rice and noodles classifier, lets stop here.\n[Future Iteration 3]: Build web app for everyone to test it out\n[Future Iteration 4]: Make it useable on my blog\n[Question] I wonder if theres a way to quickly see all specific headings I’ve used, I find myself scrolling up and download to find what Iteration I’m up to…\nApologies for the lack of neatness, lets hope this improves over time…"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "",
    "text": "This post shows how to host your working Local Gradio App on HuggingFace.\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "Part 3: Host on HuggingFace account",
    "text": "Part 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "1 Create HuggingFace Account and Create a ‘Space’",
    "text": "1 Create HuggingFace Account and Create a ‘Space’\n\nChoose your Space name\nChoose Apache-2.0 to avoid any copyright issues\nChoose Gradio\nChoose the Free option\nChoose Public (show you can show it to the world!)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2 Clone the repo",
    "text": "2 Clone the repo\nThis will create allow us deploy the Gradio app to the HuggingFace repository:\ngit clone https://huggingface.co/spaces/tonyjustdevs/pets_breed_predictor"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#gather-your-files",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#gather-your-files",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2. Gather your files",
    "text": "2. Gather your files\nRecall the various files we needed to run the app locally part 2.\nGather into the cloned huggingface folder:\n- Learner (.pkl)\n- Pet examples (pets.jpg)\n- Gradio app (app.py)\n\nA good way to check for me is seeing the pets_breed_predictor is the git folder and huggingface space."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "3. Push to HuggingFace Repo",
    "text": "3. Push to HuggingFace Repo\nIf you’ve pushed succesfully your app (could take several minutes), then your app is live! Congrats!\nIf you’re like me and forgot to include the requirements.txt then you’ll be greeted with this error.\n\n\n3.1 Add the requirements.txt\nWe imported two libraries fastai and gradio so include them in the requirements.txt file. Commit and push."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "href": "posts/datascience/machinelearning/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "4 Web App Complete and is Live",
    "text": "4 Web App Complete and is Live\nIf all goes well, the HuggingFace space is hosting the Gradio App!\nCheck out my web app here!"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-26-random_forest/index.html",
    "href": "posts/datascience/machinelearning/2024-04-26-random_forest/index.html",
    "title": "Random Forests - Random Forest Classifier (Part 3)",
    "section": "",
    "text": "1. Introduction\nIn Part 1, a simple model was built using single binary split called OneR Classifier.\nIn Part 2, sklearn DecisionTreeClassifier framework was used and by setting a sample limit per node, loss was reduced\nIn this post:\n\nCreate alot of bigger trees\n\nTake the average of their predictions, that is, the averaged emsemble or bagging results is a random forest\n\nCompare the results with sklearn’s RandomForestClassifier\n\nIn the next few posts, the topics will follows:\n\nFeature Importance Plot\n\nGradient Boosting (sum of trees) Decision Tree or Machine\n\n\n\n2. Training and Validation Sets\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\ntitanic folder doesn't exist, downloading...\nDownloading titanic.zip to /home/tonydevs/github/blog/posts/2024-04-26-random_forest\n\n\n100%|██████████| 34.1k/34.1k [00:00&lt;00:00, 55.8kB/s]\n\n\n\ngender_submission.csv  test.csv  train.csv\n\n\n\n\n\n\n\n3. Using DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\ndef get_tree(prop=0.75):\n    n = len(trn_dep)\n    idxs = random.choice(n, int(n*prop))\n    return DecisionTreeClassifier(min_samples_leaf=5).fit(trn_idep.iloc[idxs], trn_dep.iloc[idxs])\n\n\n# create as many trees as we want\ntrees = [get_tree() for t in range(100)] \n\n\n# average them\nall_probs = [t.predict(val_idep) for t in trees]\navg_probs = np.stack(all_probs).mean(0)\n\nfrom sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(val_dep, avg_probs)\n\n0.2272645739910314\n\n\n\n\n4. Using RandomForestClassifier\nThis is nearly identical to what sklearn’s RandomForestClassifier does.\nThe main extra piece in a “real” random forest (is that as well as choosing a random sample of data for each tree):\n\nit also picks a random subset of columns for each split.\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(100, min_samples_leaf=5)\nrf.fit(trn_idep, trn_dep);\nmean_absolute_error(val_dep, rf.predict(val_idep))\n\n0.18834080717488788"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "",
    "text": "This post shows how to create a Gradio App (app.py) and run it locally in a browser. This app should:\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "Part 2: Create Gradio application file (app.py)",
    "text": "Part 2: Create Gradio application file (app.py)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "1. Import Gradio and Fast AI libraries",
    "text": "1. Import Gradio and Fast AI libraries\n\nfrom fastai.vision.all import * \nimport gradio as gr\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn("
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "2. Import Learner (.pkl file)",
    "text": "2. Import Learner (.pkl file)\nRecall, this file was created and exported in Part 1\n\nIf you’re running on a Linux, you shouldn’t have any import issues.\n\nIf you’re running a Windows PC, you’ll likely to experience an error.\n\n\npets_learner = load_learner('pets_learner.pkl') \n\n\n---------------------------------------------------------------------------\nNotImplementedError                       Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 pets_learner = load_learner('pets_learner.pkl') \n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\learner.py:446, in load_learner(fname, cpu, pickle_module)\n    444 distrib_barrier()\n    445 map_loc = 'cpu' if cpu else default_device()\n--&gt; 446 try: res = torch.load(fname, map_location=map_loc, pickle_module=pickle_module)\n    447 except AttributeError as e: \n    448     e.args = [f\"Custom classes or functions exported with your `Learner` not available in namespace.\\Re-declare/import before loading:\\n\\t{e.args[0]}\"]\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torch\\serialization.py:1014, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n   1012             except RuntimeError as e:\n   1013                 raise pickle.UnpicklingError(UNSAFE_MESSAGE + str(e)) from None\n-&gt; 1014         return _load(opened_zipfile,\n   1015                      map_location,\n   1016                      pickle_module,\n   1017                      overall_storage=overall_storage,\n   1018                      **pickle_load_args)\n   1019 if mmap:\n   1020     raise RuntimeError(\"mmap can only be used with files saved with \",\n   1021                        \"`torch.save(_use_new_zipfile_serialization=True), \"\n   1022                        \"please torch.save your checkpoint with this option in order to use mmap.\")\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torch\\serialization.py:1422, in _load(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\n   1420 unpickler = UnpicklerWrapper(data_file, **pickle_load_args)\n   1421 unpickler.persistent_load = persistent_load\n-&gt; 1422 result = unpickler.load()\n   1424 torch._utils._validate_loaded_sparse_tensors()\n   1425 torch._C._log_api_usage_metadata(\n   1426     \"torch.load.metadata\", {\"serialization_id\": zip_file.serialization_id()}\n   1427 )\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\pathlib.py:873, in Path.__new__(cls, *args, **kwargs)\n    871 self = cls._from_parts(args)\n    872 if not self._flavour.is_supported:\n--&gt; 873     raise NotImplementedError(\"cannot instantiate %r on your system\"\n    874                               % (cls.__name__,))\n    875 return self\n\nNotImplementedError: cannot instantiate 'PosixPath' on your system\n\n\n\n\n2.1 Import Learner Error (.pkl file) Solution (Windows only)\nI found a solution here.\nNot too sure why this happens, probably linux vs windows compatibility, forward vs backlashes probably?\nImport the pathlib library below and run the code below to fix the paths:\nNote:\n- This fix is only required during the testing phase of our Gradio App.\n- This testing phase is defined as being able to run the Gradio App locally.\n- When we Upload to HuggingFace Spaces, this code fix is not required (because HF is run on Linux, hence no Posix issues, from my understanding)\n\n# only run to import pkl in windows when youre doing testing in windows | when run in hus | its run via dock images ie linux ie no problems\nimport pathlib # \ntemp = pathlib.PosixPath\npathlib.PosixPath = pathlib.WindowsPath\n\n\npets_learner = load_learner('pets_learner.pkl')"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "3 Predict the Breed with Imported Learner",
    "text": "3 Predict the Breed with Imported Learner\n\n3.1 Import Local Image\n\npet1 = PILImage.create('pet1.jpg')\npet1.thumbnail((224,224))\npet1\n\n\n\n\n\n\n\n\n\n\n3.2 Make prediction\nUse predict() to make prediction on the uploaded local image. The results will have 3 items:\n1. The prediction of the breed.\n2. Index of the Tensor (in point 3.)\n3. A Tensor of length 37. Why the odd number?\n- These are the probabilities of each unique breeds in our data!\n- Recall in Part 1, we determined the different categories by using a custom labelling function\n\nres = pets_learner.predict(pet1)\nres\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n('Bombay',\n tensor(3),\n tensor([3.4475e-02, 1.7813e-03, 8.1388e-03, 6.3685e-01, 6.0993e-03, 4.8830e-04,\n         5.0747e-02, 8.8036e-03, 2.1084e-01, 3.4832e-02, 9.6598e-04, 7.6646e-04,\n         6.3764e-04, 2.5949e-04, 8.7999e-05, 1.3308e-03, 6.6650e-05, 5.7116e-05,\n         9.0377e-04, 6.9052e-05, 2.0095e-04, 2.1758e-05, 2.5767e-04, 2.1859e-05,\n         3.8547e-05, 1.6165e-06, 6.2601e-05, 4.3552e-05, 1.4901e-04, 9.6175e-05,\n         1.0010e-04, 1.3717e-04, 2.7684e-04, 5.5386e-05, 5.7012e-05, 4.6809e-05,\n         2.2643e-04]))\n\n\n\n\n3.3 What is the probabilities representing?\nThe probabilities tensor from predict() are the unique categories in our data and are stored in our dataloader\n\ncategories = pets_learner.dls.vocab \ncategories\n\n['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'boxer', 'chihuahua', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian', 'pug', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']\n\n\n\n\n3.4 The prediction and probabilities of our image\n\n# get index of predction\nidx = res[1]\n\n# store list of probalities of our predction\nprobabilities = res[2]\n\n# get breed and probability of our prediction\ncategories[idx],probabilities[idx]\n\n\n('Bombay', tensor(0.6369))\n\n\n\n\n3.5 Probability of every category available\n\ndef classify_image_fn(img):\n    prediction, idx, probabilities = pets_learner.predict(img)\n    return dict(zip(categories, map(float, probabilities)))\n\nclassify_image_fn(pet1)     # names and probabilities\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n{'Abyssinian': 0.034474823623895645,\n 'Bengal': 0.0017812795704230666,\n 'Birman': 0.008138809353113174,\n 'Bombay': 0.6368528604507446,\n 'British_Shorthair': 0.006099338177591562,\n 'Egyptian_Mau': 0.0004883029614575207,\n 'Maine_Coon': 0.05074741691350937,\n 'Persian': 0.008803554810583591,\n 'Ragdoll': 0.21084259450435638,\n 'Russian_Blue': 0.03483246639370918,\n 'Siamese': 0.0009659799397923052,\n 'Sphynx': 0.0007664564182050526,\n 'american_bulldog': 0.0006376394885592163,\n 'american_pit_bull_terrier': 0.0002594943216536194,\n 'basset_hound': 8.799932402325794e-05,\n 'beagle': 0.0013307805638760328,\n 'boxer': 6.664981629000977e-05,\n 'chihuahua': 5.711586709367111e-05,\n 'english_cocker_spaniel': 0.0009037724230438471,\n 'english_setter': 6.905203190399334e-05,\n 'german_shorthaired': 0.00020094779029022902,\n 'great_pyrenees': 2.1758336515631527e-05,\n 'havanese': 0.0002576670085545629,\n 'japanese_chin': 2.1859435946680605e-05,\n 'keeshond': 3.85471066692844e-05,\n 'leonberger': 1.616517351976654e-06,\n 'miniature_pinscher': 6.26009568804875e-05,\n 'newfoundland': 4.355219061835669e-05,\n 'pomeranian': 0.00014901049144100398,\n 'pug': 9.617456089472398e-05,\n 'saint_bernard': 0.0001000974079943262,\n 'samoyed': 0.0001371700782328844,\n 'scottish_terrier': 0.00027684049564413726,\n 'shiba_inu': 5.5386270105373114e-05,\n 'staffordshire_bull_terrier': 5.701235932065174e-05,\n 'wheaten_terrier': 4.680879646912217e-05,\n 'yorkshire_terrier': 0.0002264348149765283}"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "4 Run local Gradio App",
    "text": "4 Run local Gradio App\nTheres a variety of ways to alter the app, I’ve set the size of the images and provided some examples:\n\ngr_image = gr.Image(width=244, height=244)\ngr_label = gr.Label()\n\ninput_examples = ['pet1.jpg','pet2.jpg','pet3.jpg','pet4.jpg','pet5.jpg']\nintf = gr.Interface(fn=classify_image_fn,\n                    inputs=gr_image,    \n                    outputs=gr_label,\n                    examples=input_examples)\nintf.launch(inline=False)\n\nRunning on local URL:  http://127.0.0.1:7863\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n\n4.1 Open Local Gradio App\nOpen the URL provided in your favourite browser\n\n\n\n4.2 Test it out\nThe app knows a pug when it sees one! The app is ready."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#export-app.py",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#export-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "5. Export (app.py)",
    "text": "5. Export (app.py)\nGradio app must be all inside a app.py script when being deployed on HuggingFaces.\nThankfully, there is a library to export all the cell-blocks from our notebook (.ipynb) to python script (app.py).\nReference\n\n5.1 Put directives at front of notebook\n\nPlace ‘#| default_exp app’ in a python codeblock in front of the the notebook\n\n\n\n\n5.2 Choose the cellblocks to export\n\nPlace ‘#| export’ in front of each codeblock you need to export\n\n\n\n\n5.3 Run nbdev and export\n\nfrom nbdev.export import nb_export\nnb_export('app.ipynb')\n\nThis will create a new folder as home directory and place in the app.py"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "href": "posts/datascience/machinelearning/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "title": "Let’s Make Some Noise",
    "section": "2.1 Statistical Properties",
    "text": "2.1 Statistical Properties\n\nGaussian noise is characterized by a normal distribution, which is well-studied and has known statistical properties.\nThis makes it easy to model and analyze mathematically."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "title": "Let’s Make Some Noise",
    "section": "2.2 Central Limit Theorem:",
    "text": "2.2 Central Limit Theorem:\n\nThe Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables, each with finite mean and variance, will be approximately normally distributed.\nThis property makes Gaussian noise a natural choice in many scenarios where the noise is a result of multiple independent factors."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "title": "Let’s Make Some Noise",
    "section": "2.3 Mathematical Simplicity:",
    "text": "2.3 Mathematical Simplicity:\n\nThe normal distribution has simple and well-defined mathematical properties, making it easy to work with in analytical and computational contexts."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "title": "Let’s Make Some Noise",
    "section": "2.4 Robustness in Estimation:",
    "text": "2.4 Robustness in Estimation:\n\nMany statistical estimation methods, including maximum likelihood estimation, assume that the underlying noise follows a Gaussian distribution.\nThis can lead to more robust parameter estimates when the actual noise is close to Gaussian."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "title": "Let’s Make Some Noise",
    "section": "2.5 Convenient in Machine Learning:",
    "text": "2.5 Convenient in Machine Learning:\n\nIn machine learning, adding Gaussian noise can act as a form of regularization, preventing overfitting by introducing a controlled amount of randomness during training. It is also commonly used in generative models, such as Gaussian Mixture Models (GMMs)."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#noise-function",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#noise-function",
    "title": "Let’s Make Some Noise",
    "section": "3.1 noise function",
    "text": "3.1 noise function\nThis function generates random noise using NumPy’s random.normal function.\n\ny: numpy or pytorch array\n\nscale: standard deviation of the normal distribution from which the noise is drawn.\noutput: array of random values with the same shape as the input array y.\n\n\ndef add_noise(x, mult, add): \n    return x * (1+noise(x, mult)) + noise(x, add)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#add_noise-function",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#add_noise-function",
    "title": "Let’s Make Some Noise",
    "section": "3.2 add_noise function",
    "text": "3.2 add_noise function\nThis function uses the noise function to add noise to the input x:\n\n* (1 + noise(x, mult)): The multiplicative noise is applied by multiplying x with.\n+ noise(x, add): The additive noise is added directly to the result of the multiplicative part."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#differences",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#differences",
    "title": "Let’s Make Some Noise",
    "section": "3.3 Differences:",
    "text": "3.3 Differences:\nThe noise function generates:\n\nrandom noise independently of any input array,\nusing a specified scale.\nIt’s a standalone function for generating random noise.\n\nThe add_noise function is specifically designed to:\n\napply noise to an input array x.\ncombines both multiplicative and additive noise components,\nallowing for a more complex noise model."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "title": "Let’s Make Some Noise",
    "section": "4.1 Regularization and Preventing Memorization:",
    "text": "4.1 Regularization and Preventing Memorization:\nAvoid and  Discouraging Overfitting:\n\nAdding random noise to the input data can act as a form of regularization, preventing the model from fitting the training data too closely.\nThis can improve the generalization of the model to new, unseen data.\nModels that are too complex may memorize the training data instead of learning the underlying patterns.\nAdding noise makes it more challenging for the model to memorize specific examples and encourages it to focus on general patterns."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "title": "Let’s Make Some Noise",
    "section": "4.2 Data Augmentation:",
    "text": "4.2 Data Augmentation:\nIncreased Variability:\n\nIntroducing noise during training can artificially increase the variability in the dataset.\nThis can be particularly useful when dealing with limited training data, helping the model generalize better to different variations of the input."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "title": "Let’s Make Some Noise",
    "section": "4.3 Robustness Testing:",
    "text": "4.3 Robustness Testing:\nModel Robustness:\n\nAdding noise during training can make the model more robust to variations and uncertainties in real-world data.\nThis is especially important when the model needs to perform well on data that may have different levels of noise or unexpected variations."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "href": "posts/datascience/machinelearning/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "title": "Let’s Make Some Noise",
    "section": "4.4 Stochasticity in Training:",
    "text": "4.4 Stochasticity in Training:\nEncouraging Exploration:\n\nDuring the training process, introducing randomness can encourage the model to explore different parts of the parameter space.\nThis can be especially beneficial in reinforcement learning or optimization problems, helping to avoid getting stuck in local minima."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html",
    "title": "Tabular Deep-Learning Model",
    "section": "",
    "text": "import torch, numpy as np, pandas as pd"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#download-competition-data",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#download-competition-data",
    "title": "Tabular Deep-Learning Model",
    "section": "1. Download Competition Data",
    "text": "1. Download Competition Data\n\nimport kaggle, zipfile\nfrom pathlib import Path\n\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n\n!ls {path}\n\ntitanic folder doesn't exist, downloading...\nDownloading titanic.zip to /home/tonydevs/github/blog/posts/2024-04-21-deep_learning\n\n\n100%|██████████| 34.1k/34.1k [00:00&lt;00:00, 92.8kB/s]\n\n\n\ngender_submission.csv  test.csv  train.csv"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#clean-data",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#clean-data",
    "title": "Tabular Deep-Learning Model",
    "section": "2. Clean Data",
    "text": "2. Clean Data\n\n2.1 Read Training Data\n\ndf = pd.read_csv(path/\"train.csv\")\n\n\n\n2.2 Deal with NA’s\n\ndf.isna().sum() # find nas\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\nmodes = df.mode(axis=0).iloc[0] # get modes\ndf.fillna(modes, inplace=True)  # replace nas with mode per col\ndf.isna().sum() # no more nas \n\nPassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\ndtype: int64\n\n\n\n\n2.3 Deal with Numeric Data\n\ndf['Fare'].hist() # Not evenly spread\n\n\n\n\n\n\n\n\n\ndf['LogFare'] = np.log1p(df['Fare'])\ndf['LogFare'].hist() # more evenly spread\n\n\n\n\n\n\n\n\n\n\n2.4 Deal with Categorical Data\n\ndf.nunique() \n# [Pclass], [Sex] and [Age] variables only has 2-3 categories.\n# A good choice to create dummy variables\n\nPassengerId    891\nSurvived         2\nPclass           3\nName           891\nSex              2\nAge             88\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nEmbarked         3\nLogFare        248\ndtype: int64\n\n\n\ndf = pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=int)\nadded_cols          = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\nindep_cols          = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n\n\ndf.nunique() \n# [Sex], [Pclass] and [Embarked] dummy variables created\n\nPassengerId    891\nSurvived         2\nName           891\nAge             88\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nLogFare        248\nSex_female       2\nSex_male         2\nPclass_1         2\nPclass_2         2\nPclass_3         2\nEmbarked_C       2\nEmbarked_Q       2\nEmbarked_S       2\ndtype: int64\n\n\n\n\n2.5 Normalise Numerical Data\n\nidep_values_2d_tsr  = torch.tensor(df[indep_cols].values, dtype=torch.float)\nidep_values_2d_tsr[0:5] # Column 1 (20s) and Column 4 (2-4) are much larger than others (0-1).\n\ntensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000],\n        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,\n          0.0000,  1.0000,  0.0000,  0.0000],\n        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000]])\n\n\n\nmaxes, _            = idep_values_2d_tsr.max(axis=0) # get max of each column\nidep_norms_2d_tsr_mxn   = idep_values_2d_tsr / maxes\nidep_norms_2d_tsr_mxn[0:5] # values are normalised about 0-1\n\ntensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n         1.0000, 0.0000, 0.0000],\n        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000]])"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#training-and-validation-sets",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#training-and-validation-sets",
    "title": "Tabular Deep-Learning Model",
    "section": "3. Training and Validation Sets",
    "text": "3. Training and Validation Sets\n\nfrom fastai.data.transforms import RandomSplitter\ndep_mx0                     = torch.tensor(df[\"Survived\"])\n\ntrn_idx, val_idx            = RandomSplitter(seed=42)(idep_norms_2d_tsr_mxn)\ntrn_idep_mxn, val_idep_mxn  = idep_norms_2d_tsr_mxn[trn_idx], idep_norms_2d_tsr_mxn[val_idx] \ntrn_dep_mx0,  val_dep_mx0   = dep_mx0[trn_idx], dep_mx0[val_idx] \n\ntrn_dep_mx1 = trn_dep_mx0[:,None] # add extra dimention for matrix multiplies comparisons\nval_dep_mx1 = val_dep_mx0[:,None]"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#deep-learning-neural-network",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#deep-learning-neural-network",
    "title": "Tabular Deep-Learning Model",
    "section": "4. Deep Learning Neural Network",
    "text": "4. Deep Learning Neural Network\n\n4.1 Initialise Coefficients\n\nimport torch.nn.functional as F\ndef init_coeffs():\n    n_coeffs    = trn_idep_mxn.shape[1] # 12\n    hidden_layers = [10,10]\n    sizes = [n_coeffs] + hidden_layers + [1]    # [12,10,10,1]\n    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(len(sizes)-1)]   # 0,1,2\n    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(len(sizes)-1)]   # [0,1,2]\n\n    for layer in layers+consts:\n        layer.requires_grad_()\n\n    return layers, consts\n\n\n\n4.2 Calculate Predictions\n\n\n# i=1: [12,10]  [nxq1]      res1 = [713x12]@[12x10] = [713x10]\n# i=2: [10,10]  [q1xq2]     res2 = [713x10]@[10x10] = [713x10]\n# ...\n# i=n: [10,1]   [qnx1]      resn = [713x10]@[10x1] = [713x1]\n\ndef calc_preds_deeplearning(trn_idep_mxn, coeffs):    \n    layers, consts = coeffs\n    n = len(layers)\n    res = trn_idep_mxn\n    for i in range(n):\n        res = res@layers[i] + consts[i] # [mxn]@[nxq]  [713x12][12x10]\n        if i!=n-1: \n            res = F.relu(res) \n    sgm_preds_mx1 = torch.sigmoid(res)\n    return sgm_preds_mx1\n\n\n\n4.3 Calculate Loss\n\ndef calc_loss(idep_mxn, dep_mx1, coeffs):\n    preds_mx1 = calc_preds_deeplearning(idep_mxn, coeffs)\n    return torch.abs(dep_mx1-preds_mx1).mean()\n\n\n\n4.4 Update Coefficients and Constants\n\ndef update_coeffs(coeffs, lr):\n    layers, consts = coeffs\n    for layer in layers+consts:\n        layer.sub_(layer.grad*lr)\n        layer.grad.zero_()\n\n\n\n4.5 One Epoch\n\ndef one_epoch(coeffs,lr):\n    loss = calc_loss(trn_idep_mxn, trn_dep_mx1, coeffs)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:.3f}\",end=';')\n\n\n\n4.6 Train Model with 30 Epochs\n\ndef train_model(n_epochs=30,lr=0.1):\n    torch.manual_seed(442)\n    coeffs = init_coeffs()\n    for _ in range(n_epochs):\n        one_epoch(coeffs,lr)\n    return coeffs\n\n\ncoeffs = train_model(lr=4)\n\n0.521;0.483;0.427;0.379;0.379;0.379;0.379;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.377;0.376;0.371;0.333;0.239;0.224;0.208;0.204;0.203;0.203;0.207;0.197;0.196;0.195;"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#submit-to-kaggles",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#submit-to-kaggles",
    "title": "Tabular Deep-Learning Model",
    "section": "5. Submit to Kaggles",
    "text": "5. Submit to Kaggles\n\n5.1 Prepare Test-Set\n\ntst_df = pd.read_csv(path/'test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\ntst_df.fillna(modes, inplace=True)\ntst_df['LogFare'] = np.log(tst_df['Fare']+1)\ntst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"], dtype=int)\ntst_indep = torch.tensor(tst_df[indep_cols].values, dtype=torch.float)\ntst_indep = tst_indep / maxes\n\n\n\n5.2 Predictions on Test-Set\n\ntst_df['Survived'] = (calc_preds_deeplearning(tst_indep, coeffs)&gt;0.5).int()\n\n\n\n5.3 Create Submission CSV\n\ntitanic_submission_df = tst_df[['PassengerId','Survived']]\ntitanic_submission_df.to_csv('titanic_submission.csv', index=False)\n\n\nkaggle.api.competition_submit(file_name='titanic_submission.csv', \n                              message='20240420_tit_submission', \n                              competition='titanic')\n\nWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.12 / client 1.6.6)\n\n\n100%|██████████| 2.77k/2.77k [00:00&lt;00:00, 3.42kB/s]100%|██████████| 2.77k/2.77k [00:01&lt;00:00, 1.82kB/s]\n\n\nSuccessfully submitted to Titanic - Machine Learning from Disaster"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#success",
    "href": "posts/datascience/machinelearning/2024-04-21-deep_learning/index.html#success",
    "title": "Tabular Deep-Learning Model",
    "section": "6. Success!",
    "text": "6. Success!\nI’ve finally completed building my first deep-learning neural-network model from scratch and successfully submitting to Kaggle with 77.75% Accuracy."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "href": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "1. Introduction",
    "text": "1. Introduction\nEmbedding a classic Convolutional Neural Network (CNN) Gradio ‘Cat versus Dog’ classifier Gradio App, hosted on HuggingFace Spaces, into my Quarto Blog. What a mouthful!"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "href": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "2. Background",
    "text": "2. Background\nThis App will guess whether an image is a Cat or Dog with a level of confidence using a deep learning neural network based on 700 mbs of labelled photos of dogs and cats. I’ll post more information on the model itself in a different post.\nAll doggos🐕 & cats🐈 image examples has never been viewed by the Model and it makes a prediction in milliseconds! Images supplied by my good friends in Australia 🦘 and Vietnam 🍜. Thanks guys!\nThe App isn’t perfect:\n- It guesses Incorrectly with great 95% confidence a cat as a dog!\nI’m thrilled to be able to build the app, get it hosted and embed it all in one day for the first time! Alot of firsts today!"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "href": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "3. Future stuff",
    "text": "3. Future stuff\n[1]: Multi-Image Uploader + Predictor.\n[2]: Explain how I built the Gradio App, got it hosted Hugging Face, and embedded here.\n[4]: Upgrade the rice vs noodle model an App and hosted.\n[4]: Learn some HTML/CSS to make things prettier."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "href": "posts/datascience/machinelearning/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "4. Heres the App!",
    "text": "4. Heres the App!"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html",
    "href": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html",
    "title": "How To Setup a Kaggle API",
    "section": "",
    "text": "I’m planning to learn and test myself with competitions on Kaggle.\nKaggle is a place with real-world problems where Data Scientists and alike can go against each other to solve problems with Machine Learning.\nFrom my understanding:\n- There is a validation set where your model is tested against and a public leader board to see how you’re going.\n- At the end of the competition, there is an unseen test set where everyones models is tested against and where the final rankings are determined.\n- This is quite reflective of real world where preparing a representative validation set is vital, thus will perform well on the test set.\n- A common mistake for newbs is over-fitting to the validation set. I’m ready to make that mistake 🤣.\nAs for the Kaggle API, you can download the kernel which is the necessary datasets and source files to do the competitions.\nAlternatively, I can use the notebooks on their website. I plan to try doing competitions both ways.\nThis is how I set up my Kaggle API"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#install-library",
    "href": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#install-library",
    "title": "How To Setup a Kaggle API",
    "section": "1. Install Library",
    "text": "1. Install Library\npip install python"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "href": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "title": "How To Setup a Kaggle API",
    "section": "2. Create API token (.json file)",
    "text": "2. Create API token (.json file)\n\nGo to Kaggle\n\nGo to Settings\n\nCreate New Token"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "href": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "title": "How To Setup a Kaggle API",
    "section": "3. Save to your local .kaggle folder (Windows)",
    "text": "3. Save to your local .kaggle folder (Windows)\nLocation: C:\\Users\\&lt;Windows-username&gt;\\.kaggle\\kaggle.json\nKaggle Github Reference\n\n3.1 Pasted into the wrong folder?\nIf you did something wrong then ran kaggle in the terminal, you’ll an error (telling you where to put it):"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "href": "posts/datascience/machinelearning/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "title": "How To Setup a Kaggle API",
    "section": "4 Start Kaggling",
    "text": "4 Start Kaggling\n\nimport kaggle\n??kaggle\n\nType:        module\nString form: &lt;module 'kaggle' from 'c:\\\\Users\\\\tonyp\\\\miniconda3\\\\envs\\\\fastai\\\\Lib\\\\site-packages\\\\kaggle\\\\__init__.py'&gt;\nFile:        c:\\users\\tonyp\\miniconda3\\envs\\fastai\\lib\\site-packages\\kaggle\\__init__.py\nSource:     \n#!/usr/bin/python\n#\n# Copyright 2024 Kaggle Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# coding=utf-8\nfrom __future__ import absolute_import\nfrom kaggle.api.kaggle_api_extended import KaggleApi\nfrom kaggle.api_client import ApiClient\n\napi = KaggleApi(ApiClient())\napi.authenticate()"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html",
    "href": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 1)",
    "section": "",
    "text": "A neural network is a mathematical function. So what’s that?\nA function is a mapping or transformation where each unique set of inputs is equal to exactly one output.\nIn highschool, the Vertical Line Test was used to determine whether a line was a function.\nThis post will go through basics of how to fit a line to some data."
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "href": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 1)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "href": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "title": "Neural Network Basics (Part 1)",
    "section": "2. Upload and Plot Data",
    "text": "2. Upload and Plot Data\n\ndf = pd.read_csv(\"upload_dataset.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2.000000\n11.869037\n\n\n1\n-1.789474\n6.543284\n\n\n2\n-1.578947\n5.939607\n\n\n3\n-1.368421\n2.630370\n\n\n4\n-1.157895\n1.794741\n\n\n\n\n\n\n\n\nplt.scatter(df.x, df.y)"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "href": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "title": "Neural Network Basics (Part 1)",
    "section": "3. Quadratic Equation",
    "text": "3. Quadratic Equation\n\n3.1 General Quadratic Equation\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\n\n\n\n3.2 Custom Quadratric Equation\n\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\n\n\n\n3.3 Creating \\(1x^2 + 1x + 1\\)\n\nquad_111 = custom_quad_fn(1,1,1)\n\n\n\n3.4 Plotting \\(1x^2 + 1x + 1\\)\n\nxs_111 = df.x\nys_111 = quad_111(xs_111)\nplt.plot(xs_111,ys_111)\nplt.scatter(df.x, df.y)\n\n\n\n\n\n\n\n\n\n\n3.4 Interactive Quadratic Equation\nThe coefficients a, b and c of the Quadratic Function can be adjusted which in turn changes the shape of the line.\n[Future Iteration]: Figure out how to embed this adjustable plot into quarto blog\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot(a,b,c):\n# 1. plot scatter\n    plt.scatter(df.x, df.y)    \n# 2. create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n# 3. plot custom_quad_interactive\n    plt.ylim(-1,15)\n    plt.plot(xs_interact, custom_quad_fn(a,b,c)(xs_interact))\n\n\n\n\n\n\n\n3.5 Mean Absolute Errors (MAE)\nBy calculating a Loss Function such as Mean Absolute Errors, we can numerically determine what is the ‘best’ fit of our line to the data.\nSure it isn’t entirely scientific to adjust it manually but its a good starting point.\n\ndef mae(prediction, actual): return np.mean(abs(prediction-actual))\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot2(a,b,c):\n# 1.    plot scatter\n    plt.scatter(df.x, df.y)\n\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n\n# 4.    calc mae\n    y_actual     = df.y\n    y_predicted  = custom_quad_fn(a,b,c)(df.x)\n    interact_mae = round(mae(y_actual, y_predicted),3)\n\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae}\")"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "href": "posts/datascience/machinelearning/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nThe next section go through a more automated method to find the smallest MAE.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-01-16-99_welcome/index.html",
    "href": "posts/datascience/machinelearning/2024-01-16-99_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nDefault Quarto content:\n“Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.””"
  },
  {
    "objectID": "posts/datascience/machinelearning/2024-04-27-feature_importance_plot/index.html",
    "href": "posts/datascience/machinelearning/2024-04-27-feature_importance_plot/index.html",
    "title": "Random Forests - Feature Importance Plot (Part 4)",
    "section": "",
    "text": "1. Introduction\nIn Part 1, a simple model was built using single binary split called OneR Classifier.\nIn Part 2, sklearn DecisionTreeClassifier framework was used and by setting a sample limit per node, loss was reduced.\nIn Part 3, we used the concept of bagging by averaging predictions from many big trees to create a random forest.\nToday, we’ll create a Feature Importance Plot very easily and quickly.\nIn the next post I’ll go into:\n\nGradient Boosting (sum of trees ) Decision Tree or Machines (GBMs)\n\n\n\n2. Training and Validation Sets\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n\n\n\n\n3. Build Decision Tree Classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtc_min50 = DecisionTreeClassifier(min_samples_leaf=50)\n\n\n\n4. Fit Decision Tree to our Training Data\n\ndtc_min50.fit(trn_idep, trn_dep)\n\nDecisionTreeClassifier(min_samples_leaf=50)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(min_samples_leaf=50) \n\n\n\n\n5. Create Feature Importance Plot\n\npd.DataFrame(dict(cols=trn_idep.columns, imp=dtc_min50.feature_importances_)).plot('cols', 'imp', 'barh')\n\n\n\n\n\n\n\n\n\n\n6. Completed\nAs expected, Sex and Pclass are the most important features to survivability on the Titanic."
  },
  {
    "objectID": "kaggle.html",
    "href": "kaggle.html",
    "title": "Kaggle 🧪",
    "section": "",
    "text": "KAGG 2: A Basic NLP model - [Competition Version]\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nKAGG 1: A Basic NLP model\n\n\n\n\n\n\nkaggle\n\n\ndatascience\n\n\nnlp\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "linearalgebra.html",
    "href": "linearalgebra.html",
    "title": "Linear Algebra 🧮",
    "section": "",
    "text": "LA 6: More Eigen examples\n\n\n\n\n\n\nlinearalgebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 4: Diagonal Matrices are trivial\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 5: It’s nice to be similar (matrices)\n\n\n\n\n\n\nlinearalgebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 3: Eigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinearalgebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 2: Eigen is my valentines in 2024\n\n\n\n\n\n\nlinearalgebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLA 1: Change of Basis\n\n\n\n\n\n\nlinearalgebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "leetcode.html",
    "href": "leetcode.html",
    "title": "LeetCode 💻",
    "section": "",
    "text": "LeetCode 5: 49 - Group Anagrams\n\n\n\n\n\n\nleetcode\n\n\n\nGroup Anagrams\n\n\n\n\n\nJan 13, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 4: 74 - Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 3: 704 - Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 2: 150 - Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLeetCode 1: 155 - Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  }
]