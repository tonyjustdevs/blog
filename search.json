[
  {
    "objectID": "leetcode.html",
    "href": "leetcode.html",
    "title": "leetcode",
    "section": "",
    "text": "LC: 74. Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 704. Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 150. Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 155. Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/notes/calculus/Ch3-1-Ex-17.html",
    "href": "posts/notes/calculus/Ch3-1-Ex-17.html",
    "title": "Calculus: Find A Derivative And Tangent",
    "section": "",
    "text": "1. Question\nAssume:\n\n\\(f(x)=\\sqrt{x}\\)\n\nAt \\((4,2)\\), Find:\n\n\\(f'(x)\\)\n\\(Tangent\\)\n\n\n\n2. Working-Out (Hand-written)\n\n\n\n3. Charts (Python)\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nx_at_c = 4\nx_deviation = 2\nx_increments = 21\nxs_min = x_at_c-x_deviation\nxs_max = x_at_c+x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)\n\n# # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 0]\nxs = xs[xs &gt;= 0]\n\nlbl_numerator = r'$f(x)=\\sqrt{x}$'\nfx_numerator = lambda x: np.sqrt(x)\nys_numerator = fx_numerator(xs)\n\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\nlbl_tangent = r'$f(x)=\\frac{x}{4}+1$ (tangent) '\nfx_tangent = lambda x: x/4+1\nys_tangent = fx_tangent(xs)\n\n\n# plot_title = lbl_numerator + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\nplot_title = lbl_numerator + \" and \" + lbl_tangent + \"at (4,2)\"\n\nplt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=6, label=lbl_numerator)\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.plot(xs, ys_tangent,      'bo-', linewidth=2, markersize=6, label=lbl_tangent)\nplt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.scatter(xs, ys, marker=\"o\")\n\n# zoom and enhance!\n# plt.xlim(3.5, 4.5)  # X-axis range\n# plt.ylim(1.8, 2.2)  # Y-axis range\n# plt.xlim(-0.1, 0.1)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(plot_title, loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=4, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=2, color='grey', linestyle='--', linewidth=0.5)\n\n# # X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# # plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# # OTHER\n# # # b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# # plt.ylim(bottom=0)  # chart starts from y=0\n# # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# # ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n\n\n\n\n\n\n\n# ##################### FINAL FUNCTION ##################### \n# x_at_c = 3\n# x_deviation = 3\n# x_increments = 51\n# xs_min = x_at_c-x_deviation\n# xs_max = x_at_c+x_deviation\n# xs = np.linspace(xs_min, xs_max, x_increments)\n\n# # # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 2]\n\n# # lbl_numerator = r'$f(x)=x$'\n# # fx_numerator = lambda x: x\n# # ys_numerator = fx_numerator(xs)\n\n# # lbl_denom = r'$f(x)=x-2$'\n# # fx_denom = lambda x: x-2\n# # ys_denom = fx_denom(xs)\n\n# lbl_fx = r'$f(x)=\\frac{x}{x-2}$'\n# fx_fx = lambda x: (x)/(x-2)\n# ys_fx = fx_fx(xs)\n\n# # plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_fx\n\n# # plt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=8, label=lbl_numerator)\n# # plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\n# plt.scatter(xs, ys_fx, marker=\"o\", label=lbl_fx)\n\n# # zoom and enhance!\n# # plt.xlim(-5, 1)  # X-axis range\n# plt.ylim(-8,8)  # Y-axis range\n# plt.xlim(-2, 7)  # X-axis range\n# # plt.ylim(-3.1, 3.1)  # Y-axis range\n\n# # Add grid, title, and legend\n# plt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n# plt.title(plot_title, loc='left')\n# # plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\n\n# # Optionally, add vertical and horizontal lines to highlight the zoomed area\n# ax = plt.gca()  # Get the current axis\n# ax.axvline(x=3, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=3, color='grey', linestyle='--', linewidth=0.5)"
  },
  {
    "objectID": "posts/notes/calculus/Ch3-1-Ex-23.html",
    "href": "posts/notes/calculus/Ch3-1-Ex-23.html",
    "title": "Calculus: Find A Derivative And Tangent",
    "section": "",
    "text": "\\(f(x)=6t^2-9.28t+16.43\\)\n\n\nFind \\(f'(t)\\) at \\(t=5\\)\n\n\n1. Working-Out (Hand-written)\n\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nxpt = 5\nx_deviation = 2\nx_increments = 21\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\nxs = np.linspace(xs_min, xs_max, x_increments)  # XS\n# # X-EXCLUDE LIMIT VALUE\n# xs = xs[xs != 1]\n# xs = xs[xs &gt;= 0]\n\nlbl_numerator = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\nfx_numerator = lambda x: 6.1*(x**2)-9.28*x+16.43   # F(X)\nys_numerator = fx_numerator(xs)             # YS = F(XS) \nypt_fx = fx_numerator(xpt)\nprint(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n# lbl_denom = r'$f(x)=x-2$'\n# fx_denom = lambda x: x-2\n# ys_denom = fx_denom(xs)\n\nlbl_dydx = r\"$f'(x)=6.10*(2t)-9.28$ (dydx or slope fn)\"\nfx_dydx = lambda x: 6.1*(2*x)-9.28\nxpt_dydx = xpt\ndydx = fx_dydx(xpt_dydx)\nprint(f\"ypt_dydx_at_P(x={xpt_dydx}): {dydx}\")\n\nc_tangent = ypt_fx-(dydx)*(xpt)\ntgt = \"tangent\"\nlbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_tangent:,.1f}$ (tangent at t={xpt})'\nfx_tangent = lambda x: dydx*xs+c_tangent\nys_tangent = fx_tangent(xs)\n\n\nplot_title = lbl_numerator + f\" & it's tangent at t={xpt}\"\n# plot_title = lbl_numerator + \"at (4,2)\"\n# plot_title = lbl_denom + \" and \" + lbl_denom + \"at (3,3)\"\n# plot_title = lbl_numerator + \" and \" + lbl_tangent + \"at (4,2)\"\n\nplt.plot(xs, ys_numerator,  'r^-', linewidth=2, markersize=6, label=lbl_numerator)\n# plt.scatter(xs, ys_numerator, marker=\"o\")\n# plt.plot(xs, ys_denom,      'bo-', linewidth=2, markersize=8, label=lbl_denom)\nplt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n\n# zoom and enhance!\nplt.xlim(xpt-5,xpt+5)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(plot_title, loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\n# plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=fx_numerator(xpt), color='grey', linestyle='--', linewidth=0.5)\n\nplt.scatter(x=xpt, y=fx_numerator(xpt), marker=\"o\")\n# print(fx_numerator(5))\n\nypt_fx_at_P(x=5): 122.53\nypt_dydx_at_P(x=5): 51.72\n\n\n\n\n\n\n\n\n\n\n# # X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\n# # plt.plot(x_at_c, 0.5,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# # OTHER\n# # # b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# # plt.ylim(bottom=0)  # chart starts from y=0\n# # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.000025)) # minor ticks\n# # ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html"
  },
  {
    "objectID": "posts/notes/coding/8-quarto_on_wsl.html",
    "href": "posts/notes/coding/8-quarto_on_wsl.html",
    "title": "How to install Quarto via WSL",
    "section": "",
    "text": "How to install Quarto on WSL (Ubuntu)\n\nCheck you are indeed on ubuntu (Note: All commands in [Windows Terminal] -&gt; [Ubuntu distro]):\n\nlsb_release -a :\n\n\nGo to official site and get copy Ubuntu link:\n\nofficial quarto download site\n\nCreate (or navigate to) Downloads folder:\n\nmkdir downloads && cd downloads\n\nDownload Official Quarto Deb file (your official link from above dotpoint is newer, use that!):\n\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.5.57/quarto-1.5.57-linux-amd64.deb:\n\nInstall:\n\nsudo dpkg -i quarto-1.5.57-linux-amd64.deb\n\nTest it (prints version to terminal):\n\nquarto version"
  },
  {
    "objectID": "posts/notes/coding/27-singleton-pattern.html",
    "href": "posts/notes/coding/27-singleton-pattern.html",
    "title": "Singleton Pattern",
    "section": "",
    "text": "1. Create Singleton Class\nSingleton pattern creates a metaclass that limits the number of instance of a particular class to 1\nMetaclasses allow the customisation of object instantiation (see metaclasses post)\n\n__call__ method is overriden (see: call-magic-method post)\nself._instances list: keeps track of existence of instance\nid(cls._instances[cls]): allows us compare object instances\n\n\nclass SingleTonyCls(type):\n    _instances = {}\n    \n    def __call__(cls, *args, **kwds):\n        if cls not in cls._instances:\n            print(f\"{cls} does not exist! Creating new... \")\n            object_instance = super().__call__(*args, **kwds)\n            cls._instances[cls] = object_instance\n            print(f\"[{id(object_instance)}] added to {cls} list\")\n            # print(f\"[__name__]: {__name__}\") -- main file\n            # print(f\"[cls]: {cls}\") --  class name\n            # print(f\"[__class__]: {__class__}\") metaclass name\n        else:\n            print(f\"{cls} exists: [{id(cls._instances[cls])}] \")\n        return cls._instances[cls]\n\n\n\n2. Create Classes: Singleton\nThere should only be a single instances of any class that has metaclass following the singleton pattern.\nAll objects have the same id.\n\nclass FooSGL(metaclass = SingleTonyCls):\n    pass\n\n\n\n3. Create Classes: Regular Way\nThere is no limit to unique instances created.\nEach object should have a unique id.\n\nclass Foo():\n    pass\n\n\n\n4. Compare Object IDs: Singleton vs Regular Way\n\n\n4.1 Create Multiple Objects: Singleton\n\nfoo_sgl_a = FooSGL()\nfoo_sgl_b = FooSGL()\nfoo_sgl_c = FooSGL()\n\n&lt;class '__main__.FooSGL'&gt; does not exist! Creating new... \n[139808669538272] added to &lt;class '__main__.FooSGL'&gt; list\n&lt;class '__main__.FooSGL'&gt; exists: [139808669538272] \n&lt;class '__main__.FooSGL'&gt; exists: [139808669538272] \n\n\n\n\n4.2 Compare Object IDs: Singleton\nEach instantiation results in the returning of the first created object evidenced by the same object id\n\nprint(id(foo_sgl_a))\nprint(id(foo_sgl_b))\nprint(id(foo_sgl_c))\n\n139808669538272\n139808669538272\n139808669538272\n\n\n\n\n4.3 Create Multiple Objects: Regular Way\n\nfoo_a = Foo()\nfoo_b = Foo()\nfoo_c = Foo()\n\n\n\n4.4 Compare Object IDs: Regular Way\nEach instantiation results in a unique object id\n\nprint(id(foo_a))\nprint(id(foo_b))\nprint(id(foo_c))\n\n139808669355984\n139808669358432\n139808669357808"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#introduction",
    "href": "posts/notes/coding/2-linux_setup.html#introduction",
    "title": "Setting up a Data Science Machine",
    "section": "1. Introduction",
    "text": "1. Introduction\nThis post shows how to set up Linux-based Python Notebooks on a Windows PC for Data Science and Deep Learning Projects.\nOne of the drawbacks of Python-based Projects are compatability issues with packages which were developed with Linux.\nLinux is often preferred for Python development due to its:\n- powerful terminal for scripting and automation\n- has a open-source philosophy fostering community-driven ecosystem\n- containerization (e.g. Docker) and orchestration (e.g. Kubernetes)\n- Has a robust package management (APT and YUM)\n- Resource efficiency suitable for running Python applications (in resource-constrained environments)\n- compatibility with production environments & real-world deployments"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#linux",
    "href": "posts/notes/coding/2-linux_setup.html#linux",
    "title": "Setting up a Data Science Machine",
    "section": "2. Linux",
    "text": "2. Linux\n\n2.1 Install Linux\nI had previously blindly installed Linux, officially named “Windows Subsystem for Linux (wsl)” and then never used it again.\nI’ll firstly uninstall the existing distribution, then install a fresh copy.\n\nCheck any existing installation: wsl -l\nIf exists, uninstall: wsl --unregister Ubuntu\nRun 1. again wsl - l\nInstall Linux wsl --install\nCreate username\nCreate passwword\n\n\nwsl -l # Run in Windows Powershell \nwsl --unregister Ubuntu # Unregister if exists\nwsl -l\nwsl --install # Install wsl\n\n\n\n\n2.2 Linux Basics\n\nUsername: whoami\nSwitch user (from admin): sudo -u user_name -i\nSwitch user (user login): su - username\nWorking directory: pwd\nMove to folder in current directory : cd /\nHome: echo $HOME\nMove to root : cd /\nMove up 1-level: cd ..\nList all in folder: ls\nMove up a level: cd ..\nPrivledges: sudo id\nCreate user: sudo adduser new_user_name\nList usernames: cut -d: -f1 /etc/passwd\nGrant “bob” permission to install a pkg:: sudo -u bob apt install pkg-name\nDownload url: wget url\nRemove: rm folder\nRemove forcefully : rm -rf folder\nMove folder: mv folder_from folder_to\nList human readable: ls -lh\nList all includes hidden: la -a\nList with permissions: ls -l\nAdd permissions to file: chmod u+x theshell.sh\nA Shell script: .sh\nRead .sh script: less scriptname.sh\nRun .sh with Bash: bash scriptname.sh\nRun .sh with Bash accept all licenses: bash scriptname.sh -b\nRun .sh with pattern with Bash: bash Miniforge3-*.sh -b\nAutomatically runs when Terminal starts: .bashrc\nEdit a script: vim .bashrc\nBash history: cat .bash_history\nSearch Bash history: ctrl r + word\nRun last command starting with: !ju (runs jupyter if you’ve previously run it)\nRerun last command: !!\nMove to start of line: ctrl+a\nMove to end of line: ctrl+e\nMove by word: alt+l, alt+r\nCreate alias: alias jl = \"jupyter lab --no-browser\"\n[vim] - enter normal mode: Esc key\n[vim] - move to front: gg\n[vim] - move to end: G\n[vim] - highlight to end: V(visual mode) G (move to end)\n[vim] - move along word: h,j,k,l,w,b,e,0\n[vim] - move along line: 0,$,^\n[vim] - move along screen: H,M,L\n[vim] - move along pages: ctrl + f,b,d,u\n[vim] - move line: zt,zz,zb\n[vim] - search: /pattern,?pattern,n,N\n[vim] - move line nbr: :[line number]\n[vim] - make changes / insert mode: i then esc\n[vim] - save changes: :w\n[vim] - quit: :q\n[vim] - quit and discard changes: :q!\n[vim] - help: self-explanatory\n[tmux] - split-right: ctrl-b %\n[tmux] - split-down: ctrl-b \"\n[tmux] - move: ctrl-b arrows\n[tmux] - detach: ctrl-b d\n[tmux] - attach: tmux a"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#python",
    "href": "posts/notes/coding/2-linux_setup.html#python",
    "title": "Setting up a Data Science Machine",
    "section": "3. Python",
    "text": "3. Python\nThere are several options for building linux python projects:\n\nConda: For extensive package management and control or flexibility beyond deep learning/data science.\nMiniforge: For lightweight and focused option for deep learning/data science projects.\nAnaconda: For a convenient, pre-configured environment for data science and deep learning, but be mindful of its larger size.\n\nFor my purposes, I’d like to be focused on deep learning / data science projects hence I’ll install Miniforge.\nSee miniforge github\n\n3.1 Miniforge\nMiniforge offers a powerful and user-friendly environment management platform for data science and deep learning.\nSeveral reasons to use Miniforge:\n- Virtual environments: Isolate projects and manage dependencies.\n- Pre-built environments: Quickly set up optimized environments (TensorFlow, PyTorch, etc.).\n- Cross-platform compatibility: Works on Windows, macOS, and Linux.\n- Large community and support: Extensive resources and active development.\n- Performance and efficiency: Caching and optimized packages.\n- Free and open-source: No licensing costs or limitations.\n\n\n3.2 Get Miniforge download link\n\nGet amd64 (Windows) download link from Miniforge Github\nDownload link used: “https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh”\n\n\n\n\n3.3 Install Miniforge in Ubuntu\n\nOpen Windows Terminal (this should automatically open Ubuntu now)\nGo to Home directory (echo $HOME) :\n\nLogging in su - username or\nMoving up cd .. and down cd folder_name_in_curr_dir\n\nGo to your home/directory: echo $HOME\nCreate a new working directory: mkdir downloads\nMove to downloads folder: cd downloads\n\nThis folder should be empty, and your Ubuntu should be not found with these keywords: Python, Jupyter, ipython etc.\nIf they are found:\n\nUninstall: pip install ipython,\nDelete: rm -rf ipython or rm usr/bin/jyp or\nMove: mv folder_from folder_to\n\n\nDownload url: wget the_copied_url_link_from_github_above or\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n\n\n\n3.4 Run downloaded Miniforge shell script\n\n[Manual Method]:\n\nAccept All Permissions (Creates environment variables so that keywords like ‘conda’ works and automatically runs Conda when Terminal is first logged on and activates a base environment. This automation is done by editting the .bashrc file.) or\n\n[Script Method]:\n\nbash Miniforge3-*.sh -b and then\n~/miniforge3/bin/conda init bash. This runs python file conda.py within miniforge which runs another file that creates the Conda Paths and Adding Paths to Ubuntu Environment variables (same as accepting all permissions in manual method)\n\n\nThere should be two folders: downloads and miniforge3 in the Home directory (Ignore nbs, this is created later)"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#conda",
    "href": "posts/notes/coding/2-linux_setup.html#conda",
    "title": "Setting up a Data Science Machine",
    "section": "4. Conda",
    "text": "4. Conda\nPython should be now installed via miniforge3:\n- which python should be running from miniforge3 folder within your Home directory.\n- If not, something went wrong!\n\n\n4.1 Conda basics\n\nShow conda arguments: conda\n\nGeneral system info: conda info\n\nShow environments: conda env\n\nCreate new environment: conda create -n deep_learning\n\nActivate environment: conda activate deep_learning\n\nShow installed packages: conda list\n\nInstall a package: conda install package_name\n\n\n\n4.2 Install Pytorch\nGo to Official Website and choose accordingly and install\nI used conda install pytorch torchvision torchaudio cpuonly -c pytorch\nNotes: Following the website ensures all binary dependencies are install, simply typing pip install pytorch wont work as normally due to requiring to also needing to installing CUDA SDK (if you have a NVidia GPU)\n\n\n\n4.3 Checking Pytorch is working\n\nHave Ipython installed and ipython\nimport torch\ntorch. + *tab* button This should display a list of available pytorch methods.\nctrl_d to exit"
  },
  {
    "objectID": "posts/notes/coding/2-linux_setup.html#jupyter-notebooks",
    "href": "posts/notes/coding/2-linux_setup.html#jupyter-notebooks",
    "title": "Setting up a Data Science Machine",
    "section": "5. Jupyter Notebooks",
    "text": "5. Jupyter Notebooks\nInstall Jupyter Lab to have suite of notebooks and other useful tools for testing and developing data science and deep learning projects.\n\n5.1 Install Jupyter Lab\nGo to Official Website and select appropriate install option I used conda install -c conda-forge jupyterlab.\n\n\n\n5.2 Run Jupyter Lab\n\nRun Jupyter: jupyter lab or\nRun Jupyter: jupyter lab --no-browser (avoids attempting to open a browser in linux because it cant)\n\n\n\n\n5.3 Automate Alias\nSave alias jl=\"jupyter lab --no-browser\" into .bashrc to jl works everytime:\n\nOpen bashrc: vim ~/.bashrc\nGo to End: G\nPaste: alias jl=\"jupyter lab --no-browser\nSave: :qw: (quit q and save w)\n\n\n\n\n5.4 Open in Browser\n\nOpen in Browser by [Control+Click] the link\n\n\n\n\n5.5 Save First Notebook in Linux\nTry out PyTorch in the Notebook and save it."
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#download-and-install-uv",
    "href": "posts/notes/coding/21-uv-package.html#download-and-install-uv",
    "title": "uv Python & Package Manager",
    "section": "1.1 Download and Install uv",
    "text": "1.1 Download and Install uv\n\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nmkdir NameOfNewProject && cd $_"
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#create-project",
    "href": "posts/notes/coding/21-uv-package.html#create-project",
    "title": "uv Python & Package Manager",
    "section": "1.2 Create Project",
    "text": "1.2 Create Project\n\nuv init"
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#check-project-initialisations",
    "href": "posts/notes/coding/21-uv-package.html#check-project-initialisations",
    "title": "uv Python & Package Manager",
    "section": "1.3 Check Project Initialisations",
    "text": "1.3 Check Project Initialisations\nInside pyproject.toml:\n\nrequires-python = \"&gt;=3.13\"\ndependencies = []\n\nThese can be updated later."
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#check-python-version",
    "href": "posts/notes/coding/21-uv-package.html#check-python-version",
    "title": "uv Python & Package Manager",
    "section": "1.4 Check Python Version",
    "text": "1.4 Check Python Version\n\nuv run python --version\n\nThe first time uv run is executed, two files are created:\n\n.venv and\nuv.lock\n\nResponsible for keeping track of python package dependencies and versions."
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#add-a-project-dependency-via-terminal",
    "href": "posts/notes/coding/21-uv-package.html#add-a-project-dependency-via-terminal",
    "title": "uv Python & Package Manager",
    "section": "2.1 Add a project dependency via terminal",
    "text": "2.1 Add a project dependency via terminal\n\nuv add typer\n\nAdds typer to dependencies list in .toml file and resolves all dependencies."
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#add-dev-dependency-via-terminal",
    "href": "posts/notes/coding/21-uv-package.html#add-dev-dependency-via-terminal",
    "title": "uv Python & Package Manager",
    "section": "2.2 Add dev-dependency via terminal",
    "text": "2.2 Add dev-dependency via terminal\n\nuv add pytest --dev\n\nAdds pytest to dev dependencies list in .toml file and resolves all dependencies."
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#create-test-folder-file",
    "href": "posts/notes/coding/21-uv-package.html#create-test-folder-file",
    "title": "uv Python & Package Manager",
    "section": "3.1 Create Test Folder & File",
    "text": "3.1 Create Test Folder & File\n\ncode tests/test_main.py\n\n\ndef test_main(): assert True"
  },
  {
    "objectID": "posts/notes/coding/21-uv-package.html#run-test",
    "href": "posts/notes/coding/21-uv-package.html#run-test",
    "title": "uv Python & Package Manager",
    "section": "3.2 Run Test",
    "text": "3.2 Run Test\n\nuv run pytest\n\nNote: I wrote the equivalent thing but in bash\n\n\n[TBA] Updating Python versions\n\n\n[TBA] Updating Redudencies .toml\n\n\n\n\n\n\n[TBA] DEV DEP VIA UVX OR UV TOOL RUN\n\n\n\n[TBA] ADD COMPLEX PKGS"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#function-class-vs-method-class",
    "href": "posts/notes/coding/14-python-classes-101.html#function-class-vs-method-class",
    "title": "Python Classes Basics 101",
    "section": "2.1 function class vs method class:",
    "text": "2.1 function class vs method class:\nA function becomes a method when the function is accessed via an object instance (see examples)"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#function-and-integer-class",
    "href": "posts/notes/coding/14-python-classes-101.html#function-and-integer-class",
    "title": "Python Classes Basics 101",
    "section": "2.2 function and integer class:",
    "text": "2.2 function and integer class:\nThese two classes remain as is when declared within a Class. - Wheter standalone or - A Class attribute (e.g. ClassName.function).\n\ninteger remains as is as Object Instance attribute too."
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#class-and-instance-attributes-examples",
    "href": "posts/notes/coding/14-python-classes-101.html#class-and-instance-attributes-examples",
    "title": "Python Classes Basics 101",
    "section": "2.3 Class and Instance Attributes Examples",
    "text": "2.3 Class and Instance Attributes Examples\n\ndelim = \": \"\n\nline0=\"type(MyClass.i)\" + delim\nline0val=type(MyClass.i)\n\nline1=\"type(MyClass.f)\" + delim\nline1val=type(MyClass.f)\n\nline2=\"type(temp_fn)\" + delim\nline2val=type(temp_fn)\n\nline3=\"type(instance_object.f)\" + delim\nline3val=type(instance_object.f)\n\nline4=\"type(instance_object.i)\" + delim\nline4val=type(instance_object.i)\n\nprint(f\"{line0:&lt;25}{str(line0val)}\") # experimenting new way to print()\nprint(f\"{line1:&lt;25}{str(line1val)}\")\nprint(f\"{line2:&lt;25}{str(line2val)}\")\nprint(f\"{line3:&lt;25}{str(line3val)}\")\nprint(f\"{line4:&lt;25}{str(line4val)}\")\n\ntype(MyClass.i):         &lt;class 'int'&gt;\ntype(MyClass.f):         &lt;class 'function'&gt;\ntype(temp_fn):           &lt;class 'function'&gt;\ntype(instance_object.f): &lt;class 'method'&gt;\ntype(instance_object.i): &lt;class 'int'&gt;"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#data-attributes",
    "href": "posts/notes/coding/14-python-classes-101.html#data-attributes",
    "title": "Python Classes Basics 101",
    "section": "3.1 Data Attributes",
    "text": "3.1 Data Attributes\n\nNeed not be declared\ndata members in C++\nspring into existence when first assigned"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#example",
    "href": "posts/notes/coding/14-python-classes-101.html#example",
    "title": "Python Classes Basics 101",
    "section": "3.1.1 Example",
    "text": "3.1.1 Example\nBelow counter is data_attribute of the object instance_object (which is of type MyClass).\ncounters value 16 is printed, then deleted without leaving a trace:\n\nprint(type(instance_object))  \n\ninstance_object.counter = 1\n\nprint(type(instance_object.counter))  \n\nwhile instance_object.counter &lt; 10:\n    instance_object.counter = instance_object.counter * 2\nprint(instance_object.counter)\ndel instance_object.counter\n\nprint(type(instance_object.counter))  \n\n&lt;class '__main__.MyClass'&gt;\n&lt;class 'int'&gt;\n16\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 12\n      9 print(instance_object.counter)\n     10 del instance_object.counter\n---&gt; 12 print(type(instance_object.counter))  \n\nAttributeError: 'MyClass' object has no attribute 'counter'"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#assign-a-method-object",
    "href": "posts/notes/coding/14-python-classes-101.html#assign-a-method-object",
    "title": "Python Classes Basics 101",
    "section": "4.1 Assign a Method Object",
    "text": "4.1 Assign a Method Object\n\n# assign method object\nxf = instance_object.f\nxf\n\n&lt;bound method MyClass.f of &lt;__main__.MyClass object at 0x7fc46c36b8b0&gt;&gt;"
  },
  {
    "objectID": "posts/notes/coding/14-python-classes-101.html#call-the-method-oject",
    "href": "posts/notes/coding/14-python-classes-101.html#call-the-method-oject",
    "title": "Python Classes Basics 101",
    "section": "4.2 Call the Method Oject",
    "text": "4.2 Call the Method Oject\n\nxf()\n\n'hello world'"
  },
  {
    "objectID": "posts/notes/coding/6-measuring_accuracy.html",
    "href": "posts/notes/coding/6-measuring_accuracy.html",
    "title": "Measuring Model Accuracy",
    "section": "",
    "text": "1. Methodology\n\nCalculate Predictions with our model Coefficients with our Independent Variables (Validation Set).\n\nExpected output: Float Values (between 0 and 1).\n\nConvert Predictions to True if above 0.5 otherwise False.\n\nExpected output: Boolean Values (True and False).\n\nCompare Booled Predictions to Dependent Variables (Validation Set)\n\nExpected output: Boolean Values (True and False).\n\n\nConvert the Boolean values to Float.\n\nExpected output: Integer Values (1s and 0s).\n\nCalculate Mean of the floated values.\n\nExpected output: Single Float Value (between 0 and 1)\n\n\n\n\n2. Run Deep-Learning Model and Get Coefficients\nSee previous blog post for model and code explanation.\n\nimport kaggle, zipfile\nfrom pathlib import Path\nimport torch, numpy as np, pandas as pd\nfrom fastai.data.transforms import RandomSplitter\nimport torch.nn.functional as F\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} already exists, using this folder...\")\n!ls {path}\ndf = pd.read_csv(path/\"train.csv\")\ndef df_1_fillna_inplace(df):\n    modes = df.mode(axis=0).iloc[0] # get modes\n    df.fillna(modes, inplace=True)  # replace nas with mode per col\ndef df_2_log_numeric_data_addlogfare(df): df['LogFare'] = np.log1p(df['Fare'])\ndef df_3_create_dummy_variables_add(df):\n    return pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=int)\ndef df_clean(df):\n    df_1_fillna_inplace(df)\n    df_2_log_numeric_data_addlogfare(df)\n    return df_3_create_dummy_variables_add(df)\n\ndef get_idep_and_dep_from_df(df):\n    def normalise_idep_by_max(idep):\n        maxes, _ = idep.max(axis=0) # get max of each column\n        return idep / maxes \n    \n    added_cols          = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n    indep_cols          = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n    idep                = torch.tensor(df[indep_cols].values, dtype=torch.float)\n    idep                = normalise_idep_by_max(idep)\n    dep                 = torch.tensor(df[\"Survived\"])\n    return idep, dep\n\ndef get_trn_val_idep_dep(idep, dep):     \n    trn_idx, val_idx            = RandomSplitter(seed=42)(idep)\n    trn_dep_mx0,  val_dep_mx0   = dep[trn_idx], dep[val_idx] # 1-dimension i.e. cant matrix multiply \n    trn_idep_mxn, val_idep_mxn  = idep[trn_idx], idep[val_idx] \n    trn_dep_mx1                 = trn_dep_mx0[:,None] # add extra dimention for matrix multiply\n    val_dep_mx1                 = val_dep_mx0[:,None]\n    return trn_idep_mxn, val_idep_mxn, trn_dep_mx1, val_dep_mx1 \ndf = df_clean(df)\nidep, dep = get_idep_and_dep_from_df(df)\ntrn_idep_mxn, val_idep_mxn, trn_dep_mx1, val_dep_mx1 = get_trn_val_idep_dep(idep, dep)\ndef init_coeffs():\n    n_coeffs    = trn_idep_mxn.shape[1] # 12\n    hidden_layers = [10,10]\n    sizes = [n_coeffs] + hidden_layers + [1]    # [12,10,10,1]\n    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(len(sizes)-1)]   # 0,1,2\n    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(len(sizes)-1)]   # [0,1,2]\n    for layer in layers+consts:\n        layer.requires_grad_()\n    return layers, consts\ndef calc_preds_deeplearning(trn_idep_mxn, coeffs):    \n    layers, consts = coeffs\n    n = len(layers)\n    res = trn_idep_mxn\n    for i in range(n):\n        res = res@layers[i] + consts[i] # [mxn]@[nxq]  [713x12][12x10]\n        if i!=n-1: \n            res = F.relu(res) \n    sgm_preds_mx1 = torch.sigmoid(res)\n    return sgm_preds_mx1\ndef calc_loss(idep_mxn, dep_mx1, coeffs):\n    preds_mx1 = calc_preds_deeplearning(idep_mxn, coeffs)\n    return torch.abs(dep_mx1-preds_mx1).mean()\ndef update_coeffs(coeffs, lr):\n    layers, consts = coeffs\n    for layer in layers+consts:\n        layer.sub_(layer.grad*lr)\n        layer.grad.zero_()\ndef one_epoch(coeffs,lr):\n    loss = calc_loss(trn_idep_mxn, trn_dep_mx1, coeffs)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:.3f}\",end=';')\ndef train_model(n_epochs=30,lr=0.1):\n    torch.manual_seed(442)\n    coeffs = init_coeffs()\n    for _ in range(n_epochs):\n        one_epoch(coeffs,lr)\n    return coeffs\ncoeffs = train_model(lr=4)\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n0.521;0.483;0.427;0.379;0.379;0.379;0.379;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.377;0.376;0.371;0.333;0.239;0.224;0.208;0.204;0.203;0.203;0.207;0.197;0.196;0.195;\n\n\n\n\n3. Accuracy Function\n\ndef calculate_accuracy_deepelearning(val_idep_mxn, coeffs):\n    val_preds_mx1               = calc_preds_deeplearning(val_idep_mxn, coeffs)     # 1.\n    bool_preds_mx1              = val_preds_mx1&gt;0.5                                 # 2. \n    comp_dep_vs_preds_val_mx1   = (val_dep_mx1==bool_preds_mx1)                     # 3.\n    float_comp_mx1              = comp_dep_vs_preds_val_mx1.float()                 # 4.   \n    accuracy_mx1                = float_comp_mx1.mean()                             # 5. \n    return accuracy_mx1\n\ncalculate_accuracy_deepelearning(val_idep_mxn, coeffs)\n\ntensor(0.8258)"
  },
  {
    "objectID": "posts/notes/coding/25-call-magic-method.html",
    "href": "posts/notes/coding/25-call-magic-method.html",
    "title": "Magic Method: __call__",
    "section": "",
    "text": "1. Create Tony_Counter Class\n\nInstance attribute .counter defaulted to zero.\nInstance method increment() increases .counter attribute by 1\nMagic Method __call__() calls instance method increment():\nIn other words, when an instance calls itself with (), the instance.__call__() will be called:\n\nIn this case incrementing .counter by 1 each time.\n\n\n\nclass Tony_Counter():\n    def __init__(self):\n        self.counter: int = 0\n        \n    def increment(self):\n        self.counter += 1\n        \n    def __call__(self):\n        self.increment() \n\n\nctr = Tony_Counter()\nprint(ctr.counter)\n\n0\n\n\n\nctr.increment()\nprint(ctr.counter)\n\n1\n\n\n\nctr.increment()\nprint(ctr.counter)\n\n2"
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#install-github-api-in-wsl",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#install-github-api-in-wsl",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "2.1 Install Github API in wsl",
    "text": "2.1 Install Github API in wsl\n\nRun sudo apt install gh.\nRun gh to see if install properly. Looks Good.\nSee Command: issue available for us to call."
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#get-authenticated",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#get-authenticated",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "2.2 Get Authenticated",
    "text": "2.2 Get Authenticated\n\nIf you don’t have ssh setup then here is a [Two Step Tutorial]"
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#test-out-a-single-issue-transfer",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#test-out-a-single-issue-transfer",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "2.3 Test out a single Issue Transfer",
    "text": "2.3 Test out a single Issue Transfer\n\nRun gh issue transfer 23 tonyjustdevs/learning_csharp_vs -R tonyjustdevs/learning_csharp\n\n\n\nNo error message and it looked like it [github issue event]"
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#before-transfer",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#before-transfer",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "3.1 Before Transfer",
    "text": "3.1 Before Transfer\nIssues are currently with original repo:\n\ntonyjustdevs/learning_csharp\n\nRecall, the goal is to transfer them to:\n\ntonyjustdevs/learning_csharp_vs"
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#before-transfer-1",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#before-transfer-1",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "4.1 [Before Transfer]",
    "text": "4.1 [Before Transfer]\n\n4.1.1 Part 4: Issues 32 to 39\n\n\n\n4.1.2 [Before Transfer] Part 5: Issues 40 to 45\n\n\n\n4.1.3 [Before Transfer] Part 4: Issues 46 to 52\n\n\n\n4.1.4 [Before Transfer] Part 4: Issues 53 to 54"
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#run-code-for-issues-32-to-54",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#run-code-for-issues-32-to-54",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "4.2 Run Code for Issues 32 to 54",
    "text": "4.2 Run Code for Issues 32 to 54\nLooks like theres a limit of 20 requests per minutes or something since it stopped:\n\nIssues 32 to 51 went through\nHalted at Issues 52\n\nI ran the code again for Issue 52 to 54 a minute later and everything worked fine."
  },
  {
    "objectID": "posts/notes/coding/18-transfer-multiple-issues-github.html#after-transfer-example",
    "href": "posts/notes/coding/18-transfer-multiple-issues-github.html#after-transfer-example",
    "title": "Transfer Multiple Issues via Github API in Bash",
    "section": "5.1 [After Transfer] Example",
    "text": "5.1 [After Transfer] Example"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#create-task-list-and-set-list-action-parameter",
    "href": "posts/notes/coding/11-github-api.html#create-task-list-and-set-list-action-parameter",
    "title": "Using Github API via Python",
    "section": "4.1 Create Task List and Set List Action parameter",
    "text": "4.1 Create Task List and Set List Action parameter\n\n# 1. Choose 'New' or 'Append' to current description:\nlist_action_param = 'New'\n# list_action_param = 'Append'\n\n# 2. Enter list of tasks\nlist_of_tasks = [\n  \"A very cool new task\",\n  \"Another mad chill new task\",\n  \"A final exquisite crazy new task\"\n]"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#set-github-configs",
    "href": "posts/notes/coding/11-github-api.html#set-github-configs",
    "title": "Using Github API via Python",
    "section": "4.2 Set Github Configs",
    "text": "4.2 Set Github Configs\n\n# 3. Set Repo and Issue\nREPO_USER = \"tonyjustdevs\"\nREPO_TOPIC = \"blog\"\nISSUE_NUMBER = 95\n\n# 4. Configs\nGITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nREPO = f\"{REPO_USER}/{REPO_TOPIC}\"\nGITHUB_API_URL = f\"https://api.github.com/repos/{REPO}/issues\"\nHEADERS = {\n    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n    \"Accept\": \"application/vnd.github.v3+json\"\n}"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#check-response-is-okay-200",
    "href": "posts/notes/coding/11-github-api.html#check-response-is-okay-200",
    "title": "Using Github API via Python",
    "section": "4.3 Check Response is OKAY (200)",
    "text": "4.3 Check Response is OKAY (200)\n\nissue_url = f\"{GITHUB_API_URL}/{ISSUE_NUMBER}\"\nresponse = requests.get(issue_url, headers=HEADERS) #200\nresponse\n\n&lt;Response [200]&gt;"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#get-and-check-current-description-data",
    "href": "posts/notes/coding/11-github-api.html#get-and-check-current-description-data",
    "title": "Using Github API via Python",
    "section": "4.4 Get and Check Current Description Data",
    "text": "4.4 Get and Check Current Description Data\n\nissue_data = response.json()\ndescription = issue_data['body']\ndescription\n\n'sample description'"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#prepare-description-string-objects",
    "href": "posts/notes/coding/11-github-api.html#prepare-description-string-objects",
    "title": "Using Github API via Python",
    "section": "4.5 Prepare description string objects",
    "text": "4.5 Prepare description string objects\n\nprint(f\"List action parameter selected: '{list_action_param}'\")\nif description is not None and list_action_param==\"Append\": #\"New\" or \"Append\"\n  print(\"Description exists, no action required.\")\nelse:\n  description= \"\"\n  print(\"New (empty) description created.\") \n\nList action parameter selected: 'New'\nNew (empty) description created."
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#convert-tasks-to-single-string-object",
    "href": "posts/notes/coding/11-github-api.html#convert-tasks-to-single-string-object",
    "title": "Using Github API via Python",
    "section": "4.6 Convert tasks to single string object",
    "text": "4.6 Convert tasks to single string object\n\nadded_description_str = \"\"\nEOL_str = \"\\r\\n\"\ngithub_check_pointer_str = \"- [ ]\"\nfor task in list_of_tasks:\n  added_description_str += f\"{github_check_pointer_str} {task}{EOL_str}\"\n  print(f\"'{task}' appended.\")\n\n'A very cool new task' appended.\n'Another mad chill new task' appended.\n'A final exquisite crazy new task' appended.\n\n\n\nadded_description_str\n\n'- [ ] A very cool new task\\r\\n- [ ] Another mad chill new task\\r\\n- [ ] A final exquisite crazy new task\\r\\n'"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#append-to-current-description",
    "href": "posts/notes/coding/11-github-api.html#append-to-current-description",
    "title": "Using Github API via Python",
    "section": "4.7 Append to current description",
    "text": "4.7 Append to current description\n\ndescription+=added_description_str\n\n\nend_description_str = \"description added via [tony_add_tasks.ipynb]\"\ndescription += f\"{EOL_str}{end_description_str}{EOL_str}\"\n\n\nprint(description)\n\n- [ ] A very cool new task\n- [ ] Another mad chill new task\n- [ ] A final exquisite crazy new task\n\ndescription added via [tony_add_tasks.ipynb]"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#prepare-description-dictionary-object-to-send-to-api",
    "href": "posts/notes/coding/11-github-api.html#prepare-description-dictionary-object-to-send-to-api",
    "title": "Using Github API via Python",
    "section": "4.7 Prepare description dictionary object to send to API",
    "text": "4.7 Prepare description dictionary object to send to API\n\nupdate_data = {\n    \"body\": description\n}"
  },
  {
    "objectID": "posts/notes/coding/11-github-api.html#update-description-object-via-api",
    "href": "posts/notes/coding/11-github-api.html#update-description-object-via-api",
    "title": "Using Github API via Python",
    "section": "4.8 Update description object via API",
    "text": "4.8 Update description object via API\n\nresponse = requests.patch(issue_url, headers=HEADERS, json=update_data)\n\nif response.status_code == 200:\n    print(\"Issue description updated successfully!\")\nelse:\n    print(f\"Failed to update issue description: {response.status_code}, {response.text}\")\n\nIssue description updated successfully!"
  },
  {
    "objectID": "posts/notes/coding/23-interfaces-2-protocols.html#the-scenario",
    "href": "posts/notes/coding/23-interfaces-2-protocols.html#the-scenario",
    "title": "Interfaces [Part 2]: Protocols",
    "section": "1.1 The Scenario",
    "text": "1.1 The Scenario"
  },
  {
    "objectID": "posts/notes/coding/23-interfaces-2-protocols.html#the-problem",
    "href": "posts/notes/coding/23-interfaces-2-protocols.html#the-problem",
    "title": "Interfaces [Part 2]: Protocols",
    "section": "1.2 The Problem",
    "text": "1.2 The Problem"
  },
  {
    "objectID": "posts/notes/coding/23-interfaces-2-protocols.html#one-of-the-solutions",
    "href": "posts/notes/coding/23-interfaces-2-protocols.html#one-of-the-solutions",
    "title": "Interfaces [Part 2]: Protocols",
    "section": "1.3 (One of) The Solution(s):",
    "text": "1.3 (One of) The Solution(s):"
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html",
    "href": "posts/notes/coding/16-open-source-beginners.html",
    "title": "Open Source as a Beginner",
    "section": "",
    "text": "FreeCodeCamp Open Source Beginners Guide"
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html#step-by-steps",
    "href": "posts/notes/coding/16-open-source-beginners.html#step-by-steps",
    "title": "Open Source as a Beginner",
    "section": "4.1 Step-by-Steps",
    "text": "4.1 Step-by-Steps\n\nFork: os project becomes “https://github.com//projectname”\nClone:git clone https://github.com/&lt;YourUserName&gt;/&lt;projectname&gt;\n\nthis creates a copy of project on local machine\n\nCreate local folder + branch: cd to folder + eg git checkout -b tonyjustdev-branch\n\nsee all changes: git status\nadd all changes: git add *\ncommit changes: git commit -m \"message here\"\n\npush to remote: git push origin tonyjustdev-branch"
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html#advantages-of-above-steps",
    "href": "posts/notes/coding/16-open-source-beginners.html#advantages-of-above-steps",
    "title": "Open Source as a Beginner",
    "section": "4.2 Advantages of Above Steps",
    "text": "4.2 Advantages of Above Steps\n\nIt allows you to contribute to another repo without needing administrative privileges to make changes to the repo.\nIt allows others to review your changes and suggest corrections, additions, edits, and so on.\nIt gives repo administrators control over what gets added to their project repo."
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html#fork-a-repo-first-contributions",
    "href": "posts/notes/coding/16-open-source-beginners.html#fork-a-repo-first-contributions",
    "title": "Open Source as a Beginner",
    "section": "5.1 Fork a repo first contributions",
    "text": "5.1 Fork a repo first contributions\nBy forking a repo, I am creating a copy of the particular repository in my own github account:\n\nClick fork button on top right of the repo\nRename [Repository name] (if you want)\nClick Create fork\n\nRepo used: https://github.com/firstcontributions/first-contributions."
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html#clone-your-forked-repo-tonyjustdevsfirst-contributions",
    "href": "posts/notes/coding/16-open-source-beginners.html#clone-your-forked-repo-tonyjustdevsfirst-contributions",
    "title": "Open Source as a Beginner",
    "section": "5.2 Clone your forked repo tonyjustdevs/first-contributions",
    "text": "5.2 Clone your forked repo tonyjustdevs/first-contributions\n\nCopy URL and git clone &lt;your copied url&gt;"
  },
  {
    "objectID": "posts/notes/coding/16-open-source-beginners.html#create-local-branch",
    "href": "posts/notes/coding/16-open-source-beginners.html#create-local-branch",
    "title": "Open Source as a Beginner",
    "section": "5.3 Create local branch",
    "text": "5.3 Create local branch\n\n5.3.1 Clone to local with Windows Terminal\nMy current workflow involves firstly opening VSCode , then creating/switching to a branch in the Terminal of VSCode.\n\ncd to cloned folder\nopen vscode\ncreate/switch to new branch\n\n(I have not had a chance to test whether there a difference to creating the branch first before launching VS Code. I currently run almost all terminal commands in VSCode’s Terminal rather than Windows Terminal)\n\n\n\n5.3.2 Create Local Branch with VS Code’s Terminal\nVSCode shows which branch you’re currently in which is neat."
  },
  {
    "objectID": "posts/notes/coding/12-vscode-keybindings-json.html",
    "href": "posts/notes/coding/12-vscode-keybindings-json.html",
    "title": "Create new key-bindings in VSCode via JSON file",
    "section": "",
    "text": "1. How to add a new Key-Binding via VSCode JSON file\n\n1.1 Go to Preferences\n\nGo to Preferences or\n\nctrl-shift-p then [**Preferences: Open Keyboard Shortcuts (JSON)**]\n\n\n\n1.2 Add entry JSON file\n\nThe entry is all the code below (including curly brackets).\nInsert code into the json list already existing in the json file:\n\nie in betweeen the square brackets in the json file.\n\n\n\n\n1.3 Keybinding: [Go to next terminal] - json code\n\n{\n    \"key\": \"ctrl+tab\",\n    \"command\": \"workbench.action.terminal.focusNext\",\n    \"when\": \"terminalFocus\"\n}\n\n\n\n1.4 Keybinding: [Go to next terminal] - screenshot\n\n\n\n1.5 [Bonus] Keybinding: [Kill all terminals] - json code\n\n{\n    \"key\": \"ctrl+shift+w\",\n    \"command\": \"workbench.action.terminal.killAll\",\n    \"when\": \"terminalHasBeenCreated || terminalIsOpen || terminalProcessSupported\"\n}\n\n\n\n1.6 [Bonus] Keybinding: [Kill all terminals] - screenshot"
  },
  {
    "objectID": "posts/notes/coding/5-debug_1l_nn.html",
    "href": "posts/notes/coding/5-debug_1l_nn.html",
    "title": "Debugging a 1-Hidden-Layer Neural Network Model",
    "section": "",
    "text": "1. Introduction\nI’ve coded from scratch a neural network using Kaggle Titanic dataset based on a Jeremy Howard’s popular NN-model.\nI noticed descrepancies in Loss between my model and the reference model and will attempt debug My Model (TP) without looking at the Reference Models (RM) code.\n\n\n2. The Problem\nLoss differences (from 2nd epoch onwards):\n\nTP-Loss: 0.544 (epoch_1), 0.538 (epoch_2)\nRM-Loss: 0.543 (epoch_1), 0.532 (epoch_2)\n\nThe difference grows per epoch.\n\n\n\n3. The Approach\nThis neural network model only has one-hidden-layer.\nI’ve decided to test differences at 3 stages:\n\nInput level (input data, coefficients, and constants)\nIntermediary Calculations (hidden layers and relu)\nPredictions (predictions and sigmoid)\nUpdate Coefficients (gradients and updated coefficients)\n\n\n\n4. The Analysis\n\n4.1 Input Level - Normalised Input Data - idep_mxn\nEPOCH 1 and 2: OKAY (data-matching) \n\n\n4.2 Input Level - Coeffs - Layer 1 - L1_nxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.3 Input Level - Coeffs - Layer 2 - L2_qx1\nEPOCH 1: OKAY (data-matching) \n\n\n4.4 Input Level - Coeffs - Constant - CONST_1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.5 Intermediary Calcs - idep@L1 - pred_PSET_HL_mxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.6 Intermediary Calcs - relu(idep@L1) - PSET_HL_mxq\nEPOCH 1: OKAY (data-matching) \n\n\n4.7 Final Preds - PSET_HL_mxq@L2 - PREDS_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.8 Final Preds - PREDS_mx1 + CONST_1 - PREDS_C_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.9 Final Preds - Sigmoid(PREDS_C_mx1) - SGM_PREDS_C_mx1\nEPOCH 1: OKAY (data-matching)\n\n\n\n4.10 - Loss -\nEPOCH 1: NOT OKAY, Loss values different from 4th decimals\nSince Loss is created taking the absolute difference (then mean) between the:\n\npredictions and\n(actual) dependent variables\n\nLets validate across the neural network models:\n\nDependent Variable (“Survived”)\n\nPredictions\n\n\n\n\nModel\nLoss\n\n\n\n\nTP\n0.5433918237686157\n\n\nRM\n0.5439100861549377\n\n\n\n\n\n\n5. The Bug\n\n5.1 Input Level - Dep Variable - dep_mx1\nEPOCH 1: NOT OKAY:- **Dimensions are different!\nFound the Bug!\n\nTP-dimensions: [713,1]\nRM-dimensions: [713]\n\n\n\n\n\n6. The Fix\n\n6.1 Adding Trailing Dimension [:,None]\nSolution: Add trailing dimesion for dependent variables, fixing the predictions calculation, thus loss.\n\n\n\n6.2 Check New Loss\nIt matches EXACTLY!\n\n\n\n\n7. Conclusion\nIt goes to show how important getting the correct dimensions can change things so subtley and materially at the same time."
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#the-setup",
    "href": "posts/notes/coding/1-github_resolve.html#the-setup",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "1. The Setup",
    "text": "1. The Setup\nTesting the automation of closing a GitHub Issue via a VSCode Commit Message shown in youtube tutorial: How to Use GitHub for Automated Kanban Project Management\n\nHigh level steps:\n\nCreate Issue\n\nAttach associated Repo\n\nAttach associated Project\n\nAttach any relevant Tags\n\nDo required changes to your repo files\n\nCommit with “resolve #” associated to Issue\n\n[Important]: to include “resolve #58” in Commit Message in order to tell Github to automatically resolve it."
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#issue-is-open",
    "href": "posts/notes/coding/1-github_resolve.html#issue-is-open",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "2. Issue is Open",
    "text": "2. Issue is Open"
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#issue-is-closed-successfully",
    "href": "posts/notes/coding/1-github_resolve.html#issue-is-closed-successfully",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "3. Issue is Closed successfully",
    "text": "3. Issue is Closed successfully\nActions: Commmited, Staged and Pushed.\n[SUCCESS]: Issue #58 has indeed been automatically closed without a manual intervention on the kanban board!"
  },
  {
    "objectID": "posts/notes/coding/1-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "href": "posts/notes/coding/1-github_resolve.html#a-tick-as-a-little-reward-for-work-done",
    "title": "Automate the closing of Issues in Github Projects",
    "section": "4. A Tick ☑️ as a little reward for work done",
    "text": "4. A Tick ☑️ as a little reward for work done"
  },
  {
    "objectID": "posts/notes/linear_algebra/4-diagonlisation.html#normal-mode",
    "href": "posts/notes/linear_algebra/4-diagonlisation.html#normal-mode",
    "title": "Diagonal Matrices are trivial",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/2-eigenvalues_eigenvectors.html",
    "href": "posts/notes/linear_algebra/2-eigenvalues_eigenvectors.html",
    "title": "Eigen is my valentines in 2024",
    "section": "",
    "text": "Note on Colours:\n- I’m colourblind (red-green). Read more here.\n- I’m using Nebo App on a Lenovo Tablet in Dark Mode. The app doesn’t actually export the way I see it, it exports in non-dark mode so it looks completely different to how I chose the colours. If the colours are an eyesore, I apologise 🤭 (It’s probably sub-optimal without the export issues already).\n- I used a website to reverse colours but it isn’t right either.\nI’ll figure it out… for now I’ve put up both unwanted versions because I havent posted in 4 days (awful).\n\n1. Dark-mode\n\n\n\n2. Normal-mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/1-chg_of_bse.html#normal-mode",
    "href": "posts/notes/linear_algebra/1-chg_of_bse.html#normal-mode",
    "title": "Notes: Change of Basis",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/dsa/dsa-ch01-array-set-exs.html",
    "href": "posts/notes/dsa/dsa-ch01-array-set-exs.html",
    "title": "DSA: Array and Sets Exercises",
    "section": "",
    "text": "1. Array Operations: Exercises\nFor an array \\(Arr[n_1,..n_{100}]\\) containing \\(100\\) elements.\nProvide the number_of_steps for the operation:\n\n\\(Reading()\\)\n\\(Searching()\\) target not in the array\n\\(Insertion()\\) at \\([beginning]\\)\n\\(Insertion()\\) at \\([end]\\)\n\\(Deletion()\\) at \\([beginning]\\)\n\\(Deletion()\\) at \\([end]\\)\n\nof the array.\n\n\n1.1 Array Operations: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on array \\(\\{a_i\\}^{100}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Reading()\\) any position in the array\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- Reading an array is like having a numpad and pressing/accessing the number required at the time needed.- No requirement count up to a particular number, we can see all numbers at once.\n\n\n\\(Searching()\\) target not in the array\n\\(O(n)\\)\n\\(O(100)=100\\) steps\n- Search (or iterate) through whole array- i.e. every single item is read once and checked against a target- It could be argued that \\(Comparison()\\) is an operation though but here we do not consider it as one.\n\n\n\\(Insertion()\\) at \\([beginning]\\)\n\\(O(n+1)\\)\n\\(O(101+1)=101\\) steps\n- \\(Move()\\) each item right by one- \\(Move()\\) last item \\(Arr[n] \\to Arr[n+1]\\) - \\(Move()\\) \\(2nd\\_last\\) item to last \\(Arr[n+1] \\to Arr[n],\\ ...etc\\)- After \\(MovingAll()\\) items \\(\\to\\) \\(n\\) operations - \\(Insert()\\) value into array in \\(1\\ step\\)  - \\(Total=100+1=101\\ steps\\)\n\n\n\\(Insertion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- Go to end of array and \\(Insert()\\) value in \\(1\\ step\\)\n\n\n\\(Deletion()\\) at \\([beginning]\\)\n\\(O(n)\\)\n\\(O(99+1)=100\\) steps\n- \\(Delete()\\) \\([first]\\) item in $1 step - This leaves \\((n-1)\\) items left in the array - Move each item right by 1 - Thus, \\(Arr[1] \\to Arr[0],\\ Arr[2] \\to Arr[1]...etc...(n-1)\\ times\\) - \\(Total=1+99=100\\ steps\\)\n\n\n\\(Deletion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)=1\\) steps\n- \\(Delete()\\) \\([last]\\) item in \\(1\\ step\\)\n\n\n\n\n\n2. Array-Based Set Operations\nFor an array-based set \\(Set\\{n_1,..n_{100}\\}\\) containing \\(100\\) elements.\nProvide the number_of_steps for the operation:\n\n\\(Reading()\\)\n\\(Searching()\\) target not in set\n\\(Insertion()\\) new_value at \\([beginning]\\)\n\\(Insertion()\\) new_value at \\([end]\\)\n\\(Deletion()\\) at \\([beginning]\\)\n\\(Deletion()\\) at \\([end]\\)\n\nof the set.\n\n\n2.1 Array-Based Set Operations: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on set \\(\\{a_i\\}^{100}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Reading()\\) any position in the set\n\\(O(1)\\)\n\\(O(1)\\)\n- Same as array\n\n\n\\(Searching()\\) target not in the set\n\\(O(n)\\)\n\\(O(100)\\)\n- Same as array\n\n\n\\(Insertion()\\) at \\([beginning]\\)\n\\(O(n+1)\\)\n\\(O(2*100+1)=O(201)\\)\n- Search whole array: \\(100\\ steps\\) - \\(Move()\\ or\\ Shift()\\) items right from \\(Set{0} \\to Set{1}, Set{1} \\to Set{2}...\\) (Same as array): \\(100\\ steps\\) - \\(Insert()\\): \\(1\\ step\\) - \\(Search(100)\\) + \\(Move(100)\\) + \\(Insert(1)\\) = \\(201\\ steps\\)\n\n\n\\(Insertion()\\) at \\([end]\\)\n\\(O(n+1)\\)\n\\(O(100+1)=O(101)\\)\n- \\(Search(100)\\) then \\(Insert(1)\\) =\\(101\\ steps\\)\n\n\n\\(Deletion()\\) at \\([beginning]\\)\n\\(O(n)\\)\n\\(O(n)\\)\n- \\(Delete(1)\\) then \\(ShiftLeft(99)\\) = \\(100\\ steps\\)\n\n\n\\(Deletion()\\) at \\([end]\\)\n\\(O(1)\\)\n\\(O(1)\\)\n- \\(Delete(1)\\)=\\(1\\ steps\\)\n\n\n\n\n\n3. \\(Search()\\) vs \\(Count()\\) In Arrays: Exercises\n\\(Search()\\):\n\nFinds the \\(first\\ instance\\) of a \\(given\\_value\\) in an array.\n\n\\(Count()\\):\n\nHow many steps to find all the target_value (\\(every\\ instance\\) of a \\(given\\_value\\)). Give your answer \\(N\\).\n\n\n\n3.1 \\(Search()\\) vs \\(Count()\\) In Arrays: Tony’s Solutions\n\n\n\n\n\n\n\n\n\nOperation on array \\(\\{a_i\\}^{n}_{i=1}\\)\nBig \\(O(n)\\)\nnumber_of_steps\nComments\n\n\n\n\n\\(Count()\\) target_value in array\n\\(O(n)\\)\n\\(O(1)=1\\) steps\n- \\(Search(n)\\) whole array - Increase \\(Counter()\\) by 1 each time an occurence of target_value is seen"
  },
  {
    "objectID": "posts/2024-04-27-feature_importance_plot/index.html",
    "href": "posts/2024-04-27-feature_importance_plot/index.html",
    "title": "Random Forests - Feature Importance Plot (Part 4)",
    "section": "",
    "text": "1. Introduction\nIn Part 1, a simple model was built using single binary split called OneR Classifier.\nIn Part 2, sklearn DecisionTreeClassifier framework was used and by setting a sample limit per node, loss was reduced.\nIn Part 3, we used the concept of bagging by averaging predictions from many big trees to create a random forest.\nToday, we’ll create a Feature Importance Plot very easily and quickly.\nIn the next post I’ll go into:\n\nGradient Boosting (sum of trees ) Decision Tree or Machines (GBMs)\n\n\n\n2. Training and Validation Sets\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n\n\n\n\n3. Build Decision Tree Classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtc_min50 = DecisionTreeClassifier(min_samples_leaf=50)\n\n\n\n4. Fit Decision Tree to our Training Data\n\ndtc_min50.fit(trn_idep, trn_dep)\n\nDecisionTreeClassifier(min_samples_leaf=50)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(min_samples_leaf=50) \n\n\n\n\n5. Create Feature Importance Plot\n\npd.DataFrame(dict(cols=trn_idep.columns, imp=dtc_min50.feature_importances_)).plot('cols', 'imp', 'barh')\n\n\n\n\n\n\n\n\n\n\n6. Completed\nAs expected, Sex and Pclass are the most important features to survivability on the Titanic."
  },
  {
    "objectID": "posts/2024-01-16-99_welcome/index.html",
    "href": "posts/2024-01-16-99_welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nDefault Quarto content:\n“Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.””"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 1)",
    "section": "",
    "text": "A neural network is a mathematical function. So what’s that?\nA function is a mapping or transformation where each unique set of inputs is equal to exactly one output.\nIn highschool, the Vertical Line Test was used to determine whether a line was a function.\nThis post will go through basics of how to fit a line to some data."
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 1)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#upload-and-plot-data",
    "title": "Neural Network Basics (Part 1)",
    "section": "2. Upload and Plot Data",
    "text": "2. Upload and Plot Data\n\ndf = pd.read_csv(\"upload_dataset.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2.000000\n11.869037\n\n\n1\n-1.789474\n6.543284\n\n\n2\n-1.578947\n5.939607\n\n\n3\n-1.368421\n2.630370\n\n\n4\n-1.157895\n1.794741\n\n\n\n\n\n\n\n\nplt.scatter(df.x, df.y)"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#quadratic-equation",
    "title": "Neural Network Basics (Part 1)",
    "section": "3. Quadratic Equation",
    "text": "3. Quadratic Equation\n\n3.1 General Quadratic Equation\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\n\n\n\n3.2 Custom Quadratric Equation\n\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\n\n\n\n3.3 Creating \\(1x^2 + 1x + 1\\)\n\nquad_111 = custom_quad_fn(1,1,1)\n\n\n\n3.4 Plotting \\(1x^2 + 1x + 1\\)\n\nxs_111 = df.x\nys_111 = quad_111(xs_111)\nplt.plot(xs_111,ys_111)\nplt.scatter(df.x, df.y)\n\n\n\n\n\n\n\n\n\n\n3.4 Interactive Quadratic Equation\nThe coefficients a, b and c of the Quadratic Function can be adjusted which in turn changes the shape of the line.\n[Future Iteration]: Figure out how to embed this adjustable plot into quarto blog\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot(a,b,c):\n# 1. plot scatter\n    plt.scatter(df.x, df.y)    \n# 2. create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n# 3. plot custom_quad_interactive\n    plt.ylim(-1,15)\n    plt.plot(xs_interact, custom_quad_fn(a,b,c)(xs_interact))\n\n\n\n\n\n\n\n3.5 Mean Absolute Errors (MAE)\nBy calculating a Loss Function such as Mean Absolute Errors, we can numerically determine what is the ‘best’ fit of our line to the data.\nSure it isn’t entirely scientific to adjust it manually but its a good starting point.\n\ndef mae(prediction, actual): return np.mean(abs(prediction-actual))\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,5,0.1),b=(0,5,0.1),c=(0,5,0.1))\ndef interactive_plot2(a,b,c):\n# 1.    plot scatter\n    plt.scatter(df.x, df.y)\n\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = torch.linspace(-2.1,2.1,100)\n\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n\n# 4.    calc mae\n    y_actual     = df.y\n    y_predicted  = custom_quad_fn(a,b,c)(df.x)\n    interact_mae = round(mae(y_actual, y_predicted),3)\n\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae}\")"
  },
  {
    "objectID": "posts/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "href": "posts/2024-01-31-99_neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nThe next section go through a more automated method to find the smallest MAE.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html",
    "href": "posts/2024-01-27-99_kaggle_api/index.html",
    "title": "How To Setup a Kaggle API",
    "section": "",
    "text": "I’m planning to learn and test myself with competitions on Kaggle.\nKaggle is a place with real-world problems where Data Scientists and alike can go against each other to solve problems with Machine Learning.\nFrom my understanding:\n- There is a validation set where your model is tested against and a public leader board to see how you’re going.\n- At the end of the competition, there is an unseen test set where everyones models is tested against and where the final rankings are determined.\n- This is quite reflective of real world where preparing a representative validation set is vital, thus will perform well on the test set.\n- A common mistake for newbs is over-fitting to the validation set. I’m ready to make that mistake 🤣.\nAs for the Kaggle API, you can download the kernel which is the necessary datasets and source files to do the competitions.\nAlternatively, I can use the notebooks on their website. I plan to try doing competitions both ways.\nThis is how I set up my Kaggle API"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#install-library",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#install-library",
    "title": "How To Setup a Kaggle API",
    "section": "1. Install Library",
    "text": "1. Install Library\npip install python"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#create-api-token-.json-file",
    "title": "How To Setup a Kaggle API",
    "section": "2. Create API token (.json file)",
    "text": "2. Create API token (.json file)\n\nGo to Kaggle\n\nGo to Settings\n\nCreate New Token"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#save-to-your-local-.kaggle-folder-windows",
    "title": "How To Setup a Kaggle API",
    "section": "3. Save to your local .kaggle folder (Windows)",
    "text": "3. Save to your local .kaggle folder (Windows)\nLocation: C:\\Users\\&lt;Windows-username&gt;\\.kaggle\\kaggle.json\nKaggle Github Reference\n\n3.1 Pasted into the wrong folder?\nIf you did something wrong then ran kaggle in the terminal, you’ll an error (telling you where to put it):"
  },
  {
    "objectID": "posts/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "href": "posts/2024-01-27-99_kaggle_api/index.html#start-kaggling",
    "title": "How To Setup a Kaggle API",
    "section": "4 Start Kaggling",
    "text": "4 Start Kaggling\n\nimport kaggle\n??kaggle\n\nType:        module\nString form: &lt;module 'kaggle' from 'c:\\\\Users\\\\tonyp\\\\miniconda3\\\\envs\\\\fastai\\\\Lib\\\\site-packages\\\\kaggle\\\\__init__.py'&gt;\nFile:        c:\\users\\tonyp\\miniconda3\\envs\\fastai\\lib\\site-packages\\kaggle\\__init__.py\nSource:     \n#!/usr/bin/python\n#\n# Copyright 2024 Kaggle Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# coding=utf-8\nfrom __future__ import absolute_import\nfrom kaggle.api.kaggle_api_extended import KaggleApi\nfrom kaggle.api_client import ApiClient\n\napi = KaggleApi(ApiClient())\napi.authenticate()"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html",
    "title": "Saving a Fast AI Model",
    "section": "",
    "text": "This is a short tutorial to save (export) down a fast ai model (pkl file)."
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#load-fast-ai-libaries-and-download-dataset",
    "title": "Saving a Fast AI Model",
    "section": "1. Load Fast AI Libaries and Download Dataset",
    "text": "1. Load Fast AI Libaries and Download Dataset\n\n!pip install -Uqq fastai\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath\n\nPath('C:/Users/tonyp/.fastai/data/oxford-iiit-pet/images')\n\n\nIf you ran it in GoogleColab or Kaggle (recommended, its faster) then it’ll be stored in the cloud. \nIf you ran it locally, its stored on your machine and you can take a look at the all the cute images! (Not recommended, its slow)"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#labelling-function",
    "title": "Saving a Fast AI Model",
    "section": "2. Labelling Function",
    "text": "2. Labelling Function\n\ndef is_cat(x): return x[0].isupper()\n\nOur data must be consistently labelled and parsed through into the model.\nFor this particular dataset, filenames starting with a Capital letter denotes a Cat, vice versa for a Non-Cat (Dog, in this case).\n\n\n\nPet Filenames\n\n\nLets write a function to handle the files names to get our labels (psuedo-code):\n1. Parse in file name and\n2. Obtain the first character and\n3. Check whether it is an upper case,\n4. If True, then it is a Cat.\nThere are various ways for us to supply the labelling to our model, in a previous blog Rice vs Noodles, the label was supplied via the parent folders name (rice folder and noodle folder).\n\nFast AI provides various helpful functions for common ways data is labelled to parse into our models\nFast AI Docs - Transforms - Label"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#dataloader",
    "title": "Saving a Fast AI Model",
    "section": "3. DataLoader",
    "text": "3. DataLoader\nCreate the Dataloader and supply the labelling function we wrote into label_func.\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#fine-tune-non-gpu-vs-gpu",
    "title": "Saving a Fast AI Model",
    "section": "4. Fine-tune (Non-GPU vs GPU)",
    "text": "4. Fine-tune (Non-GPU vs GPU)\nI attempted to fine-tune via Kaggle (GPU) and Locally (No GPU) and not suprisingly it is incredibly faster with a GPU setup.\nNvidia (and maybe other) GPUs are designed to be able to take multiple images at once (batches) grouped together (tensors) (I think 64 images at once), whereas a laptop without a GPU like mine will be processing 1 image at a time.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\nGPU took 35 seconds an epoch \nNon-GPU took 8 minutes an epoch"
  },
  {
    "objectID": "posts/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "href": "posts/2024-01-19-99_saving_a_fastai_model/index.html#export-the-model",
    "title": "Saving a Fast AI Model",
    "section": "5. Export the model",
    "text": "5. Export the model\n\nlearn.export('catdogmodel.pkl')\n\nIn Kaggle, the model will be saved on their cloud and you can access it by using right-hand sidebar under Notebook -&gt; Data -&gt; Output\n\nIt’s only 46 Mb!, not too shabby!\n\nThats it! We’ll go through how to use a saved/exported model in an upcoming post."
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#available-files",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#available-files",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.1 Available files",
    "text": "2.1 Available files\n\npath = untar_data(URLs.ML_100k)\nos.listdir(path)\n\n['ub.base',\n 'u.data',\n 'u4.test',\n 'u3.test',\n 'ua.test',\n 'ub.test',\n 'u2.base',\n 'u1.test',\n 'u.info',\n 'README',\n 'mku.sh',\n 'u.genre',\n 'u3.base',\n 'u4.base',\n 'u.item',\n 'u.occupation',\n 'u5.base',\n 'ua.base',\n 'allbut.pl',\n 'u5.test',\n 'u2.test',\n 'u1.base',\n 'u.user']"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#checking-out-the-readme",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#checking-out-the-readme",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.2 Checking out the README",
    "text": "2.2 Checking out the README\n\ndef get_info(folder_name):\n    info_path = os.path.join(path,folder_name)\n    with open(info_path) as f:\n        info_content = f.read()\n    print(info_content)  \n\n# get_info('README')\n\n\n2.2.1 README - u.data\n\nThe full u data set, 100000 ratings by 943 users on 1682 items etc…\nThis is a tab separated list of user id | item id | rating | timestamp.\n\n\n\n2.2.2 README - u.item\n\nInformation about the items (movies);\nThis is a tab separated list of movie id | movie title | release date | video release date | etc…"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#movies-data",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#movies-data",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3 Movies data",
    "text": "2.3 Movies data"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#codecencoding-import-problem",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#codecencoding-import-problem",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.1 Codec/Encoding import problem",
    "text": "2.3.1 Codec/Encoding import problem\nThere is a code problem with importing the movies dataset.\n\nmovies_df = pd.read_csv(path/'u.item')\n\n\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 movies_df = pd.read_csv(path/'u.item')\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898, in TextFileReader._make_engine(self, f, engine)\n   1895     raise ValueError(msg)\n   1897 try:\n-&gt; 1898     return mapping[engine](f, **self.options)\n   1899 except Exception:\n   1900     if self.handles is not None:\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93, in CParserWrapper.__init__(self, src, **kwds)\n     90 if kwds[\"dtype_backend\"] == \"pyarrow\":\n     91     # Fail here loudly instead of in cython after reading\n     92     import_optional_dependency(\"pyarrow\")\n---&gt; 93 self._reader = parsers.TextReader(src, **kwds)\n     95 self.unnamed_cols = self._reader.unnamed_cols\n     97 # error: Cannot determine type of 'names'\n\nFile parsers.pyx:574, in pandas._libs.parsers.TextReader.__cinit__()\n\nFile parsers.pyx:663, in pandas._libs.parsers.TextReader._get_header()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2053, in pandas._libs.parsers.raise_parser_error()\n\nFile &lt;frozen codecs&gt;:322, in decode(self, input, final)\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 76620: invalid continuation byte"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#chardet-library",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#chardet-library",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.2 chardet library",
    "text": "2.3.2 chardet library\nLets use chardet library to decode encoding automatically.\nWe find that data is in ‘ISO-8859-1’ encoding.\n\nimport chardet\n\nread_mode   = 'rb' #'rb' means \"open the file in read mode, and read it as a binary file\".\nmovie_path  = path/'u.item'\n\nwith open(movie_path, read_mode) as f: #'rb' means \"open the file in read mode, and read it as a binary file\".\n    result = chardet.detect(f.read())\nencoding_id = result['encoding']\nencoding_id\n\n'ISO-8859-1'"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#updating-codec-error-persists",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#updating-codec-error-persists",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.3 Updating Codec (error persists)",
    "text": "2.3.3 Updating Codec (error persists)\n\nmovies_df = pd.read_csv(path/'u.item', encoding=encoding_id)\n\n\n---------------------------------------------------------------------------\nParserError                               Traceback (most recent call last)\nCell In[17], line 1\n----&gt; 1 movies_df = pd.read_csv(path/'u.item', encoding=encoding_id)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626, in _read(filepath_or_buffer, kwds)\n    623     return parser\n    625 with parser:\n--&gt; 626     return parser.read(nrows)\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923, in TextFileReader.read(self, nrows)\n   1916 nrows = validate_integer(\"nrows\", nrows)\n   1917 try:\n   1918     # error: \"ParserBase\" has no attribute \"read\"\n   1919     (\n   1920         index,\n   1921         columns,\n   1922         col_dict,\n-&gt; 1923     ) = self._engine.read(  # type: ignore[attr-defined]\n   1924         nrows\n   1925     )\n   1926 except Exception:\n   1927     self.close()\n\nFile ~/miniforge3/envs/fast/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234, in CParserWrapper.read(self, nrows)\n    232 try:\n    233     if self.low_memory:\n--&gt; 234         chunks = self._reader.read_low_memory(nrows)\n    235         # destructive to chunks\n    236         data = _concatenate_chunks(chunks)\n\nFile parsers.pyx:838, in pandas._libs.parsers.TextReader.read_low_memory()\n\nFile parsers.pyx:905, in pandas._libs.parsers.TextReader._read_rows()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2061, in pandas._libs.parsers.raise_parser_error()\n\nParserError: Error tokenizing data. C error: Expected 1 fields in line 12, saw 3"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#update-delimiter",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#update-delimiter",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.3.4 Update Delimiter",
    "text": "2.3.4 Update Delimiter\nBy adding the delimiter we’ve resolved the issue.\n\nmovies_df = pd.read_csv(path/'u.item', encoding=encoding_id, delimiter='|')\nmovies_df[0:3]\n\n\n\n\n\n\n\n\n1\nToy Story (1995)\n01-Jan-1995\nUnnamed: 3\nhttp://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\n0\n0.1\n0.2\n1.1\n1.2\n...\n0.6\n0.7\n0.8\n0.9\n0.10\n0.11\n0.12\n0.13\n0.14\n0.15\n\n\n\n\n0\n2\nGoldenEye (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?GoldenEye%20(1995)\n0\n1\n1\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n1\n3\nFour Rooms (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n4\nGet Shorty (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)\n0\n1\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n3 rows × 24 columns"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#import-movies-and-ratings-and-merging",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#import-movies-and-ratings-and-merging",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4 Import Movies and Ratings and Merging",
    "text": "2.4 Import Movies and Ratings and Merging"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#movies",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#movies",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.1 Movies",
    "text": "2.4.1 Movies\n\nmovies_df = pd.read_csv(path/'u.item', delimiter='|', encoding=encoding_id, header=None, usecols=(0,1),\n            names =['movie_id','movie_title'])\nmovies_df[0:5]\n\n\n\n\n\n\n\n\nmovie_id\nmovie_title\n\n\n\n\n0\n1\nToy Story (1995)\n\n\n1\n2\nGoldenEye (1995)\n\n\n2\n3\nFour Rooms (1995)\n\n\n3\n4\nGet Shorty (1995)\n\n\n4\n5\nCopycat (1995)"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#user-ratings",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#user-ratings",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.2 User Ratings",
    "text": "2.4.2 User Ratings\n\nusr_ratings_df = pd.read_csv(path/'u.data',delimiter='\\t', header=None,\n                       names=['user_id','movie_id','rating','timestamp'])\nusr_ratings_df[0:5]\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ntimestamp\n\n\n\n\n0\n196\n242\n3\n881250949\n\n\n1\n186\n302\n3\n891717742\n\n\n2\n22\n377\n1\n878887116\n\n\n3\n244\n51\n2\n880606923\n\n\n4\n166\n346\n1\n886397596"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#merged",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#merged",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "2.4.3 Merged",
    "text": "2.4.3 Merged\n\nratings_merged = usr_ratings_df.merge(movies_df)\nratings_merged[0:5]\n\n\n\n\n\n\n\n\nuser_id\nmovie_id\nrating\ntimestamp\nmovie_title\n\n\n\n\n0\n196\n242\n3\n881250949\nKolya (1996)\n\n\n1\n186\n302\n3\n891717742\nL.A. Confidential (1997)\n\n\n2\n22\n377\n1\n878887116\nHeavyweights (1994)\n\n\n3\n244\n51\n2\n880606923\nLegends of the Fall (1994)\n\n\n4\n166\n346\n1\n886397596\nJackie Brown (1997)"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-1-all-users-by-1-latent-factor",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-1-all-users-by-1-latent-factor",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.1 Excel Matrix-Multiply-1: All Users by 1-Latent-Factor",
    "text": "4.1 Excel Matrix-Multiply-1: All Users by 1-Latent-Factor\nNote: When matrix-multipying:\n\nuser_factors matrix [user (m) by factors (n)] by\n\none_hot encoded matrix [each column is one_hot_encoded vector of required index]\n\nThe result is a matrix where each column is the chosen factor index, i.e:\n\neach column of the resultant matrix: [every user m by the single factor]: [m,1]"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-2-individual-users-by-all-latent-factors",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#excel-matrix-multiply-2-individual-users-by-all-latent-factors",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.2 Excel Matrix-Multiply-2: Individual Users by All-Latent-Factors",
    "text": "4.2 Excel Matrix-Multiply-2: Individual Users by All-Latent-Factors\nHowever, what we want is the transpose of this result, i.e:\n\neach column representing [1 user and all its factors]"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#one-hot-encoded-vector",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#one-hot-encoded-vector",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3 One-Hot-Encoded Vector",
    "text": "4.3 One-Hot-Encoded Vector\nConvert our index of our latent factor matrix into one-hot-encoded vectors using:\n\nfrom fastai.torch_core import one_hot"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#steps",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#steps",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.1 Steps",
    "text": "4.3.1 Steps\n\nConvert some all indices of our matrix (944) to one-hot-encoded vectors (i.e. 944 individual vectors).\nFor e.g. Index [3] becomes a 1D-vector of length (n_users) or torch.Size([944])\nMatrix-Multiplying two single vectors is equivalent to the dot-product\n\n\nn_users_integer = len(dls.classes['user_id']) # get number of users ids\nn_movies_integer = len(dls.classes['movie_title']) # get number of users ids\nn_latent_factors_integer = 5\n\n\none_hot_2 = one_hot(2, n_users_integer).float()\n\n\nusers_latent_factors = torch.rand(n_users_integer, n_latent_factors_integer) # 944,5\nmovie_latent_factors = torch.rand(n_movies_integer, n_latent_factors_integer) # 1665,5"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#index2-of-user-latent-factors",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#index2-of-user-latent-factors",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.2 Index[2] of User-Latent-Factors",
    "text": "4.3.2 Index[2] of User-Latent-Factors\n\nusers_latent_factors[2]\n\ntensor([0.1049, 0.5802, 0.1599, 0.2081, 0.5760])\n\n\n\nusers_latent_factors.shape # [m,n] - [944,5]\nusr_t = users_latent_factors.t()\nusr_t.shape #[5,944]\none_hot_2.shape #[944]\n\ntorch.Size([944])"
  },
  {
    "objectID": "posts/2024-05-07_latent_factors_matrix/index.html#matrix-multiply-user-latent-factorsone_hot_idx2",
    "href": "posts/2024-05-07_latent_factors_matrix/index.html#matrix-multiply-user-latent-factorsone_hot_idx2",
    "title": "Collaborative Filtering - Latent Factor Matrix (Part 1)",
    "section": "4.3.3 Matrix-Multiply [User-Latent-Factors@One_Hot_IDX2]",
    "text": "4.3.3 Matrix-Multiply [User-Latent-Factors@One_Hot_IDX2]\nEquivalent to Index 2 of Original User-Latent-Factors\n\nusr_t@one_hot_2 # [5,944]@[944] ~ [m_x_n]@[n] =  \none_hot_user_factors_1d_tsr = users_latent_factors.t() @ one_hot_2 #[n_x_m]\none_hot_user_factors_1d_tsr\n\ntensor([0.1049, 0.5802, 0.1599, 0.2081, 0.5760])"
  },
  {
    "objectID": "posts/2024-04-24-one_r_classifier/index.html",
    "href": "posts/2024-04-24-one_r_classifier/index.html",
    "title": "Random Forests - OneR Classifier (Part 1)",
    "section": "",
    "text": "1. Introduction\nIn order to build Random Forests, we need to build Decision Trees.\nIn order to build Decisions-Trees, we need to build Binary Splits.\nThis post will show how to do find the best binary split per column, also known as OneR Classifier\n\n\n2. Data Cleaning\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ntitanic exists!\ngender_submission.csv  test.csv  train.csv\n\n\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\n\n\n3. Binary Splits\nA binary split is where all rows are placed into one of two groups, based on whether they’re above or below some threshold of some column.\n\n\n4. 1R Classifier model\nIn laymens:\n1. Get all unique values of each idependent value.\n2. Split on the value, ie. binary split.\n3. Make predictions on survivability using the above split.\n4. Calculate standard deviation for each split and add them.\n5. If std.dev is high, than its a bad split since survived and perished within each split. A good split results in low-variability.\n6. find the split point for each column with lowest std.dev.\n7. This is the 1R model.\n\n\n5. Code\n\ndef _side_score(side, y):\n    tot = side.sum()\n    if tot&lt;=1: return 0\n    return y[side].std()*tot\n\ndef score(idep_col, dep, split_val):\n    lhs_bool_list = idep_col &lt;= split_val\n    return (_side_score(lhs_bool_list, dep) + _side_score(~lhs_bool_list, dep)) / len(dep)\n\ndef min_col(df, idep_col_name):\n    idep_col    = df[idep_col_name]\n    dep         = df[dep_col]\n\n    col_uniques = idep_col.dropna().unique() # get all unique values of idep col\n    \n    scores = np.array( # get score for each unique value in idep_col\n        [score(idep_col, dep, col_val) \n         for col_val in col_uniques \n         if not np.isnan(col_val)\n         ])\n    \n    idx = scores.argmin() # get index of min score\n    return col_uniques[idx],scores[idx]\nall_cols = cat_list+cont_list \n{col:min_col(trn_df, col) for col in all_cols}\n\n{'Sex': (0, 0.40787530982063946),\n 'Embarked': (0, 0.47883342573147836),\n 'Age': (6.0, 0.478316717508991),\n 'SibSp': (4, 0.4783740258817434),\n 'Parch': (0, 0.4805296527841601),\n 'LogFare': (2.4390808375825834, 0.4620823937736597),\n 'Pclass': (2, 0.46048261885806596)}\n\n\n\n\n6. The Best Binary-Split\nThus, Sex&lt;=0 is best single binary split."
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html",
    "href": "posts/2024-02-03-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 3)",
    "section": "",
    "text": "In Neural Network Basics: Part 2, the parameters of a function were found (optimised) to Minimise the Loss Function. The Loss Function chosen was the Mean Absolute Error, it could have been chosen to be the Mean Squared Error.\nBut What is the mathematical function if the wish to model something more complex like predicting the breed of Cat?\nUnfortunately, its unlikely the relationship between the parameters and whether a pixel is part of a Maine Coon 🐈 is a Quadratic, its going to be something more complicated.\nThankfully, there exists the infinitely flexible function known as Rectified Linear Unit (ReLU)"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "href": "posts/2024-02-03-neural_network_basics/index.html#rectified-linear-unit-relu",
    "title": "Neural Network Basics (Part 3)",
    "section": "1. Rectified Linear Unit (ReLU)",
    "text": "1. Rectified Linear Unit (ReLU)\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nfrom functools import partial\n\n\n1.1 Function\nThe function does two things:\n1. Calculate the output of a line\n2. If the output is smaller than zero, return zero\n\ndef rectified_linear(m,b,x):\n    y = m*x+b\n    return torch.clip(y,0.)\n\n\n\n1.2 Create A Custom ReLU Method\n\ndef custom_relu_fn(m,b): return partial(rectified_linear,m,b)\n\n\n\n1.3 Create y = 1x + 1 with Custom ReLU Method\n\nfn_11 = custom_relu_fn(1,1)\nfn_11\n\nfunctools.partial(&lt;function rectified_linear at 0x00000220331C9D00&gt;, 1, 1)\n\n\n\n\n1.4 ReLU y = 1x+ 1 Plot\n\nx = torch.linspace(-2.1,2.1,20)\nplt.plot(x,fn_11(x))\n\n\n\n\n\n\n\n\n\n1.4.1 Interactive ReLU\n\nplt.rc('figure', dpi=90)\n\n@interact(m=1.2, b=1.2)\ndef plot_relu(m, b):\n    min, max = -4.1, 4.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(rectified_linear, m,b)\n    ylim=(-1,4)\n    plt.ylim(ylim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n\n1.5 Double ReLU Function\n\ndef double_relu(m1,b1,m2,b2,x):\n    return rectified_linear(m1,b1) + rectified_linear(m2,b2) \n\n\n1.5.1 Interactive Double ReLU\n\nplt.rc('figure', dpi=90)\n\ndef dbl_rectified_linear(m1, b1,m2,b2,x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2)\ndef plot_dbl_relu(m1,b1,m2,b2):\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    fn_fixed = partial(dbl_rectified_linear, m1,b1,m2,b2)\n    ylim=(-1,4)\n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, fn_fixed(x))\n\n\n\n\n\n\n\n1.5.1 Triple ReLU for Good Measure!\n\ndef trple_rectified_linear(m1, b1, m2, b2, m3, b3, x): \n    return rectified_linear(m1,b1,x) + rectified_linear(m2,b2,x) + rectified_linear(m3,b3,x)\n \n@interact(m1=-1.2, b1=-1.2,m2=1.2, b2=1.2, m3=0.5, b3=0.5)\ndef plot_trple_relu(m1,b1,m2,b2,m3,b3):\n# static variables\n    min, max = -3.1, 3.1\n    x = torch.linspace(min,max, 100)[:,None]\n    \n# update partial to include extra parameters m3, b3\n    triple_relu_fn_y = partial(trple_rectified_linear, m1,b1,m2,b2,m3,b3)\n\n# static variables\n    ylim=(-1,4) \n    xlim=(-4,4)\n    plt.ylim(ylim)\n    plt.xlim(xlim)\n    plt.axvline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.axhline(0, color='gray', linestyle='dotted', linewidth=2)\n    plt.plot(x, triple_relu_fn_y(x))"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "href": "posts/2024-02-03-neural_network_basics/index.html#relu-is-an-infinitely-flexible-function",
    "title": "Neural Network Basics (Part 3)",
    "section": "2. ReLU is An Infinitely Flexible Function",
    "text": "2. ReLU is An Infinitely Flexible Function\nThere could be arbitrarily many ReLus added together to form any function!\nThe previous functions are of a single input x i.e. 2-Dimensions.\nReLU’s could be added together over as many dimensions as desired, i.e. ReLU’s over surfaces or ReLU’s over 3D, 4D 5D etc.\nBut adding these ReLU’s, this means there are arbitrary amount of parameters related to each ReLU, how can these parameters be calculated?\nIn Part 2, a optimisation method called Gradient Descent was used to determine Parameters.\nThat’s Deep Learning in a nutshell. Beyond this, Tweaks are to:\n- make it faster\n- require less data"
  },
  {
    "objectID": "posts/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "href": "posts/2024-02-03-neural_network_basics/index.html#neural-network-basics-completed.",
    "title": "Neural Network Basics (Part 3)",
    "section": "Neural Network Basics Completed.",
    "text": "Neural Network Basics Completed.\nGo back to a previous post:\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#introduction",
    "href": "posts/kaggle/2-us-patents-offline/index.html#introduction",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "1. Introduction",
    "text": "1. Introduction\nFrom Part 1, the Kaggle Competition: U.S. Patent Phrase to Phrase Matching was a notebook competition, that is, a simple csv upload of predictions would not suffice.\nA notebook with code needs to be submitted in order to succesfully enter and be graded.\nThis notebook will have access the kaggles cloud folders to gather the raw data, process and model it. The only catch is the notebook has no access to the internet. This means pip install package will not work.\nThus, the pre-trained models and tokenizers need to be uploaded to the inputs folder, before being installed.\nWhy? Even though transformers library is available on Kaggle via import, each time a function like AutoTokenizer is called, this accesses the internet to reach the HuggingFace Model Hub and looks for the latest available models.\nIn order to upload files though, they need to be exported first, but in order for them to be exported, they need to be downloaded first!. Well that is what I figured out, there’s probably a vastly more seemless way but I didn’t go out of my way to find out a way to do it, this way just made the most sense. In the future, I’ll find out a better way.\nSo, the idea is:\n1. create new kaggle noteook with internet access\n2. install libraries\n3. run our models\n4. export our models\n5. download our libraries\n6. create new kaggle noteook with no internet access\n7. upload downloaded libraries and exported models\n8. install libraries via uploaded files\n9. import pre-trained models vias uploaded files\n10. conduct training\n11. make predictions 12. export to csv\n13. submit notebook"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#export-model-and-tokenizer",
    "href": "posts/kaggle/2-us-patents-offline/index.html#export-model-and-tokenizer",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "2. Export Model and Tokenizer",
    "text": "2. Export Model and Tokenizer\n\ndebv3_tokenizer.save_pretrained(\"./tokenizer\")\nmodel.save_pretrained(\"./model\")"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#download-libraries",
    "href": "posts/kaggle/2-us-patents-offline/index.html#download-libraries",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "3. Download Libraries",
    "text": "3. Download Libraries\nTwo libraries are required for this notebook to run datasets and transformers\n\n!pip download datasets\n!pip download transformers"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#upload-file-to-kaggle",
    "href": "posts/kaggle/2-us-patents-offline/index.html#upload-file-to-kaggle",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "4. Upload File to Kaggle",
    "text": "4. Upload File to Kaggle\n\n4.1 Gather files\nPlace all json files (tokenizer and model) and whl files (libraries) in the same folder.\n\n\n\n4.2 Kaggle Upload\n\nGo to [Datasets]\nThen [New Dataset]\nName a [Dataset Title]\nChoose all files from your local folder\nClick [Create]\n\n\n\n\n4.3 Load Succesful\nUpon completion, a greeting of success should appear.\n\n\n\n4.4 Add Data\n\nClick [Add Data]\nFilter for [Your Datasets]\nFind the uploaded Dataset"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#code",
    "href": "posts/kaggle/2-us-patents-offline/index.html#code",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "5. Code",
    "text": "5. Code\nIt’s almost the same code as the previous post so I’ve combined it altogether.\n\n!pip install --no-index --find-links=. transformers\n!pip install --no-index --find-links=. datasets\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments,Trainer\nfrom pathlib import Path\nfrom datasets import Dataset,DatasetDict\nimport pandas as pd\nimport numpy as np\nimport datasets\n\nmodel_nm = \"microsoft/deberta-v3-small\"\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching')\nmypath = Path('/kaggle/input/us-patents-libraries-model-tokenizer')\ntokenizer_uploaded  = AutoTokenizer.from_pretrained(mypath)\nmodel_uploaded = AutoModelForSequenceClassification.from_pretrained(mypath)\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\nds = Dataset.from_pandas(df)\ndef tok_func(x): return tokenizer_uploaded(x[\"input\"])\ntok_ds = ds.map(tok_func, batched=True)\ntok_ds = tok_ds.rename_columns({'score':'labels'})\ndds = tok_ds.train_test_split(0.25, seed=42)\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\nbs = 128\nepochs = 2\nlr = 8e-5\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\nmodel = AutoModelForSequenceClassification.from_pretrained(mypath, num_labels=1,ignore_mismatched_sizes=True)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokenizer_uploaded, compute_metrics=corr_d)\ntrainer.train()\npreds = trainer.predict(eval_ds).predictions.astype(float)\npreds = np.clip(preds, 0, 1)\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds.squeeze()\n})\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/kaggle/2-us-patents-offline/index.html#results",
    "href": "posts/kaggle/2-us-patents-offline/index.html#results",
    "title": "A Basic NLP model - [Competition Version]",
    "section": "6. Results",
    "text": "6. Results\nIt worked!"
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "",
    "text": "Today I’ll go through how to find and test different deep-learning architectures from Pytorch Image Models (timm) library made available here by Ross Wightman and use them in our models."
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html#using-timm---pytorch-image-models",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "1. Using timm - PyTorch Image Models",
    "text": "1. Using timm - PyTorch Image Models\n\n1.1 Introduction\nWhat are timm’s models? They’re mathematical functions (i.e. application of matrix multiplication, non-linearities e.g. ReLu’s)\nReference: “Which image model are best” - Jeremy Howard\nReference: “timm” - Ross Wightman\nWe want to know 3 things:\n1. how fast are they? You’d want models in top left of chart.\n2. how much memory?\n3. how accurate are they? Lower error rate the better.\n[Future iteration I]: A formalised metholodgy to decide what is fast enough, appropriate memory-use, and what is accurate enough for our use-cases.\nThere is a useful high-level chart from Jeremy’s notebook charting accuracy (Y-axis) vs secs per sample (X-axis):\n\nI chose to use a model from the convnext family due to its balance of high accuracy and speed.\n[Future iteration II]: Some more formalised methodology on choosing the architecture. Jeremy does mention architecture should be the one last thing things to worry about and he usually builds from resnet and tests whether it is, accurate enough and fast enough, then iterate from there.\n\n\n1.2 Import timm library\n\nimport timm\n\n\n\n1.3 List available model architectures and choose one\n\ntimm.list_models('convnext*') # * wild card searches \n\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_mlp',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnext_xlarge',\n 'convnext_xxlarge',\n 'convnextv2_atto',\n 'convnextv2_base',\n 'convnextv2_femto',\n 'convnextv2_huge',\n 'convnextv2_large',\n 'convnextv2_nano',\n 'convnextv2_pico',\n 'convnextv2_small',\n 'convnextv2_tiny']"
  },
  {
    "objectID": "posts/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "href": "posts/2024-01-23-99-testing-different_archs/index.html#create-your-learner-with-a-timm-model",
    "title": "How to choose a different Deep-Learning Model Architecture",
    "section": "2. Create your Learner with a timm model",
    "text": "2. Create your Learner with a timm model\n\n2.1 Get your data\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)/'images'\n\n\n\n2.2 Prepare your Functions\n\ndef is_cat(x): return x[0].isupper()\n\n\n\n2.3 Load your DataLoader\n\ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\n\n\n\n2.4 Build your Learner\n\nlearn_conv = vision_learner(dls, 'convnext_tiny', metrics=error_rate).to_fp16()\nlearn_resn = vision_learner(dls, 'resnet18', metrics=error_rate).to_fp16()\n\n\n\n2.5 Fine-Tune: ResNet18 vs ConvNextTiny\nA 90% reduction in the error rate! (0.6766% to 0.0667%: 1-(0.000677/0.006766)). It’s noted that the resnet error rate was quite low and changing the model was probably not necessary."
  },
  {
    "objectID": "posts/2024-01-16-98_post_without_code/index.html",
    "href": "posts/2024-01-16-98_post_without_code/index.html",
    "title": "Post Without Code",
    "section": "",
    "text": "Learning how to quarto blog.\nThis is a post with just this sentence."
  },
  {
    "objectID": "posts/leetcode/LC150.html",
    "href": "posts/leetcode/LC150.html",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/LC150.html#problem-description",
    "href": "posts/leetcode/LC150.html#problem-description",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an array of strings tokens that represents an arithmetic expression in a Reverse Polish Notation (RPN).\nInput: Evaluate the input RPN arithmetic expression.\nOutput: Return an integer that represents the value of the expression.\nRules:\n1. The valid operators are ‘+’, ‘-’, ‘*’, and ‘/’.\n2. Each operand may be an integer or another expression.\n3. The division between two integers always truncates toward zero\n4. There will not be any division by zero.\n5. The input represents a valid arithmetic expression in a reverse polish notation.\n6. The answer and all the intermediate calculations can be represented in a 32-bit integer."
  },
  {
    "objectID": "posts/leetcode/LC150.html#leetcode-examples",
    "href": "posts/leetcode/LC150.html#leetcode-examples",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "2. LeetCode Examples",
    "text": "2. LeetCode Examples\n\n2.1 Example 1\nInput: tokens = [\"2\",\"1\",\"+\",\"3\",\"*\"]\nOutput: 9\nExplanation: ((2 + 1) * 3) = 9\n\n\n2.2 Example 2\nInput: tokens = [\"4\",\"13\",\"5\",\"/\",\"+\"]\nOutput: 6\nExplanation: (4 + (13 / 5)) = 6\n\n\n2.3 Example 3\nInput: tokens = [\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"]\nOutput: 22\nExplanation:\n((10 * (6 / ((9 + 3) * -11))) + 17) + 5\n= ((10 * (6 / (12 * -11))) + 17) + 5\n= ((10 * (6 / -132)) + 17) + 5\n= ((10 * 0) + 17) + 5\n= (0 + 17) + 5\n= 17 + 5\n= 22"
  },
  {
    "objectID": "posts/leetcode/LC150.html#background-and-analysis",
    "href": "posts/leetcode/LC150.html#background-and-analysis",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "3. Background and Analysis",
    "text": "3. Background and Analysis\nThe wiki explains this is also known as postfix notation, the operators follow their operands, in contrast to prefix (Polish) notation (operators precede their operands).\n\n3.1 Wiki Example\nTo add 3 and 4 together, the expression is [3 4 +] rather than [3 + 4].\n- The conventional notation expression [3 − 4 + 5] becomes [3 4 − 5 +] in reverse Polish notation:\n- 4 is first subtracted from 3, then - 5 is added to it.\n\n\n3.2 Stack Explanation\nThe concept of a stack, a last-in/first-out construct. In the example [3 4 −]:\n1. push 3 to stack: [3] 2. push 4 to stack; ie 4 is now on top, 3 below it: [3 4] 3. apply subtraction operator: - Remove top two items from the stack: - performs 3 − 4, and 4. push the result of −1 to top of stack.\n\n\n3.3 Stack Explanation Table\n\n3.3.1 Example 1: [3 4 −] with all steps\n\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nOutput_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\nnull\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\nnull\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\nnull\npush 4 to stack_top\n\n\nrpn_obj.op()[pt_1]: .pop(top 2)\n[  ]\n[3,4]\npop [3] [4] stack_top_2\n\n\nrpn_obj.op()[pt_2]: .op(top 2)\n[-1]\n[3,4]\noperate(3,4,-) on stack_top_2\n\n\nrpn_obj.op()[pt_3]: .truncate(res)\n[-1]\n-1\nint(result), truncate to zero as per Rule_3\n\n\nrpn_obj.op()[pt_4]: .return()\n[-1]\n-1\nreturn operated result\n\n\nrpn_obj.op()[pt_5]: .push(result)\n[-1]\nnull\npush results stack_top\n\n\n\n\n\n3.3.2 Example 2: [3 4 × 5 6 × +] with concise steps\n\n\n\n\n\n\n\n\nPython Pseudocode\nStack_Expected\nComments\n\n\n\n\nrpn_obj = rpn_cls()\n[  ]\ninitialise stack\n\n\nrpn_obj.push(3)\n[3]\npush 3 to stack_top\n\n\nrpn_obj.push(4)\n[3,4]\npush 4 to stack_top\n\n\nrpn_obj.op(x)\n[12]\nrem top_2 3,4, op 3*4, push top 12\n\n\nrpn_obj.push(5)\n[12,5]\npush 5 to stack_top\n\n\nrpn_obj.push(6)\n[12,5,6]\npush 6 to stack_top\n\n\nrpn_obj.op(x)\n[12,30]\nrem top_2 5,6, op 5*6, push top 30\n\n\nrpn_obj.op(+)\n[meaning of life]\nrem top_2 12,30, op 12+30, push top 42\n\n\n\n\n\n\n3.3 Why?\nThe advantage of RPN is it:\n- removes the need for order of operations and parentheses that are required by infix notation and\n- can be evaluated linearly, left-to-right.\nFor example, the infix expression (3 × 4) + (5 × 6) becomes [3 4 × 5 6 × +] in reverse Polish notation.*"
  },
  {
    "objectID": "posts/leetcode/LC150.html#coding",
    "href": "posts/leetcode/LC150.html#coding",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "4. Coding",
    "text": "4. Coding\n\n4.1 Write pseudo-python-code\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        # Rule 5: Input expression is valid, no check required, \n        # ie doesn't start with operateor\n        if len(tokens) ==0: # check if no token \n            return 0 # Probably not needed due for R5 but wrote save time in case \n\n        stack = [] #initialise stack\n        stack.append(tokens[0])  # first item is valid due to R5 so set it to stk\n\n        ### [1]     operator functions/mapping (*,-,+,/)\n        ### [2]     .pop_top_2(stack):    \n        ### [3]     .operate(top_2_items, operator #[2.1]): \n\n        for i in range(1,len(tokens)):\n            # stack = [2]\n            curr_chr = tokens[i]\n\n            if curr_chr in operators:\n                top_2_items = [top_2, top_1] = pop_top_2(stack) # [1]\n                # [validation]: do spot check stacked removed top 2\n                res   = operate(top_2_items,curr_chr) #[2]\n                stack.append(res)\n\n            else: # is a valid integer so just append to top\n                stack.append(curr_chr)\n        return stack\n\n\n\n4.2 Write Required Functions\n\nclass Solution:\n    def evalRPN(self, tokens: [str]) -&gt; int:\n        if len(tokens) == 0: \n            return 0 \n        stack = []\n        stack.append(int(tokens[0])) \n\n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            print(f\"operator: {operator}, top2:{x2}, top1:{x1}\")\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            elif operator == '/':\n                return int(x2/x1)\n            else:\n                print(\"unknown operator!\")\n                return False\n                \n        def pop_top_2(stack):\n            print(len(stack))\n            if len(stack) &lt;2:\n                print(\"Stack too short!\")\n                return False\n            else:\n                top_1 = stack.pop()\n                top_2 = stack.pop()\n                top_2_items = [top_2,top_1]\n                print(top_2_items)\n            return top_2_items\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                operator = curr_chr\n                top_2_items = pop_top_2(stack) \n                res   = operate(operator, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        print(stack)\n        return stack\nsoln = Solution()"
  },
  {
    "objectID": "posts/leetcode/LC150.html#test-functionality",
    "href": "posts/leetcode/LC150.html#test-functionality",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "5. Test Functionality",
    "text": "5. Test Functionality\n\n5.1 Case 1 Expected 9\n\nsoln.evalRPN([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n2\n[2, 1]\noperator: +, top2:2, top1:1\n2\n[3, 3]\noperator: *, top2:3, top1:3\n[9]\n\n\n[9]\n\n\n\n\n5.2 Case 2 Expected 6\n\nsoln.evalRPN([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n3\n[13, 5]\noperator: /, top2:13, top1:5\n2\n[4, 2]\noperator: +, top2:4, top1:2\n[6]\n\n\n[6]\n\n\n\n\n5.3 Case 2 Expected 22\n\nsoln.evalRPN([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])  \n\n4\n[9, 3]\noperator: +, top2:9, top1:3\n4\n[12, -11]\noperator: *, top2:12, top1:-11\n3\n[6, -132]\noperator: /, top2:6, top1:-132\n2\n[10, 0]\noperator: *, top2:10, top1:0\n2\n[0, 17]\noperator: +, top2:0, top1:17\n2\n[17, 5]\noperator: +, top2:17, top1:5\n[22]\n\n\n[22]"
  },
  {
    "objectID": "posts/leetcode/LC150.html#clean-version",
    "href": "posts/leetcode/LC150.html#clean-version",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "6. Clean Version",
    "text": "6. Clean Version\n\nclass Solution:\n    def evalRPN_clean(self, tokens: [str]) -&gt; int:\n        stack = []\n        stack.append(int(tokens[0])) \n        operators = ['*', '+', '-', '/'] \n\n        def operate(operator,x2,x1):\n            if operator == '+':\n                return x2+x1\n            elif operator == '-':\n                return x2-x1\n            elif operator == '*':\n                return x2*x1\n            else:\n                return int(x2/x1)\n\n        def pop_top_2(stack):\n            top_1 = stack.pop()\n            top_2 = stack.pop()\n            return [top_2,top_1]\n\n        for i in range(1,len(tokens)):\n            curr_chr = tokens[i]\n            if curr_chr in operators:\n                top_2_items = pop_top_2(stack) \n                res   = operate(curr_chr, top_2_items[0],top_2_items[1])\n                stack.append(res)\n            else: \n                stack.append(int(curr_chr))\n        return stack[0] ############### fixed after submission 2  ###############\nsoln = Solution()\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22\n\n\n\n6.1 Clean Check\n\nsoln.evalRPN_clean([\"2\",\"1\",\"+\",\"3\",\"*\"])\n\n9\n\n\n\nsoln.evalRPN_clean([\"4\",\"13\",\"5\",\"/\",\"+\"])\n\n6\n\n\n\nsoln.evalRPN_clean([\"10\",\"6\",\"9\",\"3\",\"+\",\"-11\",\"*\",\"/\",\"*\",\"17\",\"+\",\"5\",\"+\"])\n\n22"
  },
  {
    "objectID": "posts/leetcode/LC150.html#submit",
    "href": "posts/leetcode/LC150.html#submit",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "7. Submit",
    "text": "7. Submit\n\nFirst attempt Failed, because I returned the stack as a list with result as the first item.\nSecond attempt Accepted! Quick fix after indexing out the value form the list. Not a bad result.\n\nTop 40% in Speed and\nTop 20% in Memory."
  },
  {
    "objectID": "posts/leetcode/LC150.html#notes-to-self.",
    "href": "posts/leetcode/LC150.html#notes-to-self.",
    "title": "LC: 150. Evaluate Reverse Polish Notation",
    "section": "6. Notes to self.",
    "text": "6. Notes to self.\nThis took alot of time setting up the problem, the solving part was quite fast.\nI need to be more seemless in set up!\n[Future Iterations 1]: Incorporate best solutions from LC\n[Future Iterations 2]: Attempt iterations for speed and memory\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/leetcode/LC155.html",
    "href": "posts/leetcode/LC155.html",
    "title": "LC: 155. Min Stack",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/LC155.html#problem-description",
    "href": "posts/leetcode/LC155.html#problem-description",
    "title": "LC: 155. Min Stack",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time.\nImplement the MinStack class:\n1. MinStack() initializes the stack object.\n2. void push(int val) pushes the element val onto the stack.\n3. void pop() removes the element on the top of the stack.\n4. int top() gets the top element of the stack.\n5. int getMin() retrieves the minimum element in the stack.\n\n1.1 LeetCode example\nInput:\n[\"MinStack\",\"push\",\"push\",\"push\",\"getMin\",\"pop\",\"top\",\"getMin\"]\n[[],[-2],[0],[-3],[],[],[],[]]\nOutput:\n[null,null,null,null,-3,null,0,-2]"
  },
  {
    "objectID": "posts/leetcode/LC155.html#analysis",
    "href": "posts/leetcode/LC155.html#analysis",
    "title": "LC: 155. Min Stack",
    "section": "2. Analysis",
    "text": "2. Analysis\nI’ve decomposed the Inputs (code + variables) and expected outputs (stack and return values) for each line of code run.\n[Future Iteration 1]: Learn how to assert or include code that checks inputs what they are expected in an automatic way (The Output_Mine should be filled later hopefully automatically. For now, I eyeball the results and have LeetCode accept whether its passing or failing)\n[Future Iteration 2]: I’m using Python Lists, I could do the same attempt with chr and string types as parentheses are simply characters.\n\n2.1 Summary Table\n\n\n\nPython_Executed\nStack_Expected\nOutput_Expected\nOutput_Mine\n\n\n\n\nMinStack minStack = new MinStack();\n[]\nnull\nasdf\n\n\nminStack.push(-2);\n[-2]\nnull\nasdf\n\n\nminStack.push(0)\n[0,-2]\nnull\nasdf\n\n\nminStack.push(-3);\n[-3,0,-2]\nnull\nasdf\n\n\nminStack.getMin()\n[-3,0,-2]\n-3\nasdf\n\n\nminStack.pop()\n[0,-2]\nnull\nasdf\n\n\nminStack.top()\n[0,-2]\n0\nasdf\n\n\nminStack.getMin()\n[0,-2]\n-2\nasdf"
  },
  {
    "objectID": "posts/leetcode/LC155.html#code",
    "href": "posts/leetcode/LC155.html#code",
    "title": "LC: 155. Min Stack",
    "section": "3. Code",
    "text": "3. Code\nWrite the MinStack() class and its requried methods.\n\nclass MinStack():\n    def __init__(self):\n        self.stack = [] # create empty list\n\n    def push(self, val: int) -&gt; None:\n        self.stack.append(val) # add value to end of list\n\n    def pop(self) -&gt; None:\n        self.stack.pop() # remove last val of the list\n\n    def top(self) -&gt; int:\n        return self.stack[-1] # in a list, top of stack is the last item list[-1]\n    \n    def getMin(self) -&gt; int:\n        return min(self.stack)"
  },
  {
    "objectID": "posts/leetcode/LC155.html#test-functionality",
    "href": "posts/leetcode/LC155.html#test-functionality",
    "title": "LC: 155. Min Stack",
    "section": "4. Test Functionality",
    "text": "4. Test Functionality\n\nminStack = MinStack()\n\n\nminStack.push(-2);\n\n\nminStack.push(0);\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.push(-3);\nminStack.stack\n\n[-2, 0, -3]\n\n\n\nminStack.getMin() # // return -3\n# minStack.stack\n\n-3\n\n\n\nminStack.pop();\nminStack.stack\n\n[-2, 0]\n\n\n\nminStack.top() # return 0\n\n0\n\n\n\nminStack.getMin() # return -2\n\n-2"
  },
  {
    "objectID": "posts/leetcode/LC155.html#submit",
    "href": "posts/leetcode/LC155.html#submit",
    "title": "LC: 155. Min Stack",
    "section": "5. Submit",
    "text": "5. Submit\nThe code is slow but great memory management.\nAt the my current level, I’m happy to simply solve the problems. I don’t usually solve Mediums that easily."
  },
  {
    "objectID": "posts/leetcode/LC155.html#some-commentary",
    "href": "posts/leetcode/LC155.html#some-commentary",
    "title": "LC: 155. Min Stack",
    "section": "6. Some Commentary",
    "text": "6. Some Commentary\nThe question is framed from a Java’s perspective hence there are types in front of each declaration:\n- void pop()\n- int top()\n- new MinStack()\nNote: I’ve never touched Java 🤭.\nJava is a Static-Typed whilst Python is a Dynamically-Type.\n\nJava requires variables and method return values be explicitly declared at compile-time.\nPython data types are determined at runtime.\n\nPython doesn’t require explicit type declarations for variables, function return types, or when creating objects.\n\n\nThat is, since I’m using Python, so I won’t need to declare my return types when creating a method of a class.\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/leetcode/index.html",
    "href": "posts/leetcode/index.html",
    "title": "❄️LeetCode Posts❄️",
    "section": "",
    "text": "link to leetcode profile here\n\nCreated new leetcode.qmd based on front page index.qmd and\n\nDirected contents to point here: contents: posts/lc_posts.\n\nProbably not the ideal blog + folder structure but it’ll do the job👌.\nI don’t claim to be a web-designer in any sense 😂.\nI began 3 months ago with no algorithm or data structures academic background at all. The Easys were definitey not Easy to me as you can see from the number of submissions.\nThe majority of submissions were 2-3 months ago and I made no attempts in January 2024 👏.\nThis page should keep me accountable and these fingers minty as a mojito on a hot day 🍹."
  },
  {
    "objectID": "posts/2024-01-16-97_post_with_notebook/index.html",
    "href": "posts/2024-01-16-97_post_with_notebook/index.html",
    "title": "Post With Sample Jupyter Notebook",
    "section": "",
    "text": "Learning how quarto works with jupyter notebooks. This is a sample editted notebook from fastai.\n\nfrom fastai.vision.all import *\nchosen_sample_seed          = 42\nchosen_sample_n             = 5\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n# useful informative functions\ndef print_useful_info():\n    global path_dir_obj, list_all_img_path_obj\n    print()\n    print(f\"path_obj_home_dir: \\t{path_dir_obj}\")\n    print(f\"image_list_count: \\t{len(list_all_img_path_obj)}\")\n    return None\n\ndef print_sample_imgs():\n    global path_dir_obj, list_all_img_path_obj, chosen_sample_seed, chosen_sample_n\n    import random\n    set_seed(chosen_sample_seed)\n    print(f\"set_seed_number: \\t{chosen_sample_seed}\")\n    rng         = len(list_all_img_path_obj)-1  # Replace 10 with the desired upper limit (exclusive)\n    random_nos  = random.sample(range(rng), chosen_sample_n)\n    print()\n    print(\"sample_images:\")\n    for index, img_path in enumerate(list_all_img_path_obj[random_nos]):\n        print(f\" {random_nos[index]:&gt;7}: \\t\\t{img_path}\")\n    \n    \n    for image_path in list_all_img_path_obj[random_nos]:\n        img = PILImage.create(image_path)\n        show_image(img)\n    return None\n\n\n# 0. get paths of images\npath_dir_obj                = untar_data(URLs.MNIST_TINY)\nlist_all_img_path_obj       = get_image_files(path_dir_obj)\n\n\n# 1. create learner\ndata_loader = ImageDataLoaders.from_folder(path_dir_obj, \n                                    img_cls=PILImageBW,\n                                    set_seed=42)\nx1,y1 = data_loader.one_batch()\ntest_eq(x1.shape, [64, 1, 28, 28])\n\nprint_useful_info()\nprint_sample_imgs()\n# check valid data sets - can check if splits are as expected\nprint(len(data_loader.valid_ds.items)) # 699 as expected\nprint(len(data_loader.train_ds.items)) # 709 as expected\n\n# can show sample pics\ndata_loader.show_batch() #show examples?\n\n\npath_obj_home_dir:  C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\nimage_list_count:   1428\nset_seed_number:    42\n\nsample_images:\n    1309:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\valid\\7\\9036.png\n     228:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\8830.png\n      51:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\3\\731.png\n     563:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\868.png\n     501:       C:\\Users\\tonyp\\.fastai\\data\\mnist_tiny\\train\\7\\8186.png\n699\n709\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnbr_learner = vision_learner(data_loader, resnet34, metrics=error_rate)\n\n\nnbr_learner.fine_tune(4)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/11 00:00&lt;?]\n    \n    \n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.303663\n0.174878\n0.054363\n00:21\n\n\n1\n0.228222\n0.127563\n0.040057\n00:20\n\n\n2\n0.172806\n0.091346\n0.027182\n00:21\n\n\n3\n0.139439\n0.056558\n0.015737\n00:21\n\n\n\n\n\n\nfrom IPython.display import Image # import image viewer\n\n\n\nuploader = SimpleNamespace(data = ['3.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [0], representing [3]\")\n\n\n\n\n\n\n\n\n3\ntensor(0)\ntensor([9.9998e-01, 2.1658e-05])\ncorrectly guessed the [0], representing [3]\n\n\n\n\nuploader = SimpleNamespace(data = ['7.png'])\nimage_path = uploader.data[0]\nImage(filename=image_path)\nres1, res2, res3 = nbr_learner.predict(image_path) # predict unseen input using LEARNER\nprint(res1,res2,res3, sep=\"\\n\") #fix output formatting later\nprint(\"correctly guessed the [1], representing [7]\")\n\n\n\n\n\n\n\n\n\n7\ntensor(1)\ntensor([0.0050, 0.9950])\ncorrectly guessed the [1], representing [7]"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "notes",
    "section": "",
    "text": "DSA: Binary Search Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 2 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex23, Thomas 13e pp.126\n\n\n\n\n\nJan 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA: Array and Sets Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 1 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 5, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex17, Thomas 13e pp.126\n\n\n\n\n\nJan 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Applying Binomial Theorem\n\n\n\n\n\n\ncalculus\n\n\nbinomial theorem\n\n\n\nFind the derivative and plot the tangent (from Ch3.1.Ex9, Thomas 13e pp.126)\n\n\n\n\n\nJan 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nBig-O: Arrays and Sets\n\n\n\n\n\n\npython\n\n\n\nBig-O for Array Operations\n\n\n\n\n\nJan 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Metaclasses: Customising Class Creation\n\n\n\n\n\n\npython\n\n\n\nBeing very meta\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSingleton Pattern\n\n\n\n\n\n\npython\n\n\n\nA Design (or Anti) Pattern Allowing Only A Single Instance\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMagic Method: __call__\n\n\n\n\n\n\npython\n\n\n\nAllowing instances to be called like functions\n\n\n\n\n\nDec 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nUnicode, UTF-8 and Bytes\n\n\n\n\n\n\npython\n\n\n\nConverting my (Chinese) name to bytes and back\n\n\n\n\n\nDec 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Synthetic Division\n\n\n\n\n\n\ncalculus\n\n\n\nLearning a factoring technique (from Ex 2.2.85, Thomas 13e pp.77)\n\n\n\n\n\nDec 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting functions with limits\n\n\n\n\n\n\ncalculus\n\n\nlimits\n\n\n\nCh2.2: Limit of a Function & Limit Laws (Ex2.2.11-21, Thomas 13e pp.74)\n\n\n\n\n\nDec 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nInterfaces [Part 2]: Protocols\n\n\n\n\n\n\npython\n\n\n\nProgramming to Interfaces rather than Implementation specificsgit\n\n\n\n\n\nDec 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nInterfaces [Part 1]: ABC Abstract Base Classes\n\n\n\n\n\n\npython\n\n\n\nProgramming to Interfaces rather than Implementation specifics\n\n\n\n\n\nDec 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nuv Python & Package Manager\n\n\n\n\n\n\npython\n\n\n\nA modern alternative to creating & managing Python projects\n\n\n\n\n\nDec 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEncapsulation: Getter Method in Python\n\n\n\n\n\n\ndesign patterns\n\n\nencapsulation\n\n\npython\n\n\n\nUsing Python’s @property to create a getter method\n\n\n\n\n\nNov 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Exceptions 101\n\n\n\n\n\n\npython\n\n\n\nDel ving into Python Exceptions, In-Builts vs Custom Exceptions, Assert, Raise and Exception-Handlers\n\n\n\n\n\nNov 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to C# in Visual Studio Code\n\n\n\n\n\n\nc#\n\n\nvscode\n\n\n\nCreating, Building and Running Simple C# Console Apps\n\n\n\n\n\nOct 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTransfer Multiple Issues via Github API in Bash\n\n\n\n\n\n\ngithub\n\n\nbash\n\n\n\nRun a simple loop to transfer multiple issues from one repo to another\n\n\n\n\n\nOct 29, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Source as a Beginner\n\n\n\n\n\n\npython\n\n\n\nLearning How To Contribute to Open Source Projects as a Beginner\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Classes Basics 101\n\n\n\n\n\n\npython\n\n\n\nPython Classes, Instance Objects, Data Attributes and Method Objects\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nShallow or Deep?\n\n\n\n\n\n\npython\n\n\n\nLearning to copy the right way\n\n\n\n\n\nOct 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreate new key-bindings in VSCode via JSON file\n\n\n\n\n\n\nvscode\n\n\n\nA handy keybinding to switch between Terminals in VSCode\n\n\n\n\n\nOct 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Inverse Properties of \\(a^x\\) and \\(\\log_a x\\)\n\n\n\n\n\n\ncalculus\n\n\nmathematics\n\n\nhand-written\n\n\n\nExploring the compositions of \\(a^x\\), \\(\\log_a x\\), \\(e^x\\) and \\(\\ln x\\) and deriving the Change of Base formula\n\n\n\n\n\nOct 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Github API via Python\n\n\n\n\n\n\napi python\n\n\n\nLearn to update an Issue Description with Github’s API\n\n\n\n\n\nOct 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAdd a script to PATH\n\n\n\n\n\n\nlinux\n\n\n\nRun a script without specifying its path\n\n\n\n\n\nSep 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreating and using Symlinks\n\n\n\n\n\n\nlinux\n\n\n\nAvoiding unnecessarily duplicating files with Symlinks\n\n\n\n\n\nSep 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to install Quarto via WSL\n\n\n\n\n\n\nlinux\n\n\n\nMigrating quarto blog from windows to wsl\n\n\n\n\n\nSep 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nVirtual Environments: 3 different ways\n\n\n\n\n\n\ncoding\n\n\n\nSetting up virtual environments to produce reproducible work\n\n\n\n\n\nJul 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring Model Accuracy\n\n\n\n\n\n\ncoding\n\n\nmetrics\n\n\n\nStep-by-step guide on how to measure accuracy of a deeplearning model\n\n\n\n\n\nApr 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDebugging a 1-Hidden-Layer Neural Network Model\n\n\n\n\n\n\ncoding\n\n\ndebugging\n\n\n\nDocumenting my debugging of a neural network model I built from scratch\n\n\n\n\n\nApr 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreate new Users in WSL\n\n\n\n\n\n\ncoding\n\n\n\nQuick instructions to set up a new user in wsl\n\n\n\n\n\nMar 15, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nBash Basics\n\n\n\n\n\n\ncoding\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMore Eigen examples\n\n\n\n\n\n\nlinear algebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s nice to be similar (matrices)\n\n\n\n\n\n\nlinear algebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDiagonal Matrices are trivial\n\n\n\n\n\n\nlinear algebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a Data Science Machine\n\n\n\n\n\n\ncoding\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinear algebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAutomate the closing of Issues in Github Projects\n\n\n\n\n\n\ncoding\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigen is my valentines in 2024\n\n\n\n\n\n\nlinear algebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNotes: Change of Basis\n\n\n\n\n\n\nlinear algebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "DSA: Binary Search Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 2 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 7, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex23, Thomas 13e pp.126\n\n\n\n\n\nJan 6, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDSA: Array and Sets Exercises\n\n\n\n\n\n\ndata structures\n\n\nalgorithms\n\n\n\nChapter 1 Exercises, J.Wengrow Vol 2\n\n\n\n\n\nJan 5, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Find A Derivative And Tangent\n\n\n\n\n\n\ncalculus\n\n\n\nFrom Ch3.1.Ex17, Thomas 13e pp.126\n\n\n\n\n\nJan 4, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Applying Binomial Theorem\n\n\n\n\n\n\ncalculus\n\n\nbinomial theorem\n\n\n\nFind the derivative and plot the tangent (from Ch3.1.Ex9, Thomas 13e pp.126)\n\n\n\n\n\nJan 2, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nBig-O: Arrays and Sets\n\n\n\n\n\n\npython\n\n\n\nBig-O for Array Operations\n\n\n\n\n\nJan 1, 2025\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Metaclasses: Customising Class Creation\n\n\n\n\n\n\npython\n\n\n\nBeing very meta\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSingleton Pattern\n\n\n\n\n\n\npython\n\n\n\nA Design (or Anti) Pattern Allowing Only A Single Instance\n\n\n\n\n\nDec 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMagic Method: __call__\n\n\n\n\n\n\npython\n\n\n\nAllowing instances to be called like functions\n\n\n\n\n\nDec 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nUnicode, UTF-8 and Bytes\n\n\n\n\n\n\npython\n\n\n\nConverting my (Chinese) name to bytes and back\n\n\n\n\n\nDec 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Synthetic Division\n\n\n\n\n\n\ncalculus\n\n\n\nLearning a factoring technique (from Ex 2.2.85, Thomas 13e pp.77)\n\n\n\n\n\nDec 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting functions with limits\n\n\n\n\n\n\ncalculus\n\n\nlimits\n\n\n\nCh2.2: Limit of a Function & Limit Laws (Ex2.2.11-21, Thomas 13e pp.74)\n\n\n\n\n\nDec 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nInterfaces [Part 2]: Protocols\n\n\n\n\n\n\npython\n\n\n\nProgramming to Interfaces rather than Implementation specificsgit\n\n\n\n\n\nDec 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nInterfaces [Part 1]: ABC Abstract Base Classes\n\n\n\n\n\n\npython\n\n\n\nProgramming to Interfaces rather than Implementation specifics\n\n\n\n\n\nDec 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nuv Python & Package Manager\n\n\n\n\n\n\npython\n\n\n\nA modern alternative to creating & managing Python projects\n\n\n\n\n\nDec 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEncapsulation: Getter Method in Python\n\n\n\n\n\n\ndesign patterns\n\n\nencapsulation\n\n\npython\n\n\n\nUsing Python’s @property to create a getter method\n\n\n\n\n\nNov 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Exceptions 101\n\n\n\n\n\n\npython\n\n\n\nDel ving into Python Exceptions, In-Builts vs Custom Exceptions, Assert, Raise and Exception-Handlers\n\n\n\n\n\nNov 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to C# in Visual Studio Code\n\n\n\n\n\n\nc#\n\n\nvscode\n\n\n\nCreating, Building and Running Simple C# Console Apps\n\n\n\n\n\nOct 30, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTransfer Multiple Issues via Github API in Bash\n\n\n\n\n\n\ngithub\n\n\nbash\n\n\n\nRun a simple loop to transfer multiple issues from one repo to another\n\n\n\n\n\nOct 29, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Source as a Beginner\n\n\n\n\n\n\npython\n\n\n\nLearning How To Contribute to Open Source Projects as a Beginner\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPython Classes Basics 101\n\n\n\n\n\n\npython\n\n\n\nPython Classes, Instance Objects, Data Attributes and Method Objects\n\n\n\n\n\nOct 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nShallow or Deep?\n\n\n\n\n\n\npython\n\n\n\nLearning to copy the right way\n\n\n\n\n\nOct 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreate new key-bindings in VSCode via JSON file\n\n\n\n\n\n\nvscode\n\n\n\nA handy keybinding to switch between Terminals in VSCode\n\n\n\n\n\nOct 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCalculus: Inverse Properties of \\(a^x\\) and \\(\\log_a x\\)\n\n\n\n\n\n\ncalculus\n\n\nmathematics\n\n\nhand-written\n\n\n\nExploring the compositions of \\(a^x\\), \\(\\log_a x\\), \\(e^x\\) and \\(\\ln x\\) and deriving the Change of Base formula\n\n\n\n\n\nOct 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Github API via Python\n\n\n\n\n\n\napi python\n\n\n\nLearn to update an Issue Description with Github’s API\n\n\n\n\n\nOct 1, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAdd a script to PATH\n\n\n\n\n\n\nlinux\n\n\n\nRun a script without specifying its path\n\n\n\n\n\nSep 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreating and using Symlinks\n\n\n\n\n\n\nlinux\n\n\n\nAvoiding unnecessarily duplicating files with Symlinks\n\n\n\n\n\nSep 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to install Quarto via WSL\n\n\n\n\n\n\nlinux\n\n\n\nMigrating quarto blog from windows to wsl\n\n\n\n\n\nSep 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nVirtual Environments: 3 different ways\n\n\n\n\n\n\ncoding\n\n\n\nSetting up virtual environments to produce reproducible work\n\n\n\n\n\nJul 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCollaborative Filtering - Latent Factor Matrix (Part 1)\n\n\n\n\n\n\nmachine learning\n\n\n\nCreating Latent Factors Matrix using set of Users, Items and Ratings\n\n\n\n\n\nMay 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Feature Importance Plot (Part 4)\n\n\n\n\n\n\nmachine learning\n\n\n\nBuilding a Feature Importance Plot in a few lines of code\n\n\n\n\n\nApr 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Random Forest Classifier (Part 3)\n\n\n\n\n\n\nmachine learning\n\n\n\nBuilding a Random Forest Classifier with the Sklearn framework\n\n\n\n\n\nApr 26, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - Decision Tree Classifier (Part 2)\n\n\n\n\n\n\nmachine learning\n\n\n\nBuilding a Decision Tree Classifier from scratch and then a framework called Sklearn\n\n\n\n\n\nApr 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests - OneR Classifier (Part 1)\n\n\n\n\n\n\nmachine learning\n\n\n\nBuilding a OneR classifier model from scratch\n\n\n\n\n\nApr 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring Model Accuracy\n\n\n\n\n\n\ncoding\n\n\nmetrics\n\n\n\nStep-by-step guide on how to measure accuracy of a deeplearning model\n\n\n\n\n\nApr 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nTabular Deep-Learning Model\n\n\n\n\n\n\ndeep learning\n\n\n\nBuilding a Deep-Learning Neural Network Model from scratch based on tabular data\n\n\n\n\n\nApr 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDebugging a 1-Hidden-Layer Neural Network Model\n\n\n\n\n\n\ncoding\n\n\ndebugging\n\n\n\nDocumenting my debugging of a neural network model I built from scratch\n\n\n\n\n\nApr 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nCreate new Users in WSL\n\n\n\n\n\n\ncoding\n\n\n\nQuick instructions to set up a new user in wsl\n\n\n\n\n\nMar 15, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nRectified Linear Unit (ReLU)\n\n\n\n\n\n\nbasics\n\n\n\nReLU from scratch with Gradient Descent\n\n\n\n\n\nMar 13, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Make Some Noise\n\n\n\n\n\n\nbasics\n\n\n\nA function to add gaussian noise\n\n\n\n\n\nMar 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nBash Basics\n\n\n\n\n\n\ncoding\n\n\n\nLearning Bash from scratch\n\n\n\n\n\nFeb 28, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nMore Eigen examples\n\n\n\n\n\n\nlinear algebra\n\n\n\nA few more worked examples\n\n\n\n\n\nFeb 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s nice to be similar (matrices)\n\n\n\n\n\n\nlinear algebra\n\n\n\nShort working equating eigenvalues between two similar matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDiagonal Matrices are trivial\n\n\n\n\n\n\nlinear algebra\n\n\n\nShowing the wonderful characteristics of Diagonal Matrices\n\n\n\n\n\nFeb 22, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a Data Science Machine\n\n\n\n\n\n\ncoding\n\n\n\nHow to setup a Linux-based Python on a Windows PC for Data Science and Deep Learning Projects\n\n\n\n\n\nFeb 21, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvales and Eigenvectors Example\n\n\n\n\n\n\nlinear algebra\n\n\n\nWorking out some algebraic examples\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nAutomate the closing of Issues in Github Projects\n\n\n\n\n\n\ncoding\n\n\n\nHow to automate the closing of an issue in Github Projects via a Commit Message\n\n\n\n\n\nFeb 20, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model - [Competition Version]\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nEigen is my valentines in 2024\n\n\n\n\n\n\nlinear algebra\n\n\n\nEigenvalues and Eigenvectors Mind-Map\n\n\n\n\n\nFeb 14, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 74. Search a 2D Matrix\n\n\n\n\n\n\nleetcode\n\n\n\nAlmost the same as binary search problem\n\n\n\n\n\nFeb 10, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 704. Binary Search\n\n\n\n\n\n\nleetcode\n\n\n\nFirst binary search question\n\n\n\n\n\nFeb 9, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNotes: Change of Basis\n\n\n\n\n\n\nlinear algebra\n\n\n\nAn interpretation of change of basis\n\n\n\n\n\nFeb 8, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 150. Evaluate Reverse Polish Notation\n\n\n\n\n\n\nleetcode\n\n\n\nImplement a Stack Class using Postfix Notation\n\n\n\n\n\nFeb 7, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nLC: 155. Min Stack\n\n\n\n\n\n\nleetcode\n\n\n\nAn introduction to .append(), .pop() and .min() list functions and creating them as method as part of a class\n\n\n\n\n\nFeb 6, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\n❄️LeetCode Posts❄️\n\n\n\n\n\n\nleetcode\n\n\nhello world\n\n\n\nA page to archive my (naively hopeful daily) leetcode attempts.\n\n\n\n\n\nFeb 5, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in a Spreadsheet (Attempt 1)\n\n\n\n\n\n\nspreadsheet\n\n\n\nA failed attempt to apply neural network concepts in a spreadsheet\n\n\n\n\n\nFeb 4, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 3)\n\n\n\n\n\n\nbasics\n\n\n\nCreating the ReLU Function \n\n\n\n\n\nFeb 3, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 2)\n\n\n\n\n\n\nbasics\n\n\n\nOptimising with Gradient Descent\n\n\n\n\n\nFeb 2, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Network Basics (Part 1)\n\n\n\n\n\n\nbasics\n\n\n\nManually fitting a Line (Quadratic Function) to a dataset\n\n\n\n\n\nJan 31, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow To Setup a Kaggle API\n\n\n\n\n\n\nkaggle\n\n\n\nContinuing my Data Science journey with Kaggle\n\n\n\n\n\nJan 27, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\n\n\n\n\n\n\napp\n\n\n\nHost a neural network app live on HuggingFace\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)\n\n\n\n\n\n\napp\n\n\n\nCreate a local neural network Gradio App\n\n\n\n\n\nJan 25, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)\n\n\n\n\n\n\nclassifier\n\n\n\nCreate a simple neural network model\n\n\n\n\n\nJan 24, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nHow to choose a different Deep-Learning Model Architecture\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nSaving a Fast AI Model\n\n\n\n\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying My First Live App & it’s a Neural Network!\n\n\n\n\n\n\napp\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nImage Classifier 1: Noodles vs Rice\n\n\n\n\n\n\nclassifier\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Git Clone\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Sample Jupyter Notebook\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nPost Without Code\n\n\n\n\n\n\nquarto test\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nquarto test\n\n\nhello world\n\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "This is a blog is my journey from applied finance into (a hopefully useful) developer.\nA Poem of Oreo\nIn a bustling town of Ultimo, where city lights gleam,\nA tale unfolds of Oreo, a kitten’s sweet dream.\nTony brought him home with Lilo by his side,\nA tuxedo cat, in black and white pride.\nOreo, a Maine Coon with a fluffy coat,\nBlack all over, with white around his throat.\nWhite paws that dance, a playful delight,\nA mischievous gleam in his eyes, shining bright.\nLilo, a tiny British Shorthair so fair,\nA dainty companion with a gentle air.\nThey grew up together, a dynamic pair,\nFrom Ultimo to Pyrmont, a journey to share.\nThrough the streets of Townhall, they explored,\nAdventures aplenty, their spirits soared.\nYet, runaway moments were a frequent feat,\nFound and embraced, their connection so sweet.\nOreo, a rogue, with a penchant for bins,\nA greedy delight, where the treasure begins.\nFeasting on scraps, his appetite vast,\nBut his cuteness prevails, a spell he has cast.\nLilo, petite, with a modest cuisine,\nA nibble here, a delicate routine.\nShe watches Oreo with curious eyes,\nAs he plays around, chasing butterflies.\nIn the city’s heartbeat, their story unfolds,\nThrough alleys and parks, where the tale molds.\nOreo, the player, with antics so grand,\nLilo, the watcher, in the city so grand.\nNow, in the world of influencers and fame,\nOreo has found his claim to the game.\nAn influencer cat, with followers galore,\nFrom bins to glamour, a journey to adore.\nThrough Ultimo, Pyrmont, and Townhall’s embrace,\nOreo and Lilo found their special place.\nA tale of friendship, of mischief and grace,\nIn the city’s heartbeat, a memory to trace."
  },
  {
    "objectID": "posts/2024-01-16-96_post_with_git_clone/index.html",
    "href": "posts/2024-01-16-96_post_with_git_clone/index.html",
    "title": "Post With Git Clone",
    "section": "",
    "text": "Learning how git work and\nthis is a post initiated by cloning existing repo."
  },
  {
    "objectID": "posts/2024-04-25-decision_tree_classifier/index.html#male-training-set",
    "href": "posts/2024-04-25-decision_tree_classifier/index.html#male-training-set",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "3.1 Male Training Set",
    "text": "3.1 Male Training Set\n\n{col_name:calc_best_bin_split_per_col(trn_males, col_name) for col_name in all_cols}\n\n{'Embarked': (0, 0.3875581870410906),\n 'Age': (6.0, 0.3739828371010595),\n 'SibSp': (4, 0.3875864227586273),\n 'Parch': (0, 0.3874704821461959),\n 'LogFare': (2.803360380906535, 0.3804856231758151),\n 'Pclass': (1, 0.38155442004360934)}"
  },
  {
    "objectID": "posts/2024-04-25-decision_tree_classifier/index.html#female-training-set",
    "href": "posts/2024-04-25-decision_tree_classifier/index.html#female-training-set",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "3.2 Female Training Set",
    "text": "3.2 Female Training Set\n\n{col_name:calc_best_bin_split_per_col(trn_females, col_name) for col_name in all_cols}\n\n{'Embarked': (0, 0.4295252982857327),\n 'Age': (50.0, 0.4225927658431649),\n 'SibSp': (4, 0.42319212059713535),\n 'Parch': (3, 0.4193314500446158),\n 'LogFare': (4.256321678298823, 0.41350598332911376),\n 'Pclass': (2, 0.3335388911567601)}"
  },
  {
    "objectID": "posts/2024-04-25-decision_tree_classifier/index.html#max-4-nodes",
    "href": "posts/2024-04-25-decision_tree_classifier/index.html#max-4-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.1 Max 4 nodes",
    "text": "5.1 Max 4 nodes\nStart with maximum 4 nodes.\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nm_DecTree_max4nodes = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_idep, trn_dep)\n\n\nimport graphviz\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n                      special_characters=True, rotate=False, precision=precision, **kwargs)\n    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))"
  },
  {
    "objectID": "posts/2024-04-25-decision_tree_classifier/index.html#draw-the-decision-tree-with-4-nodes",
    "href": "posts/2024-04-25-decision_tree_classifier/index.html#draw-the-decision-tree-with-4-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.2 Draw the Decision Tree with 4 nodes",
    "text": "5.2 Draw the Decision Tree with 4 nodes\nThe model applied 1R to two levels and determined the same splits I did. Graph terminology: - colour: Blue is high survival rate, Orange is low survival rate. - samples: rows matching the set of rules - values: how many survived or perished, hence two values. - gini: measure of impurity, 1 means the whole group is the same, 0 means all rows are different\n\ndraw_tree(m_DecTree_max4nodes, trn_idep, size=10)\n\n\n\n\n\n\n\n\n\n5.2.1 Loss (DTree, max 4 leaf nodes)\nMAE 22.4%\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(val_dep, m_DecTree_max4nodes.predict(val_idep))\n\n0.2242152466367713"
  },
  {
    "objectID": "posts/2024-04-25-decision_tree_classifier/index.html#decision-tree-with-minimum-50-leaf-nodes",
    "href": "posts/2024-04-25-decision_tree_classifier/index.html#decision-tree-with-minimum-50-leaf-nodes",
    "title": "Random Forests - Decision Tree Classifier (Part 2)",
    "section": "5.3 Decision Tree with minimum 50 leaf nodes",
    "text": "5.3 Decision Tree with minimum 50 leaf nodes\n\nm_DecTree_min50nodes = DecisionTreeClassifier(min_samples_leaf=50)\nm_DecTree_min50nodes.fit(trn_idep, trn_dep)\ndraw_tree(m_DecTree_min50nodes, trn_idep, size=25)\n\n\n\n\n\n\n\n\n\n5.3.1 Loss (DTree, min 50 leaf nodes)\nMAE 18.4% (previous model 22.4%)\n\nmean_absolute_error(val_dep, m_DecTree_min50nodes.predict(val_idep))\n\n0.18385650224215247"
  },
  {
    "objectID": "posts/leetcode/LC704.html",
    "href": "posts/leetcode/LC704.html",
    "title": "LC: 704. Binary Search",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/LC704.html#problem-description",
    "href": "posts/leetcode/LC704.html#problem-description",
    "title": "LC: 704. Binary Search",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nGiven an array of integers nums which is sorted in:\n- ascending order, and an\n- integer target,\n- write a function to search target in nums.\n\nIf target exists, then\n\nreturn its index\n\n\nOtherwise,\n\nreturn -1\n\n\nYou must write an algorithm with O(log n) runtime complexity.\n\n1.1 Example 1:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 9\nOutput: 4\nExplanation: 9 exists in nums and its index is 4\n\n\n1.2 Example 2:\nInput: nums = [-1,0,3,5,9,12]\ntarget = 2\nOutput: -1\nExplanation: 2 does not exist in nums so return -1"
  },
  {
    "objectID": "posts/leetcode/LC704.html#code",
    "href": "posts/leetcode/LC704.html#code",
    "title": "LC: 704. Binary Search",
    "section": "3. Code",
    "text": "3. Code\nTest the cases that its larger, smaller and on the split.\n\n3.1 larger than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],  1, {2}, 3, *4*, [5]]\n           # [[-1], 0, {3}, 5, *9*, [12]] \n            if nums[m]&lt;target: #if 3&lt;9:\n                l = m + 1\n           # [[3], *4*, [5]]\n           # [[5], *9*, [12]] \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1\n    \narr = [-1,0,3,5,9,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n4\n\n\n\n\n3.2 less than binary split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{-1}, 9, {10}, 11, 12, [12]] \n            \n            if nums[m]&lt;target:\n                l = m + 1\n\n           # [[0],*1*,{2},3,*4*,[5]]\n           # [{-1}, *9*, {10}, 11, 12, [12]] \n                \n            elif nums[m]&gt;target:\n                \n           # [[0],*1*,[2],3,*4*,[5]]\n           # [{-1}, *9*, [10], 11, 12, [12]]                \n                r = m\n            else:\n                return m\n        return -1\n\narr = [-1,9,10,11,12,12]\nsoln = Solution()\nsoln.search(arr, 9)\n\n1\n\n\n\n\n3.3 On a split\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n           # [[0],1,{2},3,*4*,[5]]\n           # [{7}, 8, {*9*}, 11, 12, [13]] \n            \n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:          \n                r = m\n            else:\n                return m\n        return -1\n    \n\narr = [7,7,9,11,12,13]\nsoln = Solution()\nsoln.search(arr, 9)\n\n2\n\n\n\n\n4.4 Clean version\n\nclass Solution:\n    def search(self, nums: [int], target: int) -&gt; int:\n        l = 0\n        r = len(nums)\n\n        while l&lt;r:\n            m = (l+r)//2\n            if nums[m]&lt;target:\n                l = m + 1                \n            elif nums[m]&gt;target:\n                r = m\n            else:\n                return m\n        return -1"
  },
  {
    "objectID": "posts/leetcode/LC704.html#submit",
    "href": "posts/leetcode/LC704.html#submit",
    "title": "LC: 704. Binary Search",
    "section": "6. Submit",
    "text": "6. Submit\nMiddle of the pack \nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/leetcode/LC74.html",
    "href": "posts/leetcode/LC74.html",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "",
    "text": "link to my leetcode profile"
  },
  {
    "objectID": "posts/leetcode/LC74.html#problem-description",
    "href": "posts/leetcode/LC74.html#problem-description",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "1. Problem Description",
    "text": "1. Problem Description\nYou are given an m x n integer matrix matrix with the following two properties:\nEach row is sorted in non-decreasing order.\nThe first integer of each row is greater than the last integer of the previous row.\nGiven an integer target, return true if target is in matrix or false otherwise.\nYou must write a solution in O(log(m * n)) time complexity."
  },
  {
    "objectID": "posts/leetcode/LC74.html#code",
    "href": "posts/leetcode/LC74.html#code",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "2. Code",
    "text": "2. Code\n\nFlatten array then\nUse code from binary search\n\n\nclass Solution:\n    def searchMatrix(self, matrix: [[int]], target: int) -&gt; bool:\n        # its a ascending matrix,\n        # 1. turn into array then \n        # 2. apply binsearch \n        arr = [element for row in matrix for element in row]\n\n        l = 0\n        r = len(arr)\n\n        if r==1:\n            if target == l[0]:\n                return True\n            else: return False\n\n        while l&lt;r:\n            m = (l+r)//2\n            if arr[m]&lt;target:\n                l = m + 1                \n            elif arr[m]&gt;target:\n                r = m\n            else:                \n                return True\n        return False\n\n\nsoln = Solution()\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],3)\n# soln.searchMatrix([[1,3,5,7],[10,11,16,20],[23,30,34,60]],13)\n# soln.searchMatrix([[1,3]],3)"
  },
  {
    "objectID": "posts/leetcode/LC74.html#submit",
    "href": "posts/leetcode/LC74.html#submit",
    "title": "LC: 74. Search a 2D Matrix",
    "section": "3. Submit",
    "text": "3. Submit\n\nGo to Main Blog\nGo to LeetCode Blog"
  },
  {
    "objectID": "posts/2024-01-18-99_rice_vs_noodles/index.html",
    "href": "posts/2024-01-18-99_rice_vs_noodles/index.html",
    "title": "Image Classifier 1: Noodles vs Rice",
    "section": "",
    "text": "Today I’ll be attempting to build my first deep learning image classifier to distinguish between rice and noodles using knowledge gained from Jeremy Howards Fast AI course\nHigh-level steps:\n1. Search and Prepare Data\n2. Create DataLoader\n3. Create Learner\n4. Prediction\nI will detail any problems, issues, questions and resolutions during the process.\n\n!pip install -Uqq fastai\n\n\nfrom fastbook import * \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n\n\n\n1. Search and Prepare Data\n\n# 1.1 Get 'rice' photos\ndownload_url(search_images_ddg('rice',max_images=1)[0],'rice.jpg',show_progress=False)\nImage.open('rice.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\n\n# 1.2 Get 'noodles' photos\ndownload_url(search_images_ddg('noodles', max_images=1)[0],'noodles.jpg',show_progress=False)\nImage.open('noodles.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\nLets use 60 imagess of ‘rice’ and ‘noodles’ from DuckDuckGo.\nNote: I downloaded for 100 images of each and then taking 60 of them as some images fail so I’m leaving room for failed photos.\nQuestion: Why do we need verify and why do some photos fail?\n\n# 1.3 Prep images in folders\nsearches = ['rice', 'noodles']\npath = Path('rice_or_noodles')\n\nif not path.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=100)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:60])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n# 1.4 Remove Failed images\npath = Path('rice_or_noodles')\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\n\n2. Create DataLoader\n\n# 2.1 \ndls = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path) \n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n# 2.2 We can see Paths were created for every image and split into our training and data sets\ndls.train_ds.items[:2]\ndls.valid_ds.items[:2]\n\n[Path('rice_or_noodles/rice/4280fe58-691a-4c0b-85a5-5c1c8400ecb7.jpg'),\n Path('rice_or_noodles/rice/f8a77d77-c007-4854-af8b-2af624a8da66.jpg')]\n\n\n[Question]: How does it know whether it is training set or valid set? I guess theres some indexing somewhere that I dont know how to obtain.\n\n# 2.1 Show a training batch which has an 'image' and a 'label'\ndls.show_batch(max_n=6) #batch shows input and label\n\n\n\n\n\n\n\n\n\n\n2. Create Learner using ResNet\nIn the course, we used a pre-trained model ‘ResNet18’ (RN).\nWhy Pre-trained Models?:\n- Pre-trained models is like getting an athlete who is very good basic sport related skills like hand-eye coordination, jumping, running/sprinting, changing directions etc and then - telling them to learn a specific sport (fine-tuning), - say tennis (labelled dataset provided). With a good base of skills, this person should be able to learn tennis to a good level…\nResNet18:\n- ResNet18 is trained on 1.28 million images with 1000 object categories. - 18 layers\n- Trained on ImageNet dataset\n[Future iterations 1]: Perhaps there are alternative pre-trained models specialising in food?\n[Future iterations 2]: - Read up and try understand the various architectures Fast AI’s TIMM model architectures - Try different architectures and different versions\n\nlearner_RN18 = vision_learner(dls, resnet18, metrics=error_rate)\n\n\n2.1 Learner Model Times:\nThey all took under 10 seconds to create the general learner. Now to fine-tune them!\n\nlearner_RN18.fine_tune(8)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.840357\n4.676042\n0.476190\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.763106\n3.761843\n0.476190\n00:04\n\n\n1\n1.517361\n2.798523\n0.476190\n00:04\n\n\n2\n1.202234\n2.308116\n0.428571\n00:04\n\n\n3\n0.953227\n1.637496\n0.428571\n00:04\n\n\n4\n0.770979\n1.034023\n0.380952\n00:04\n\n\n5\n0.662257\n0.641428\n0.190476\n00:04\n\n\n6\n0.563239\n0.405057\n0.142857\n00:04\n\n\n7\n0.490904\n0.285846\n0.095238\n00:04\n\n\n\n\n\n\nOur learner is performing at 90% accuracy (9% error rate) by looking at only 60 photos!\nLets try predict some random photos of rice and noodles I’ve found on the internet.\n\nfrom IPython.display import Image # import image viewer\n\n\n# noodle predictor\nuploader = SimpleNamespace(data = ['test_noodle.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nnoodles: 99.98%\n\n\n\n\nPrediction 1: Noodles\nThe model predicted noodles correctly with 99.98% confidence!\n\n# rice predictor 1\nuploader = SimpleNamespace(data = ['test_rice.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path))\n\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 66.22%\n\n\n\n\nPrediction and Results 2: Rice 1\nThe model predicted rice incorrectly with 66.22% confidence!\nI was a bit confused so I decided to provide another image of rice to make\n\n# rice predictor 2\nuploader = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path = uploader.data[0]\ndisplay(Image(filename=image_path)) # show image\n\n# get\nres1, res2, res3 = learner_RN18.predict(image_path)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnoodles: 98.51%\n\n\n\n\nPrediction and Results 3: Rice 2\nThe model predicted rice incorrectly with 98.51% confidence!\nOkay now there is clearly something wrong going on. I decide to take a gander at the photos in my ‘rice’ folder.\n\nIt looks like we’ve trained a learner specialises in bowled or white rice. I was testing the model with fried rice since that is my favourite rice dish.\nLets test out a couple photos on bowled rice.\n\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice: 88.73%\n\n\n\n\n\n\n\n\n\nnoodles: 92.57%\n\n\nNow I’m confused as its predicting incorrectly with 92.57% confidence.\nPerhaps the model isnt seeing enough data?\nLets train a new model with:\n- 300 images instead of 60\n- ‘rice food’ and ‘noodle food’ as keyword insteads of just ‘rice’ and ‘noodles’\n\nsearches = ['rice food', 'noodles food']\npath_200 = Path('rice_or_noodles_300')\n\nif not path_200.exists(): # Ensure the path exists\n    for o in searches:\n        dest = (path_200/o)\n        dest.mkdir(parents=True, exist_ok=True)\n        print(f'Searching for {o} images...')\n        results = search_images_ddg(f'{o} photo',max_images=300)\n        print(f'{len(results)} images found for {o}. Downloading...')\n        download_images(dest, urls=results[:200])\n        print(f'Resizing images in {dest}')\n        resize_images(dest, max_size=400, dest=dest)\n\n\n\n# 1.4 Remove Failed images\npath_200 = Path('rice_or_noodles_300')\nfailed = verify_images(get_image_files(path_200))\nfailed.map(Path.unlink)\n\n\n(#10) [None,None,None,None,None,None,None,None,None,None]\n\n\n\n\ndls_200 = DataBlock(\n    blocks = (ImageBlock, CategoryBlock), # i.e.input image / ouput is category (coin or notes)\n    get_items = get_image_files, # returns list of images files\n    splitter = RandomSplitter(valid_pct=0.2, seed=42), # critical to test accuracy with validation set\n    get_y=parent_label, # use parents folder of a path\n    item_tfms=[Resize(192, method=\"squish\")] # most computer vision architecutres need all your inputs to be same size \n).dataloaders(path_200) \n\n\nlearner_RN18_200 = vision_learner(dls_200, resnet18, metrics=error_rate)\n\n\nlearner_RN18_200.fine_tune(4)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.155098\n0.872050\n0.338462\n00:11\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.625260\n0.402908\n0.169231\n00:15\n\n\n1\n0.442973\n0.289800\n0.138462\n00:14\n\n\n2\n0.317375\n0.328805\n0.153846\n00:14\n\n\n3\n0.235606\n0.327507\n0.123077\n00:15\n\n\n\n\n\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_boiledrice1.jpg'])\nuploader2 = SimpleNamespace(data = ['test_boiledrice2.jpg'])\nimage_path1 = uploader1.data[0]\nimage_path2 = uploader2.data[0]\n\ndisplay(Image(filename=image_path1)) # show image\ndisplay(Image(filename=image_path2)) # show image\n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\nres1, res2, res3 = learner_RN18_200.predict(image_path2)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 100.00%\n\n\n\n\n\n\n\n\n\nrice food: 99.95%\n\n\nSo it’s now 100 and 99.95% confident they’re rice, which is great!\nLets try some fried rice!\nWe’ll retest now at the fried rice photo which the initial model guessed to be noodles with 98.5% confidence\n\n# Prediction with new learner (300 images and specific keywords)\n# rice predictor 2\nuploader1 = SimpleNamespace(data = ['test_rice2.jpg'])\nimage_path1 = uploader1.data[0]\n\ndisplay(Image(filename=image_path1)) \n\nres1, res2, res3 = learner_RN18_200.predict(image_path1)\nprint(f\"{res1}: {res3[res2]*100:.2f}%\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice food: 99.56%\n\n\nGreat! It is correct with 99.56% confidence.\nI think we’ve created a great rice and noodles classifier, lets stop here.\n[Future Iteration 3]: Build web app for everyone to test it out\n[Future Iteration 4]: Make it useable on my blog\n[Question] I wonder if theres a way to quickly see all specific headings I’ve used, I find myself scrolling up and download to find what Iteration I’m up to…\nApologies for the lack of neatness, lets hope this improves over time…"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html",
    "href": "posts/2024-01-25-98_huggingface/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "",
    "text": "This post shows how to host your working Local Gradio App on HuggingFace.\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "href": "posts/2024-01-25-98_huggingface/index.html#part-3-host-on-huggingface-account",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "Part 3: Host on HuggingFace account",
    "text": "Part 3: Host on HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "href": "posts/2024-01-25-98_huggingface/index.html#create-huggingface-account-and-create-a-space",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "1 Create HuggingFace Account and Create a ‘Space’",
    "text": "1 Create HuggingFace Account and Create a ‘Space’\n\nChoose your Space name\nChoose Apache-2.0 to avoid any copyright issues\nChoose Gradio\nChoose the Free option\nChoose Public (show you can show it to the world!)"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "href": "posts/2024-01-25-98_huggingface/index.html#clone-the-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2 Clone the repo",
    "text": "2 Clone the repo\nThis will create allow us deploy the Gradio app to the HuggingFace repository:\ngit clone https://huggingface.co/spaces/tonyjustdevs/pets_breed_predictor"
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#gather-your-files",
    "href": "posts/2024-01-25-98_huggingface/index.html#gather-your-files",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "2. Gather your files",
    "text": "2. Gather your files\nRecall the various files we needed to run the app locally part 2.\nGather into the cloned huggingface folder:\n- Learner (.pkl)\n- Pet examples (pets.jpg)\n- Gradio app (app.py)\n\nA good way to check for me is seeing the pets_breed_predictor is the git folder and huggingface space."
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "href": "posts/2024-01-25-98_huggingface/index.html#push-to-huggingface-repo",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "3. Push to HuggingFace Repo",
    "text": "3. Push to HuggingFace Repo\nIf you’ve pushed succesfully your app (could take several minutes), then your app is live! Congrats!\nIf you’re like me and forgot to include the requirements.txt then you’ll be greeted with this error.\n\n\n3.1 Add the requirements.txt\nWe imported two libraries fastai and gradio so include them in the requirements.txt file. Commit and push."
  },
  {
    "objectID": "posts/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "href": "posts/2024-01-25-98_huggingface/index.html#web-app-complete-and-is-live",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)",
    "section": "4 Web App Complete and is Live",
    "text": "4 Web App Complete and is Live\nIf all goes well, the HuggingFace space is hosting the Gradio App!\nCheck out my web app here!"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#import-a-pretrained-language-model",
    "href": "posts/kaggle/1-us-patents/index.html#import-a-pretrained-language-model",
    "title": "A Basic NLP model",
    "section": "1. Import a Pretrained Language Model",
    "text": "1. Import a Pretrained Language Model\n\nchosen_pretrained_model = \"microsoft/deberta-v3-small\"\n\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\ndebv3_tokenizer = AutoTokenizer.from_pretrained(chosen_pretrained_model)\n\n\n\n1.1 Look Inside the Language Model\n\nprint(debv3_tokenizer)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#test-out-tokenizer",
    "href": "posts/kaggle/1-us-patents/index.html#test-out-tokenizer",
    "title": "A Basic NLP model",
    "section": "2. Test out Tokenizer",
    "text": "2. Test out Tokenizer\n\ntest_string = (\"Hey all! What's going on? It's Tony from Sydney!\")\ndebv3_tokenizer.tokenize(test_string)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#import-competition-data",
    "href": "posts/kaggle/1-us-patents/index.html#import-competition-data",
    "title": "A Basic NLP model",
    "section": "3. Import Competition Data",
    "text": "3. Import Competition Data\nTo add relevant competition data to your kaggle “Input” folder.\nThis “Input” folder is persistent when you submit to the competition. All other folders created during prior to submitting are disregarded.\n\n3.1 Via GUI:\n\nOn Kaggle, Go to [Add Data]\n\nFilter for “Competition Datasets”\n\nSearch “US Patents”\nClick [Add Competition]\n\n \n\n\n3.2 Via Programatically:\nNote: You’ll need your own GPU’s, I don’t so the rest of the notebook is ran on the Kaggle website 1. Have kaggle login + keys ready locally, explained in this post 2. Run code to download data locally.\n\nfrom pathlib import Path\npath = Path('us-patent-phrase-to-phrase-matching')\nif not path.exists():\n    import zipfile,kaggle\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)\n\n\n\n3.3 Look Inside the Competition Data\n\npath = Path('/kaggle/input/us-patent-phrase-to-phrase-matching') # Using GUI places comp-data into 'kaggle/input' folder\nimport pandas as pd\ndf = pd.read_csv(path/'train.csv')\ndf.describe(include='object')"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#data-preparation",
    "href": "posts/kaggle/1-us-patents/index.html#data-preparation",
    "title": "A Basic NLP model",
    "section": "4. Data Preparation",
    "text": "4. Data Preparation\n\n4.1 Create Input Column\nCreate a contentated column of imporatant columns context, target and anchor.\n\ndf['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\ndf['input']\n\n\n\n\n4.2 Convert Pandas Dataframe to HuggingFace Dataset\n\nfrom datasets import Dataset,DatasetDict\nhf_datasets = Dataset.from_pandas(df)\nhf_datasets.keys\n\n\n\n\n4.3 Tokenize our HuggingFace Dataset\nUsing the tokenizer, we can apply pre-trained model to our new concatenated column.\nA hugging face dataset is in the form of a dictionary so we can index to get a column with dict['column']\nWe can apply the tokenization with batching, resulting in an additional few columns input_ids, token_type_ids, attention_marks, which only took 2 seconds!\n\ndef tok_func(x): return debv3_tokenizer(x[\"input\"])\ntok_ds = hf_datasets.map(tok_func, batched=True)\ntok_ds\n\n\n\n\n4.4 Rename the Columns as to what HF expects\n\ntok_ds = tok_ds.rename_columns({'score':'labels'})\n\n\n\n4.5 Training and Validation Sets\nSplit the above tokenized hugging face datasets into validation and training sets, into DatasetDicts.\nNote: The validation set here is called test and not validate\n\ntok_ds_dicts = tok_ds.train_test_split(0.25, seed=42)\ntok_ds_dicts"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#data-modelling",
    "href": "posts/kaggle/1-us-patents/index.html#data-modelling",
    "title": "A Basic NLP model",
    "section": "5. Data Modelling",
    "text": "5. Data Modelling\n\n5.1 Import libraries and set parameters\nImport modules: - TrainingArgument: to take in all the hyperparameters - Trainer class: combines the TrainingArguments and Pre-trained model Set the main hyper-parameters: - Batch Sizes: to fit on the GPU, - Number of Epochs: for each ‘experiment’ and the - Learning Rate, so it doesnt fail.\n[“Future Iteration”]: More descriptions on these and other parameters in future posts.\n\nfrom transformers import TrainingArguments,Trainer\nbs = 128\nepochs = 4\nlr = 8e-5\n\n\n\n5.2 Setup Training Arguments\n\nargs = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n\n\n\n5.3 Create Model\n\nmodel = AutoModelForSequenceClassification.from_pretrained(chosen_pretrained_model, \n                                                           num_labels=1,\n                                                           ignore_mismatched_sizes=True)\n\n\n\n5.4 Create Metrics Functions\nThe Pearson coefficient using numpy.\n\nimport numpy as np\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n\n\n\n5.5 Create Trainer\n\ntrainer = Trainer(model, \n                  args, \n                  train_dataset=tok_ds_dicts['train'], \n                  eval_dataset=tok_ds_dicts['test'],\n                  tokenizer=debv3_tokenizer, \n                  compute_metrics=corr_d)\n\n\n\n5.6 Do the Training\n\ntrainer.train()"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#predictions",
    "href": "posts/kaggle/1-us-patents/index.html#predictions",
    "title": "A Basic NLP model",
    "section": "6. Predictions",
    "text": "6. Predictions\nNow that we have a Trainer (same as Learner in FastAI), we could use it on a an unseen set of data such as a Test Set and make predictions.\n\n6.1 Import Test Dataset\n\neval_df = pd.read_csv(path/'test.csv')\neval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n\n\n\n6.2 Make Predictions\nPredictions are going beyond 0 and 1\n\npreds = trainer.predict(eval_ds).predictions.astype(float)\n\n\n\n\n6.3 Clip Predictions\nPredictions are going beyond 0 and 1\n\npreds = np.clip(preds, 0, 1)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#submission",
    "href": "posts/kaggle/1-us-patents/index.html#submission",
    "title": "A Basic NLP model",
    "section": "7. Submission",
    "text": "7. Submission\n\nimport datasets\n\nsubmission = datasets.Dataset.from_dict({\n    'id': eval_ds['id'],\n    'score': preds\n})\n\nsubmission.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "posts/kaggle/1-us-patents/index.html#part-2",
    "href": "posts/kaggle/1-us-patents/index.html#part-2",
    "title": "A Basic NLP model",
    "section": "8. Part 2",
    "text": "8. Part 2\nActually the submissiong won’t work because it is a Notebook competition is the Internet is Turned Off.\nWhat needs to be done is convert this version to one that works without installing anything from the internet.\nThat would be in Part 2."
  },
  {
    "objectID": "posts/2024-04-26-random_forest/index.html",
    "href": "posts/2024-04-26-random_forest/index.html",
    "title": "Random Forests - Random Forest Classifier (Part 3)",
    "section": "",
    "text": "1. Introduction\nIn Part 1, a simple model was built using single binary split called OneR Classifier.\nIn Part 2, sklearn DecisionTreeClassifier framework was used and by setting a sample limit per node, loss was reduced\nIn this post:\n\nCreate alot of bigger trees\n\nTake the average of their predictions, that is, the averaged emsemble or bagging results is a random forest\n\nCompare the results with sklearn’s RandomForestClassifier\n\nIn the next few posts, the topics will follows:\n\nFeature Importance Plot\n\nGradient Boosting (sum of trees) Decision Tree or Machine\n\n\n\n2. Training and Validation Sets\n\nfrom fastai.imports import *\nimport torch, numpy as np, pandas as pd\nimport kaggle, zipfile\nfrom pathlib import Path\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n!ls {path}\n\ndef proc_data_1(df):\n    modes           = df.mode().iloc[0]\n    df['Fare']      = df.Fare.fillna(0)\n    df.fillna(modes, inplace=True)\n    df['LogFare']   = np.log1p(df['Fare'])\n    df['Embarked']  = pd.Categorical(df.Embarked)\n    df['Sex']       = pd.Categorical(df.Sex)\n\ndef convert_cats_to_codes_2(trn_df, val_df, cat_list):\n    trn_df[cat_list] = trn_df[cat_list].apply(lambda dfcol: dfcol.cat.codes) # replace with 1 and 0s\n    val_df[cat_list] = val_df[cat_list].apply(lambda dfcol: dfcol.cat.codes)\n    return trn_df, val_df\n\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nrandom.seed(42)\n\n# 0 get raw data\ndf              = pd.read_csv(path/'train.csv')\ntst_df          = pd.read_csv(path/'test.csv')\n# 1. clean data ([replace nas with mode], [logfare], [sex/embarked to cat])\nproc_data_1(df)\nproc_data_1(tst_df)\n\n# 2. split training data: training and validation set\ntrn_df,val_df   = train_test_split(df, test_size=0.25)\n\n# 3. convert cats to codes\ncat_list        = [\"Sex\",\"Embarked\"]\ntrn_df, val_df  = convert_cats_to_codes_2(trn_df, val_df, cat_list)\n\n# 4. get idep and deps\ndep_col         = \"Survived\"\ncont_list       = ['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\ndef get_trn_and_val_idep_dep(df):\n    idep    = df[ cat_list + cont_list ].copy()\n    dep     = df[dep_col]\n    return idep, dep\n\ntrn_idep,trn_dep = get_trn_and_val_idep_dep(trn_df)\nval_idep,val_dep = get_trn_and_val_idep_dep(val_df)\n\ntitanic folder doesn't exist, downloading...\nDownloading titanic.zip to /home/tonydevs/github/blog/posts/2024-04-26-random_forest\n\n\n100%|██████████| 34.1k/34.1k [00:00&lt;00:00, 55.8kB/s]\n\n\n\ngender_submission.csv  test.csv  train.csv\n\n\n\n\n\n\n\n3. Using DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\ndef get_tree(prop=0.75):\n    n = len(trn_dep)\n    idxs = random.choice(n, int(n*prop))\n    return DecisionTreeClassifier(min_samples_leaf=5).fit(trn_idep.iloc[idxs], trn_dep.iloc[idxs])\n\n\n# create as many trees as we want\ntrees = [get_tree() for t in range(100)] \n\n\n# average them\nall_probs = [t.predict(val_idep) for t in trees]\navg_probs = np.stack(all_probs).mean(0)\n\nfrom sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(val_dep, avg_probs)\n\n0.2272645739910314\n\n\n\n\n4. Using RandomForestClassifier\nThis is nearly identical to what sklearn’s RandomForestClassifier does.\nThe main extra piece in a “real” random forest (is that as well as choosing a random sample of data for each tree):\n\nit also picks a random subset of columns for each split.\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(100, min_samples_leaf=5)\nrf.fit(trn_idep, trn_dep);\nmean_absolute_error(val_dep, rf.predict(val_idep))\n\n0.18834080717488788"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html",
    "href": "posts/2024-01-25-99_gradio_app/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "",
    "text": "This post shows how to create a Gradio App (app.py) and run it locally in a browser. This app should:\nThis post is part of a series:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "href": "posts/2024-01-25-99_gradio_app/index.html#part-2-create-gradio-application-file-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "Part 2: Create Gradio application file (app.py)",
    "text": "Part 2: Create Gradio application file (app.py)"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "href": "posts/2024-01-25-99_gradio_app/index.html#import-gradio-and-fast-ai-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "1. Import Gradio and Fast AI libraries",
    "text": "1. Import Gradio and Fast AI libraries\n\nfrom fastai.vision.all import * \nimport gradio as gr\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn("
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "href": "posts/2024-01-25-99_gradio_app/index.html#import-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "2. Import Learner (.pkl file)",
    "text": "2. Import Learner (.pkl file)\nRecall, this file was created and exported in Part 1\n\nIf you’re running on a Linux, you shouldn’t have any import issues.\n\nIf you’re running a Windows PC, you’ll likely to experience an error.\n\n\npets_learner = load_learner('pets_learner.pkl') \n\n\n---------------------------------------------------------------------------\nNotImplementedError                       Traceback (most recent call last)\nCell In[4], line 1\n----&gt; 1 pets_learner = load_learner('pets_learner.pkl') \n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\learner.py:446, in load_learner(fname, cpu, pickle_module)\n    444 distrib_barrier()\n    445 map_loc = 'cpu' if cpu else default_device()\n--&gt; 446 try: res = torch.load(fname, map_location=map_loc, pickle_module=pickle_module)\n    447 except AttributeError as e: \n    448     e.args = [f\"Custom classes or functions exported with your `Learner` not available in namespace.\\Re-declare/import before loading:\\n\\t{e.args[0]}\"]\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torch\\serialization.py:1014, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\n   1012             except RuntimeError as e:\n   1013                 raise pickle.UnpicklingError(UNSAFE_MESSAGE + str(e)) from None\n-&gt; 1014         return _load(opened_zipfile,\n   1015                      map_location,\n   1016                      pickle_module,\n   1017                      overall_storage=overall_storage,\n   1018                      **pickle_load_args)\n   1019 if mmap:\n   1020     raise RuntimeError(\"mmap can only be used with files saved with \",\n   1021                        \"`torch.save(_use_new_zipfile_serialization=True), \"\n   1022                        \"please torch.save your checkpoint with this option in order to use mmap.\")\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\torch\\serialization.py:1422, in _load(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\n   1420 unpickler = UnpicklerWrapper(data_file, **pickle_load_args)\n   1421 unpickler.persistent_load = persistent_load\n-&gt; 1422 result = unpickler.load()\n   1424 torch._utils._validate_loaded_sparse_tensors()\n   1425 torch._C._log_api_usage_metadata(\n   1426     \"torch.load.metadata\", {\"serialization_id\": zip_file.serialization_id()}\n   1427 )\n\nFile c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\pathlib.py:873, in Path.__new__(cls, *args, **kwargs)\n    871 self = cls._from_parts(args)\n    872 if not self._flavour.is_supported:\n--&gt; 873     raise NotImplementedError(\"cannot instantiate %r on your system\"\n    874                               % (cls.__name__,))\n    875 return self\n\nNotImplementedError: cannot instantiate 'PosixPath' on your system\n\n\n\n\n2.1 Import Learner Error (.pkl file) Solution (Windows only)\nI found a solution here.\nNot too sure why this happens, probably linux vs windows compatibility, forward vs backlashes probably?\nImport the pathlib library below and run the code below to fix the paths:\nNote:\n- This fix is only required during the testing phase of our Gradio App.\n- This testing phase is defined as being able to run the Gradio App locally.\n- When we Upload to HuggingFace Spaces, this code fix is not required (because HF is run on Linux, hence no Posix issues, from my understanding)\n\n# only run to import pkl in windows when youre doing testing in windows | when run in hus | its run via dock images ie linux ie no problems\nimport pathlib # \ntemp = pathlib.PosixPath\npathlib.PosixPath = pathlib.WindowsPath\n\n\npets_learner = load_learner('pets_learner.pkl')"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "href": "posts/2024-01-25-99_gradio_app/index.html#predict-the-breed-with-imported-learner",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "3 Predict the Breed with Imported Learner",
    "text": "3 Predict the Breed with Imported Learner\n\n3.1 Import Local Image\n\npet1 = PILImage.create('pet1.jpg')\npet1.thumbnail((224,224))\npet1\n\n\n\n\n\n\n\n\n\n\n3.2 Make prediction\nUse predict() to make prediction on the uploaded local image. The results will have 3 items:\n1. The prediction of the breed.\n2. Index of the Tensor (in point 3.)\n3. A Tensor of length 37. Why the odd number?\n- These are the probabilities of each unique breeds in our data!\n- Recall in Part 1, we determined the different categories by using a custom labelling function\n\nres = pets_learner.predict(pet1)\nres\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n('Bombay',\n tensor(3),\n tensor([3.4475e-02, 1.7813e-03, 8.1388e-03, 6.3685e-01, 6.0993e-03, 4.8830e-04,\n         5.0747e-02, 8.8036e-03, 2.1084e-01, 3.4832e-02, 9.6598e-04, 7.6646e-04,\n         6.3764e-04, 2.5949e-04, 8.7999e-05, 1.3308e-03, 6.6650e-05, 5.7116e-05,\n         9.0377e-04, 6.9052e-05, 2.0095e-04, 2.1758e-05, 2.5767e-04, 2.1859e-05,\n         3.8547e-05, 1.6165e-06, 6.2601e-05, 4.3552e-05, 1.4901e-04, 9.6175e-05,\n         1.0010e-04, 1.3717e-04, 2.7684e-04, 5.5386e-05, 5.7012e-05, 4.6809e-05,\n         2.2643e-04]))\n\n\n\n\n3.3 What is the probabilities representing?\nThe probabilities tensor from predict() are the unique categories in our data and are stored in our dataloader\n\ncategories = pets_learner.dls.vocab \ncategories\n\n['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'boxer', 'chihuahua', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian', 'pug', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier']\n\n\n\n\n3.4 The prediction and probabilities of our image\n\n# get index of predction\nidx = res[1]\n\n# store list of probalities of our predction\nprobabilities = res[2]\n\n# get breed and probability of our prediction\ncategories[idx],probabilities[idx]\n\n\n('Bombay', tensor(0.6369))\n\n\n\n\n3.5 Probability of every category available\n\ndef classify_image_fn(img):\n    prediction, idx, probabilities = pets_learner.predict(img)\n    return dict(zip(categories, map(float, probabilities)))\n\nclassify_image_fn(pet1)     # names and probabilities\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n{'Abyssinian': 0.034474823623895645,\n 'Bengal': 0.0017812795704230666,\n 'Birman': 0.008138809353113174,\n 'Bombay': 0.6368528604507446,\n 'British_Shorthair': 0.006099338177591562,\n 'Egyptian_Mau': 0.0004883029614575207,\n 'Maine_Coon': 0.05074741691350937,\n 'Persian': 0.008803554810583591,\n 'Ragdoll': 0.21084259450435638,\n 'Russian_Blue': 0.03483246639370918,\n 'Siamese': 0.0009659799397923052,\n 'Sphynx': 0.0007664564182050526,\n 'american_bulldog': 0.0006376394885592163,\n 'american_pit_bull_terrier': 0.0002594943216536194,\n 'basset_hound': 8.799932402325794e-05,\n 'beagle': 0.0013307805638760328,\n 'boxer': 6.664981629000977e-05,\n 'chihuahua': 5.711586709367111e-05,\n 'english_cocker_spaniel': 0.0009037724230438471,\n 'english_setter': 6.905203190399334e-05,\n 'german_shorthaired': 0.00020094779029022902,\n 'great_pyrenees': 2.1758336515631527e-05,\n 'havanese': 0.0002576670085545629,\n 'japanese_chin': 2.1859435946680605e-05,\n 'keeshond': 3.85471066692844e-05,\n 'leonberger': 1.616517351976654e-06,\n 'miniature_pinscher': 6.26009568804875e-05,\n 'newfoundland': 4.355219061835669e-05,\n 'pomeranian': 0.00014901049144100398,\n 'pug': 9.617456089472398e-05,\n 'saint_bernard': 0.0001000974079943262,\n 'samoyed': 0.0001371700782328844,\n 'scottish_terrier': 0.00027684049564413726,\n 'shiba_inu': 5.5386270105373114e-05,\n 'staffordshire_bull_terrier': 5.701235932065174e-05,\n 'wheaten_terrier': 4.680879646912217e-05,\n 'yorkshire_terrier': 0.0002264348149765283}"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "href": "posts/2024-01-25-99_gradio_app/index.html#run-local-gradio-app",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "4 Run local Gradio App",
    "text": "4 Run local Gradio App\nTheres a variety of ways to alter the app, I’ve set the size of the images and provided some examples:\n\ngr_image = gr.Image(width=244, height=244)\ngr_label = gr.Label()\n\ninput_examples = ['pet1.jpg','pet2.jpg','pet3.jpg','pet4.jpg','pet5.jpg']\nintf = gr.Interface(fn=classify_image_fn,\n                    inputs=gr_image,    \n                    outputs=gr_label,\n                    examples=input_examples)\nintf.launch(inline=False)\n\nRunning on local URL:  http://127.0.0.1:7863\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)\n\n\n\n\n\n\n\n\n\n\n4.1 Open Local Gradio App\nOpen the URL provided in your favourite browser\n\n\n\n4.2 Test it out\nThe app knows a pug when it sees one! The app is ready."
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#export-app.py",
    "href": "posts/2024-01-25-99_gradio_app/index.html#export-app.py",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "5. Export (app.py)",
    "text": "5. Export (app.py)\nGradio app must be all inside a app.py script when being deployed on HuggingFaces.\nThankfully, there is a library to export all the cell-blocks from our notebook (.ipynb) to python script (app.py).\nReference\n\n5.1 Put directives at front of notebook\n\nPlace ‘#| default_exp app’ in a python codeblock in front of the the notebook\n\n\n\n\n5.2 Choose the cellblocks to export\n\nPlace ‘#| export’ in front of each codeblock you need to export\n\n\n\n\n5.3 Run nbdev and export\n\nfrom nbdev.export import nb_export\nnb_export('app.ipynb')\n\nThis will create a new folder as home directory and place in the app.py"
  },
  {
    "objectID": "posts/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "href": "posts/2024-01-25-99_gradio_app/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Upload to HuggingFace account"
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#statistical-properties",
    "title": "Let’s Make Some Noise",
    "section": "2.1 Statistical Properties",
    "text": "2.1 Statistical Properties\n\nGaussian noise is characterized by a normal distribution, which is well-studied and has known statistical properties.\nThis makes it easy to model and analyze mathematically."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#central-limit-theorem",
    "title": "Let’s Make Some Noise",
    "section": "2.2 Central Limit Theorem:",
    "text": "2.2 Central Limit Theorem:\n\nThe Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables, each with finite mean and variance, will be approximately normally distributed.\nThis property makes Gaussian noise a natural choice in many scenarios where the noise is a result of multiple independent factors."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#mathematical-simplicity",
    "title": "Let’s Make Some Noise",
    "section": "2.3 Mathematical Simplicity:",
    "text": "2.3 Mathematical Simplicity:\n\nThe normal distribution has simple and well-defined mathematical properties, making it easy to work with in analytical and computational contexts."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#robustness-in-estimation",
    "title": "Let’s Make Some Noise",
    "section": "2.4 Robustness in Estimation:",
    "text": "2.4 Robustness in Estimation:\n\nMany statistical estimation methods, including maximum likelihood estimation, assume that the underlying noise follows a Gaussian distribution.\nThis can lead to more robust parameter estimates when the actual noise is close to Gaussian."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#convenient-in-machine-learning",
    "title": "Let’s Make Some Noise",
    "section": "2.5 Convenient in Machine Learning:",
    "text": "2.5 Convenient in Machine Learning:\n\nIn machine learning, adding Gaussian noise can act as a form of regularization, preventing overfitting by introducing a controlled amount of randomness during training. It is also commonly used in generative models, such as Gaussian Mixture Models (GMMs)."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#noise-function",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#noise-function",
    "title": "Let’s Make Some Noise",
    "section": "3.1 noise function",
    "text": "3.1 noise function\nThis function generates random noise using NumPy’s random.normal function.\n\ny: numpy or pytorch array\n\nscale: standard deviation of the normal distribution from which the noise is drawn.\noutput: array of random values with the same shape as the input array y.\n\n\ndef add_noise(x, mult, add): \n    return x * (1+noise(x, mult)) + noise(x, add)"
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#add_noise-function",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#add_noise-function",
    "title": "Let’s Make Some Noise",
    "section": "3.2 add_noise function",
    "text": "3.2 add_noise function\nThis function uses the noise function to add noise to the input x:\n\n* (1 + noise(x, mult)): The multiplicative noise is applied by multiplying x with.\n+ noise(x, add): The additive noise is added directly to the result of the multiplicative part."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#differences",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#differences",
    "title": "Let’s Make Some Noise",
    "section": "3.3 Differences:",
    "text": "3.3 Differences:\nThe noise function generates:\n\nrandom noise independently of any input array,\nusing a specified scale.\nIt’s a standalone function for generating random noise.\n\nThe add_noise function is specifically designed to:\n\napply noise to an input array x.\ncombines both multiplicative and additive noise components,\nallowing for a more complex noise model."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#regularization-and-preventing-memorization",
    "title": "Let’s Make Some Noise",
    "section": "4.1 Regularization and Preventing Memorization:",
    "text": "4.1 Regularization and Preventing Memorization:\nAvoid and  Discouraging Overfitting:\n\nAdding random noise to the input data can act as a form of regularization, preventing the model from fitting the training data too closely.\nThis can improve the generalization of the model to new, unseen data.\nModels that are too complex may memorize the training data instead of learning the underlying patterns.\nAdding noise makes it more challenging for the model to memorize specific examples and encourages it to focus on general patterns."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#data-augmentation",
    "title": "Let’s Make Some Noise",
    "section": "4.2 Data Augmentation:",
    "text": "4.2 Data Augmentation:\nIncreased Variability:\n\nIntroducing noise during training can artificially increase the variability in the dataset.\nThis can be particularly useful when dealing with limited training data, helping the model generalize better to different variations of the input."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#robustness-testing",
    "title": "Let’s Make Some Noise",
    "section": "4.3 Robustness Testing:",
    "text": "4.3 Robustness Testing:\nModel Robustness:\n\nAdding noise during training can make the model more robust to variations and uncertainties in real-world data.\nThis is especially important when the model needs to perform well on data that may have different levels of noise or unexpected variations."
  },
  {
    "objectID": "posts/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "href": "posts/2024-03-02-nice_and_noisy/index.html#stochasticity-in-training",
    "title": "Let’s Make Some Noise",
    "section": "4.4 Stochasticity in Training:",
    "text": "4.4 Stochasticity in Training:\nEncouraging Exploration:\n\nDuring the training process, introducing randomness can encourage the model to explore different parts of the parameter space.\nThis can be especially beneficial in reinforcement learning or optimization problems, helping to avoid getting stuck in local minima."
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html",
    "href": "posts/2024-04-21-deep_learning/index.html",
    "title": "Tabular Deep-Learning Model",
    "section": "",
    "text": "import torch, numpy as np, pandas as pd"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#download-competition-data",
    "href": "posts/2024-04-21-deep_learning/index.html#download-competition-data",
    "title": "Tabular Deep-Learning Model",
    "section": "1. Download Competition Data",
    "text": "1. Download Competition Data\n\nimport kaggle, zipfile\nfrom pathlib import Path\n\npath = Path(\"titanic\")\nif not path.exists():\n    print(f\"{path} folder doesn't exist, downloading...\")\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f\"{path}.zip\").extractall(path)\nelse:\n    print(f\"{path} exists!\")\n\n!ls {path}\n\ntitanic folder doesn't exist, downloading...\nDownloading titanic.zip to /home/tonydevs/github/blog/posts/2024-04-21-deep_learning\n\n\n100%|██████████| 34.1k/34.1k [00:00&lt;00:00, 92.8kB/s]\n\n\n\ngender_submission.csv  test.csv  train.csv"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#clean-data",
    "href": "posts/2024-04-21-deep_learning/index.html#clean-data",
    "title": "Tabular Deep-Learning Model",
    "section": "2. Clean Data",
    "text": "2. Clean Data\n\n2.1 Read Training Data\n\ndf = pd.read_csv(path/\"train.csv\")\n\n\n\n2.2 Deal with NA’s\n\ndf.isna().sum() # find nas\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\nmodes = df.mode(axis=0).iloc[0] # get modes\ndf.fillna(modes, inplace=True)  # replace nas with mode per col\ndf.isna().sum() # no more nas \n\nPassengerId    0\nSurvived       0\nPclass         0\nName           0\nSex            0\nAge            0\nSibSp          0\nParch          0\nTicket         0\nFare           0\nCabin          0\nEmbarked       0\ndtype: int64\n\n\n\n\n2.3 Deal with Numeric Data\n\ndf['Fare'].hist() # Not evenly spread\n\n\n\n\n\n\n\n\n\ndf['LogFare'] = np.log1p(df['Fare'])\ndf['LogFare'].hist() # more evenly spread\n\n\n\n\n\n\n\n\n\n\n2.4 Deal with Categorical Data\n\ndf.nunique() \n# [Pclass], [Sex] and [Age] variables only has 2-3 categories.\n# A good choice to create dummy variables\n\nPassengerId    891\nSurvived         2\nPclass           3\nName           891\nSex              2\nAge             88\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nEmbarked         3\nLogFare        248\ndtype: int64\n\n\n\ndf = pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=int)\nadded_cols          = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\nindep_cols          = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n\n\ndf.nunique() \n# [Sex], [Pclass] and [Embarked] dummy variables created\n\nPassengerId    891\nSurvived         2\nName           891\nAge             88\nSibSp            7\nParch            7\nTicket         681\nFare           248\nCabin          147\nLogFare        248\nSex_female       2\nSex_male         2\nPclass_1         2\nPclass_2         2\nPclass_3         2\nEmbarked_C       2\nEmbarked_Q       2\nEmbarked_S       2\ndtype: int64\n\n\n\n\n2.5 Normalise Numerical Data\n\nidep_values_2d_tsr  = torch.tensor(df[indep_cols].values, dtype=torch.float)\nidep_values_2d_tsr[0:5] # Column 1 (20s) and Column 4 (2-4) are much larger than others (0-1).\n\ntensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000],\n        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,\n          0.0000,  1.0000,  0.0000,  0.0000],\n        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  1.0000],\n        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,\n          1.0000,  0.0000,  0.0000,  1.0000]])\n\n\n\nmaxes, _            = idep_values_2d_tsr.max(axis=0) # get max of each column\nidep_norms_2d_tsr_mxn   = idep_values_2d_tsr / maxes\nidep_norms_2d_tsr_mxn[0:5] # values are normalised about 0-1\n\ntensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n         1.0000, 0.0000, 0.0000],\n        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 1.0000],\n        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n         0.0000, 0.0000, 1.0000]])"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#training-and-validation-sets",
    "href": "posts/2024-04-21-deep_learning/index.html#training-and-validation-sets",
    "title": "Tabular Deep-Learning Model",
    "section": "3. Training and Validation Sets",
    "text": "3. Training and Validation Sets\n\nfrom fastai.data.transforms import RandomSplitter\ndep_mx0                     = torch.tensor(df[\"Survived\"])\n\ntrn_idx, val_idx            = RandomSplitter(seed=42)(idep_norms_2d_tsr_mxn)\ntrn_idep_mxn, val_idep_mxn  = idep_norms_2d_tsr_mxn[trn_idx], idep_norms_2d_tsr_mxn[val_idx] \ntrn_dep_mx0,  val_dep_mx0   = dep_mx0[trn_idx], dep_mx0[val_idx] \n\ntrn_dep_mx1 = trn_dep_mx0[:,None] # add extra dimention for matrix multiplies comparisons\nval_dep_mx1 = val_dep_mx0[:,None]"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#deep-learning-neural-network",
    "href": "posts/2024-04-21-deep_learning/index.html#deep-learning-neural-network",
    "title": "Tabular Deep-Learning Model",
    "section": "4. Deep Learning Neural Network",
    "text": "4. Deep Learning Neural Network\n\n4.1 Initialise Coefficients\n\nimport torch.nn.functional as F\ndef init_coeffs():\n    n_coeffs    = trn_idep_mxn.shape[1] # 12\n    hidden_layers = [10,10]\n    sizes = [n_coeffs] + hidden_layers + [1]    # [12,10,10,1]\n    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(len(sizes)-1)]   # 0,1,2\n    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(len(sizes)-1)]   # [0,1,2]\n\n    for layer in layers+consts:\n        layer.requires_grad_()\n\n    return layers, consts\n\n\n\n4.2 Calculate Predictions\n\n\n# i=1: [12,10]  [nxq1]      res1 = [713x12]@[12x10] = [713x10]\n# i=2: [10,10]  [q1xq2]     res2 = [713x10]@[10x10] = [713x10]\n# ...\n# i=n: [10,1]   [qnx1]      resn = [713x10]@[10x1] = [713x1]\n\ndef calc_preds_deeplearning(trn_idep_mxn, coeffs):    \n    layers, consts = coeffs\n    n = len(layers)\n    res = trn_idep_mxn\n    for i in range(n):\n        res = res@layers[i] + consts[i] # [mxn]@[nxq]  [713x12][12x10]\n        if i!=n-1: \n            res = F.relu(res) \n    sgm_preds_mx1 = torch.sigmoid(res)\n    return sgm_preds_mx1\n\n\n\n4.3 Calculate Loss\n\ndef calc_loss(idep_mxn, dep_mx1, coeffs):\n    preds_mx1 = calc_preds_deeplearning(idep_mxn, coeffs)\n    return torch.abs(dep_mx1-preds_mx1).mean()\n\n\n\n4.4 Update Coefficients and Constants\n\ndef update_coeffs(coeffs, lr):\n    layers, consts = coeffs\n    for layer in layers+consts:\n        layer.sub_(layer.grad*lr)\n        layer.grad.zero_()\n\n\n\n4.5 One Epoch\n\ndef one_epoch(coeffs,lr):\n    loss = calc_loss(trn_idep_mxn, trn_dep_mx1, coeffs)\n    loss.backward()\n    with torch.no_grad(): update_coeffs(coeffs, lr)\n    print(f\"{loss:.3f}\",end=';')\n\n\n\n4.6 Train Model with 30 Epochs\n\ndef train_model(n_epochs=30,lr=0.1):\n    torch.manual_seed(442)\n    coeffs = init_coeffs()\n    for _ in range(n_epochs):\n        one_epoch(coeffs,lr)\n    return coeffs\n\n\ncoeffs = train_model(lr=4)\n\n0.521;0.483;0.427;0.379;0.379;0.379;0.379;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.378;0.377;0.376;0.371;0.333;0.239;0.224;0.208;0.204;0.203;0.203;0.207;0.197;0.196;0.195;"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#submit-to-kaggles",
    "href": "posts/2024-04-21-deep_learning/index.html#submit-to-kaggles",
    "title": "Tabular Deep-Learning Model",
    "section": "5. Submit to Kaggles",
    "text": "5. Submit to Kaggles\n\n5.1 Prepare Test-Set\n\ntst_df = pd.read_csv(path/'test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\ntst_df.fillna(modes, inplace=True)\ntst_df['LogFare'] = np.log(tst_df['Fare']+1)\ntst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"], dtype=int)\ntst_indep = torch.tensor(tst_df[indep_cols].values, dtype=torch.float)\ntst_indep = tst_indep / maxes\n\n\n\n5.2 Predictions on Test-Set\n\ntst_df['Survived'] = (calc_preds_deeplearning(tst_indep, coeffs)&gt;0.5).int()\n\n\n\n5.3 Create Submission CSV\n\ntitanic_submission_df = tst_df[['PassengerId','Survived']]\ntitanic_submission_df.to_csv('titanic_submission.csv', index=False)\n\n\nkaggle.api.competition_submit(file_name='titanic_submission.csv', \n                              message='20240420_tit_submission', \n                              competition='titanic')\n\nWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.12 / client 1.6.6)\n\n\n100%|██████████| 2.77k/2.77k [00:00&lt;00:00, 3.42kB/s]100%|██████████| 2.77k/2.77k [00:01&lt;00:00, 1.82kB/s]\n\n\nSuccessfully submitted to Titanic - Machine Learning from Disaster"
  },
  {
    "objectID": "posts/2024-04-21-deep_learning/index.html#success",
    "href": "posts/2024-04-21-deep_learning/index.html#success",
    "title": "Tabular Deep-Learning Model",
    "section": "6. Success!",
    "text": "6. Success!\nI’ve finally completed building my first deep-learning neural-network model from scratch and successfully submitting to Kaggle with 77.75% Accuracy."
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#introduction",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "1. Introduction",
    "text": "1. Introduction\nEmbedding a classic Convolutional Neural Network (CNN) Gradio ‘Cat versus Dog’ classifier Gradio App, hosted on HuggingFace Spaces, into my Quarto Blog. What a mouthful!"
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#background",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "2. Background",
    "text": "2. Background\nThis App will guess whether an image is a Cat or Dog with a level of confidence using a deep learning neural network based on 700 mbs of labelled photos of dogs and cats. I’ll post more information on the model itself in a different post.\nAll doggos🐕 & cats🐈 image examples has never been viewed by the Model and it makes a prediction in milliseconds! Images supplied by my good friends in Australia 🦘 and Vietnam 🍜. Thanks guys!\nThe App isn’t perfect:\n- It guesses Incorrectly with great 95% confidence a cat as a dog!\nI’m thrilled to be able to build the app, get it hosted and embed it all in one day for the first time! Alot of firsts today!"
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#future-stuff",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "3. Future stuff",
    "text": "3. Future stuff\n[1]: Multi-Image Uploader + Predictor.\n[2]: Explain how I built the Gradio App, got it hosted Hugging Face, and embedded here.\n[4]: Upgrade the rice vs noodle model an App and hosted.\n[4]: Learn some HTML/CSS to make things prettier."
  },
  {
    "objectID": "posts/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "href": "posts/2024-01-19-98_embed_gradio_hgface/index.html#heres-the-app",
    "title": "Deploying My First Live App & it’s a Neural Network!",
    "section": "4. Heres the App!",
    "text": "4. Heres the App!"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#numpy.maximum",
    "href": "posts/2024-03-13-relu/index.html#numpy.maximum",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.1 numpy.maximum",
    "text": "2.1 numpy.maximum\n\nimport numpy as np\n\ndef sgl_relu_np(m,b,x):\n    y = m*x+b\n    relu_y = np.maximum(y,0)\n    return relu_y \n\nsgl_relu_np(1,1,1)\n\n2"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#torch.clip---version-1",
    "href": "posts/2024-03-13-relu/index.html#torch.clip---version-1",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.2 torch.clip - version 1",
    "text": "2.2 torch.clip - version 1\nNote: torch.clip won’t work because it accepts tensors only, and the below function is inputting python native types\n\nimport torch\n\ndef sgl_relu_pytclip_v1(m,b,x):\n    y = m*x+b # input to torch needs to be a tensor, ie y=mx+b doesnt work as seen in error:\n    print(type(y))\n    return torch.clip(y,0.)\n    \n\nsgl_relu_pytclip_v1(1,1,1)\n\n&lt;class 'int'&gt;\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[3], line 9\n      5     print(type(y))\n      6     return torch.clip(y,0.)\n----&gt; 9 sgl_relu_pytclip_v1(1,1,1)\n\nCell In[3], line 6, in sgl_relu_pytclip_v1(m, b, x)\n      4 y = m*x+b # input to torch needs to be a tensor, ie y=mx+b doesnt work as seen in error:\n      5 print(type(y))\n----&gt; 6 return torch.clip(y,0.)\n\nTypeError: clip() received an invalid combination of arguments - got (int, float), but expected one of:\n * (Tensor input, Tensor min, Tensor max, *, Tensor out)\n * (Tensor input, Number min, Number max, *, Tensor out)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#torch.clip---version-2",
    "href": "posts/2024-03-13-relu/index.html#torch.clip---version-2",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.3 torch.clip - version 2",
    "text": "2.3 torch.clip - version 2\n\ndef sgl_relu_pytclip_v2(m,b,x):\n    xs_tsr = torch.tensor(x)\n    y = m*xs_tsr+b # convert inputs to tensor first\n    print(type(y))\n    return torch.clip(y,0.)\n    \nsgl_relu_pytclip_v2(1,1,1)\n\n&lt;class 'torch.Tensor'&gt;\n\n\ntensor(2.)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#torch.nn.functional.relu",
    "href": "posts/2024-03-13-relu/index.html#torch.nn.functional.relu",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "2.4 torch.nn.functional.relu",
    "text": "2.4 torch.nn.functional.relu\nnn.relu also only takes Tensor input. I’ll use this function going forward.\n\nimport torch.nn.functional as nn\n\ndef sgl_relu_nn(m,b,x):\n    xs_tsr = torch.tensor(x)\n    ys_tsr = m*xs_tsr+b # convert inputs to tensor first\n    relu_y = nn.relu(ys_tsr)\n    print(type(relu_y))\n    return relu_y\n\nsgl_relu_nn(1,1,1)\n\n&lt;class 'torch.Tensor'&gt;\n\n\ntensor(2)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#create-noisey-data-we-wish-to-model",
    "href": "posts/2024-03-13-relu/index.html#create-noisey-data-we-wish-to-model",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.1 Create noisey data we wish to model",
    "text": "5.1 Create noisey data we wish to model\n\nimport torch\nimport torch.nn.functional as nn\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact\n\ndef quad_fn(a,b,c,x): return a*x**2 + b*x + c\ndef quad_abc_fn(a,b,c): return partial(quad_fn,a,b,c)\n\nog_a= 3\nog_b= 2\nog_c= 1\n\nxs_100_tsr = torch.linspace(-2.1,2.1,steps=100)\nquad_og_model = quad_abc_fn(og_a,og_b,og_c)\n\nnp.random.seed(42)\n\ndef noise(tsr, scale): return np.random.normal(scale=scale,size=tsr.shape)\ndef add_scale_noise_to_tsr(tsr,scale,additive):\n    tsr = tsr+tsr*noise(tsr, scale)\n    tsr = tsr+noise(tsr, additive)\n    return tsr\n\nxs_20_tsr = torch.linspace(-2,2,steps=20)\nys_20_og_tsr = quad_og_model(xs_20_tsr)\nys_20_noisey_tsr = add_scale_noise_to_tsr(ys_20_og_tsr,0.15,1.5)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#recreate-double-relu-functions-learnt-earlier",
    "href": "posts/2024-03-13-relu/index.html#recreate-double-relu-functions-learnt-earlier",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.2 Recreate Double ReLU functions learnt earlier",
    "text": "5.2 Recreate Double ReLU functions learnt earlier\n\ndef relu_dbl_fn(m1,b1,m2,b2,x):\n    y1 = m1*x+b1\n    y2 = m2*x+b2\n    return nn.relu(y1) + nn.relu(y2)\n\n\ndef relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2): return partial(relu_dbl_fn,m1,b1,m2,b2)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#create-mae-calculate-and-loss-function",
    "href": "posts/2024-03-13-relu/index.html#create-mae-calculate-and-loss-function",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.3 Create MAE calculate and Loss Function",
    "text": "5.3 Create MAE calculate and Loss Function\n\ndef calc_mae(actual, preds): return torch.abs(actual-preds).mean()\n\ndef relu_2_loss_function(params):\n    def relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2): return partial(relu_dbl_fn,m1,b1,m2,b2)\n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(*params)\n    ys_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    return calc_mae(ys_20_noisey_tsr,ys_preds_20_tsr)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#loss-is-4.1318-with-original-input-tensor0.50.5-0.5-0.5",
    "href": "posts/2024-03-13-relu/index.html#loss-is-4.1318-with-original-input-tensor0.50.5-0.5-0.5",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.4 Loss is 4.1318 with original input tensor([0.5,0.5,-0.5,-0.5])",
    "text": "5.4 Loss is 4.1318 with original input tensor([0.5,0.5,-0.5,-0.5])\nOriginal model predictions (blue line) are not great, not very close to our data (red dots)\nThat makes sense since I arbitrarily chose the parameters of 0.5 and -0.5\n\nm1b1_m2b2_tsr = torch.tensor([0.5,0.5,-0.5,-0.5],requires_grad=True)\nrelu_2_loss_function(m1b1_m2b2_tsr)\n\ntensor(4.1318, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n# @interact(m1=0.5,b1=0.5,m2=-.5,b2=-.5)\ndef relu_dbl_interactive_plotter_fn(m1,b1,m2,b2):\n    xs_sgl_100_tsr = torch.linspace(-4.1,4.1,steps=100)\n    \n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2)\n    ys_dbl_m1b1m2b2_100_tsr = relu_dbl_m1b1m2b2_model(xs_sgl_100_tsr)\n\n    plt.xlim((-2,2))\n    plt.ylim((-1,15))\n    plt.plot(xs_sgl_100_tsr, ys_dbl_m1b1m2b2_100_tsr)\n    plt.scatter(xs_20_tsr,ys_20_noisey_tsr, color='r')\n\n    # print(ys_20_noisey_tsr)\n    ys_dbl_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    mae = calc_mae(ys_20_noisey_tsr, ys_dbl_preds_20_tsr)\n    plt.title(label=f\"mae: {mae:.2f}\")\nrelu_dbl_interactive_plotter_fn(0.5,0.5,-0.5,-0.5)"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#loss-with-gradient-descent-after-40-epochs",
    "href": "posts/2024-03-13-relu/index.html#loss-with-gradient-descent-after-40-epochs",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.5 1.96 Loss with Gradient Descent after 40 epochs",
    "text": "5.5 1.96 Loss with Gradient Descent after 40 epochs\n\nm1b1_m2b2_tsr = torch.tensor([0.5,0.5,-0.5,-0.5],requires_grad=True)\n\nfor i in range(40):\n    loss = relu_2_loss_function(m1b1_m2b2_tsr)\n    loss.backward()\n\n    with torch.no_grad():\n        m1b1_m2b2_tsr -= m1b1_m2b2_tsr.grad*0.01\n        print(f\"loss_{i+1}: {loss:.2f} - [{m1b1_m2b2_tsr}]\")\n\nloss_1: 4.13 - [tensor([ 0.5049,  0.5045, -0.5039, -0.4975], requires_grad=True)]\nloss_2: 4.13 - [tensor([ 0.5147,  0.5135, -0.5118, -0.4925], requires_grad=True)]\nloss_3: 4.11 - [tensor([ 0.5295,  0.5260, -0.5237, -0.4850], requires_grad=True)]\nloss_4: 4.09 - [tensor([ 0.5493,  0.5420, -0.5399, -0.4745], requires_grad=True)]\nloss_5: 4.07 - [tensor([ 0.5741,  0.5615, -0.5606, -0.4610], requires_grad=True)]\nloss_6: 4.04 - [tensor([ 0.6038,  0.5845, -0.5857, -0.4445], requires_grad=True)]\nloss_7: 4.00 - [tensor([ 0.6386,  0.6110, -0.6153, -0.4250], requires_grad=True)]\nloss_8: 3.95 - [tensor([ 0.6784,  0.6410, -0.6488, -0.4030], requires_grad=True)]\nloss_9: 3.90 - [tensor([ 0.7237,  0.6740, -0.6865, -0.3785], requires_grad=True)]\nloss_10: 3.85 - [tensor([ 0.7744,  0.7100, -0.7282, -0.3515], requires_grad=True)]\nloss_11: 3.78 - [tensor([ 0.8306,  0.7490, -0.7742, -0.3215], requires_grad=True)]\nloss_12: 3.71 - [tensor([ 0.8916,  0.7900, -0.8245, -0.2885], requires_grad=True)]\nloss_13: 3.65 - [tensor([ 0.9573,  0.8330, -0.8791, -0.2525], requires_grad=True)]\nloss_14: 3.57 - [tensor([ 1.0277,  0.8780, -0.9379, -0.2140], requires_grad=True)]\nloss_15: 3.50 - [tensor([ 1.1028,  0.9250, -1.0008, -0.1730], requires_grad=True)]\nloss_16: 3.41 - [tensor([ 1.1827,  0.9740, -1.0679, -0.1295], requires_grad=True)]\nloss_17: 3.33 - [tensor([ 1.2674,  1.0250, -1.1392, -0.0835], requires_grad=True)]\nloss_18: 3.24 - [tensor([ 1.3567,  1.0780, -1.2146, -0.0355], requires_grad=True)]\nloss_19: 3.15 - [tensor([ 1.4508,  1.1330, -1.2941,  0.0145], requires_grad=True)]\nloss_20: 3.05 - [tensor([ 1.5497,  1.1900, -1.3776,  0.0665], requires_grad=True)]\nloss_21: 2.94 - [tensor([ 1.6533,  1.2490, -1.4653,  0.1205], requires_grad=True)]\nloss_22: 2.84 - [tensor([ 1.7616,  1.3100, -1.5559,  0.1755], requires_grad=True)]\nloss_23: 2.74 - [tensor([ 1.8746,  1.3730, -1.6496,  0.2310], requires_grad=True)]\nloss_24: 2.65 - [tensor([ 1.9926,  1.4375, -1.7457,  0.2860], requires_grad=True)]\nloss_25: 2.57 - [tensor([ 2.1154,  1.5035, -1.8419,  0.3385], requires_grad=True)]\nloss_26: 2.51 - [tensor([ 2.2432,  1.5710, -1.9384,  0.3885], requires_grad=True)]\nloss_27: 2.45 - [tensor([ 2.3758,  1.6400, -2.0349,  0.4360], requires_grad=True)]\nloss_28: 2.39 - [tensor([ 2.5133,  1.7105, -2.1317,  0.4810], requires_grad=True)]\nloss_29: 2.33 - [tensor([ 2.6552,  1.7815, -2.2286,  0.5235], requires_grad=True)]\nloss_30: 2.27 - [tensor([ 2.8015,  1.8530, -2.3256,  0.5635], requires_grad=True)]\nloss_31: 2.23 - [tensor([ 2.9509,  1.9240, -2.4228,  0.6010], requires_grad=True)]\nloss_32: 2.19 - [tensor([ 3.1036,  1.9945, -2.5202,  0.6360], requires_grad=True)]\nloss_33: 2.16 - [tensor([ 3.2595,  2.0645, -2.6177,  0.6685], requires_grad=True)]\nloss_34: 2.12 - [tensor([ 3.4186,  2.1340, -2.7154,  0.6985], requires_grad=True)]\nloss_35: 2.07 - [tensor([ 3.5809,  2.2030, -2.8133,  0.7260], requires_grad=True)]\nloss_36: 2.05 - [tensor([ 3.7455,  2.2705, -2.9113,  0.7510], requires_grad=True)]\nloss_37: 2.03 - [tensor([ 3.9124,  2.3365, -3.0094,  0.7735], requires_grad=True)]\nloss_38: 2.01 - [tensor([ 4.0815,  2.4010, -3.1077,  0.7935], requires_grad=True)]\nloss_39: 1.98 - [tensor([ 4.2528,  2.4640, -3.2062,  0.8110], requires_grad=True)]\nloss_40: 1.96 - [tensor([ 4.4251,  2.5245, -3.3031,  0.8250], requires_grad=True)]"
  },
  {
    "objectID": "posts/2024-03-13-relu/index.html#predictions-blue-line-vs-data-red-dots",
    "href": "posts/2024-03-13-relu/index.html#predictions-blue-line-vs-data-red-dots",
    "title": "Rectified Linear Unit (ReLU)",
    "section": "5.6 Predictions (blue line) vs Data (red dots)",
    "text": "5.6 Predictions (blue line) vs Data (red dots)\nNew Parameters has created a Double ReLU predictions shaped closer to the Noisey Data as seen below!\n\ndef relu_dbl_interactive_plotter_fn(m1,b1,m2,b2):\n    xs_sgl_100_tsr = torch.linspace(-4.1,4.1,steps=100)\n    \n    relu_dbl_m1b1m2b2_model = relu_dbl_m1b1m2b2_fn(m1,b1,m2,b2)\n    ys_dbl_m1b1m2b2_100_tsr = relu_dbl_m1b1m2b2_model(xs_sgl_100_tsr)\n\n    plt.xlim((-2,2))\n    plt.ylim((-1,15))\n    plt.plot(xs_sgl_100_tsr, ys_dbl_m1b1m2b2_100_tsr)\n    plt.scatter(xs_20_tsr,ys_20_noisey_tsr, color='r')\n\n    # print(ys_20_noisey_tsr)\n    ys_dbl_preds_20_tsr = relu_dbl_m1b1m2b2_model(xs_20_tsr)\n    mae = calc_mae(ys_20_noisey_tsr, ys_dbl_preds_20_tsr)\n    plt.title(label=f\"mae: {mae:.2f}\")\nrelu_dbl_interactive_plotter_fn(m1=4.4251,  b1=2.5245, m2=-3.3031,  b2=0.8250)"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html",
    "href": "posts/2024-01-24-99_multi_classifier/index.html",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "",
    "text": "I’ve just created my first multi-category classifier using Jeremy Howard’s popular fast ai which is an astraction layer library built on top of the most world’s used deep-learning library PyTorch. I’ve documented the process including the issues I faced (i.e. bugs)\nI found it more easier to digest and understand this process by splitting the steps into 3 parts:\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#part-1-create-learner-.pkl-file",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "Part 1: Create Learner (.pkl file)",
    "text": "Part 1: Create Learner (.pkl file)"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#install-and-import-libraries",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.1 Install and import libraries",
    "text": "1.1 Install and import libraries\n\n!pip install timm\n!pip install fastai \n\n\nfrom fastai.vision.all import *\nimport timm"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#download-pets-breed-data",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.2 Download Pets Breed Data",
    "text": "1.2 Download Pets Breed Data\n\npath = untar_data(URLs.PETS)/'images'"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#create-data-loader",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.3 Create Data Loader",
    "text": "1.3 Create Data Loader\n\n1.3.1 (A different) Labelling Function\nHere a different method to label our data was used:\n\nIn ‘noodles vs rice’ model: There were two parent folders separating two categories of data: get_y=parent_label\nIn ‘saving a fast ai’ model: There was a custom labelling function that looked for capital letters for cat breeds def is_cat(x): return x[0].isupper()\nIn this model, I used Regex to find breed names before the last ’_’ in the file name: label_func=RegexLabeller(pat=r'^([^/]+)_\\d). See show_batch() output to see the file names examples.\n\nDid you notice this is the same dataset as the is_cat model? So changing our label resulted in a different model!\n\n\n1.3.2 Data Loader Code\n\npets_dataloaders =  ImageDataLoaders.from_name_func(\n    '.',\n    get_image_files(path),\n    valid_pct=0.2,\n    seed=42,\n    label_func=RegexLabeller(pat=r'^([^/]+)_\\d+'),\n    item_tfms=Resize(224))\n\nc:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n  return getattr(torch, 'has_mps', False)"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#batch-examples-create-learner-fine-tune-and-export",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "1.4 Batch Examples, Create Learner, Fine-Tune and Export",
    "text": "1.4 Batch Examples, Create Learner, Fine-Tune and Export\nI grouped these steps as the code are exactly the same in previous posts.\n\n1.4.1 Batch Examples\nThis function is also a good way to find out what is the file name structure if we were not sure.\n\npets_dataloaders.show_batch(max_n=8)\n\n\n\n\n\n\n\n\n\n\n1.4.2 Create Learner\nI am still using resnet model architecture for starters for reasons mentioned previously by Jeremy Howard\n\npets_learner = vision_learner(pets_dataloaders, resnet34, metrics=error_rate)\n\n\n\n1.4.3 Fine-Tune\n\npets_learner.fine_tune(3) \n\n\n\n1.4.4 Export\n\npets_learner.export('pets_learner.pkl')"
  },
  {
    "objectID": "posts/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "href": "posts/2024-01-24-99_multi_classifier/index.html#to-be-continued",
    "title": "How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 1)",
    "section": "To be Continued…",
    "text": "To be Continued…\nPart 1: Create Learner (.pkl file)\nPart 2: Create Gradio application file (app.py)\nPart 3: Host on HuggingFace"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#download-kaggle-data",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "1. Download Kaggle Data",
    "text": "1. Download Kaggle Data\nLog into Kaggle:\n1. Competitions\n2. Titanic\n3. Data\n4. Train.csv and Download"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#clean-dataset",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "2. Clean Dataset",
    "text": "2. Clean Dataset\nEach single passenger is represented by a single row with demographics and information across the columns.\nFor this first attempt, I’ll keep the model simple and used 8 columns and discarded the rest.\n[Future Iteration]: Would using more columns increase my accuracy?\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger - Kaggle Data Description\nNote: There are originally 891 Passengers (rows) in the training dataset.\nThere were a few steps taken to clean the data:\n1. Keep Certain Columns Only:\n- Survived\n- Pclass - Sex - Age - SibSp - Parch - Fare - Embarked 2. Remove blanks from: - Sex (177 rows removed) - Embarked (2 rows removed) Columns: Remaining Passengers (712 = 891-177-2)\n\nCreate a New Sheet and Copy over the editted Dataset"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#binary-categorical-variables",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "3. Binary Categorical Variables",
    "text": "3. Binary Categorical Variables\nRecall a Function has inputs and parameters. The output is calculated by adding the all the inputs which are weighted (multiplied) by the parameters.\nIn neural network basics: - the inputs were a single variable x and the output was a single y (or f(x)).\n- the parameters (coefficients of x) could be optimised against a Loss Function (Mean Squared Error) to achieve a high accuracy (good predictability) for that function, called Gradient Descent - an arbitrary number of Rectified Linear Unit (ReLU) could be added together to form any function to fit a given set of data and parameter (weights) can be optimised to minimise the loss function as above with gradient descent.\nSimilarly, the inputs in the Titanic model will be the information describing the passengers, i.e. columns in our spreadsheet, are multiplied by the parameters (weights or coefficients) to represents its importance.\n\nQuestion: But how can a parameter (number) be multiplied to word (text) such as male or female from the Sex Column or Letter S or C or Q from the Embarked Column?\nAnswer: You Can’t.\n\nHowever, Categorical Variables (unordered) can be converted into Binary Categorical Variables:\n- IsMale will indicate a 1 for True (Male) and 0 for False (Female)\n- Embarked has 3 categories “S, C and Q: Having two columns (S and C) to represent the 3 categories will suffice. If both S and C columns have 0’s, this implies it is a Q, so we do not need the extra column to have all the information.\n- PClass (1, 2 and 3) also has 3 categories and is treated the same as above.\n- Age and Fare are continuous values and left them as is for now"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#regression",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "4. Regression",
    "text": "4. Regression\nI created random variables (coefficients or weights for our parameters) with rand() and multiplied them to each parameter. I did this for several rows to and looked at the output.\nLooks like Age and Fare columns are dominating our function.\n\n\n4.1 Dealing with Continuous Variables Age and Fare\nIts probably fair (see what I did there) that a Passenger’s age (or fare) shouldn’t be the only two defining factors to determine their survivability as the above model suggests.\nThese values need to be normalised: - For Age, I divided each passengers age by the maximum age. - For Fare, I took the Logarithm of each passengers fare. Taking the Log of a variable where there are very small values and a few large ones distributes the values more evenly.\n\n\n\n4.2 Prediction and Loss and Average Loss\nPrediction: Multiply each parameter by the random coefficient created and sum it up to have our prediction.\n- I used the SumProduct() function. - I also created a manual linear version from scratch to see test my understanding was correct and sumproduct was working as expected. It was.\nLoss: It’s the survival (0 No, 1 Yes) minus the Prediction, then squared. - This is the squared error. If the errors are not squared, the errors end up cancelling each other off. Alternatively, the absolute errors could be taken done previously.\nAverage Loss: Self-explanatory.\n\nNote: Current Average Loss is 0.886 with random parameters.\n\n\n4.3 Gradient Descent (or Solver)\nSetting the Solver to Minimise our Average Loss, our parameters have been adjusted and Average Loss has come down to: 0.535!\nNot but but this isn’t a neural net yet, its just a regression."
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#neural-network",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "5. Neural Network",
    "text": "5. Neural Network\nParams_2: Add another set of random coefficients.\nLinear_2: Calculate the linear model on this set of coefficients.\nReLU: ReLUs are calculated with an IF() statement, if it is below zero, then set to zero, otherwise keep the value.\nPrediction: Add the ReLUs.\nLoss Prediction minus Survived.\nAverage Loss: Run Solver, but this time allow the change of both sets of coefficients Params_1 and Params_2\nNote: Current Neural Network Average Loss is 0.527 with random parameters.\n\n[Future Iteration]: To be honest, I haven’t quite understood fully whats going on here. The concept of adding a second set of parameters and then having two Linear Models and adding together their reLUs will give a prediction that can be optimised, just dont get it yet. be fair, I just learnt Gradient Descent a day or two ago.\n\n5.1 Error In Optimisation - All ReLUs going to Zero\nHaving no constraints on whether coefficients can be negative or positive, the Solver found the most convenient result of making all parameters less than zero, hence making outputs a negative linear output, which makes all the ReLUs Zero, hence simply making the prediction that everyone died! A quick and dirty prediction thats not too bad but very scientific…\nNote: I’m currently using WPS Solver rather than Excel Solver (Don’t own paid version of Excel). Not sure if I did a mistake in my model or its a Solver thing.\n\n\n\n5.2 Setting Constraints (Coefficients &gt; 0)\nBy placing the constraint the Solver seems to finally do what is expected.\nThe Average Loss has come down from the Regresssion 0.535 to 0.235!\n\n\n\n5.3 Added Ones Columns\nBut this didn’t fix the Solver Issuer.\n\n\n\n5.4 Matrix Multiplication\nI made a Matrix Multiplication version and optimised with the same silly negative parameters solution"
  },
  {
    "objectID": "posts/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "href": "posts/2024-02-04-neural_network_spreadsheet/index.html#mission-failed.",
    "title": "Neural Networks in a Spreadsheet (Attempt 1)",
    "section": "6. Mission Failed.",
    "text": "6. Mission Failed.\nHaving downloaded the spreadsheet from Jeremy and ran the Solver, the Zero ReLUs error persists. This is a WPS Sheets issue.\nI also tried getting Solver on Google Sheets with no Luck however my emails permissions didn’t allow the install. Will give it a go to fix it next time.\nFor now, today I’ll admit defeat. Onwards to tomorrow…\nI’ll upload this notebook anyway because I want to record my failures as well as my triumphs."
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html",
    "href": "posts/2024-02-02-neural_network_basics/index.html",
    "title": "Neural Network Basics (Part 2)",
    "section": "",
    "text": "Automation of finding the best parameters (lowest loss) based on Mean Average Error (MAE) using Gradient Descent for our Quadratic Function"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#import-libraries",
    "href": "posts/2024-02-02-neural_network_basics/index.html#import-libraries",
    "title": "Neural Network Basics (Part 2)",
    "section": "1. Import Libraries",
    "text": "1. Import Libraries\n\nfrom ipywidgets import interact\nfrom fastai.basics import *\nimport pandas as pd\nfrom functools import partial"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "href": "posts/2024-02-02-neural_network_basics/index.html#upload-data-and-convert-data-to-pytorch-tensors",
    "title": "Neural Network Basics (Part 2)",
    "section": "2. Upload Data and Convert Data to Pytorch Tensors",
    "text": "2. Upload Data and Convert Data to Pytorch Tensors\n\ndf = pd.read_csv(\"upload_dataset.csv\")\nx_trch = torch.tensor(df.x) \ny_trch = torch.tensor(df.y)"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "href": "posts/2024-02-02-neural_network_basics/index.html#create-customisable-quadratic-functions-and-interactively-plot-with-mae",
    "title": "Neural Network Basics (Part 2)",
    "section": "3. Create Customisable Quadratic functions and Interactively Plot with MAE",
    "text": "3. Create Customisable Quadratic functions and Interactively Plot with MAE\n\ndef gen_quad_fn(a,b,c,x): return a*x**2 + b*x + c\ndef custom_quad_fn(a,b,c): return partial(gen_quad_fn,a,b,c)\ndef torch_mae(prediction, actual): return (torch.abs(prediction-actual).mean())\ndef torch_mse(prediction, actual): return ((prediction-actual)**2).mean()\n\n\n# def mae(prediction, actual): return np.mean(abs(prediction-actual))\n# def torch_mae(prediction, actual): return np.mean(torch.abs(prediction-actual))\n# def mae(prediction, actual): return (torch.abs(prediction-actual).mean())\n# def mae2(prediction, actual): return abs(prediction-actual).mean()\n# def mae_jh(prediction, actual): return (abs(prediction-actual)).mean()\n# def mse_jh(prediction, actual): return ((prediction-actual)**2).mean()\n# def mae(preds, acts): return (torch.abs(preds-acts)).mean()\n\n\nplt.rc('figure', dpi=90)\n\n@interact(a=(0,2.1,0.1),b=(0,2.1,0.1),c=(0,2.1,0.1))\ndef interactive_plot(a,b,c):\n# 1.    plot scatter\n    plt.scatter(x_trch, y_trch)\n# 2     create custom_quad_interactive_fn\n# 2.1   create xs_interact    \n    xs_interact = x_trch\n# 3.    create ys_interact\n    plt.ylim(-1,15)\n    ys_interact = custom_quad_fn(a,b,c)(xs_interact)\n# 4.    calc mae\n    y_actual     = y_trch\n    y_predicted  = custom_quad_fn(a,b,c)(x_trch)\n    interact_mae = torch_mae(y_predicted,y_actual)\n# 5. plot   \n    plt.plot(xs_interact, ys_interact)\n    plt.title(f\"MAE: {interact_mae:.2f}\")"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "href": "posts/2024-02-02-neural_network_basics/index.html#determining-the-effect-of-the-parameters-a-b-c-in-ax-bx2-c",
    "title": "Neural Network Basics (Part 2)",
    "section": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)",
    "text": "4. Determining the effect of the parameters (\\(a\\), \\(b\\), \\(c\\)) in: \\(ax + bx^2 + c\\)\nThe key thing to understand if whether the loss function gets better or worse when you increase the parameters a little.\nThere are two ways we can try: 1. Manually adjust the parameter: Move each parameter each way and observe the impact to MAE.\n2. Calculate the Derivative of the parameter: A Derivative iS a function that tells you if you increase the input the: - direction in which output changes (increases or decreases) and the;\n- magnitude of the change to the output\n\n4.1 Create Mean-Absolute-Error (mae) Quadratic Function\nThis function will take in the parameters or coefficients of a quadratic function and output the MSE. - Input: coeffiicents of quadratic - Output: MAE (between the prediction of the quadratic with the coffecients of the quadratic and the actual predictsions)\n\ndef mae_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mae(y_predicted_trch,y_actual_trch)\n\ndef mse_quad_fn(x_trch, y_trch, abc_params):\n    quad_fn = custom_quad_fn(*abc_params)\n    y_predicted_trch = quad_fn(x_trch)\n    y_actual_trch    = y_trch\n    # so quad_params(2,3,4) -&gt;  creates a custom quad fn -&gt; 2x^2 + 3x + 4\n    return torch_mse(y_predicted_trch,y_actual_trch)\n\nThe chart shows MAE(2,2,2) = 1.4501 loss Our mae_function also calculates 1.491 loss.\n\nmae_quad_fn(x_trch=x_trch,y_trch=y_trch,abc_params=[1.0,1.0,1.0])\n\ntensor(2.6103, dtype=torch.float64)\n\n\nA tensor is a pytorch type that works with: - lists (1D tensors) - tables (2D tensors) - layers of tables of numbers (3D tensors) and etc\n\n\n4.2 Telling PyTorch to calculate gradients\nBy calling method .requires_grad_(), our abc_rg tensor is not will calculate gradients whenever we use the tensor.\n\n# rank 1 tensor\nabc_rg = torch.tensor([1.0,1.0,1.0])\nabc_rg.requires_grad_()\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\nabc_rg\n\ntensor([1., 1., 1.], requires_grad=True)\n\n\n\n4.2.1 Method .requires_grad_()\ngrad_fn=&lt;MeanBackward0&gt; shows the gradients are calculated to for each parameter (our inputs)\n\nloss = mae_quad_fn(x_trch, y_trch, abc_rg)\nloss\n\ntensor(2.6103, dtype=torch.float64, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n\n4.2.2 Method .backward()\nThis adds an attribute .grad to our abc_rg tensor.\n\nloss.backward()\n\n\n\n4.2.3 Attribute .grad\nThis attributes tells us if we increase the input slightly in the same position of this tensor, the loss will increase (if its positive) or decrease (if negative)\n\nabc_rg.grad\n\ntensor([-1.3529, -0.0316, -0.5000])\n\n\n\n\n4.2.4 Increase our abc parameters and recalculate loss\n\nwith torch.no_grad():\n    print(f\"loss before: {loss}\")\n    abc_rg -= abc_rg.grad * 0.01\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    print(f\"loss after: {loss}\")\n\nloss before: 2.61030324932801\nloss after: 2.5894896953092177\n\n\n\n\n4.2.5 Automate it\nCreate a loop that decreases the loss by iteratively increasing the parameters (since the gradients are negative, or vice versa)\n\nfor i in range(10):\n    loss = mae_quad_fn(x_trch, y_trch, abc_rg)\n    loss.backward()\n    with torch.no_grad(): abc_rg -= abc_rg.grad * 0.01\n    print(f\"step {i}: {loss} - {abc_rg.grad}\") \n\nstep 0: 2.5894896953092177 - tensor([-2.7058, -0.0632, -1.0000])\nstep 1: 2.547862587271633 - tensor([-4.0587, -0.0947, -1.5000])\nstep 2: 2.4854217639359875 - tensor([-5.4116, -0.1263, -2.0000])\nstep 3: 2.4021673865815485 - tensor([-6.7645, -0.1579, -2.5000])\nstep 4: 2.2980994552083187 - tensor([-8.1175, -0.1895, -3.0000])\nstep 5: 2.173217969816296 - tensor([-9.4704, -0.2211, -3.5000])\nstep 6: 2.0300959430578267 - tensor([-10.6892,  -0.3684,  -3.9000])\nstep 7: 1.883669135864714 - tensor([-11.9080,  -0.5158,  -4.3000])\nstep 8: 1.740979068220988 - tensor([-12.9396,  -0.8000,  -4.6000])\nstep 9: 1.5914231086209807 - tensor([-13.9712,  -1.0842,  -4.9000])\n\n\n\n\n\n5 Parameters are getting closer\nThe parameters started as 1,1,1 and now are 1.9, 1.0, 1.3, the underlying function was modelled with 3, 2, 1 so its getting there!\n[Future Iteration] How to just fix a parameter and just move the others?\n\nabc_rg\n\ntensor([1.8739, 1.0365, 1.3170], requires_grad=True)"
  },
  {
    "objectID": "posts/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "href": "posts/2024-02-02-neural_network_basics/index.html#to-be-continued",
    "title": "Neural Network Basics (Part 2)",
    "section": "To be Continued…",
    "text": "To be Continued…\nNext A universal function called the ReLU Function (rather than a quadratric function) is used for our modelling.\nNeural Network Basics: Part 1\nNeural Network Basics: Part 2\nNeural Network Basics: Part 3"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#linearsearch-n_steps-of-orderd_array",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#linearsearch-n_steps-of-orderd_array",
    "title": "DSA: Binary Search Exercises",
    "section": "1.1 \\(LinearSearch()\\): n_steps of orderd_array:",
    "text": "1.1 \\(LinearSearch()\\): n_steps of orderd_array:\n\nHow many steps perform a linear search for the number 8 in the ordered array [2, 4, 6, 8, 10, 12, 13]?"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer",
    "title": "DSA: Binary Search Exercises",
    "section": "1.2 Written Answer",
    "text": "1.2 Written Answer\n\nCount up from index 0 through array to find the target.\nIt’s the 3rd index, or 4th item, therefore 4 steps."
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#python-answer",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#python-answer",
    "title": "DSA: Binary Search Exercises",
    "section": "1.3 Python Answer",
    "text": "1.3 Python Answer\n\ndef calc_linear_search_n_steps(input_arr, target):\n    print(rf\"LinearSearch() began on array: {input_arr}\")\n    counter = 0\n    for i,v in enumerate(input_arr):\n        counter += 1\n        if input_arr[i] == target:\n            print(rf\"Target found [{target}]: [{counter}] steps\")\n            return counter\n    print(rf\"Target not found in [{input_arr}]\")\n    return False\nlinear_search_n_steps = calc_linear_search_n_steps([2, 4, 6, 8, 10, 12, 13], 8)\n\nLinearSearch() began on array: [2, 4, 6, 8, 10, 12, 13]\nTarget found [8]: [4] steps"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#binarysearch-n_steps-of-orderd_array",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#binarysearch-n_steps-of-orderd_array",
    "title": "DSA: Binary Search Exercises",
    "section": "2.1 \\(BinarySearch()\\): n_steps of orderd_array:",
    "text": "2.1 \\(BinarySearch()\\): n_steps of orderd_array:\nHow many steps would binary search take for the previous example?"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer-1",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer-1",
    "title": "DSA: Binary Search Exercises",
    "section": "2.2 Written Answer",
    "text": "2.2 Written Answer\nChoose middle index and compare against target, here it is 1 step."
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#python-answer-1",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#python-answer-1",
    "title": "DSA: Binary Search Exercises",
    "section": "2.3 Python Answer",
    "text": "2.3 Python Answer\n\ndef calc_binary_search_n_steps(input_arr, target):\n    print(rf\"BinarySearch() began on array: {input_arr}\")\n\n    l,r = 0, len(input_arr)-1 # set left, right index bounds\n    counter = 0\n    while l&lt;=r:\n        counter+=1\n        m=(l+r)//2 # middle-index\n        if input_arr[m] == target:\n            print(rf\"Target found [{target}]: [{counter}] steps\")\n            return counter\n        elif input_arr[m] &lt; target:\n            l=m+1\n        elif input_arr[m] &gt; target:\n            r=m-1\n    print(rf\"Target not found in [{input_arr}]\")\n    return False\ncalc_binary_search_n_steps([2, 4, 6, 8, 10, 12, 13], 8)\n    \n\nBinarySearch() began on array: [2, 4, 6, 8, 10, 12, 13]\nTarget found [8]: [1] steps\n\n\n1"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#middle-index-m---some-comments",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#middle-index-m---some-comments",
    "title": "DSA: Binary Search Exercises",
    "section": "2.4 Middle Index: m - Some Comments",
    "text": "2.4 Middle Index: m - Some Comments\nI did not fully understand how the middle-index m is calculated despite it looking simple:\n\nm=(l+r)//2"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#middle-index-m-table",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#middle-index-m-table",
    "title": "DSA: Binary Search Exercises",
    "section": "2.5 Middle-Index m Table",
    "text": "2.5 Middle-Index m Table\nSo, I created a table showing: * left and right-indices (like the algorithm) * middle-index calculation before rounding down * middle-index calculation after rounding down\nI didnt have any intuition on how it increments, so for me it’s fascinating and surprising that it increments by 2 each time…. Some math thing going on which I dont understand but at least I know how it works a bit more after this table\nTop Table: Calculates m with rounding down (as in algorithm):\n\nm = (l+r)//2\n\ni.e. the middle index chosen to compare against the target\n\n\nBottom Table: Calculates m with no rounding:\n\nm = (l+r)/2\n\nNotice the pre-rounded value increments is by 0.5\nAnd we dont have non-integer indexing so this forces us to round up or down,\nSo by rounding down, we see m goes up every 2 indices, pretty cool and also makes sense."
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#binarysearch-max_n_steps-of-orderd_array",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#binarysearch-max_n_steps-of-orderd_array",
    "title": "DSA: Binary Search Exercises",
    "section": "3.1 \\(BinarySearch()\\): max_n_steps of orderd_array:",
    "text": "3.1 \\(BinarySearch()\\): max_n_steps of orderd_array:\nWhat is the maximum number of steps it would take to perform a binary search on an array of size 100,000?"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer-2",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#written-answer-2",
    "title": "DSA: Binary Search Exercises",
    "section": "3.2 Written Answer",
    "text": "3.2 Written Answer\nA characteristic of the \\(BinarySearch()\\) is that:\n\nThe number of items (array_size) searchable doubles at each \\(step\\):\n\ncan be described by an exponential function\nwith base of 2\nwhere n is the number of steps:\n\n\nDefined as: \\[array\\_size = 2^n\\]\nThat is, the questions is asking: \\[100,000 = 2^n\\] \\[\\log(100,000) = \\log(2^n)\\] \\[\\log(100,000) = n\\log(2)\\] \\[\\frac{\\log(100,000)}{\\log(2)} = n\\] \\[n=\\frac{\\log(100,000)}{\\log(2)}\\] \\[n=16.610\\ steps(3\\ d.p)\\]"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#python-function",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#python-function",
    "title": "DSA: Binary Search Exercises",
    "section": "3.3 Python Function",
    "text": "3.3 Python Function\n\ndef calc_bin_search_nsteps(arr_size: int):\n    import numpy as np\n    # 2^n_steps = arr_size\n    # log (2^n_steps) = log (arr_size)\n    # (n_steps) * log (2) = log (arr_size)\n    # (n_steps)  = log (arr_size)/log(2)\n    # (n_steps)  = log (arr_size)/log(2)\n    # (n_steps  = log (100_000)/log(2)\n    return np.log(arr_size)/np.log(2)\n\nbin_search_nsteps = calc_bin_search_nsteps(100_000)\nbin_search_nsteps\n\nnp.float64(16.609640474436812)"
  },
  {
    "objectID": "posts/notes/dsa/dsa_ch02-exercises.html#n-chart",
    "href": "posts/notes/dsa/dsa_ch02-exercises.html#n-chart",
    "title": "DSA: Binary Search Exercises",
    "section": "3.4 \\(2^n\\) Chart",
    "text": "3.4 \\(2^n\\) Chart\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n### x-values ###\nxpt = 1\nx_deviation = 16\nx_no_of_increments = 32\nxs_min = xpt - x_deviation\nxs_max = xpt + x_deviation\n# xs = np.linspace(xs_min, xs_max, x_increments)  # XS\nxs = np.linspace(0, xs_max, x_no_of_increments)  # XS\nprint(xs)\n### exclude x-values ### (eg f(x!=0)=1/x, f(x&gt;0)=log(x))\n# xs = xs[xs != 1]\nxs = xs[xs &gt; 0]\n\n### the function ###\n# lbl_fx = r'$f(x)= 6.1t^{2}-9.28t+16.43$'   # LABEL\n# lbl_fx = r'$f(x)= log(x)$'   # LABEL\n# fx_fx = lambda x: np.log(x)  # f(x)\n\n# ### y-values ###\n# ys_fx = fx_fx(xs)            # ys=f(xs)\n# ypt_fx = fx_fx(xpt)\n# print(f\"ypt_fx_at_P(x={xpt}): {ypt_fx}\")\n\n### other plots ###\nlbl_fx2 = r'$f(x)=2^x$'\nfx_fx2 = lambda x: 2**x\nys_fx2 = fx_fx2(xs)\n\n### derivative ###\n# lbl_dydx = r\"$f'(x)=6s(x={xpt_dydx}): {dydx}\")\n\n### tangent ###\n# c_tangent = ypt_fx-(dydx)*(xpt)\n# tgt = \"tangent\"\n# lbl_tangent = rf'$f_t(x)={dydx:,.1f}t+{c_ta\n# ngent:,.1f}$ (tangent at x={xpt})'\n# fx_tangent = lambda x: dydx*xs+c_tangent\n# ys_tangent = fx_tangent(xs)\n\n### plot things ####\n# plt.plot(xs, ys_fx,  'o', markersize=1, label=lbl_fx)\nplt.plot(xs, ys_fx2,  '-', markersize=1, label=lbl_fx2)\n# plt.plot(xs, ys_fx,  'r^-', linewidth=2, markersize=1, label=lbl_fx)\n# plt.scatter(xs, ys_fx, marker=\"o\")\n# plt.scatter(x=xpt, y=fx_fx(xpt), marker=\"o\")\n# plt.plot(xs, ys_tangent,      'yo-', linewidth=2, markersize=6, label=lbl_tangent)\n# plt.plot(xs, ys_fx2,      'bo-', linewidth=2, markersize=8, label=lbl_fx2)\n\n##### EXTRAS: title, grid, legend, zooming, ticks, hline, vline, tickers #####\n\n# title\n# plot_title = lbl_fx\nplot_title = lbl_fx2\nplt.title(plot_title, loc='left')\n# plot_title = lbl_fx + f\" & it's tangent at x={xpt}\"\n# plot_title = lbl_fx + \"at (4,2)\"\n# plot_title = lbl_fx2 + \" and \" + lbl_fx2 + \"at (3,3)\"\n# plot_title = lbl_fx + \" and \" + lbl_tangent + \"at (4,2)\"\n\n# grid \nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\n\n# legend plt.legend(loc='upper right')\nplt.legend(loc='lower right')\n\n# zoom! enhance! #\n# zoom_inc = 20\n# plt.xlim(xpt-zoom_inc,xpt+zoom_inc)  # x-rng\n# plt.ylim(-0.1, 0.1)  # y-rng\n\n# vertical, horizontal, \nax = plt.gca()  # Get the current axis\nax.axvline(x=xpt, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n\n# ax.axvline(x=0, color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=fx_fx(xpt), color='grey', linestyle='--', linewidth=0.5)\n# ax.axhline(y=0, color='grey', linestyle='--', linewidth=0.5)\n\n# X-LIMIT & VALUE\n# plt.vlines(x_at_c,linestyles=\"dotted\", ymin=plt.ylim()[0], ymax=max(ys)) # non-monotonic\nplt.plot(bin_search_nsteps, 100_000,marker=\"o\",markersize=15, markerfacecolor='none', markeredgecolor='red')\n\n# OTHER\n# b+-- , o:b , r^ , bo    plt.xlabel(\"\") \n# plt.ylim(bottom=0)  # chart starts from y=0\n# ax.yaxis.set_minor_locator(ticker.MultipleLocator(20000)) # minor ticks\n# ax.xaxis.set_minor_locator(ticker.MultipleLocator(2)) # minor ticks\n# ref: https://matplotlib.org/stable/users/explain/axes/axes_ticks.html\n\n\n[ 0.          0.5483871   1.09677419  1.64516129  2.19354839  2.74193548\n  3.29032258  3.83870968  4.38709677  4.93548387  5.48387097  6.03225806\n  6.58064516  7.12903226  7.67741935  8.22580645  8.77419355  9.32258065\n  9.87096774 10.41935484 10.96774194 11.51612903 12.06451613 12.61290323\n 13.16129032 13.70967742 14.25806452 14.80645161 15.35483871 15.90322581\n 16.4516129  17.        ]"
  },
  {
    "objectID": "posts/notes/linear_algebra/6-more_eigen_egs.html#normal-mode",
    "href": "posts/notes/linear_algebra/6-more_eigen_egs.html#normal-mode",
    "title": "More Eigen examples",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode\n\n2.1 Exampe 1\n\n\n\n2.2 Exampe 2\n\n\n\n2.3 Exampe 3"
  },
  {
    "objectID": "posts/notes/linear_algebra/5-similar_matrices.html#normal-mode",
    "href": "posts/notes/linear_algebra/5-similar_matrices.html#normal-mode",
    "title": "It’s nice to be similar (matrices)",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/linear_algebra/3-eigen_examples.html#normal-mode",
    "href": "posts/notes/linear_algebra/3-eigen_examples.html#normal-mode",
    "title": "Eigenvales and Eigenvectors Example",
    "section": "2. Normal Mode",
    "text": "2. Normal Mode"
  },
  {
    "objectID": "posts/notes/coding/20-encapsulation-getter-python.html",
    "href": "posts/notes/coding/20-encapsulation-getter-python.html",
    "title": "Encapsulation: Getter Method in Python",
    "section": "",
    "text": "1. Introduction\nThis post is specifically related to Issue #22 of tonyjustdevs/learning_designpatterns:\n\nadd @property decorator to enable getter\n\n\n\n2. Background\nEncapsulation is the:\n\nbundling of data (attributes) and\nmethods (functions)\ninto a single unit (class) and\nrestricting direct access to some of the object’s components.\n\nPurpose:\n\nTo hide implementation details and\nenforce controlled access to an object’s data.\n\nKey Components:\n\nAccess modifiers (private, protected, public in some languages) and\nGetters & Setters for controlled access.\n\n\n2.1 Getters and Setters:\nDefinition: These are methods used to retrieve (get) and update (set) private or protected attributes of a class.\nPurpose: To provide controlled access to the attributes while maintaining encapsulation.\nRelation to Encapsulation: They implement the idea of “controlled access” in encapsulation.\nThey are tools to implement encapsulation.\n\n\n\n3. Things To Do\n\nCreate Circle class\nInstantiate a circle instance\nTest attribute access directly: circle._radius\nTest attribute access via getter1: circle.radius_accessor\nTest attribute access via getter2: circle.radius\n\n\n\n4. Create Circle class\n\ncreate private variable: _radius\n\ncreate getter method: radius_accessor()\n\ndecorate with: @property\n\n\nclass Circle():\n  def __init__(self, name: str, radius: int):\n    self.name: str = name\n    self._radius: int = radius #21\n  \n  @property\n  def radius_accessor(self):\n    '''\n    @property\n    def radius_accessor(self):\n    \n    The name of this method becomes attribute name of an instance, or \n    (more accurately the attribute accesor?) \n    to access the private attribute we want \n    (usually defined in class init(): self._private_attribute)\n    \n    e.g. Suppose we have circle instance (type Circle)\n    with private attr: circle._radius. \n    Instead of accessing it directly (circle._radius)\n    which we can but we shouldn't, we access it via the getter created here \n    via @property with: circle.radius_accessor \n    \n    i.e. circle.radius_accessor is getter for circle._radius\n    \n    Therefore, a more suitable method name for this getter would be:\n    def radius():\n    \n    i.e.\n    \n    @property\n    def radius(self) allows us to access circle._radius via circle.radius   \n    '''\n    return self._radius\n  \n  @property\n  def radius(self):\n    '''explained in radius_accessor()'''\n    return self._radius\n  \n  def __repr__(self):\n    return f\"Circle(name={self.name!r}, _radius={self._radius!r})\"\n  \n  def __str__(self):\n    return f\"It's a circle named {self.name!r} with a round belly of {self._radius} centimeters!\"\n\n\n4.1 Notes for Tony\n\nprint(Circle.radius_accessor.__doc__)\n\n\n    @property\n    def radius_accessor(self):\n    \n    The name of this method becomes attribute name of an instance, or \n    (more accurately the attribute accesor?) \n    to access the private attribute we want \n    (usually defined in class init(): self._private_attribute)\n    \n    e.g. Suppose we have circle instance (type Circle)\n    with private attr: circle._radius. \n    Instead of accessing it directly (circle._radius)\n    which we can but we shouldn't, we access it via the getter created here \n    via @property with: circle.radius_accessor \n    \n    i.e. circle.radius_accessor is getter for circle._radius\n    \n    Therefore, a more suitable method name for this getter would be:\n    def radius():\n    \n    i.e.\n    \n    @property\n    def radius(self) allows us to access circle._radius via circle.radius   \n    \n\n\n\n\n\n5. Instantiate a circle instance\n\ncircle = Circle(\"Sir Cumference\",50)\nprint(f\"{circle}\") # calls __str__\n\nIt's a circle named 'Sir Cumference' with a round belly of 50 centimeters!\n\n\n\ncircle # defaults to __repr__\n\nCircle(name='Sir Cumference', _radius=50)\n\n\n\n\n6. Test attribute access directly: circle._radius\n\ncircle._radius # still works - because private attr dont exist in python\n\n50\n\n\n\n\n7. Test attribute access via getter1: circle.radius_accessor\n\ncircle.radius_accessor\n\n50\n\n\n\n\n8. Test attribute access via getter2: circle.radius\n\ncircle.radius\n\n50"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#the-scenario",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#the-scenario",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "1.1 The Scenario",
    "text": "1.1 The Scenario\nFocusing on specifics or details of Implementation"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#the-problem",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#the-problem",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "1.2 The Problem",
    "text": "1.2 The Problem\nLeads to tightly coupled or difficult to modify code."
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#one-of-the-solutions",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#one-of-the-solutions",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "1.3 (One of) The Solution(s):",
    "text": "1.3 (One of) The Solution(s):\nThe Program to Interfaces, not Implementations principle"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#scenario-1-part-1-abc-and-abstractmethod",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#scenario-1-part-1-abc-and-abstractmethod",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "6.1 Scenario 1, Part 1: ABC and @abstractmethod",
    "text": "6.1 Scenario 1, Part 1: ABC and @abstractmethod\nBy decorating do_I_exist() with @abstractmethod of ABC class TonysExistentialCrisisBase:\n\nThis applies the implementation requirement that a do_I_exist method must be implemented in all sub-classes.\n\n\nfrom abc import ABC, abstractmethod\n\nclass TonysExistentialCrisisBase(ABC):\n    def __init__(self, name: str):\n        self.name=name\n        \n    @abstractmethod\n    def do_I_exist(self, am_i_alive: bool):\n        pass"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#scenario-1-part-2-no-required-method-in-sub-class",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#scenario-1-part-2-no-required-method-in-sub-class",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "6.2 Scenario 1, Part 2: No Required Method in Sub-Class",
    "text": "6.2 Scenario 1, Part 2: No Required Method in Sub-Class\n\nclass MyHumanBeingClass(TonysExistentialCrisisBase):\n    pass\n\n\nTherefore, Python raises a very clear error, when an instance MyHumanBeingClass is attempted to be created\nSince our sub-class does not have it’s own implementation of do_I_exist method\n\n\ndave = MyHumanBeingClass(\"Dave\")\ndave\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 dave = MyHumanBeingClass(\"Dave\")\n      2 dave\n\nTypeError: Can't instantiate abstract class MyHumanBeingClass with abstract method do_I_exist"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#scenario-2-part-1-sub-class-with-required-abstract-method",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#scenario-2-part-1-sub-class-with-required-abstract-method",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "6.3 Scenario 2, Part 1: Sub-Class With Required Abstract Method",
    "text": "6.3 Scenario 2, Part 1: Sub-Class With Required Abstract Method\n\nclass MyHumanBeingClass(TonysExistentialCrisisBase):\n    def do_I_exist(self, am_i_alive: bool=True):\n        print(\"Cogito, ergo sum...👽\")"
  },
  {
    "objectID": "posts/notes/coding/22-interfaces-1-abc.html#scenario-2-part-2-no-errors",
    "href": "posts/notes/coding/22-interfaces-1-abc.html#scenario-2-part-2-no-errors",
    "title": "Interfaces [Part 1]: ABC Abstract Base Classes",
    "section": "6.4 Scenario 2, Part 2: No errors",
    "text": "6.4 Scenario 2, Part 2: No errors\nBy adding the required method, an instance of MyHumanBeingClass is allowed.\n\njames = MyHumanBeingClass(\"James\")\njames.do_I_exist()\n\nCogito, ergo sum...👽"
  },
  {
    "objectID": "posts/notes/coding/28-big-o-arrays-sets.html#array-operation---summary",
    "href": "posts/notes/coding/28-big-o-arrays-sets.html#array-operation---summary",
    "title": "Big-O: Arrays and Sets",
    "section": "1.1 Array Operation - Summary",
    "text": "1.1 Array Operation - Summary\n\nRead \\((1)\\)\n\nSearch \\((n)\\)\n\nInsert \\((n+1)\\)\n\nDelete \\((n)\\)"
  },
  {
    "objectID": "posts/notes/coding/28-big-o-arrays-sets.html#array-operation---details",
    "href": "posts/notes/coding/28-big-o-arrays-sets.html#array-operation---details",
    "title": "Big-O: Arrays and Sets",
    "section": "1.2 Array Operation - Details",
    "text": "1.2 Array Operation - Details\n\n1.2.1 Read \\((1)\\):\n\n\\(1\\) (worse)\n\\(1\\) (best)\n\n\n\n1.2.2 Search \\((n)\\):\n\n\\(n\\) (worse: target is last value found)\n\n\\(1\\) (best: target is first value found)\n\n\n\n1.2.3 Delete \\((n)\\):\n\n\n1.2.3a Delete \\((n)\\) - Worse:\n{\\(n\\)}=({\\(1\\)} \\(+\\) {\\(n-1\\)}): worse - delete \\(first\\) item or \\(arr[0]\\):\n\n{\\(1\\)}: delete item at \\(arr[0]\\)\n{\\(n-1\\)}: shift whole array, left one item at a time:\n\n\\(arr[1] \\to arr[0]\\) (\\(index\\_1 \\to index\\_0\\))\n\\(arr[2] \\to arr[1]\\) (\\(index\\_2 \\to index\\_1\\))\n\\(...\\)\n\\(arr[n] \\to arr[n-1]\\) (\\(inde`x\\_[n] \\to index\\_[n-1]\\))\n\n\n\n\n1.2.3b Delete \\((1)\\) - Best\n{\\(1\\)}: best - delete \\(last\\) item or \\(arr[-1]\\)\n\n\n1.2.4 Insert \\((n+1)\\)\n\n\n1.2.4a Insert \\((n+1)\\) - Worse:\n{\\(n + 1\\)}: worse - insert at \\(front\\) or \\(arr[0]\\):\n\n{\\(n\\)}: whole existing array of length {\\(n\\)} needs to move right by {\\(1\\)}:\n\nstarts at {\\(n\\)}, moves it right to {\\(n+1\\)}\nthen {\\(n-1\\)} moves to {\\(n\\)}… {\\(n\\_times\\)} or {\\(n\\_steps\\)}\n\nindex \\([0]\\) becomes empty\n\nindex \\([0]\\) retains same memory address (might change for diff languages)\n\n{\\(1\\)}: insert the finally vacant spot at index 0, same memory address\n\n\n\n1.2.4b Insert \\((1)\\) - Best:\n{\\(1\\)}: best - insert at \\(end\\) or \\(arr[-1]\\):\nComputers may have to allocate additional memory cells toward this array (language specific)"
  },
  {
    "objectID": "posts/notes/coding/28-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---differences",
    "href": "posts/notes/coding/28-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---differences",
    "title": "Big-O: Arrays and Sets",
    "section": "2.1 Classic Arrays vs Array-Based Sets - Differences",
    "text": "2.1 Classic Arrays vs Array-Based Sets - Differences\nAn array-based set:\n\nis an array\nwith one additional constraint\nof barring duplicates"
  },
  {
    "objectID": "posts/notes/coding/28-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---operations-comparison-table",
    "href": "posts/notes/coding/28-big-o-arrays-sets.html#classic-arrays-vs-array-based-sets---operations-comparison-table",
    "title": "Big-O: Arrays and Sets",
    "section": "2.2 Classic Arrays vs Array-Based Sets - Operations Comparison Table",
    "text": "2.2 Classic Arrays vs Array-Based Sets - Operations Comparison Table\n\n\n\n\n\n\n\n\n\n\nOperation\nArray\nArray-Based Set\nDifference\nChange\n\n\n\n\nRead\n\\(O(1,1)\\)\n\\(O(1,1)\\)\nSame\nNone\n\n\nSearch\n\\(O(1,n)\\)\n\\(O(1,n)\\)\nSame\nNone\n\n\nDelete\n\\(O(1,n)\\)\n\\(O(1,n)\\)\nSame\nNone\n\n\nInsert\n\\(O(1,n+1)\\)\n\\(O(n+1,n*n+1)\\)or\\(O(n+1,2n+1)\\)\n\\(O(worse,worse)\\)\n\\(O_{best}(1 \\to n+1)\\)  and  \\(O_{worse}(n+1 \\to 2n+1)\\)"
  },
  {
    "objectID": "posts/notes/coding/28-big-o-arrays-sets.html#array-based-set-operation---detailed",
    "href": "posts/notes/coding/28-big-o-arrays-sets.html#array-based-set-operation---detailed",
    "title": "Big-O: Arrays and Sets",
    "section": "2.3 Array-Based Set Operation - Detailed",
    "text": "2.3 Array-Based Set Operation - Detailed\n\n2.3.1 Read \\((1)\\), Search \\((n)\\), Delete \\((n)\\)\n\nRead \\((1,1)\\)\n\nSearch \\((1,n)\\)\n\nDelete \\((1,n)\\)\n\nInsert \\((n+1,2n+1)\\)\n\n\n\n2.3.2 Insert \\((2n+1)\\): Different to Classic Arrays\n\n\n2.3.2a Insert \\((2n+1)\\) - Worse\n{\\(n*n+1\\)} - worse, insert at the \\(front\\):\n\n{\\(n\\)}: search whole array {\\(n\\_times\\)}\n\n{\\(n\\)}: shift whole array, right (one-item-at-a-time) i.e. {\\(n\\_times\\)}:\n\n\\(arr[n] \\to arr[n+1]\\) (\\(index\\_[n] \\to index\\_[n+1]\\))\n\n\\(arr[n-1] \\to arr[n]\\) (\\(index\\_[n-1] \\to index\\_[n]\\))\n\n\\(...\\)\n\n\\(arr[0] \\to arr[1]\\) (\\(index\\_[0] \\to index\\_[1]\\))\n\n{\\(1\\)}: insert at index 0, same memory address\n\n\n\n2.3.2b Insert \\((n+1)\\) - Best\n{\\(n+1\\)} - best, insert at the \\(end\\):\n\nSearch array (for dupes) + insert (at end)\n\n\n\n2.3.2c Insert \\((m*n+1)\\) - Medium\n{\\(m*n+1\\)} - medium, insert at the \\(arr[j]\\) or \\(index\\_[j]\\)):\n\n{\\(n\\)}: search whole array {\\(n\\_times\\)}\n{\\(m\\)}: shift whole array {\\(n\\_times\\)} where {\\(m\\)} \\(=\\) {\\(n-j\\)}:\n\nif want to insert at \\(index\\_[j]\\): all items after \\(index\\_[j]\\) by one\nthus we shift right {\\(m\\)} \\(=\\) {\\(n-j\\)} items\n\\(arr[n] \\to arr[n+1]\\) (\\(index\\_[n] \\to index\\_[n+1]\\))\n\\(...\\)\n\\(arr[j] \\to arr[j+1]\\) (\\(index\\_[j] \\to index\\_[j+1]\\))\nor\n\\(arr[n-m] \\to arr[n-m+1]\\) (\\(index\\_[n-m] \\to index\\_[n-m+1]\\))\n\n{\\(1\\)}: insert at \\(arr[j]\\) or \\(arr[n-m]\\)\n\n\n2.3.3 Inserting at \\(arr[j]\\) hand-drawn"
  },
  {
    "objectID": "posts/notes/coding/26-metaclasses.html",
    "href": "posts/notes/coding/26-metaclasses.html",
    "title": "Python Metaclasses: Customising Class Creation",
    "section": "",
    "text": "1. bases and dcts arguments are empty\n\nTonyDynCls1Empty = type(\"TonyDynCls1Empty\",(),{})\nprint(TonyDynCls1Empty.__name__)\nprint(TonyDynCls1Empty)\nprint(TonyDynCls1Empty.__class__.__name__)\nprint(TonyDynCls1Empty.__base__)\nprint(TonyDynCls1Empty.__bases__)\nprint(TonyDynCls1Empty.__class__.__base__)\nprint(TonyDynCls1Empty.__class__.__bases__)\n\nTonyDynCls1Empty\n&lt;class '__main__.TonyDynCls1Empty'&gt;\ntype\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n\n\n\nclass Foo:\n    pass\n\n\n\n\n2. bases: (cls1,cls2) and dcts: {attr_1: ...}\nTwo inherited classes and 1 instance attribute\n\nTonyDynCls2 = type(\"TonyDynCls2\",\n                         (TonyDynCls1Empty,Foo), # existing cls\n                         {'attr_1':'222'}\n                         )\nprint(TonyDynCls2.__name__)\nprint(TonyDynCls2)\nprint(TonyDynCls2.__class__.__name__)\nprint()\nprint(TonyDynCls2.__class__.__name__)\nprint(TonyDynCls2.__base__)\nprint(TonyDynCls2.__bases__)\nprint()\nprint(TonyDynCls2.__class__.__base__)\nprint(TonyDynCls2.__class__.__bases__)\nprint()\nprint(TonyDynCls2.attr_1)\n\nTonyDynCls2\n&lt;class '__main__.TonyDynCls2'&gt;\ntype\n\ntype\n&lt;class '__main__.TonyDynCls1Empty'&gt;\n(&lt;class '__main__.TonyDynCls1Empty'&gt;, &lt;class '__main__.Foo'&gt;)\n\n&lt;class 'object'&gt;\n(&lt;class 'object'&gt;,)\n\n222\n\n\n\n\n3. Class Attribute and Lambda Instance Method\n\nTonyDynCls3 = type(\"TonyDynCls3\",\n                         (), # existing cls\n                         {'attr_1':\"333\", \n                          'get_attr_1': lambda self: self.attr_1}\n                         )\nprint(TonyDynCls3.__name__)\nprint(TonyDynCls3)\nprint(TonyDynCls3.__class__.__name__)\nprint()\nprint(TonyDynCls3.attr_1) # class attribute\n\ntony_dc3_instance = TonyDynCls3()\nprint(tony_dc3_instance.get_attr_1()) # class attribute\n\n\n\n\nTonyDynCls3\n&lt;class '__main__.TonyDynCls3'&gt;\ntype\n\n333\n333\n\n\n\n\n4. Class Attribute and Custom Instance Method\n\ndef some_method(self):\n    return self.attr\nTonyDynCls4 = type(\"TonyDynCls4\", (), {'attr': 444,\n                                       'get_attr': some_method})\n\ntony_dc4_instance = TonyDynCls4()\nprint(tony_dc4_instance.attr)\nprint(tony_dc4_instance.get_attr())\n\n444\n444\n\n\n\n\n5. Customising Instance Creation\n\nclass Foo:\n    pass\n\n    def __new__(cls):\n        x = object.__new__(cls)\n        x._secret_attr = \"555\"\n        return x\n    \na_foo = Foo() \na_foo._secret_attr\n\n'555'\n\n\n\nNote-to-self: psuedo-code steps\n\n\nby calling type() -&gt; python sees (), looks for type.__call__()\n\n\nnote type.__call__() &lt;——-&gt; type()\n\n\nor type.__call__(*args, **kwds) &lt;——-&gt; type(*args, **kwds)\n\n\ninside type.__call__(*args, **kwds)\n\n\ntype.__new__(cls, *args, **kwds)\n\n\nreturns x\n\n\ntype.__init__(x, *args, **kwds)\n\n\nreturns x\n\n\n\n\n\n6. Customising Class Creation\n\nclass TonyMetaClass(type):\n    pass\n\n    def __new__(cls, name, bases, dcts):\n        x = super().__new__(cls, name, bases, dcts)\n        \n        # calls parents type.__new__()\n        # which is usally called when you instantiate any class\n        # e.g Foo()\n        # 1. () -&gt; python looks for __call__()\n        # 2. find parents `type.__call__()`\n        # 3. inside has __new__() and __init__()\n        # 4. python will look for __new__() in our cls\n        # 5. if cant find, it uses type.__new__()\n        # 6. by defining __new__(): we can add custom behaviour\n        # 7. super().__new__(cls, name,bases, dcts) is the same\n        #    as type.__new__(...), or we are doing nothing new here\n        # 8. then we add custom beaviour x._secret_attr = ...\n        x._secret_attr = \"gday mate\"\n        \n        # 9. return object (as would default type.__new__())\n        return x\n    \nclass FooFoo(metaclass=TonyMetaClass):\n    pass\nfoofoo = FooFoo()\n\n\nfoofoo._secret_attr\n\n'gday mate'\n\n\n\n\n7. Simple Object Factory\n\nclass FooObjectFactory():\n    def __init__(self):\n        self.attr = 777\na = FooObjectFactory()        \nb = FooObjectFactory()        \nc = FooObjectFactory()        \nprint(a.attr, b.attr, c.attr) # each instance has initialised instance attr\n\n777 777 777\n\n\n\n\n8. Simple Class Factory\n\nclass MetaFooClsFactory(type):\n    def __new__(cls, name, bases, dcts): # &lt;metaclass&gt; type.__new__() creates the class\n        x = super().__new__(cls, name, bases, dcts) \n        x._attr = [\"888\"] # x, the class itself, an instance type, has class._attr\n        return x # return the x instance (the class)\n\nclass AFooCls(metaclass = MetaFooClsFactory):\n    pass\nclass BFooCls(metaclass = MetaFooClsFactory):\n    pass\nclass CFooCls(metaclass = MetaFooClsFactory):\n    pass\nprint(AFooCls._attr, BFooCls._attr, CFooCls._attr) # each cls has initialised cls attr\n\n['888'] ['888'] ['888']\n\n\n\n\n9. Simple Inheritance\n\nclass Baz():\n    cls_attr = '999'\n\nclass ABaz(Baz):\n    pass\nclass BBaz(Baz):\n    pass\nclass CBaz(Baz):\n    pass\n\nprint(ABaz.cls_attr, BBaz.cls_attr, CBaz.cls_attr)\n\n999 999 999\n\n\n\n\n10. Simple Decorator\n\ndef tony_decorator(cls):\n    class DecoratedClass(cls):\n        cls_attr = \"10\"\n    return DecoratedClass\n\n@tony_decorator\nclass QuxA:\n    pass\n@tony_decorator\nclass QuxB:\n    pass\n@tony_decorator\nclass QuxC:\n    pass\n\nprint(QuxA.cls_attr, QuxB.cls_attr, QuxC.cls_attr)\n\n10 10 10"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#common-errors",
    "href": "posts/notes/coding/15_exceptions_101.html#common-errors",
    "title": "Python Exceptions 101",
    "section": "1.1 Common Errors",
    "text": "1.1 Common Errors\nUnexpected things or errors will occur at times in Python (and in life).\nThey might happen so often they get their own names and get categorised.\nPython has done exactly that. Creating names for specific errors whilst maintaining Python’s hierarchy structure too. Some common (automatic) errors are:\n\nInvalid syntax/code:\n\nE.g. missing closing bracket, unexpected colons, or periods etc (SyntaxError exception)\n\nInvalid username or key:\n\nE.g. not existing in the database (KeyError exception)\n\nInvalid calculation or operation:\n\nE.g. dividing by zero or dividing a number by a letter (ZeroDivisionError, TypeError exception)\n\nInvalid index:\n\nE.g. indexing a value larger than the array/list length (IndexError exception)\n\nInvalid attribute or method:\n\nE.g. calling an non-existent function from an instance (AttributeError exception)\n\n….the list goes on… (pun intended)"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#python-in-built-automatic-exceptions",
    "href": "posts/notes/coding/15_exceptions_101.html#python-in-built-automatic-exceptions",
    "title": "Python Exceptions 101",
    "section": "1.2 Python In-Built (Automatic) Exceptions",
    "text": "1.2 Python In-Built (Automatic) Exceptions\nAll the above exceptions, being automatically raised by Python, are known as In-Built exceptions.\nThat is, when something unexpected happens, Python will:\n\nAutomatically halt the program,\nAutomatically raise or create a specific type Exception object (related to the error),\n\nE.g. Syntax, KeyError, ZeriDivisionError, TypeError, IndexdError exception object\n\nAutomatically look for something that can deal with this specific type of exception,\n\ncalled an Exception Handler (EH)\n\nIf no EH in current scope, Python looks for EH in call-stack,\n\nIf no EH in call-stack, the program is terminated.\n\n\nExceptions can also manually raised by the developer (discussed later)."
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-1",
    "href": "posts/notes/coding/15_exceptions_101.html#example-1",
    "title": "Python Exceptions 101",
    "section": "2.1 Example 1",
    "text": "2.1 Example 1\n\ntry:\n    print(1/0)\nexcept ZeroDivisionError as e:\n    print(f\"An specific error has occured: [{e}]\")\n\nAn specific error has occured: [division by zero]"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-2",
    "href": "posts/notes/coding/15_exceptions_101.html#example-2",
    "title": "Python Exceptions 101",
    "section": "2.2 Example 2",
    "text": "2.2 Example 2\n\ncool_dict = {\"a\": 420, \"b\":69}\n\ntry:\n    a_val = cool_dict[\"a\"]\n    b_val = cool_dict[\"b\"]\n    c_val = cool_dict[\"c\"]\nexcept KeyError as e:\n    print(f\"KeyError caught: [{e}]\")\nelse:\n    print(f\"Code has run succesfully!\")\n\nKeyError caught: ['c']"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-3",
    "href": "posts/notes/coding/15_exceptions_101.html#example-3",
    "title": "Python Exceptions 101",
    "section": "2.3 Example 3",
    "text": "2.3 Example 3\n\ntry:\n    print(1/\"chode\")\nexcept TypeError as e:\n    print(f\"TypeError caught: [{e}]\")\n\nTypeError caught: [unsupported operand type(s) for /: 'int' and 'str']"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-4",
    "href": "posts/notes/coding/15_exceptions_101.html#example-4",
    "title": "Python Exceptions 101",
    "section": "2.4 Example 4",
    "text": "2.4 Example 4\n\ncool_list = [666,420,69]\n\ntry:\n    print(cool_list[0])\n    print(cool_list[1])\n    print(cool_list[2])\n    print(cool_list[3])\nexcept IndexError as e:\n    print(f\"Index caught: [{e}]\")\n\n666\n420\n69\nIndex caught: [list index out of range]"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-5",
    "href": "posts/notes/coding/15_exceptions_101.html#example-5",
    "title": "Python Exceptions 101",
    "section": "2.5 Example 5",
    "text": "2.5 Example 5\n\nmad_int = 69\n\ntry:\n    mad_int.append(420)\nexcept AttributeError as e:\n    print(f\"Attribute error caught: [{e}]\")\n\nAttribute error caught: ['int' object has no attribute 'append']"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#bare-except-clause",
    "href": "posts/notes/coding/15_exceptions_101.html#bare-except-clause",
    "title": "Python Exceptions 101",
    "section": "3.1 Bare except clause",
    "text": "3.1 Bare except clause\nA bare except clause:\n\nPython catches any exception that inherits from Exception (most built-in exceptions!)\nCatching parent class Exception will:\n\nHides all errors— even unexpected or previously unseen errors!"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#bare-except-clause-example",
    "href": "posts/notes/coding/15_exceptions_101.html#bare-except-clause-example",
    "title": "Python Exceptions 101",
    "section": "3.1.1 Bare except clause example",
    "text": "3.1.1 Bare except clause example\n\ntry:\n    with open(\"file.log\") as file:\n        read_data = file.read()\nexcept:\n    print(\"Couldn't open file.log\")\n\nCouldn't open file.log"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#except-exception-clause",
    "href": "posts/notes/coding/15_exceptions_101.html#except-exception-clause",
    "title": "Python Exceptions 101",
    "section": "3.2 except Exception clause",
    "text": "3.2 except Exception clause\nBy catching Exception as e, there are attributes the developer can use:\n\nThe error occured: specific information about the error\nThe error type: the specific class of error\nThe error trace-back: a detailed trace-back of the error\n\n\ntry:\n    with open(\"file.log\") as file:\n        read_data = file.read()\nexcept Exception as e:\n    import traceback\n    print(f\"[Error Occured 1/3]: \\n\\t[  {e}  ]\\n\")\n    print(f\"[Error Type 2/3]: \\n\\t[  {type(e).__name__}  ]\\n\")\n    print(f\"[Error Traceback 3/3]: \\n\\t[  {traceback.format_exc()}  ]\")\n\n[Error Occured 1/3]: \n    [  [Errno 2] No such file or directory: 'file.log'  ]\n\n[Error Type 2/3]: \n    [  FileNotFoundError  ]\n\n[Error Traceback 3/3]: \n    [  Traceback (most recent call last):\n  File \"/tmp/ipykernel_76566/3916192492.py\", line 2, in &lt;module&gt;\n    with open(\"file.log\") as file:\n  File \"/home/tonydevs/.local/share/virtualenvs/blog-T-2huGx2/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 324, in _modified_open\n    return io_open(file, *args, **kwargs)\nFileNotFoundError: [Errno 2] No such file or directory: 'file.log'\n  ]"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#raising-an-in-built-exception",
    "href": "posts/notes/coding/15_exceptions_101.html#raising-an-in-built-exception",
    "title": "Python Exceptions 101",
    "section": "3.3 Raising an in-built exception",
    "text": "3.3 Raising an in-built exception\n\ndef squared(numbers):\n    if not isinstance(numbers, list | tuple):\n        raise TypeError(\n            f\"list or tuple expected, got '{type(numbers).__name__}'\"\n        )\n    return [number**2 for number in numbers]"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#original-method-manually-raise-an-exception-when-condition-met",
    "href": "posts/notes/coding/15_exceptions_101.html#original-method-manually-raise-an-exception-when-condition-met",
    "title": "Python Exceptions 101",
    "section": "4.1 Original Method: manually raise an Exception() (when condition met)",
    "text": "4.1 Original Method: manually raise an Exception() (when condition met)\nBelow example raises an exception when a specific value is above arbitrary value (e.g. 5)\nThis exception can only be manually raised because it is:\n\nnot a syntax error exception\nnot an in-built error exception\n\nIn a way, this is more like:\n\nmodel-error (e.g. specific to some real-world model specification)\nbusiness-logic (e.g. business application)\n\n\n# number = 1\nnumber = 6\nif number &gt; 5:\n    raise Exception(f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\")\nprint(number)\n\n\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\nCell In[9], line 4\n      2 number = 6\n      3 if number &gt; 5:\n----&gt; 4     raise Exception(f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\")\n      5 print(number)\n\nException: [Manual Exc Raised & Caught]: The number should not exceed 5. (number=6)"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#another-method-automated-assertionerror-with-assert-when-condition-met",
    "href": "posts/notes/coding/15_exceptions_101.html#another-method-automated-assertionerror-with-assert-when-condition-met",
    "title": "Python Exceptions 101",
    "section": "4.2 Another Method: Automated AssertionError with assert (when condition met)",
    "text": "4.2 Another Method: Automated AssertionError with assert (when condition met)\n\nnumber = 1\nassert(number &lt; 5), f\"[Manual Exc Raised & Caught]: The number should not exceed 5. ({number=})\"\nprint(number)\n\n1\n\n\n\n# example: https://realpython.com/python-exceptions/\ndef linux_interaction():\n    import sys # https://docs.python.org/3.10/library/sys.html\n    if \"linux\" not in sys.platform: \n        raise RuntimeError(\"Function can only run on Linux systems.\")\n    print(f\"Running on a Linux system: [{sys.platform}]\")\nlinux_interaction()\n\nRunning on a Linux system: [linux]\n\n\n\n# example: https://realpython.com/python-exceptions/\ndef windows_interaction():\n    import sys # https://docs.python.org/3.10/library/sys.html\n    if \"windows\" not in sys.platform: \n        raise RuntimeError(\"Function can only run on Windows systems.\")\n    print(f\"Running on a Windows system: [{sys.platform}]\")\nwindows_interaction()\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 7\n      5         raise RuntimeError(\"Function can only run on Windows systems.\")\n      6     print(f\"Running on a Windows system: [{sys.platform}]\")\n----&gt; 7 windows_interaction()\n\nCell In[12], line 5, in windows_interaction()\n      3 import sys # https://docs.python.org/3.10/library/sys.html\n      4 if \"windows\" not in sys.platform: \n----&gt; 5     raise RuntimeError(\"Function can only run on Windows systems.\")\n      6 print(f\"Running on a Windows system: [{sys.platform}]\")\n\nRuntimeError: Function can only run on Windows systems."
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#create-custom-exception-ce",
    "href": "posts/notes/coding/15_exceptions_101.html#create-custom-exception-ce",
    "title": "Python Exceptions 101",
    "section": "5.1 Create Custom Exception (CE)",
    "text": "5.1 Create Custom Exception (CE)\nCE are created by the:\n\nclass NameOfCustomException(Exception): use class constructor and inherit from Exception.\nraise exception in a function defintion (when condition is met):\n\nwith no EH: call function outside try-except (exception is not handled): Program terminates.\nwith an EH: call function in try-except (exception is handled): Program continues."
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#raising-ce-without-eh",
    "href": "posts/notes/coding/15_exceptions_101.html#raising-ce-without-eh",
    "title": "Python Exceptions 101",
    "section": "5.2 Raising CE without EH",
    "text": "5.2 Raising CE without EH"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-1-platformexception",
    "href": "posts/notes/coding/15_exceptions_101.html#example-1-platformexception",
    "title": "Python Exceptions 101",
    "section": "5.2.1 Example 1: PlatformException",
    "text": "5.2.1 Example 1: PlatformException\n\nclass PlatformException(Exception):\n    \"\"\"Incompatible platform.\"\"\"\n    pass\n\ndef linux_interaction():\n    import sys\n    if \"linux\" not in sys.platform:\n        # raise RuntimeError(\"Function only for Linux systems.\")    # previous-code: in-built exception\n        raise PlatformException(\"Function only for Linux systems.\") # updated-code: custom exception     \n    print(\"Doing Linux things.\")\n    \nlinux_interaction()\n\nDoing Linux things."
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#example-2-gradevalueerror",
    "href": "posts/notes/coding/15_exceptions_101.html#example-2-gradevalueerror",
    "title": "Python Exceptions 101",
    "section": "5.2.2 Example 2: GradeValueError",
    "text": "5.2.2 Example 2: GradeValueError\n\nclass GradeValueError(Exception):\n    pass\n\ndef calculate_average_grade(grades):\n    total = 0\n    count = 0\n    for grade in grades:\n        if grade &lt; 0 or grade &gt; 100:\n            raise GradeValueError(\n                \"grade values must be between 0 and 100 inclusive\"\n            )\n        total += grade\n        count += 1\n    return round(total / count, 2)\n\nprint(calculate_average_grade([80,70,-90]))\nprint(\"Exception is not handled, Program is terminated by Python. This line is not printed\")\n\n\n---------------------------------------------------------------------------\nGradeValueError                           Traceback (most recent call last)\nCell In[14], line 16\n     13         count += 1\n     14     return round(total / count, 2)\n---&gt; 16 print(calculate_average_grade([80,70,-90]))\n     17 print(\"Exception is not handled, Program is terminated by Python. This line is not printed\")\n\nCell In[14], line 9, in calculate_average_grade(grades)\n      7 for grade in grades:\n      8     if grade &lt; 0 or grade &gt; 100:\n----&gt; 9         raise GradeValueError(\n     10             \"grade values must be between 0 and 100 inclusive\"\n     11         )\n     12     total += grade\n     13     count += 1\n\nGradeValueError: grade values must be between 0 and 100 inclusive"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#raising-ce-with-eh",
    "href": "posts/notes/coding/15_exceptions_101.html#raising-ce-with-eh",
    "title": "Python Exceptions 101",
    "section": "5.3 Raising CE with EH",
    "text": "5.3 Raising CE with EH"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#gradevalueerror-eh-less-verbosity",
    "href": "posts/notes/coding/15_exceptions_101.html#gradevalueerror-eh-less-verbosity",
    "title": "Python Exceptions 101",
    "section": "5.3.1 GradeValueError (EH less verbosity)",
    "text": "5.3.1 GradeValueError (EH less verbosity)\nCaptured Error output with less verbosity. This may be suitable and it may not.\n\ntry:\n    GPA = calculate_average_grade([80,70,-90])\nexcept GradeValueError as e:\n    print(f\"Captured Error: [{type(e).__name__}]:\\n\\t[{e}]\\n\")\n    # import traceback\n    # print(f\"Traceback here: \\n\\t{traceback.format_exc()}\")\nelse:\n    print(f\"Congrats, your gpa is {GPA}\")\nprint(f\"Finished Grading!\")\n\nCaptured Error: [GradeValueError]:\n    [grade values must be between 0 and 100 inclusive]\n\nFinished Grading!"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#gradevalueerror-exception-handler-more-verbosity",
    "href": "posts/notes/coding/15_exceptions_101.html#gradevalueerror-exception-handler-more-verbosity",
    "title": "Python Exceptions 101",
    "section": "5.3.2 GradeValueError (Exception-Handler more verbosity)",
    "text": "5.3.2 GradeValueError (Exception-Handler more verbosity)\nBy using traceback, the verbose output could also be provided.\n\ntry:\n    GPA = calculate_average_grade([80,70,-90])\nexcept GradeValueError as e:\n    print(f\"Captured Error: [{type(e).__name__}]:\\n\\t[{e}]\\n\")\n    import traceback\n    print(f\"Traceback here: \\n\\t{traceback.format_exc()}\")\nelse:\n    print(f\"Congrats, your gpa is {GPA}\")\nprint(f\"Finished Grading!\")\n\nCaptured Error: [GradeValueError]:\n    [grade values must be between 0 and 100 inclusive]\n\nTraceback here: \n    Traceback (most recent call last):\n  File \"/tmp/ipykernel_76566/3646266675.py\", line 2, in &lt;module&gt;\n    GPA = calculate_average_grade([80,70,-90])\n  File \"/tmp/ipykernel_76566/2024016610.py\", line 9, in calculate_average_grade\n    raise GradeValueError(\nGradeValueError: grade values must be between 0 and 100 inclusive\n\nFinished Grading!"
  },
  {
    "objectID": "posts/notes/coding/15_exceptions_101.html#multiple-exceptions",
    "href": "posts/notes/coding/15_exceptions_101.html#multiple-exceptions",
    "title": "Python Exceptions 101",
    "section": "6. Multiple Exceptions",
    "text": "6. Multiple Exceptions\n\ndef division(a, b):\n    try:\n        return {\n            'success': True,\n            'message': 'OK',\n            'result': a / b\n        }\n    except (TypeError, ZeroDivisionError, Exception) as e:\n        return {\n            'success': False,\n            'message': str(e),\n            'type': type(e).__name__,\n            'result': None\n        }\n\nresult1 = division(10,10)\nresult2 = division(10, 0)\nresult3 = division(\"A\", 10)\nprint(result1)\nprint(result2)\nprint(result3)\n\n{'success': True, 'message': 'OK', 'result': 1.0}\n{'success': False, 'message': 'division by zero', 'type': 'ZeroDivisionError', 'result': None}\n{'success': False, 'message': \"unsupported operand type(s) for /: 'str' and 'int'\", 'type': 'TypeError', 'result': None}"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html",
    "href": "posts/notes/coding/3-bash.html",
    "title": "Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#basics",
    "href": "posts/notes/coding/3-bash.html#basics",
    "title": "Bash Basics",
    "section": "",
    "text": "echo $SHELL: The shell?\nvim shelltest.sh: Open shelltest.sh in Vim\n#! /bin/bash: Place in front of bash script to tell Linux which Shell to run\nls -l: long format list\nchmod u+x shelltest.sh: user to have executable rights on shell.sh man wc + arrows + q: manual of word-count script\nwc --help: quick reference of word-count script ${1,,}: Parameter Expansion - Ignores lower and upper-cases when comparing to values"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#variables",
    "href": "posts/notes/coding/3-bash.html#variables",
    "title": "Bash Basics",
    "section": "2. Variables",
    "text": "2. Variables\nFIRST_NAME=tony: set a variable\necho FIRST_NAME: echo the variable’\n\\': escape the single quote with backtick\n\n2.1 Fixed Variables\n\nhellothere.sh # [Terminal]\n\n\n#!/bin/bash\nFIRST_NAME=Tony\nLAST_NAME=JustDevs\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere.sh # [Terminal]\n./hellothere.sh # [Terminal]\n\n\n\n2.2 Interactive Variables\n\nhellothere_interactive.sh # [Terminal]\n\n\n#/bin/bash\n\necho What is your first name?\nread FIRST_NAME\necho What is your last name?\nread LAST_NAME\n\necho Hello $FIRST_NAME $LAST_NAME\n\n\ncbmod u+x hellothere_interactive.sh # [Terminal]\n./hellothere_interactive.sh # [Terminal]\n\n\n\n2.3 Positional Arguments\n\nvim hellothere_posarg.sh  # [Terminal]\n\n\n#!/bin/bash\n\necho Hello $1 $2\n\n\ncbmod u+x hellothere_posargs.sh     # [Terminal]\n./hellothere_posargs.sh Tony JustDevs # [Terminal]"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#output-redirection",
    "href": "posts/notes/coding/3-bash.html#output-redirection",
    "title": "Bash Basics",
    "section": "3. Output redirection",
    "text": "3. Output redirection\n\n3.1 Piping |\n\nThe output of the previous command ls -l /usr/bin is forwarded to the command after the |.\nAdd grep bash to filter for bash.\n\n\nls -l /usr/bin | grep bash # [Terminal]\n\n\n\n3.2 Override &gt;\nE.g. Logging something from a script to a log-file: 1. Catch output from echo command\n2. Override of a text file\n\necho Hello World! &gt; output_override_to_text.txt\ncat output_override_to_text.txt\n\n\n\n3.3 Append &gt;&gt;\nAppend from script to a log-file: 1. Catch output from echo command\n2. Append output into a text file\n\necho Hello World! &gt; output_append_to_text.txt\ncat output_override_to_text.txt\necho Good day matey! &gt; output_append_to_text.txt\ncat output_override_to_text.txt"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#input-direction",
    "href": "posts/notes/coding/3-bash.html#input-direction",
    "title": "Bash Basics",
    "section": "4. Input direction",
    "text": "4. Input direction\n\n&lt;: from a file\n&lt;&lt;: from multiple lines of text\n&lt;&lt;&lt;: from single string of text\n\n\n4.1 &lt; from a line\nUse word-count wc command to for number of words in text 1. Command to receive Input 2. Input direction of text\n\nwc -w &lt; output_append_to_text.txt # input direction\ncat output_append_to_text.txt | wc -w # output direction\n\n\n\n4.2 &lt;&lt; from multiple lines\nSupply multiple lines of words 1. Command to receive Input 2. Input direction to Command 3. KeywordStart 4. Actual text 5. KeywordEnd\n\ncat &lt;&lt; EOF\nthis is some text\nwith multiple\nlines\nEOF\n\n\n\n4.3 &lt;&lt;&lt; from single line\n\nwc -w &lt;&lt;&lt; \"a sentence line with 6 words\""
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#test-operators",
    "href": "posts/notes/coding/3-bash.html#test-operators",
    "title": "Bash Basics",
    "section": "5. Test Operators",
    "text": "5. Test Operators\n\n5.1 Equality\nTests whether an express exists with 0(No issues) or 1 (Error) 1. Write expression 2. Print exit-code of last executed command\n\n[ hello = hello ]\necho $? # exits 0\n\n[ 1 = 0 ] \necho $? # exits 1\n\n[ 1 -eq 1 ] # equate numericals\necho $?\n\n\n\n5.2 If / Elif / Else\n${1,,} Parameter Expansion: Ignores lower and upper-cases when comparing to values\n\n#/bin/bash\n\nif [ ${1,,} = tonydevs ]; then\n        echo \"Oh, you're the boss here. Welcome!\"\nelif [ ${1,,} = help]; then\n        echo \"Just enter your username, duh!\"\nelse\n        echo \"I don't know who you are. But you're not the boss of me!\"\nfi\n~       \n\n\n\n5.3 Case statements\nBetter than if / elif /else: - Checking for multiple values - is easier to read\n\nvim case_stmts.sh #[Terminal]\n\n\n#!/bin/bash\n\ncase ${1,,} in\n        tony | administrator)\n                echo \"Gday, you're the boss here!\"\n                ;;\n        help)\n                echo \"Just enter your username!\"\n                ;;\n        *)\n                echo \"Hello there, you're not the boss of me. Enter a valid username!\"\nesac\n\n\nhttps://www.youtube.com/watch?v=tK9Oc6AEnR4"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#arrays",
    "href": "posts/notes/coding/3-bash.html#arrays",
    "title": "Bash Basics",
    "section": "6. Arrays",
    "text": "6. Arrays\nStore multiple variables in a list called Arrays\n\n6.1 Indexing\n\nMY_FIRST_LIST=(one two three four five)\necho $MY_FIRST_LIST # print only first element [TERMINAL]\necho ${MY_FIRST_LIST[@]} # prints everything\necho ${MY_FIRST_LIST[1]} # prints second element\n\n\n\n6.2 Indexing\nitem: each element in loop\n${MY_FIRST_LIST[@]}: all items in list\ndo echo -n: do echo and ignore all new line characters\n$item: represents each single item in array\n|: output direction\nwc -c: count characters\ndone: finish loop\n\nfor item in ${MY_FIRST_LIST[@]}; do echo -n $item | wc -c; done"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#functions",
    "href": "posts/notes/coding/3-bash.html#functions",
    "title": "Bash Basics",
    "section": "7. Functions",
    "text": "7. Functions\n\n7.1 Function only\n\nCreate shell\nDefine function\nCatch output for up and since with their different flags\nPrint everything between the two EOFs keywords\nCall the variables generated\nClose function\n\n\nvim first_function.sh # [Terminal]\n\n\n#!/bin/bash \nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\n\n\n\n7.2 Not Declaring Local Variables (Wrong!)\nIf variables inside a function are not declared local, they may override variables of the same name in the global variables in the global environment/\n\n#!/bin/bash \nup=\"global up\" # add global variable 1\nsince=\"global since\" # add global variable 2 \necho $up\necho $since\n\nshowuptime(){\n    up=$(uptime -p | cut -c4-)\n    since=$(uptime -s)\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.3 Declaring Local Variables in a Function\nDefine variables inside functions as local variables so they’re only available to the functions and not to the entire script.\n\n#!/bin/bash \nup=\"global up\" \nsince=\"global since\" \necho $up\necho $since\n\nshowuptime(){\n    local up=$(uptime -p | cut -c4-) # add local prefix to declare local variable 1\n    local since=$(uptime -s) # add local prefix to declare local variable 2\n    cat &lt;&lt; EOF\n------\nThis machine has been up for ${up}\nIt has been running since ${since}\n------\nEOF\n}\nshowuptime\necho up is: $up\necho since is: $since\n\n\n\n7.4 Position Arguments\nJust like shell scripts, shell functions can also have positional arguments\n\n#!/bin/bash\n\nshowname(){\n    echo hello $1 $2\n}\nshowname Tony JustDevs"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#exit-codes",
    "href": "posts/notes/coding/3-bash.html#exit-codes",
    "title": "Bash Basics",
    "section": "8. Exit Codes",
    "text": "8. Exit Codes\n\n#!/bin/bash\nshowname(){\n    echo hello $1\n    if [ ${1,,} = tony ]; then\n        return 0\n    else\n        return 1\n    fi\n}\nshowname() $1\nif [ $? = 1 ]; then\n    echo = \"A strange has called the function!\"\nfi"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#awk",
    "href": "posts/notes/coding/3-bash.html#awk",
    "title": "Bash Basics",
    "section": "9. awk",
    "text": "9. awk\nFilter contents to and fro: 1. files or 2. output of a command\n\n9.1 Filter a Text File\n\necho one two three &gt; onetwothree.txt #[Terminal]\nawk '{print $1}' onetwothree.txt\n\n\n\n9.2 Filter a CSV File\n\nvim csv_test.csv \none,two,three #[csv_test.csv]\nawk -F, '{print $1 $2}'\n\n\n\n\n\n9.3 Piping into awk\n\necho \"Just get this world: Hello\" | awk '{print $5}'\necho \"Just get this world: Hello\" | awk -F: '{print $2}' | cut -c2"
  },
  {
    "objectID": "posts/notes/coding/3-bash.html#sed",
    "href": "posts/notes/coding/3-bash.html#sed",
    "title": "Bash Basics",
    "section": "10. sed",
    "text": "10. sed\nReplace values in text files with Regular Expressions\nExample: sed 's/word1/word2/g' sedtest.txt\nsed: replace values command\ns: means subtsitute\ng: globally, across the whole text file -i.ORIGINAL: keeps original file appends .ORIGINALto file name\n\n# [terminal]\nvim sed_test.txt\n\n# [sed_test.txt]\nThe fly flies like no fly flies. \nA fly is an insect that has wings and a fly likes to eat leftovers  \n\n# Just prints into terminal \nsed 's/fly/grasshopper/g' sedtest.txt \n\n# replace og file with command + creates new file .txt.ORIGINAL of og content\nsed -i.ORIGINAL 's/fly/grasshopper/g' sedtest.txt"
  },
  {
    "objectID": "posts/notes/coding/10-add-script-to-PATH.html",
    "href": "posts/notes/coding/10-add-script-to-PATH.html",
    "title": "Add a script to PATH",
    "section": "",
    "text": "1. Create Bash Script\nPut all the bash code below into a new bash script (e.g. do_symlinks.sh)\n\n#!/bin/bash\n\n# Check if a prefix is supplied\nif [ -z \"$1\" ]; then\n          echo \"Usage: $0 &lt;prefix&gt;\"\n            exit 1\nfi\n\n# Define the source directory and the prefix\nSOURCE_DIR=~/og_files\nPREFIX=$1\n\n# Loop through files with the specified prefix and create symlinks\nfor file in \"$SOURCE_DIR\"/\"$PREFIX\"*; do\n        if [[ $(basename \"$file\") != \"$PREFIX\"d* ]]; then\n                ln -s \"$file\" .\n                echo \"Created symlink for $(basename \"$file\")\"\n        fi\ndone\n\n\n\n2. Copy or Move /usr/local/bin and Source .bashrc\n\nsudo cp do_symlinks.sh /usr/local/bin/do_symlinks && . ~/.bashrc\n\n\n\n3. Create and change directory into test1 folder\n\nmkdir test1 && cd test1\n\n\n\n4. Run do_symlinks tony_\n\ndo_symlinks tony_\n\n\n\n5. Confirm results ll\n\nll\n\n\n\n6. Terminal Code\n\nsudo cp do_symlinks.sh /usr/local/bin/do_symlinks && . ~/.bashrc\nmkdir test1 && cd test1\ndo_symlinks tony_\nll\n\n\n\n7. Screenshots of Code"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#net-runtime-explained",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#net-runtime-explained",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "2.1 .NET Runtime Explained",
    "text": "2.1 .NET Runtime Explained\nThe .NET runtime is the: - code library - required to run your C# applications - also known as Common Language Runtime, or CLR.\n    The .NET runtime isn't required to WRITE C# code, \n    The .NET runtime is required to RUN `C#` applications."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#visual-studio-code-extensions",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#visual-studio-code-extensions",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "2.2 Visual Studio Code Extensions",
    "text": "2.2 Visual Studio Code Extensions\nVisual Studio Code provides a development environment for:\n\nwriting,\nrunning, and\ndebugging C# applications\n\nBy using Visual Studio Extenions:\n\n.NET SDK\nC# extensions"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#install-extensions",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#install-extensions",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "2.3 Install Extensions",
    "text": "2.3 Install Extensions\n\n2.3.1 [C# Dev Kit - Official C#]\nThis extensions helps to develop, edit, and debug C# code in Visual Studio Code. It also installs:\n\n[.NET Install Tool]: This extension installs & manages different versions of:\n\n.NET SDK\nRuntime.\n\n[C#]: Base language support for C#.\n[C# Dev Kit]: Official C# extension from Microsoft."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#intellicode-for-c-dev-kit",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#intellicode-for-c-dev-kit",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "2.3.2 [IntelliCode for C# Dev Kit]",
    "text": "2.3.2 [IntelliCode for C# Dev Kit]\nThis extension provides AI-assisted development for the C# Dev Kit."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#net-sdk",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#net-sdk",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "2.3.3 .NET SDK",
    "text": "2.3.3 .NET SDK\nThis is required to run and debug C# applications:\n\nCheck if already install: dotnet --version\nIf not installed:\n\ntype .NET: Install and then\nselect .NET: Install New .NET SDK.\nUnder Latest, select .NET 8, select Install."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#net-cli",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#net-cli",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "3.1 .NET CLI",
    "text": "3.1 .NET CLI\nSample .NET CLI command Code below will create new console app in specified folder.\n\ndotnet new console -o ./CsharpProjects/TestProject"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#net-cli-command-structure",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#net-cli-command-structure",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "3.2 .NET CLI Command Structure",
    "text": "3.2 .NET CLI Command Structure\nThere are 3 parts: [driver] [command] [command arguments]:\n\nThe driver:\n\ndotnet\n\nThe command:\n\nnew console\n\nThe command arguments:\n\n-o ./CsharpProjects/TestProjectByCLI\n\n\ncommand arguments are optional, so dotnet new console creates a new console app in the current working directory."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#c-console-application-template",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#c-console-application-template",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "3.3 C# Console Application Template",
    "text": "3.3 C# Console Application Template\n\nProgram.cs: Source Code ? (TBA)\n\nTestProject1.csproj: Project File\n\nobj: Build files and dependencies like .dlls (TBA)"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#build-application",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#build-application",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "4.1 Build Application",
    "text": "4.1 Build Application\n\nNavigate to TestProject (Ctrl + q: Folders)\nShift + F10\nOpen in Terminal\ndotnet build"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#run-application",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#run-application",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "4.2 Run Application",
    "text": "4.2 Run Application\nThe dotnet run command:\n\nruns source code without any explicit compile or launch commands.\nA convenient option to run application from the source code\n\nUseful for fast iterative development from CLI.\nThe command depends on the dotnet build command to build the code.\n\n\nCode: dotnet run"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#oldbad-version-1",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#oldbad-version-1",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "5.1 Old/Bad (Version 1)",
    "text": "5.1 Old/Bad (Version 1)\n\nCheck dotnet (exists): dotnet --version\nCreate console app with dotnet cli command: dotnet new console -o 2-CreateRunCSConsoleApps\nCheck app has been created… [Realised I made a mistake]\n\nShould have created a extra folder within the top folder, that is: 2-CreateRunCSConsoleApps\\SimpleApp\nI’ll leave screenshot below and also provide update."
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#betterupdated-version-2",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#betterupdated-version-2",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "5.2 Better/Updated (Version 2)",
    "text": "5.2 Better/Updated (Version 2)\nCurrent Project Structure:\n\n2-CreateRunCSConsoleApps\\Program.cs:\n\nOnly one project per solution, an undesirable structure.\nProgram.cs is directly under the Solution Name.\nPreferred to be able to have multiple projects within a single Solution (see next section).\n\n\nNew Project Structure:\n\n2-CreateRunCSConsoleApps\\TestProjectNo\\Program.cs:\n\nAllows for multiple projects within single Solution. Example:\n\n[Project 1]: 2-CreateRunCSConsoleApps\\TestProject1\\Program.cs\n[Project 2]: 2-CreateRunCSConsoleApps\\TestProject2\\Program.cs"
  },
  {
    "objectID": "posts/notes/coding/19-csharp_on_vscode.html#create-build-run-version-2-steps",
    "href": "posts/notes/coding/19-csharp_on_vscode.html#create-build-run-version-2-steps",
    "title": "Introduction to C# in Visual Studio Code",
    "section": "5.3 Create, Build Run: Version 2 Steps",
    "text": "5.3 Create, Build Run: Version 2 Steps\n\nCreate TestProject1: dotnet new console -o 2-CreateRunCSConsoleApp\\TestProject1.\nCreate TestProject2: See 2.\nCheck projects created succesfully.\nUpdate Program.cs scripts and save.\nBuild.. [Realised I didnt build it first, but still works??]: No issues (see 4.3.1 dotnet run notes).\nBuild TestProject1: Go to TestProject 1 directly then: dotnet build, then dotnet run.\nBuild TestProject2: see 6.\n\nOutput for both projects are as expected.\n\n\n5.3.1 dotnet run notes\nTurns out dotnet run also runs dotnet build. GPT output:\n\nSeparate Build and Run Steps: In scenarios like continuous integration (CI) pipelines or deployment scripts, you often want to explicitly build the project first (dotnet build) and then run or test it separately. This allows for better error handling and control over each step.\nBuild Output for Distribution: dotnet build creates the build artifacts (compiled .dll files and dependencies) without running the project. If you’re distributing your code or creating deployment packages, you’ll want the output from dotnet build, not the temporary output that dotnet run uses.\nFaster Subsequent Runs: Running dotnet build first creates a compiled version that dotnet run will use as long as there are no code changes. This can make dotnet run faster on subsequent runs.\nDebugging and Optimization: dotnet build allows for setting specific build configurations, like Release or Debug, without running the program. This is useful for testing different build configurations or optimizing the final build before deployment."
  },
  {
    "objectID": "posts/notes/coding/7-virtual_environments.html#virtual-environments",
    "href": "posts/notes/coding/7-virtual_environments.html#virtual-environments",
    "title": "Virtual Environments: 3 different ways",
    "section": "1. Virtual Environments",
    "text": "1. Virtual Environments\nA virtual environment in Python is a self-contained directory that contains a Python installation and a set of packages.\nThis post will go through 3 methods to create virtual environments: - venv - conda virtual environments - pipenv"
  },
  {
    "objectID": "posts/notes/coding/7-virtual_environments.html#purpose",
    "href": "posts/notes/coding/7-virtual_environments.html#purpose",
    "title": "Virtual Environments: 3 different ways",
    "section": "2. Purpose",
    "text": "2. Purpose\nDependency Management:\n- Different projects may require different versions of the same package.\n- Virtual environments allow you to maintain these dependencies separately.\nIsolation:\n- Packages installed in a virtual environment are isolated from those installed system-wide or in other virtual environments\n- Reducing the risk of version conflicts and compatibility issues.\nPortability:\n- A virtual environment can be easily replicated on another system by sharing the environment configuration file, such as requirements.txt."
  },
  {
    "objectID": "posts/notes/coding/7-virtual_environments.html#method-1-venv",
    "href": "posts/notes/coding/7-virtual_environments.html#method-1-venv",
    "title": "Virtual Environments: 3 different ways",
    "section": "3. Method 1: venv",
    "text": "3. Method 1: venv\n\nmkdir proj && cd $_         # create proj1 and cd into proj1\npython -m venv venv1        # run python module venv and create venv1\nls                          # note: venv1 folder is created (inside proj1)\nsource venv1/bin/activate   # activate venv1 by running bash script with source\n(venv1)                     # note: (venv1) appears in front of (base) in terminal\npip freeze                  # note: no packages installed so no output\npip install sqalchemy       # install packages required\npip freeze                  # see list of packages installed\ndeactivate                  # deactivate venv1"
  },
  {
    "objectID": "posts/notes/coding/4-wsl_new_user.html",
    "href": "posts/notes/coding/4-wsl_new_user.html",
    "title": "Create new Users in WSL",
    "section": "",
    "text": "1. Creating a new user with sudo priviledges\nsudo: allows you to run the following command with elevated privileges (like root access).\nadduser: creates a new user account in your WSL distribution.\nusermod: modifies existing user accounts.\n-aG: adds the user to a specific group.\ncut -d: -f1 /etc/passwd: list users.\nsu - username: login to username.\ngroups username: groups a user belongs to.\n\nsudo adduser tonyjustkaggles - add user\nsudo usermod -aG sudo tonyjustkaggles - add priviledges\nsudo visudo - open nano\n“tonyjustkaggles ALL=(ALL) NOPASSWD: ALL” - add more priviledges\nCtrl + O, Enter, Ctrl + X - save and exit\n\n\n\n3. VS Code (pre-installed on Windows)\nAdd PATH variable in new user so by typing code ., VS Code opens for the existing folder.\nexport PATH=\"$PATH:/mnt/c/Users/tonyp/AppData/Local/Programs/Microsoft VS Code/bin\n\n\n4. [Quick Fire] Other Useful Setup Things to do\n\n4.1 miniforge\n\nsu - tonyjustkaggles - login\nmkdir downloads + cd downloads\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\nbash Miniforge33-*.sh -b - run bash script to install\n~/miniforge3/bin/conda init bash - add paths\nwhich python - see python is from miniforge\n\n\n\n4.2 conda virtual environment\n\nconda create -n kaggle_venv - create venv for individual projects + avoid dependency issues\nconda activate kaggle_venv - create venv for individual projects + avoid dependency issues\nconda install python - install python into venv\n\n\n\n4.3 pytorch\n\nconda install pytorch torchvision torchaudio cpuonly -c pytorch - install pytorch from official site\nipython -&gt; import torch -&gt; torch + [tab] - Test pytorch works\n\n\n\n4.4 jupyter\n\nconda install -c conda-forge jupyterlab - install jlab from official site\n\n\n\n4.5 bash shortcuts\n\nvim ~/.bashrc -&gt; G,i -&gt; alias vb=\"vim ~/.bashrc\" -&gt; esc :wq - shortcut for vim bash\nvb -&gt; i -&gt; alias jl=\"jupyterlab --no-browser\" - jupyter lab short-cut\nvb -&gt; i -&gt; alias dl=\"cd ~/downloads\" -&gt; esc :wq - downloads\nvb -&gt; i -&gt; alias bl=\"cd ~/blog\" -&gt; esc :wq - blog (or :q! - don't save)\nvb -&gt; i -&gt; alias kv=\"conda activate kaggle_venv\" -&gt; esc :wq - activate venv\n\n\n\n4.6 kaggle\n\nconda install conda-forge::kaggle - install kaggle api from official site\nKaggle -&gt; Settings -&gt; Create Token -&gt; Paste into: /home/tonyjustkaggles/.kaggle\n\n\n\n4.7 ssh, github and blog\n\nssh-keygen -&gt; cat pub-key -&gt; copy into Github\ngit clone git@github.com:tonyjustdevs/blog.git with ssh option\n\n\n\n4.8 visudo\n\nsudo visudo -&gt; User privilege specification -&gt; tonyjustkaggles ALL=(ALL) NOPASSWD: ALL -&gt; ctrl O + Enter + ctrl X\nexport PATH=\"$PATH:/mnt/c/Users/tonyp/AppData/Local/Programs/Microsoft VS Code/bin\"\n\n\n\n\n5. Complete"
  },
  {
    "objectID": "posts/notes/coding/24-utf-8-encoding.html#a-cool-name-梁國富",
    "href": "posts/notes/coding/24-utf-8-encoding.html#a-cool-name-梁國富",
    "title": "Unicode, UTF-8 and Bytes",
    "section": "2.1 A Cool Name “😎梁國富⚽”",
    "text": "2.1 A Cool Name “😎梁國富⚽”\n\nmy_str = \"😎梁國富⚽\" # a cool chinese name"
  },
  {
    "objectID": "posts/notes/coding/24-utf-8-encoding.html#encode-string-to-bytes-via-utf-8",
    "href": "posts/notes/coding/24-utf-8-encoding.html#encode-string-to-bytes-via-utf-8",
    "title": "Unicode, UTF-8 and Bytes",
    "section": "2.2 Encode string to bytes via utf-8",
    "text": "2.2 Encode string to bytes via utf-8\nConverts string into a bytes object using the UTF-8 encoding scheme.\nIf string contains non-ASCII characters, UTF-8 ensures they are represented properly in bytes.\n\nmy_str_utf8_bytes = my_str.encode(\"utf-8\") # (str -&gt; utf-8 bytes)\nmy_str_utf8_bytes\n\nb'\\xf0\\x9f\\x98\\x8e\\xe6\\xa2\\x81\\xe5\\x9c\\x8b\\xe5\\xaf\\x8c\\xe2\\x9a\\xbd'\n\n\n\n2.2.1 Why bytes?\nBytes data/objects are important in programming for several key reasons:\n\nEfficient Storage: Bytes provide an efficient way to store raw binary data. They use 8 bits per byte, which allows for compact storage of information.\nLow-Level Operations: Bytes are fundamental units of data in computer systems. Working with bytes enables low-level operations like memory manipulation, file I/O, and network communication.\nBinary Data Handling: Bytes are essential for handling binary data formats like images, audio files, and executable code. These formats are represented as sequences of bytes.\nCryptographic Operations: In cryptography and security-related tasks, working with raw byte data is often necessary. This includes generating random numbers, hashing, and encryption/decryption.\nNetwork Communication: When sending data over networks, it’s typically transmitted as byte streams. This allows for efficient transmission of various types of data.\nCompression Algorithms: Some compression algorithms work directly on byte sequences rather than text strings.\nMemory Efficiency: In scenarios where memory usage is critical (like embedded systems), working with bytes allows for more efficient use of available resources.\nPerformance Optimization: Certain operations, especially those involving large datasets, can be optimized by working directly with bytes rather than converting to and from strings repeatedly.\nInteroperability: Bytes provide a common format that can be easily converted between different programming languages and systems.\nData Integrity: When dealing with binary data that may contain non-printable characters or invalid Unicode sequences, working with bytes ensures data integrity.\nFile Handling: Many file formats, especially those used in scientific computing or specialized applications, are represented as byte streams.\nProtocol Buffers: In distributed systems and microservices architectures, protocols like Protocol Buffers often serialize data into byte streams for efficient transmission."
  },
  {
    "objectID": "posts/notes/coding/24-utf-8-encoding.html#convert-bytes-to-hexadecimal",
    "href": "posts/notes/coding/24-utf-8-encoding.html#convert-bytes-to-hexadecimal",
    "title": "Unicode, UTF-8 and Bytes",
    "section": "2.3 Convert bytes to hexadecimal",
    "text": "2.3 Convert bytes to hexadecimal\nConverts to base-16 representation of the binary data.\n\nmy_str_hex = my_str_utf8_bytes.hex() # (utf-8-bytes -&gt; hex-#)\nmy_str_hex\n\n'f09f988ee6a281e59c8be5af8ce29abd'\n\n\n\nmy_str_bytes = bytes.fromhex(my_str_hex) # (hex-# -&gt; utf-8-bytes)\nmy_str_bytes\n\nb'\\xf0\\x9f\\x98\\x8e\\xe6\\xa2\\x81\\xe5\\x9c\\x8b\\xe5\\xaf\\x8c\\xe2\\x9a\\xbd'\n\n\n\nmy_str_bytes.decode(\"utf-8\") # '梁國富' (utf-8-bytes to str)\n\n'😎梁國富⚽'"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#assignment",
    "href": "posts/notes/coding/13-shallow-and-deep.html#assignment",
    "title": "Shallow or Deep?",
    "section": "1.1 Assignment:",
    "text": "1.1 Assignment:\n\nCode: =\nCreates a new variable name, not a new object.\nNew varaible name references for the same original object."
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#shallow-copy",
    "href": "posts/notes/coding/13-shallow-and-deep.html#shallow-copy",
    "title": "Shallow or Deep?",
    "section": "1.2 Shallow Copy:",
    "text": "1.2 Shallow Copy:\n\nCode: copy.copy()\nCreates a new top level object\nMaintains original references (i.e. not new copies) of same objects"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#deep-copy",
    "href": "posts/notes/coding/13-shallow-and-deep.html#deep-copy",
    "title": "Shallow or Deep?",
    "section": "1.3 Deep Copy:",
    "text": "1.3 Deep Copy:\n\nCode: copy.deepcopy()\nCreates a new object\nCreates new copies recursively of all inner objects"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#create-cat-class-and-object",
    "href": "posts/notes/coding/13-shallow-and-deep.html#create-cat-class-and-object",
    "title": "Shallow or Deep?",
    "section": "2.1 Create Cat Class and Object",
    "text": "2.1 Create Cat Class and Object\n\nclass Cat():\n    def __init__(self, name: str):\n        self.name = name\n        \n    def __repr__(self) -&gt; str:\n        return self.name\n\nMilo_obj = Cat(name=\"milo\")\nprint(f\"id: [{id(Milo_obj)}]\")\n\nid: [140517113061744]"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#create-cat-list-and-append-cat-object-milo",
    "href": "posts/notes/coding/13-shallow-and-deep.html#create-cat-list-and-append-cat-object-milo",
    "title": "Shallow or Deep?",
    "section": "2.2 Create Cat List and append Cat Object milo",
    "text": "2.2 Create Cat List and append Cat Object milo\n\nimport copy\nlistcats = ['Oreo','Lilo','Wasabi',Milo_obj]\nlistcats\n\n['Oreo', 'Lilo', 'Wasabi', milo]"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#create-copies-of-cat-list-with-each-method",
    "href": "posts/notes/coding/13-shallow-and-deep.html#create-copies-of-cat-list-with-each-method",
    "title": "Shallow or Deep?",
    "section": "2.3 Create Copies of Cat List with Each Method",
    "text": "2.3 Create Copies of Cat List with Each Method\nAssignment = results:\n\nGives a reference back to same origin object (same id:140517134247168)\n\nOthers results (.copy, .deepcopy, :):\n\ncreate a new (top-level) object (difference ids):\n\nNote: Only compared ids of outer layer list objects. We need to see the individual items within the list (next section).\n\n\n\nlistcats_copy_assn      = listcats               \nlistcats_copy_shallow   = copy.copy(listcats)    \nlistcats_copy_deep      = copy.deepcopy(listcats)\nlistcats_copy_slice     = listcats[:]            \nprint(f\"[id:{id(listcats)}] listcats_og: {listcats}\")                       \nprint(f\"[id:{id(listcats_copy_assn)}] listcats_cpy_assn: {listcats_copy_assn}\")       \nprint(f\"[id:{id(listcats_copy_shallow)}] listcats_cpy_shallow: {listcats_copy_shallow}\") \nprint(f\"[id:{id(listcats_copy_deep)}] listcats_cpy_deep: {listcats_copy_deep}\")      \nprint(f\"[id:{id(listcats_copy_slice)}] listcats_cpy_slice: {listcats_copy_slice}\")\n\n[id:140517134247168] listcats_og: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517134247168] listcats_cpy_assn: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517124516096] listcats_cpy_shallow: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517110270272] listcats_cpy_deep: ['Oreo', 'Lilo', 'Wasabi', milo]\n[id:140517124392064] listcats_cpy_slice: ['Oreo', 'Lilo', 'Wasabi', milo]"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#are-each-milo-object-new-or-copies-of-original",
    "href": "posts/notes/coding/13-shallow-and-deep.html#are-each-milo-object-new-or-copies-of-original",
    "title": "Shallow or Deep?",
    "section": "2.4 Are each milo object new or copies of original?",
    "text": "2.4 Are each milo object new or copies of original?\nShallow copies keeps the same references:\n\nAll copy methods (except deepcopy()) have the same milo object as original id: [140517113061744]\n\nDeep copies creates new objects: creates new id’s\n\nprint(f\"[{id(listcats[3])}]-[milo id] of [listcats_og]: {listcats[3]}\")                       \nprint(f\"[{id(listcats_copy_assn[3])}]-[milo id] of [listcats_cpy_assn]: {listcats_copy_assn[3]}\")       \nprint(f\"[{id(listcats_copy_shallow[3])}]-[milo id] of [listcats_cpy_shallow]: {listcats_copy_shallow[3]}\") \nprint(f\"[{id(listcats_copy_deep[3])}]-[milo id] of [listcats_cpy_deep]: {listcats_copy_deep[3]}\")      \nprint(f\"[{id(listcats_copy_slice[3])}]-[milo id] of [listcats_cpy_slice]: {listcats_copy_slice[3]}\")    \n\n[140517113061744]-[milo id] of [listcats_og]: milo\n[140517113061744]-[milo id] of [listcats_cpy_assn]: milo\n[140517113061744]-[milo id] of [listcats_cpy_shallow]: milo\n[140517115254800]-[milo id] of [listcats_cpy_deep]: milo\n[140517113061744]-[milo id] of [listcats_cpy_slice]: milo"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#update-milo-to-milo",
    "href": "posts/notes/coding/13-shallow-and-deep.html#update-milo-to-milo",
    "title": "Shallow or Deep?",
    "section": "2.5 Update milo to Milo",
    "text": "2.5 Update milo to Milo\n\nMilo_obj.name=\"Milo\"\nMilo_obj\n\nMilo"
  },
  {
    "objectID": "posts/notes/coding/13-shallow-and-deep.html#results-of-milo-the-different-methods",
    "href": "posts/notes/coding/13-shallow-and-deep.html#results-of-milo-the-different-methods",
    "title": "Shallow or Deep?",
    "section": "2.6 Results of milo the Different Methods",
    "text": "2.6 Results of milo the Different Methods\nAs expected:\n\nThe deepcopy list milo has not updated (since its a new object, i.e. new object id: 140517115254800)\nAll other methods do update original milo since references are maintained, rather than creating new objects (i.e. same object id: 140517113061744)\n\n\nprint(f\"[{id(listcats[3])}]-[milo id] of [listcats_og]: {listcats[3]}\")                       \nprint(f\"[{id(listcats_copy_assn[3])}]-[milo id] of [listcats_cpy_assn]: {listcats_copy_assn[3]}\")       \nprint(f\"[{id(listcats_copy_shallow[3])}]-[milo id] of [listcats_cpy_shallow]: {listcats_copy_shallow[3]}\") \nprint(f\"[{id(listcats_copy_deep[3])}]-[milo id] of [listcats_cpy_deep]: {listcats_copy_deep[3]}\")      \nprint(f\"[{id(listcats_copy_slice[3])}]-[milo id] of [listcats_cpy_slice]: {listcats_copy_slice[3]}\")    \n\n[140517113061744]-[milo id] of [listcats_og]: Milo\n[140517113061744]-[milo id] of [listcats_cpy_assn]: Milo\n[140517113061744]-[milo id] of [listcats_cpy_shallow]: Milo\n[140517115254800]-[milo id] of [listcats_cpy_deep]: milo\n[140517113061744]-[milo id] of [listcats_cpy_slice]: Milo"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#check-existing-symlinks-in-linuxubuntu-optional",
    "href": "posts/notes/coding/9-symlinks.html#check-existing-symlinks-in-linuxubuntu-optional",
    "title": "Creating and using Symlinks",
    "section": "2.1 Check existing Symlinks in Linux/Ubuntu (Optional):",
    "text": "2.1 Check existing Symlinks in Linux/Ubuntu (Optional):\n\nA symlink is represented with -&gt;:\n\n\nls -l /path/to/symlink"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#check-existing-symlinks-in-visual-studio-code-optional",
    "href": "posts/notes/coding/9-symlinks.html#check-existing-symlinks-in-visual-studio-code-optional",
    "title": "Creating and using Symlinks",
    "section": "2.2 Check existing Symlinks in Visual Studio Code (Optional):",
    "text": "2.2 Check existing Symlinks in Visual Studio Code (Optional):\n\nThe same symlink is represented by down-then-right-arrow (reverse L):"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#delete-existing-symlinks-optional",
    "href": "posts/notes/coding/9-symlinks.html#delete-existing-symlinks-optional",
    "title": "Creating and using Symlinks",
    "section": "2.3 Delete existing Symlinks (Optional):",
    "text": "2.3 Delete existing Symlinks (Optional):\n\nrm /path/to/symlink"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#create-a-new-symlink",
    "href": "posts/notes/coding/9-symlinks.html#create-a-new-symlink",
    "title": "Creating and using Symlinks",
    "section": "2.4 Create a new Symlink",
    "text": "2.4 Create a new Symlink\n\nln -s /path/to/original/file.md /chosen/path/for/symlink/file.md"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#check-existing-symlink",
    "href": "posts/notes/coding/9-symlinks.html#check-existing-symlink",
    "title": "Creating and using Symlinks",
    "section": "2.5 Check existing Symlink",
    "text": "2.5 Check existing Symlink\nSee the symlink has been established again.\n\nls -l"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#how-to",
    "href": "posts/notes/coding/9-symlinks.html#how-to",
    "title": "Creating and using Symlinks",
    "section": "3.1 How-To",
    "text": "3.1 How-To\n\nCheck files in working directory (wd): ll (If symlink existing, it wont be overriden, delete it if required)\nCheck files in original directory (ogdir): ll ~/og_files\n\nMove files required for symlinks: mv tony_* ~/og_files\nCheck files no longer in wd: ll\nCheck files are in ogdir: ll ~/og_files\nFor Loop: create symlinks for files prefixed with tony_ to wd: for file in ~/og_files/tony_*; do ln -s $file .; done\nCheck files in wd: ll\nLooks all good!"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#the-code",
    "href": "posts/notes/coding/9-symlinks.html#the-code",
    "title": "Creating and using Symlinks",
    "section": "3.2 The Code",
    "text": "3.2 The Code\n\nll\nll ~/og_files\nmv tony_* ~/og_files\nll\nll ~/og_files\nfor file in ~/og_files/tony_*; do ln -s $file .; done\nll"
  },
  {
    "objectID": "posts/notes/coding/9-symlinks.html#screenshot-of-how-to-and-code",
    "href": "posts/notes/coding/9-symlinks.html#screenshot-of-how-to-and-code",
    "title": "Creating and using Symlinks",
    "section": "3.3 Screenshot of How-To and Code",
    "text": "3.3 Screenshot of How-To and Code"
  },
  {
    "objectID": "posts/notes/calculus/2-calc_limits_plots_ex2_2_11_21.html",
    "href": "posts/notes/calculus/2-calc_limits_plots_ex2_2_11_21.html",
    "title": "Plotting functions with limits",
    "section": "",
    "text": "Jupyter Notebooks Available\n\nEx 2.2 notebooks github download link\n\n\n\nEx2.2.5: \\(\\lim_{x\\to0}\\frac{x}{|x|}\\)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nxs = np.linspace(-0.1,0.1,20)\nxs = xs[xs != 0] # remove x=0\ndef f(x): return (x)/(np.abs(x))\nys = f(xs)\nplt.scatter(xs,ys)\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n\nEx2.2.11: \\(lim_{x\\to-3}(x^2-13)\\)\n\nxs = np.linspace(-3.1, -2.9, 50)\ndef fx(x): return (x**2-13)\nys = fx(xs)\ny_x_at_c = fx(-3)# at x=-3\ny_x_at_c\nplt.scatter(xs,ys)\nplt.grid(True)\nplt.vlines(x=-3, ymax=100, ymin=-100, linestyles=\"dotted\")\n\n\n\n\n\n\n\n\n\n\nEx2.2.13: \\(\\lim_{x\\to6}8(x-5)(x-7)\\)\n\nx_at_c, abt_x = 6,0.1\nx_abt_c = (x_at_c - 0.1, x_at_c + 0.1)\nxs = np.linspace(x_abt_c[0],x_abt_c[1], 20) # same as np.linspace(5.9, 6.1)\ndef fx(x): return 8*(x-5)*(x-7)\nys=fx(xs)\nplt.scatter(xs,ys)\nplt.grid(True)\ny_x_at_c = fx(x=x_at_c)\nplt.vlines(x=x_at_c, ymax=10,ymin=-10, linestyles='dotted')\n\n\n\n\n\n\n\n\n\n\nEx2.2.15: \\(\\lim_{x\\to2}\\frac{2x+5}{11-x^3}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = 2\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return (2*x+5)/(11-x**3)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))\n\n\n\n\n\n\n\n\n\n\nEx2.2.19: \\(\\lim_{x\\to-3}(5-x)^{\\frac{4}{3}}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = -3\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return (5-x)**(4/3)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))\n\n\n\n\n\n\n\n\n\n\nEx2.2.21: \\(\\lim_{x\\to0}\\frac{3}{\\sqrt{3x+1}+1}\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx_at_c = 0\nabt_c = 0.1\nxs_min = x_at_c - abt_c\nxs_max = x_at_c + abt_c\nxs = np.linspace(xs_min,xs_max,20)\ndef fx(x): return 3/(np.sqrt(3*x+1)+1)\nys = fx(xs)\nplt.scatter(xs, ys, marker=\"+\")\nplt.grid(True)\nplt.vlines(x=x_at_c,linestyles=\"dotted\", ymax=fx(xs_max),ymin=fx(xs_min))"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#synthetic-divison-x3-x2-5x-3-by-x1",
    "href": "posts/notes/calculus/3-synthetic_division.html#synthetic-divison-x3-x2-5x-3-by-x1",
    "title": "Calculus: Synthetic Division",
    "section": "4.1 Synthetic divison \\((x^3-x^2-5x-3)\\) by \\((x+1)\\)",
    "text": "4.1 Synthetic divison \\((x^3-x^2-5x-3)\\) by \\((x+1)\\)\n\n\n\n-1\n+1\n-1\n-5\n-3\n\n\n\n\n\\(+\\)\n+0\n-1\n+2\n+3\n\n\n\\(/\\)\n+1\n-2\n-3\n+\\(0\\)\n\n\n\nRemainder is \\(0\\) (bottom right cell).\nTherefore \\((x+1)\\) is a factor of \\((x^3-x^2-5x-3)\\)\nThe final line represents the \\(coefficients\\) of the other factor, that is:\n\\[x^2-2x-3\\]\nTherefore \\[(x^3-x^2-5x-3)\\]\n\\[=(x+1)(x^2-2x-3)\\]"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#back-to-the-question",
    "href": "posts/notes/calculus/3-synthetic_division.html#back-to-the-question",
    "title": "Calculus: Synthetic Division",
    "section": "4.2 Back to the question",
    "text": "4.2 Back to the question\n\\[\\frac{x^3-x^2-5x-3}{(x+1)^2}\\] \\[\\frac{(x+1)(x^2-2x-3)}{(x+1)(x+1)}\\] \\[\\frac{(x^2-2x-3)}{(x+1)}\\] \\[\\frac{(x-3)(x+1)}{(x+1)}\\] \\[{(x-3)}\\]\n\\[\\lim_{x\\to-1}\\frac{x^3-x^2-5x-3}{(x+1)^2}\\] \\[\\lim_{x\\to-1}(x-3)\\] \\[(-1-3)\\] \\[-4\\]"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#import-libraries",
    "href": "posts/notes/calculus/3-synthetic_division.html#import-libraries",
    "title": "Calculus: Synthetic Division",
    "section": "5.1 Import libraries",
    "text": "5.1 Import libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#create-xs-xs",
    "href": "posts/notes/calculus/3-synthetic_division.html#create-xs-xs",
    "title": "Calculus: Synthetic Division",
    "section": "5.2 Create x’s: xs",
    "text": "5.2 Create x’s: xs\n\nxs = np.linspace(-1.1,-0.9,21)\nxs\n\narray([-1.1 , -1.09, -1.08, -1.07, -1.06, -1.05, -1.04, -1.03, -1.02,\n       -1.01, -1.  , -0.99, -0.98, -0.97, -0.96, -0.95, -0.94, -0.93,\n       -0.92, -0.91, -0.9 ])"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#create-function-fx",
    "href": "posts/notes/calculus/3-synthetic_division.html#create-function-fx",
    "title": "Calculus: Synthetic Division",
    "section": "5.3 Create function: fx",
    "text": "5.3 Create function: fx"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#lambda-method",
    "href": "posts/notes/calculus/3-synthetic_division.html#lambda-method",
    "title": "Calculus: Synthetic Division",
    "section": "5.3.1 lambda method",
    "text": "5.3.1 lambda method\n\nfx = lambda x: (x**3-x**2-5*x-3)/((x+1)**2)"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#def-method",
    "href": "posts/notes/calculus/3-synthetic_division.html#def-method",
    "title": "Calculus: Synthetic Division",
    "section": "5.3.2 def method",
    "text": "5.3.2 def method\n\ndef fx2(x): return (x**3-x**2-5*x-3)/((x+1)**2)\n\n\n5.3.3 Check definitions [optional]\n\nimport inspect\ninspect.getsource(fx)\ninspect.getsource(fx2)\n\n'def fx2(x): return (x**3-x**2-5*x-3)/((x+1)**2)\\n'"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#calculate-ys-ys",
    "href": "posts/notes/calculus/3-synthetic_division.html#calculate-ys-ys",
    "title": "Calculus: Synthetic Division",
    "section": "5.4 Calculate y’s: ys",
    "text": "5.4 Calculate y’s: ys\n\nys = fx(xs)\nys\n\n/tmp/ipykernel_62451/871469998.py:1: RuntimeWarning: invalid value encountered in divide\n  fx = lambda x: (x**3-x**2-5*x-3)/((x+1)**2)\n\n\narray([-4.1 , -4.09, -4.08, -4.07, -4.06, -4.05, -4.04, -4.03, -4.02,\n       -4.01,   nan, -3.99, -3.98, -3.97, -3.96, -3.95, -3.94, -3.93,\n       -3.92, -3.91, -3.9 ])"
  },
  {
    "objectID": "posts/notes/calculus/3-synthetic_division.html#plot",
    "href": "posts/notes/calculus/3-synthetic_division.html#plot",
    "title": "Calculus: Synthetic Division",
    "section": "5.5 Plot",
    "text": "5.5 Plot\n\n# plt.scatter(xs,ys,label=\"Data Points\", color='red')\n# plt.scatter(xs,ys)\nplt.vlines(x=-1,ymin=ys[0],ymax=ys[-1],linestyles=\"dotted\", label=\"$x=-1$\", colors=\"red\")\n\n# plt.plot(xs, ys, label=r\"$\\lim_{x\\to-1}\\frac{x^3-x^2-5x-3}{(x+1)^2}$\")\nplt.plot(xs, ys, label=r'$\\lim_{x\\to-1}\\frac{x^3 - x^2 - 5x - 3}{(x+1)^2}=x-3$',)\nplt.legend()\n\n\n\n\n\n\n\n\nThe plot shows limit is \\(-4\\)"
  },
  {
    "objectID": "posts/notes/calculus/4-binomial-theorem.html",
    "href": "posts/notes/calculus/4-binomial-theorem.html",
    "title": "Calculus: Applying Binomial Theorem",
    "section": "",
    "text": "1. Calculate \\(f'(x) = x^3\\)\n\n\nThat is, calculate it’s Derivative.\n\n\nPlot Tangent at \\((-2,-8)\\) .\n\n\n\n\n2. Working Out (by Hand)\n\n\n\n3. Plot with Python\n\nfrom matplotlib.ticker import MaxNLocator\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n\nxs = np.linspace(-12, 12, 97)\n\nfx_numerator = lambda x: (x**3)\nys_numerator = fx_numerator(xs)\n\nfx_denom = lambda x: 12*x+16\nys_denom = fx_denom(xs)\n\n# Plot the lines\n# $\\lim_{x\\to0} \\frac{2x^2}{3-3\\cos{x}}$ \n\nplt.plot(xs, ys_numerator, 'r^-', linewidth=2, markersize=8, label=r'$f(x)=x^3$')\nplt.plot(xs, ys_denom, 'bo-', linewidth=2, markersize=8, label=r'$f(x)=12*x+16$')\n\n# Zoom to region\nplt.xlim(-5, 1)  # X-axis range\nplt.ylim(-30, 20)  # Y-axis range\n# plt.xlim(-0.1, 0.1)  # X-axis range\n# plt.ylim(-0.1, 0.1)  # Y-axis range\n\n# Add grid, title, and legend\nplt.grid(color='lightgrey', linestyle='--', linewidth=0.5)\nplt.title(r\"$f(x)=x^3$ and $f(x)=12*x+16$ at (-2,-8)\", loc='left')\n# plt.title(r\"$12*x+16$\", loc='left')\nplt.legend(loc='upper right')\n\n# Optionally, add vertical and horizontal lines to highlight the zoomed area\nax = plt.gca()  # Get the current axis\nax.axvline(x=-2, color='grey', linestyle='--', linewidth=0.5)\nax.axhline(y=-8, color='grey', linestyle='--', linewidth=0.5)"
  },
  {
    "objectID": "kaggle.html",
    "href": "kaggle.html",
    "title": "kaggle",
    "section": "",
    "text": "A Basic NLP model - [Competition Version]\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 17, 2024\n\n\nTony Phung\n\n\n\n\n\n\n\n\n\n\n\n\nA Basic NLP model\n\n\n\n\n\n\nNLP\n\n\nkaggle\n\n\n\nTraining my first NLP Model\n\n\n\n\n\nFeb 16, 2024\n\n\nTony Phung\n\n\n\n\n\n\nNo matching items"
  }
]