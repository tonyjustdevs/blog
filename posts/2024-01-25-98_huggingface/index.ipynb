{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"How to Build and Deploy a Deep-Learning Multi-Classifier Web App (Part 3)\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-01-25\"\n",
    "categories: [huggingface]\n",
    "image: \"dog_cat.jpg\"\n",
    "toc: true\n",
    "description: \"Host a neural network app live on **HuggingFace**\"\n",
    "---\n",
    "\n",
    "![](dog_cat.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post shows how to host your working Local Gradio App on **HuggingFace**.\n",
    "\n",
    "This post is part of a series:  \n",
    "Part 1: Create **Learner** (.pkl file)  \n",
    "Part 2: Create **Gradio** application file (app.py)    \n",
    "Part 3: Host on **HuggingFace** account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Host on **HuggingFace** account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create HuggingFace Account and Create a 'Space'\n",
    "\n",
    "1. Choose your **Space** name\n",
    "2. Choose **Apache-2.0** to avoid any copyright issues\n",
    "3. Choose **Gradio**\n",
    "4. Choose the **Free** option\n",
    "4. Choose **Public** (show you can show it to the world!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hf_space.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Clone the repo\n",
    "\n",
    "This will create allow us deploy the Gradio app to the HuggingFace repository:\n",
    "\n",
    "```git clone https://huggingface.co/spaces/tonyjustdevs/pets_breed_predictor```\n",
    "\n",
    "\n",
    "![](hf_git.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gather your files  \n",
    "\n",
    "Recall the various files we needed to [run the app locally part 2](https://tonyjustdevs.github.io/blog/posts/2024-01-25-99_gradio_app/).     \n",
    "\n",
    "Gather into the cloned huggingface folder:    \n",
    "- Learner (.pkl)  \n",
    "- Pet examples (pets.jpg)  \n",
    "- Gradio app (app.py)  \n",
    "\n",
    "![](hf_folder.jpg)\n",
    "\n",
    "A good way to check for me is seeing the  **pets_breed_predictor**  is the git folder and huggingface space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Push to HuggingFace Repo\n",
    "\n",
    "If you've pushed succesfully your app (could take several minutes), then your app is live! Congrats!\n",
    "\n",
    "If you're like me and forgot to include the `requirements.txt` then you'll be greeted with this error.\n",
    "\n",
    "![](hf_requirements.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add the requirements.txt\n",
    "\n",
    "We imported two libraries `fastai` and `gradio` so include them in the `requirements.txt` file. Commit and push.\n",
    "\n",
    "![](hf_rq_fix.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Web App Complete and is Live\n",
    "\n",
    "If all goes well, the HuggingFace space is hosting the Gradio App!\n",
    "\n",
    "Check out [my web app here](https://huggingface.co/spaces/tonyjustdevs/pets_breed_predictor)!\n",
    "\n",
    "![](hf_live.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
