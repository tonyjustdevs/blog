{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A Basic NLP model\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-02-16\"\n",
    "categories: [NLP]\n",
    "image: \"nlp.jpg\"\n",
    "toc: true\n",
    "description: \"Training my first NLP Model\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import a Pretrained Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_pretrained_model = \"microsoft/deberta-v3-small\"\n",
    "isOnline = True\n",
    "\n",
    "if isOnline:\n",
    "    from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "    debv3_tokenizer = AutoTokenizer.from_pretrained(chosen_pretrained_model)\n",
    "else:\n",
    "    print(\"Upload files! THIS PART SHOULDNT RUN YET\")\n",
    "    tokenizer_uploaded  = AutoTokenizer.from_pretrained(uploaded_path)\n",
    "    print(type(tokenizer_uploaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](import_tok.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Look Inside the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(debv3_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](inside_tok.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test out Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = (\"Hey all! What's going on? It's Tony from Sydney!\")\n",
    "debv3_tokenizer.tokenize(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](test_tok.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Kaggle Competition Data\n",
    "\n",
    "To add relevant competition data to your kaggle \"Input\" folder. \n",
    "\n",
    "This \"Input\" folder is persistent when you submit to the competition. All other folders created during prior to submitting are disregarded.\n",
    "\n",
    "### 3.1 Via GUI:\n",
    "1. On Kaggle, Go to **[Add Data]**  \n",
    "2. Filter for \"**Competition Datasets**\"  \n",
    "3. Search \"**US Patents**\"\n",
    "4. Click **[Add Competition]**\n",
    "\n",
    "![](add_uspatent_data.jpg)\n",
    "![](input_uspatent_data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Via Programatically:\n",
    "1. Have kaggle login + keys ready locally, explained in this [post](https://tonyjustdevs.github.io/blog/posts/2024-01-27-99_kaggle_api/)\n",
    "2. Run code below:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
