{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Saving a Fast AI Model\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-01-19\"\n",
    "categories: [tutorial]\n",
    "image: \"floppy.jpg\"\n",
    "---\n",
    "\n",
    "![](floppy.jpg)\n",
    "\n",
    "This is a short tutorial to save (export) down a fast ai model (pkl file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Fast AI Libaries and Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastai\n",
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('C:/Users/tonyp/.fastai/data/oxford-iiit-pet/images')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran it in **GoogleColab** or **Kaggle** (recommended, its faster) then it'll be stored in the cloud. \n",
    "![](kaggle.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran it locally, its stored on your machine and you can take a look at the all the cute images! (Not recommended, its slow)\n",
    "\n",
    "![](pets.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Labelling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat(x): return x[0].isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our data must be consistently **labelled** and parsed through into the model.  \n",
    "\n",
    "For this particular dataset, **filenames** starting with a **Capital** letter denotes a **Cat**, vice versa for a Non-Cat (Dog, in this case).  \n",
    "\n",
    "![Pet Filenames](petfilenames.jpg)  \n",
    "\n",
    "Lets write a function to handle the files names to get our labels (psuedo-code):  \n",
    "1. Parse in file name and  \n",
    "2. Obtain the first character and   \n",
    "3. Check whether it is an upper case,  \n",
    "4. If True, then it is a Cat.    \n",
    "\n",
    "There are various ways for us to supply the labelling to our model, in a previous blog [Rice vs Noodles](https://tonyjustdevs.github.io/blog/posts/2024-01-18-99_rice_vs_noodles/), the label was supplied via the parent folders name (rice folder and noodle folder).  \n",
    "\n",
    "![Rice vs Noodles](ricenoodlefolder.jpg)    \n",
    "Fast AI provides various helpful functions for common ways data is labelled to parse into our models  \n",
    "\n",
    "[Fast AI Docs - Transforms - Label](https://docs.fast.ai/data.transforms.html#label)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataLoader\n",
    "\n",
    "Create the Dataloader and supply the labelling function we wrote into **label_func**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tonyp\\miniconda3\\envs\\fastai\\Lib\\site-packages\\fastai\\torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  return getattr(torch, 'has_mps', False)\n"
     ]
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_name_func('.',\n",
    "    get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat,\n",
    "    item_tfms=Resize(192))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tune (Non-GPU vs GPU)\n",
    "\n",
    "I attempted to fine-tune via **Kaggle** (GPU) and **Locally** (No GPU) and not suprisingly it is incredibly faster with a GPU setup.\n",
    "\n",
    "Nvidia (and maybe other) GPUs are designed to be able to take multiple images at once (**batches**) grouped together (**tensors**) (I think 64 images at once), whereas a laptop without a GPU like mine will be processing 1 image at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GPU took **35 seconds** an epoch\n",
    "![](kagglefinetune.jpg)  \n",
    "Non-GPU took **8 minutes** an epoch\n",
    "![](localfinetune.jpg)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('catdogmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Kaggle, the model will be saved on their cloud and you can access it by using right-hand sidebar under **Notebook -> Data -> Output**\n",
    "\n",
    "![](kagglemodel.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's only 46 Mb!, not too shabby!\n",
    "\n",
    "![](dogcatsize.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it! We'll go through how to use a saved/exported model in an upcoming post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
