{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Deep Learning basics\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-01-24\"\n",
    "categories: [basics]\n",
    "image: \"abc.jpg\"\n",
    "---\n",
    "\n",
    "![](abc.jpg)\n",
    "\n",
    "Deep Learning basics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Deep Learning basics\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-01-24\"\n",
    "categories: [basics]\n",
    "image: \"abc.jpg\"\n",
    "---\n",
    "\n",
    "![](abc.jpg)\n",
    "\n",
    "Deep Learning basics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file:///D:/ytvideos/2022_PracDeepLearningCoders/Lesson%203%20Practical%20Deep%20Learning%20for%20Coders%202022_1080p.mp4\n",
    "\n",
    "1. load learner pkl\n",
    "2. call predict (cate and prbailtiy)\n",
    "3. see cateogeries in vcoab \n",
    "4. build dictionary \n",
    "5. build web interface\n",
    "\n",
    "\n",
    "model pkl\n",
    "1.      .model - layers - dl - like a tree\n",
    "2.      timm body, sequenctial\n",
    "3.      get_submodule - go through layers\n",
    "3b.     has code and parameters\n",
    "4a.     [kaggle] - how does NN work / its fits function to data\n",
    "4b.     quadratric example\n",
    "4c.     plot in\n",
    "5a.     general formula for quadratric\n",
    "5b.     test it with param values\n",
    "5c.     use partial to test diff quads\n",
    "5d.     plot_fn\n",
    "6a.     test data  (data that matches function)\n",
    "6b.     add noise to data \n",
    "6c.     plot scatter of this 'random' data\n",
    "7.      [manually move mouse] adjust curve\n",
    "7a.     [@interact]  + plot_quad (plot scat+plotfn)\n",
    "8.      how do we when we move it, its better or worse?\n",
    "8a.     measurement? loss function\n",
    "8b.     mse  \n",
    "8c.     do same as 7 \n",
    "8d.     move mouse with refernece (more rigor) MSE: value at top\n",
    "9a.     automate it: for each param (abc) when we move up is loss better or worse\n",
    "9b.     method1: [manual 7,8] metho2:[calc derivative]\n",
    "        derivative if you increase input, does output inc/dec and how much\n",
    "9c.     create fn (input coeffecients) mk_quad(*params) return mse(ie loss)      \n",
    "9d.     tensor: [list/vec 1d], [rectngle 2d], [layers of tbls/nbrs 3d]\n",
    "9e.     calc_gradnt requires_grad_(): rank1 tensor - 1d tenor(pytorch)\n",
    "9f.     [loss.backward()] on the loss fn -> adds .grad attribute\n",
    "9g.     results gradients of each params (ie gradients of the [LOSS_FN])\n",
    "        ie if neg've: increasing the param decreases the [LOSS_FN], which we want\n",
    "10.     decrease [abc by a bit] abc-=abc.grad*0.01\n",
    "11.     MSE for our quad, \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Turn into Gradio Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.    load learner pkl\n",
    "# 1a.   download learner from google colab.\n",
    "\n",
    "# 2.    call predict (cate and prbailtiy)\n",
    "# 3.    see cateogeries in vcoab \n",
    "# 4.    build dictionary \n",
    "# 5.    build web interface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model pkl\n",
    "# 1.      .model - layers - dl - like a tree\n",
    "# 2.      timm body, sequenctial\n",
    "# 3.      get_submodule - go through layers\n",
    "# 3b.     has code and parameters\n",
    "# 4a.     [kaggle] - how does NN work / its fits function to data\n",
    "# 4b.     quadratric example\n",
    "# 4c.     plot in\n",
    "# 5a.     general formula for quadratric\n",
    "# 5b.     test it with param values\n",
    "# 5c.     use partial to test diff quads\n",
    "# 5d.     plot_fn\n",
    "# 6a.     test data  (data that matches function)\n",
    "# 6b.     add noise to data \n",
    "# 6c.     plot scatter of this 'random' data\n",
    "# 7.      [manually move mouse] adjust curve\n",
    "# 7a.     [@interact]  + plot_quad (plot scat+plotfn)\n",
    "# 8.      how do we when we move it, its better or worse?\n",
    "# 8a.     measurement? loss function\n",
    "# 8b.     mse  \n",
    "# 8c.     do same as 7 \n",
    "# 8d.     move mouse with refernece (more rigor) MSE: value at top\n",
    "# 9a.     automate it: for each param (abc) when we move up is loss better or worse\n",
    "# 9b.     method1: [manual 7,8] metho2:[calc derivative]\n",
    "#         derivative if you increase input, does output inc/dec and how much\n",
    "# 9c.     create fn (input coeffecients) mk_quad(*params) return mse(ie loss)      \n",
    "# 9d.     tensor: [list/vec 1d], [rectngle 2d], [layers of tbls/nbrs 3d]\n",
    "# 9e.     calc_gradnt requires_grad_(): rank1 tensor - 1d tenor(pytorch)\n",
    "# 9f.     [loss.backward()] on the loss fn -> adds .grad attribute\n",
    "# 9g.     results gradients of each params (ie gradients of the [LOSS_FN])\n",
    "#         ie if neg've: increasing the param decreases the [LOSS_FN], which we want\n",
    "# 10.     decrease [abc by a bit] abc-=abc.grad*0.01\n",
    "# 11.     MSE for our quad, \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
