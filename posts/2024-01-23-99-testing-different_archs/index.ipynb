{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"How to choose a different Deep-Learning Model Architecture\"\n",
    "author: \"Tony Phung\"\n",
    "date: \"2024-01-23\"\n",
    "categories: [tutorial]\n",
    "image: \"timms.jpg\"\n",
    "toc: true\n",
    "---\n",
    "\n",
    "![](timms.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I'll go through how to find and test different deep-learning architectures from **Pytorch Image Models** (timm) library [made available here](https://timm.fast.ai/) by Ross Wightman and use them in our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using timm - PyTorch Image Models\n",
    "### 1.1 Introduction\n",
    "What are timm's models? They're mathematical functions (i.e. application of matrix  multiplication, non-linearities e.g. ReLu's)  \n",
    "\n",
    "Reference: [\"Which image model are best\"](https://www.kaggle.com/code/jhoward/which-image-models-are-best) - Jeremy Howard  \n",
    "Reference: [\"timm\"](https://timm.fast.ai/) - Ross Wightman\n",
    "\n",
    "We want to know 3 things:  \n",
    "1. how **fast** are they? You'd want models in top left of chart.  \n",
    "2. how much **memory**?  \n",
    "3. how **accurate** are they? Lower error rate the better.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Future iteration I]**: A formalised metholodgy to decide what is fast enough, appropriate memory-use, and what is accurate enough for our use-cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a useful high-level chart from Jeremy's notebook charting **accuracy** (Y-axis) vs **secs per sample** (X-axis):  \n",
    "\n",
    "![](convnext.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use a model from the **convnext** family due to its balance of **high accuracy** and **speed**.\n",
    "\n",
    "**[Future iteration II]**: Some more formalised methodology on choosing the architecture. Jeremy does mention architecture should be the one **last thing** things to worry about and he usually builds from resnet and tests whether it is, accurate enough and fast enough, then iterate from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import timm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 List available model architectures and choose one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('convnext*') # * wild card searches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create your Learner with a timm model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Get your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prepare your Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat(x): return x[0].isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load your DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func('.',\n",
    "    get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat,\n",
    "    item_tfms=Resize(192))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Build your Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_conv = vision_learner(dls, 'convnext_tiny', metrics=error_rate).to_fp16()\n",
    "learn_resn = vision_learner(dls, 'resnet18', metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Fine-Tune: ResNet18 vs ConvNextTiny\n",
    "\n",
    "A **90% reduction** in the error rate! (0.6766% to 0.0667%: 1-(0.000677/0.006766)). It's noted that the resnet error rate was quite low and changing the model was probably not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resn_conv.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
